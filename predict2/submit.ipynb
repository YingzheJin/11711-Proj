{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from ast import literal_eval as load\n",
    "\n",
    "def output_submission(entity_data: pd.DataFrame or str, triple_data: pd.DataFrame or str, out_dir: str):\n",
    "    \"\"\"\n",
    "    Format the output from prediction into the final output form.\n",
    "    :param entity_data: The dataframe prediction of entities or path to csv file\n",
    "    :param triple_data: The dataframe prediction of triples or path to csv file\n",
    "    :param out_dir: Output directory\n",
    "    \"\"\"\n",
    "    if type(entity_data) is str:\n",
    "        entity_data: pd.DataFrame = pd.read_csv(entity_data)\n",
    "    if type(triple_data) is str:\n",
    "        triple_data: pd.DataFrame = pd.read_csv(triple_data)\n",
    "    triple_list = ['triple_A', 'triple_B', 'triple_C', 'triple_D']\n",
    "    triple_frame = triple_data[['paper_idx', 'topic', 'labels', 'subj/obj'] + triple_list]\n",
    "    entity_frame = entity_data[['text', 'topic', 'paper_idx', 'idx', 'BIO_1']]\n",
    "    topics = list(entity_frame['topic'].drop_duplicates())\n",
    "    for topic in topics:\n",
    "        topic_entity = entity_frame[entity_frame['topic'] == topic]\n",
    "        topic_triple = triple_frame[triple_frame['topic'] == topic]\n",
    "        paper_indices = topic_entity['paper_idx'].drop_duplicates()\n",
    "        for paper_index in paper_indices:\n",
    "            entity_df = topic_entity[topic_entity['paper_idx'] == paper_index]\n",
    "            triple_df = topic_triple[topic_triple['paper_idx'] == paper_index]\n",
    "            dir_path = os.path.join(out_dir, topic, str(paper_index))\n",
    "            Path(os.path.join(dir_path, 'triples')).mkdir(parents=True, exist_ok=True)\n",
    "            entities = ''\n",
    "            sentences = set()\n",
    "            for _, row in triple_df.iterrows():\n",
    "                triples_text = ''\n",
    "                try:\n",
    "                    info_unit = row['labels']\n",
    "                except AttributeError:\n",
    "                    continue\n",
    "                if info_unit not in ['code', 'research-problem']:\n",
    "                    for triple in triple_list:\n",
    "                        for t in load(row[triple]):\n",
    "                            triples_text += f\"({'||'.join(t)})\\n\"\n",
    "                elif info_unit=='code':\n",
    "                    for p in load(row['subj/obj']):\n",
    "                        triples_text += f\"(Contribution||Code||{p[0]})\\n\"\n",
    "                elif info_unit=='research-problem':\n",
    "                    for p in load(row['subj/obj']):\n",
    "                        triples_text += f\"(Contribution||has research problem||{p[0]})\\n\"\n",
    "                with open(os.path.join(dir_path, 'triples', f'{info_unit}.txt'), 'a+') as f_triple:\n",
    "                    f_triple.write(triples_text)\n",
    "            # Add specific tuple\n",
    "            for tuple_file in os.listdir(os.path.join(dir_path, 'triples')):\n",
    "                info_unit = str(tuple_file).split('.')[0].replace('-', ' ')\n",
    "                if info_unit not in ['code', 'research problem']:\n",
    "                    with open(os.path.join(dir_path, 'triples', tuple_file), 'a') as f_triple:\n",
    "                        f_triple.write(f\"(Contribution||has||{info_unit[0].upper()+info_unit[1:]})\\n\")\n",
    "            # Getting entities\n",
    "            for _, row in entity_df.iterrows():\n",
    "                idx = row['idx']\n",
    "                spans = load(row['BIO_1'])\n",
    "                text = row['text']\n",
    "                words = text.split()\n",
    "                sentences.add(str(idx))\n",
    "                for st, ed in spans:\n",
    "                    start_idx = sum([len(i) + 1 for i in words[:st]])\n",
    "                    end_idx = sum([len(i) + 1 for i in words[:ed]]) - 1\n",
    "                    phrase = ' '.join(words[st: ed])\n",
    "                    entities += f'{idx}\\t{start_idx}\\t{end_idx}\\t{phrase}\\n'\n",
    "            with open(os.path.join(dir_path, 'entities.txt'), 'w+') as f_entity:\n",
    "                f_entity.write(entities)\n",
    "            with open(os.path.join(dir_path, 'sentences.txt'), 'w+') as f_sentence:\n",
    "                f_sentence.write('\\n'.join(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission('pos_sent.csv','triples.csv','submission')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
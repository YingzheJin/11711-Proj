{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "from pathlib import Path\r\n",
    "import os\r\n",
    "from ast import literal_eval as load\r\n",
    "\r\n",
    "def get_entity_span(annotations: list) -> list:\r\n",
    "    \"\"\"\r\n",
    "    Given a sequence of BIO annotations, get the list of tuples representing spans of entities\r\n",
    "    :param annotations: BIO annotation\r\n",
    "    :return: A list of the span of entities [start, end)\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    types = ['-p', '-n']\r\n",
    "    span = []\r\n",
    "    for tp in types:\r\n",
    "        start = 0\r\n",
    "        while start < len(annotations):\r\n",
    "            if annotations[start] == 'B' + tp:\r\n",
    "                for end in range(start + 1, len(annotations)):\r\n",
    "                    if annotations[end] != 'I' + tp:\r\n",
    "                        span.append((start, end))\r\n",
    "                        break\r\n",
    "                else:\r\n",
    "                    span.append((start, len(annotations)))\r\n",
    "            start += 1\r\n",
    "    span = sorted(span, key=lambda x: x[0])\r\n",
    "    return span\r\n",
    "\r\n",
    "def output_submission(entity_data: pd.DataFrame or str, triple_data: pd.DataFrame or str, out_dir: str):\r\n",
    "    \"\"\"\r\n",
    "    Format the output from prediction into the final output form.\r\n",
    "    :param entity_data: The dataframe prediction of entities or path to csv file\r\n",
    "    :param triple_data: The dataframe prediction of triples or path to csv file\r\n",
    "    :param out_dir: Output directory\r\n",
    "    \"\"\"\r\n",
    "    if type(entity_data) is str:\r\n",
    "        entity_data: pd.DataFrame = pd.read_csv(entity_data)\r\n",
    "    if type(triple_data) is str:\r\n",
    "        triple_data: pd.DataFrame = pd.read_csv(triple_data)\r\n",
    "    triple_list = ['triple_A', 'triple_B', 'triple_C', 'triple_D']\r\n",
    "    triple_frame = triple_data[['paper_idx', 'topic', 'labels', 'subj/obj'] + triple_list]\r\n",
    "    entity_frame = entity_data[['text', 'topic', 'paper_idx', 'idx', 'BIO_1']]\r\n",
    "    topics = list(entity_frame['topic'].drop_duplicates())\r\n",
    "    for topic in topics:\r\n",
    "        topic_entity = entity_frame[entity_frame['topic'] == topic]\r\n",
    "        topic_triple = triple_frame[triple_frame['topic'] == topic]\r\n",
    "        paper_indices = topic_entity['paper_idx'].drop_duplicates()\r\n",
    "        for paper_index in paper_indices:\r\n",
    "            entity_df = topic_entity[topic_entity['paper_idx'] == paper_index]\r\n",
    "            triple_df = topic_triple[topic_triple['paper_idx'] == paper_index]\r\n",
    "            dir_path = os.path.join(out_dir, topic, str(paper_index))\r\n",
    "            Path(os.path.join(dir_path, 'triples')).mkdir(parents=True, exist_ok=True)\r\n",
    "            entities = ''\r\n",
    "            sentences = set()\r\n",
    "            for _, row in triple_df.iterrows():\r\n",
    "                triples_text = ''\r\n",
    "                try:\r\n",
    "                    info_unit = row['labels']\r\n",
    "                except AttributeError:\r\n",
    "                    continue\r\n",
    "                if info_unit not in ['code', 'research-problem']:\r\n",
    "                    for triple in triple_list:\r\n",
    "                        for t in load(row[triple]):\r\n",
    "                            triples_text += f\"({'||'.join(t)})\\n\"\r\n",
    "                elif info_unit=='code':\r\n",
    "                    for p in load(row['subj/obj']): \r\n",
    "                        triples_text += f\"(Contribution||Code||{p[0]})\\n\"\r\n",
    "                elif info_unit=='research-problem':\r\n",
    "                    for p in load(row['subj/obj']):\r\n",
    "                        triples_text += f\"(Contribution||has research problem||{p[0]})\\n\"\r\n",
    "                with open(os.path.join(dir_path, 'triples', f'{info_unit}.txt'), 'a+') as f_triple:\r\n",
    "                    f_triple.write(triples_text)\r\n",
    "            # Add specific tuple\r\n",
    "            for tuple_file in os.listdir(os.path.join(dir_path, 'triples')):\r\n",
    "                info_unit = str(tuple_file).split('.')[0].replace('-', ' ')\r\n",
    "                if info_unit not in ['code', 'research problem']:\r\n",
    "                    with open(os.path.join(dir_path, 'triples', tuple_file), 'a') as f_triple:\r\n",
    "                        f_triple.write(f\"(Contribution||has||{info_unit[0].upper()+info_unit[1:]})\\n\")\r\n",
    "            # Getting entities\r\n",
    "            for _, row in entity_df.iterrows():\r\n",
    "                idx = row['idx']\r\n",
    "                bio = load(row['BIO_1'])\r\n",
    "                text = row['text']\r\n",
    "                words = text.split()\r\n",
    "                spans = get_entity_span(bio)\r\n",
    "                sentences.add(str(idx))\r\n",
    "                for st, ed in spans:\r\n",
    "                    start_idx = sum([len(i) + 1 for i in words[:st]])\r\n",
    "                    end_idx = sum([len(i) + 1 for i in words[:ed]]) - 1\r\n",
    "                    phrase = ' '.join(words[st: ed])\r\n",
    "                    entities += f'{idx}\\t{start_idx}\\t{end_idx}\\t{phrase}\\n'\r\n",
    "            with open(os.path.join(dir_path, 'entities.txt'), 'w+') as f_entity:\r\n",
    "                f_entity.write(entities)\r\n",
    "            with open(os.path.join(dir_path, 'sentences.txt'), 'w+') as f_sentence:\r\n",
    "                f_sentence.write('\\n'.join(sentences))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission('pos_sent.csv','triples.csv','submission')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bae6546355a940aef21a1ec3c358906dbfda972b422ba2c211a5d8f2f4cba271"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('d2l': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
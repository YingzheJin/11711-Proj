idx,text,main_heading,heading,topic,paper_idx,BIO,BIO_1,BIO_2,offset1,pro1,offset2,pro2,offset3,pro3,mask,bi_labels,labels
5,"Conditional computation , where parts of the network are active on a per-example basis , has been proposed in theory as away of dramatically increasing model capacity without a proportional increase in computation .",abstract,abstract,machine-translation,7,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.021739130434782608,4,0.010723860589812333,2,0.04081632653061224,1,1,research-problem
16,Exploiting scale in both training data and model size has been central to the success of deep learning .,abstract,abstract,machine-translation,7,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.14130434782608695,15,0.040214477211796246,13,0.2653061224489796,1,1,research-problem
45,Our approach to conditional computation is to introduce a new type of general purpose neural network component : a Sparsely - Gated Mixture - of - Experts Layer ( MoE ) .,abstract,abstract,machine-translation,7,"['O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",42,0.45652173913043476,44,0.11796246648793565,42,0.8571428571428571,1,1,approach
46,"The MoE consists of a number of experts , each a simple feed - forward neural network , and a trainable gating network which selects a sparse combination of the experts to process each input ( see ) .",abstract,abstract,machine-translation,7,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",43,0.4673913043478261,45,0.12064343163538874,43,0.8775510204081632,1,1,approach
47,All parts of the network are trained jointly by back - propagation .,abstract,abstract,machine-translation,7,"['B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-ob', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O']",44,0.4782608695652174,46,0.12332439678284182,44,0.8979591836734694,1,1,approach
183,100 BILLION WORD GOOGLE NEWS CORPUS,Training the Gating Network,Computational,machine-translation,7,"['B', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",87,0.71900826446281,182,0.4879356568364611,0,0.0,1,1,tasks
186,"In addition to a baseline LSTM model , we trained models augmented with MoE layers containing 32 , experts .",Training the Gating Network,Computational,machine-translation,7,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",90,0.743801652892562,185,0.4959785522788204,3,0.1111111111111111,1,1,tasks
190,"When training over the full 100 billion words , test perplexity improves significantly up to 65536 experts ( 68 billion parameters ) , dropping 39 % lower than the computationally matched baseline , but degrades at 131072 experts , possibly a result of too much sparsity .",Training the Gating Network,Computational,machine-translation,7,"['B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",94,0.7768595041322314,189,0.5067024128686327,7,0.25925925925925924,1,1,tasks
193,MACHINE TRANSLATION ( SINGLE LANGUAGE PAIR ),Training the Gating Network,Computational,machine-translation,7,"['B', 'I', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",97,0.8016528925619835,192,0.514745308310992,10,0.37037037037037035,1,1,tasks
195,Our model was a modified version of the GNMT model described in .,Training the Gating Network,Computational,machine-translation,7,"['O', 'B', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O']","['O', 'B-p', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'B-p', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O']",99,0.8181818181818182,194,0.5201072386058981,12,0.4444444444444444,1,1,tasks
196,"To reduce computation , we decreased the number of LSTM layers in the encoder and decoder from 9 and 8 to 3 and 2 respectively .",Training the Gating Network,Computational,machine-translation,7,"['B', 'I', 'B', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-ob', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",100,0.8264462809917356,195,0.5227882037533512,13,0.48148148148148145,1,1,tasks
197,We inserted MoE layers in both the encoder ( between layers 2 and 3 ) and the decoder ( between layers 1 and 2 ) .,Training the Gating Network,Computational,machine-translation,7,"['O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O']",,,101,0.8347107438016529,196,0.5254691689008043,14,0.5185185185185185,1,1,tasks
198,"Each MoE layer contained up to 2048 experts each with about two million parameters , adding a total of about 8 billion parameters to the models .",Training the Gating Network,Computational,machine-translation,7,"['B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",102,0.8429752066115702,197,0.5281501340482574,15,0.5555555555555556,1,1,tasks
206,Our approach achieved BLEU scores of 40.56 and 26.03 on the WMT ' 14 En?Fr and En ? De benchmarks .,Training the Gating Network,Computational,machine-translation,7,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",110,0.9090909090909091,205,0.5495978552278821,23,0.8518518518518519,1,1,tasks
210,"On the Google Production dataset , our model achieved 1.01 higher test BLEU score even after training for only one sixth of the time .",Training the Gating Network,Computational,machine-translation,7,"['B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",114,0.9421487603305785,209,0.5603217158176944,27,1.0,1,1,tasks
211,MULTILINGUAL MACHINE TRANSLATION,Training the Gating Network,Computational,machine-translation,7,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",115,0.9504132231404959,210,0.5630026809651475,0,0.0,1,1,tasks
214,The MoE model achieves 19 % lower perplexity on the dev set than the multilingual GNMT model .,Training the Gating Network,Computational,machine-translation,7,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",118,0.9752066115702479,213,0.5710455764075067,3,0.5,1,1,tasks
215,"On BLEU score , the MoE model significantly beats the multilingual GNMT model on 11 of the 12 language pairs ( by as much as 5.84 points ) , and even beats the monolingual GNMT models on 8 of 12 language pairs .",Training the Gating Network,Computational,machine-translation,7,"['B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']",,,119,0.9834710743801653,214,0.5737265415549598,4,0.6666666666666666,1,1,tasks
2,Semi-supervised sequence tagging with bidirectional language models,title,,named-entity-recognition,3,"['B', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.005405405405405406,1,0.0,1,1,research-problem
6,"In this paper , we demonstrate a general semi-supervised approach for adding pretrained context embeddings from bidirectional language models to NLP systems and apply it to sequence labeling tasks .",abstract,abstract,named-entity-recognition,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.75,5,0.02702702702702703,3,0.75,1,1,research-problem
16,"In this paper , we explore an alternate semisupervised approach which does not require additional labeled data .",Introduction,Introduction,named-entity-recognition,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.4444444444444444,15,0.08108108108108109,8,0.4444444444444444,1,1,approach
17,"We use a neural language model ( LM ) , pre-trained on a large , unlabeled corpus to compute an encoding of the context at each position in the sequence ( hereafter an LM embedding ) and use it in the supervised sequence tagging model .",Introduction,Introduction,named-entity-recognition,3,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.5,16,0.08648648648648649,9,0.5,1,1,approach
75,CoNLL 2003 NER .,Experiments,,named-entity-recognition,3,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",5,0.2631578947368421,74,0.4,5,0.11904761904761904,1,1,tasks
80,We use two bidirectional GRUs with 80 hidden units and 25 dimensional character embeddings for the token character encoder .,Experiments,CoNLL 2003 NER .,named-entity-recognition,3,"['O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O']",10,0.5263157894736842,79,0.42702702702702705,10,0.23809523809523808,1,1,tasks
81,The sequence layer uses two bidirectional GRUs with 300 hidden units each .,Experiments,CoNLL 2003 NER .,named-entity-recognition,3,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.5789473684210527,80,0.43243243243243246,11,0.2619047619047619,1,1,tasks
82,"For regularization , we add 25 % dropout to the input of each GRU , but not to the recurrent connections .",Experiments,CoNLL 2003 NER .,named-entity-recognition,3,"['O', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.631578947368421,81,0.43783783783783786,12,0.2857142857142857,1,1,tasks
83,CoNLL 2000 chunking .,Experiments,,named-entity-recognition,3,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",13,0.6842105263157895,82,0.44324324324324327,13,0.30952380952380953,1,1,tasks
87,The baseline sequence tagger uses 30 dimensional character embeddings and a CNN with 30 filters of width 3 characters followed by a tanh non-linearity for the token character encoder .,Experiments,CoNLL 2000 chunking .,named-entity-recognition,3,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.8947368421052632,86,0.4648648648648649,17,0.40476190476190477,1,1,tasks
88,The sequence layer uses two bidirectional LSTMs with 200 hidden units .,Experiments,CoNLL 2000 chunking .,named-entity-recognition,3,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'I-p', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'B-p', 'I-p', 'O']",18,0.9473684210526315,87,0.4702702702702703,18,0.42857142857142855,1,1,tasks
89,"Following we added 50 % dropout to the character embeddings , the input to each LSTM layer ( but not recurrent connections ) and to the output of the final LSTM layer .",Experiments,CoNLL 2000 chunking .,named-entity-recognition,3,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,1.0,88,0.4756756756756757,19,0.4523809523809524,1,1,tasks
104,"All experiments use the Adam optimizer ( Kingma and Ba , 2015 ) with gradient norms clipped at 5.0 .",Pre-trained language models .,Pre-trained language models .,named-entity-recognition,3,"['O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",14,0.6363636363636364,103,0.5567567567567567,34,0.8095238095238095,1,1,hyperparameters
105,"In all experiments , we fine tune the pre-trained Senna word embeddings but fix all weights in the pre-trained language models .",Pre-trained language models .,Pre-trained language models .,named-entity-recognition,3,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",15,0.6818181818181818,104,0.5621621621621622,35,0.8333333333333334,1,1,hyperparameters
106,"In addition to explicit dropout regularization , we also use early stopping to prevent over-fitting and use the following process to determine when to stop training .",Pre-trained language models .,Pre-trained language models .,named-entity-recognition,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.7272727272727273,105,0.5675675675675675,36,0.8571428571428571,1,1,hyperparameters
107,We first train with a constant learning rate ? = 0.001 on the training data and monitor the development set performance at each epoch .,Pre-trained language models .,Pre-trained language models .,named-entity-recognition,3,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.7727272727272727,106,0.572972972972973,37,0.8809523809523809,1,1,hyperparameters
118,"In the CoNLL 2003 NER task , our model scores 91.93 mean F 1 , which is a statistically significant increase over the previous best result of 91.62 0.33 from that used gazetteers ( at 95 % , two - sided Welch t- test , p = 0.021 ) .",Overall system results,Overall system results,named-entity-recognition,3,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.13157894736842105,117,0.6324324324324324,3,0.2727272727272727,1,1,results
119,"In the CoNLL 2000 Chunking task , Tag LM achieves 96.37 mean F 1 , exceeding all previously published results without additional labeled data by more then 1 % absolute F 1 .",Overall system results,Overall system results,named-entity-recognition,3,"['O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.15789473684210525,118,0.6378378378378379,4,0.36363636363636365,1,1,results
2,Deep contextualized word representations,title,,named-entity-recognition,4,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.003676470588235294,1,0.0,1,1,research-problem
13,Our representations differ from traditional word type embeddings in that each token is assigned a representation that is a function of the entire input sentence .,Introduction,Introduction,named-entity-recognition,4,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.1282051282051282,12,0.04411764705882353,5,0.13157894736842105,1,1,approach
14,We use vectors derived from a bidirectional LSTM that is trained with a coupled lan - guage model ( LM ) objective on a large text corpus .,Introduction,Introduction,named-entity-recognition,4,"['O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.15384615384615385,13,0.04779411764705882,6,0.15789473684210525,1,1,approach
15,"For this reason , we call them ELMo ( Embeddings from Language Models ) representations .",Introduction,Introduction,named-entity-recognition,4,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.1794871794871795,14,0.051470588235294115,7,0.18421052631578946,1,1,approach
17,"More specifically , we learn a linear combination of the vectors stacked above each input word for each end task , which markedly improves performance over just using the top LSTM layer .",Introduction,Introduction,named-entity-recognition,4,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.23076923076923078,16,0.058823529411764705,9,0.23684210526315788,1,1,approach
108,"Textual entailment is the task of determining whether a "" hypothesis "" is true , given a "" premise "" .",Evaluation,Question Textual entailment,named-entity-recognition,4,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.017391304347826087,107,0.39338235294117646,2,0.14285714285714285,1,1,tasks
109,The Stanford Natural Language Inference ( SNLI ) corpus provides approximately 550K hypothesis / premise pairs .,Evaluation,Question Textual entailment,named-entity-recognition,4,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.02608695652173913,108,0.39705882352941174,3,0.21428571428571427,1,1,tasks
111,"Overall , adding ELMo to the ESIM model improves accuracy by an average of 0.7 % across five random seeds .",Evaluation,Question Textual entailment,named-entity-recognition,4,"['O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",5,0.043478260869565216,110,0.40441176470588236,5,0.35714285714285715,1,1,tasks
117,As shown in Coreference resolution Coreference resolution is the task of clustering mentions in text that refer to the same underlying real world entities .,Evaluation,He et al .,named-entity-recognition,4,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.09565217391304348,116,0.4264705882352941,11,0.7857142857142857,1,1,tasks
120,"In our experiments with the OntoNotes coreference annotations from the CoNLL 2012 shared task , adding ELMo improved the average F 1 by 3.2 % from 67.2 to 70.4 , establishing a new state of the art , again improving over the previous best ensemble result by 1.6 % F 1 .",Evaluation,He et al .,named-entity-recognition,4,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,14,0.12173913043478261,119,0.4375,14,1.0,1,1,tasks
2,BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding,title,title,named-entity-recognition,8,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.002583979328165375,1,0.0,1,1,research-problem
4,"We introduce a new language representation model called BERT , which stands for Bidirectional Encoder Representations from Transformers .",abstract,abstract,named-entity-recognition,8,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.1111111111111111,3,0.007751937984496124,1,0.1111111111111111,1,1,research-problem
14,Language model pre-training has been shown to be effective for improving many natural language processing tasks .,Introduction,Introduction,named-entity-recognition,8,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.041666666666666664,13,0.03359173126614987,1,0.041666666666666664,1,1,research-problem
24,"In this paper , we improve the fine - tuning based approaches by proposing BERT : Bidirectional Encoder Representations from Transformers .",Introduction,Introduction,named-entity-recognition,8,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.4583333333333333,23,0.059431524547803614,11,0.4583333333333333,1,1,approach
25,"BERT alleviates the previously mentioned unidirectionality constraint by using a "" masked language model "" ( MLM ) pre-training objective , inspired by the Cloze task .",Introduction,Introduction,named-entity-recognition,8,"['B', 'B', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.5,24,0.06201550387596899,12,0.5,1,1,approach
26,"The masked language model randomly masks some of the tokens from the input , and the objective is to predict the original vocabulary id of the masked word based only on its context .",Introduction,Introduction,named-entity-recognition,8,"['O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'O']",13,0.5416666666666666,25,0.06459948320413436,13,0.5416666666666666,1,1,approach
27,"Unlike left - toright language model pre-training , the MLM objective enables the representation to fuse the left and the right context , which allows us to pretrain a deep bidirectional Transformer .",Introduction,Introduction,named-entity-recognition,8,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",14,0.5833333333333334,26,0.06718346253229975,14,0.5833333333333334,1,1,approach
28,"In addition to the masked language model , we also use a "" next sentence prediction "" task that jointly pretrains text - pair representations .",Introduction,Introduction,named-entity-recognition,8,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.625,27,0.06976744186046512,15,0.625,1,1,approach
155,GLUE,Experiments,,named-entity-recognition,8,['B'],['B-n'],['B-b'],2,0.02857142857142857,154,0.3979328165374677,0,0.0,1,1,tasks
156,"The General Language Understanding Evaluation ( GLUE ) benchmark ( Wang et al. , 2018 a ) is a collection of diverse natural language understanding tasks .",Experiments,GLUE,named-entity-recognition,8,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.04285714285714286,155,0.4005167958656331,1,0.14285714285714285,1,1,tasks
170,We use a batch size of 32 and fine - tune for 3 epochs over the data for all GLUE tasks .,Experiments,GLUE,named-entity-recognition,8,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.24285714285714285,169,0.43669250645994834,7,0.1346153846153846,1,1,tasks
171,"For each task , we selected the best fine - tuning learning rate ( among 5 e - 5 , 4 e - 5 , 3 e - 5 , and 2 e - 5 ) on the Dev set .",Experiments,GLUE,named-entity-recognition,8,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",18,0.2571428571428571,170,0.4392764857881137,8,0.15384615384615385,1,1,tasks
172,"Additionally , for BERT LARGE we found that finetuning was sometimes unstable on small datasets , so we ran several random restarts and selected the best model on the Dev set .",Experiments,GLUE,named-entity-recognition,8,"['O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.2714285714285714,171,0.4418604651162791,9,0.17307692307692307,1,1,tasks
175,"Both BERT BASE and BERT LARGE outperform all systems on all tasks by a substantial margin , obtaining 4.5 % and 7.0 % respective average accuracy improvement over the prior state of the art .",Experiments,GLUE,named-entity-recognition,8,"['O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",22,0.3142857142857143,174,0.4496124031007752,12,0.23076923076923078,1,1,tasks
179,"We find that BERT LARGE significantly outperforms BERT BASE across all tasks , especially those with very little training data .",Experiments,GLUE,named-entity-recognition,8,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",26,0.37142857142857144,178,0.4599483204134367,16,0.3076923076923077,1,1,tasks
181,SQuAD v 1.1,Experiments,GLUE,named-entity-recognition,8,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",28,0.4,180,0.46511627906976744,18,0.34615384615384615,1,1,tasks
182,The Stanford Question Answering Dataset ( SQuAD v1.1 ) is a collection of 100 k crowdsourced question / answer pairs .,Experiments,GLUE,named-entity-recognition,8,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",29,0.4142857142857143,181,0.46770025839793283,19,0.36538461538461536,1,1,tasks
195,We fine - tune for 3 epochs with a learning rate of 5 e - 5 and a batch size of 32 .,Experiments,GLUE,named-entity-recognition,8,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",42,0.6,194,0.5012919896640827,32,0.6153846153846154,1,1,tasks
199,Our best performing system outperforms the top leaderboard system by + 1.5 F1 in ensembling and + 1.3 F1 as a single system .,Experiments,GLUE,named-entity-recognition,8,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",46,0.6571428571428571,198,0.5116279069767442,36,0.6923076923076923,1,1,tasks
203,SQuAD v 2.0,Experiments,GLUE,named-entity-recognition,8,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",50,0.7142857142857143,202,0.5219638242894057,40,0.7692307692307693,1,1,tasks
213,We fine - tuned for 2 epochs with a learning rate of 5 e - 5 and a batch size of 48 .,Experiments,GLUE,named-entity-recognition,8,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",60,0.8571428571428571,212,0.5478036175710594,50,0.9615384615384616,1,1,tasks
215,We observe a + 5.1 F1 improvement over the previous best system .,Experiments,GLUE,named-entity-recognition,8,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",62,0.8857142857142857,214,0.5529715762273901,52,1.0,1,1,tasks
216,SWAG,Experiments,,named-entity-recognition,8,['B'],['B-n'],['B-b'],63,0.9,215,0.5555555555555556,0,0.0,1,1,tasks
217,The Situations With Adversarial Generations ( SWAG ) dataset contains 113 k sentence - pair completion examples that evaluate grounded commonsense inference .,Experiments,SWAG,named-entity-recognition,8,"['O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",64,0.9142857142857143,216,0.5581395348837209,1,0.14285714285714285,1,1,tasks
221,We fine - tune the model for 3 epochs with a learning rate of 2 e - 5 and a batch size of 16 .,Experiments,SWAG,named-entity-recognition,8,"['O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O']",,,68,0.9714285714285714,220,0.5684754521963824,5,0.7142857142857143,1,1,tasks
223,BERT LARGE outperforms the authors ' baseline ESIM + ELMo system by + 27.1 % and OpenAI GPT by 8.3 % .,Experiments,SWAG,named-entity-recognition,8,"['B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']",,,70,1.0,222,0.5736434108527132,7,1.0,1,1,tasks
250,Effect of Model Size,,,named-entity-recognition,8,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",0,0.0,249,0.6434108527131783,0,0.0,1,1,ablation-analysis
260,"However , we believe that this is the first work to demonstrate convincingly that scaling to extreme model sizes also leads to large improvements on very small scale tasks , provided that the model has been sufficiently pre-trained .",Effect of Model Size,Effect of Model Size,named-entity-recognition,8,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.37037037037037035,259,0.6692506459948321,10,0.37037037037037035,1,1,ablation-analysis
263,Feature - based Approach with BERT,Effect of Model Size,Effect of Model Size,named-entity-recognition,8,"['B', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",13,0.48148148148148145,262,0.6770025839793282,13,0.48148148148148145,1,1,ablation-analysis
275,BERT LARGE performs competitively with state - of - the - art methods .,Effect of Model Size,Effect of Model Size,named-entity-recognition,8,"['B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",25,0.9259259259259259,274,0.7080103359173127,25,0.9259259259259259,1,1,ablation-analysis
277,This demonstrates that BERT is effective for both finetuning and feature - based approaches .,Effect of Model Size,Effect of Model Size,named-entity-recognition,8,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,1.0,276,0.7131782945736435,27,1.0,1,1,ablation-analysis
2,Gated - Attention Readers for Text Comprehension,title,,natural_language_inference,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.005076142131979695,1,0.0,1,1,research-problem
11,Source code is available on github : https:// github.com/bdhingra/ga-reader,abstract,abstract,natural_language_inference,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",8,1.0,10,0.050761421319796954,8,1.0,1,1,code
13,A recent trend to measure progress towards machine reading is to test a system 's ability to answer questions about a document it has to comprehend .,Introduction,Introduction,natural_language_inference,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.06666666666666667,12,0.06091370558375635,1,0.06666666666666667,1,1,research-problem
23,"More specifically , unlike existing models where the query attention is applied either token - wise or sentence - wise to allow weighted aggregation , the Gated - Attention ( GA ) module proposed in this work allows the query to directly interact with each dimension of the token embeddings at the semantic - level , and is applied layer - wise as information filters during the multi-hop representation learning process .",Introduction,Introduction,natural_language_inference,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.7333333333333333,22,0.1116751269035533,11,0.7333333333333333,1,1,model
24,"Such a fine - grained attention enables our model to learn conditional token representations w.r.t. the given question , leading to accurate answer selections .",Introduction,Introduction,natural_language_inference,0,"['O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.8,23,0.116751269035533,12,0.8,1,1,model
137,"Interestingly , we observe that feature engineering leads to significant improvements for WDW and CBT datasets , but not for CNN and Daily Mail datasets .",Experiments and Results,Performance Comparison,natural_language_inference,0,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,0.4153846153846154,136,0.6903553299492385,7,0.3333333333333333,1,1,results
140,"Similarly , fixing the word embeddings provides an improvement for the WDW and CBT , but not for CNN and Daily Mail .",Experiments and Results,Performance Comparison,natural_language_inference,0,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",30,0.46153846153846156,139,0.7055837563451777,10,0.47619047619047616,1,1,results
142,"Comparing with prior work , on the WDW dataset the basic version of the GA Reader outperforms all previously published models when trained on the Strict setting .",Experiments and Results,Performance Comparison,natural_language_inference,0,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",32,0.49230769230769234,141,0.7157360406091371,12,0.5714285714285714,1,1,results
143,By adding the qecomm feature the performance increases by 3.2 % and 3.5 % on the Strict and Relaxed settings respectively to set a new state of the art on this dataset .,Experiments and Results,Performance Comparison,natural_language_inference,0,"['O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",33,0.5076923076923077,142,0.7208121827411168,13,0.6190476190476191,1,1,results
144,On the CNN and Daily Mail datasets the GA Reader leads to an improvement of 3.2 % and 4.3 % respectively over the best previous single models .,Experiments and Results,Performance Comparison,natural_language_inference,0,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",34,0.5230769230769231,143,0.7258883248730964,14,0.6666666666666666,1,1,results
146,"For CBT - NE , GA Reader with the qecomm feature outperforms all previous single and ensemble models except the AS Reader trained on the much larger BookTest Corpus .",Experiments and Results,Performance Comparison,natural_language_inference,0,"['B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",36,0.5538461538461539,145,0.7360406091370558,16,0.7619047619047619,1,1,results
147,"Lastly , on CBT - CN the GA Reader with the qe-comm feature outperforms all previously published single models except the NSE , and AS Reader trained on a larger corpus .",Experiments and Results,Performance Comparison,natural_language_inference,0,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",37,0.5692307692307692,146,0.7411167512690355,17,0.8095238095238095,1,1,results
182,"Next , we observe a substantial drop when removing tokenspecific attentions over the query in the GA module , which allow gating individual tokens in the document only by parts of the query relevant to that token rather than the over all query representation .",Model Accuracy,Model Accuracy,natural_language_inference,0,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.36363636363636365,181,0.9187817258883249,4,0.8,1,1,ablation-analysis
183,"Finally , removing the character embeddings , which were only used for WDW and CBT , leads to a reduction of about 1 % in the performance .",Model Accuracy,Model Accuracy,natural_language_inference,0,"['O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.45454545454545453,182,0.9238578680203046,5,1.0,1,1,ablation-analysis
2,Large - scale Simple Question Answering with Memory Networks,title,,natural_language_inference,1,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",1,0.0,1,0.003663003663003663,1,0.0,1,1,research-problem
4,Training large - scale question answering systems is complicated because training sources usually cover a small portion of the range of possible questions .,abstract,abstract,natural_language_inference,1,"['O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.25,3,0.01098901098901099,1,0.25,1,1,research-problem
5,"This paper studies the impact of multitask and transfer learning for simple question answering ; a setting for which the reasoning required to answer is quite easy , as long as one can retrieve the correct evidence given a question , which can be difficult in large - scale conditions .",abstract,abstract,natural_language_inference,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.5,4,0.014652014652014652,2,0.5,1,1,research-problem
12,"However , while most recent efforts have focused on designing systems with higher reasoning capabilities , that could jointly retrieve and use multiple facts to answer , the simpler problem of answering questions that refer to a single fact of the KB , which we call Simple Question Answering in this paper , is still far from solved .",Introduction,Introduction,natural_language_inference,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.02666666666666667,11,0.040293040293040296,4,0.16666666666666666,1,1,research-problem
19,"First , as an effort to study the coverage of existing systems and the possibility to train jointly on different data sources via multitasking , we collected the first large - scale dataset of questions and answers based on a KB , called SimpleQuestions .",Introduction,Introduction,natural_language_inference,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'B-p', 'B-ob', 'O']",11,0.07333333333333333,18,0.06593406593406594,11,0.4583333333333333,1,1,dataset
20,"This dataset , which is presented in Section 2 , contains more than 100 k questions written by human anno-What American cartoonist is the creator of Andy Lippincott ?",Introduction,Introduction,natural_language_inference,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.08,19,0.0695970695970696,12,0.5,1,1,dataset
24,"Second , in sections 3 and 4 , we present an embedding - based QA system developed under the framework of Memory Networks ( Mem NNs ) .",Introduction,Introduction,natural_language_inference,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.10666666666666667,23,0.08424908424908426,16,0.6666666666666666,1,1,model
25,"Memory Networks are learning systems centered around a memory component that can be read and written to , with a particular focus on cases where the relationship between the input and response languages ( here natural language ) and the storage language ( here , the facts from KBs ) is performed by embedding all of them in the same vector space .",Introduction,Introduction,natural_language_inference,1,"['B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.11333333333333333,24,0.08791208791208792,17,0.7083333333333334,1,1,model
26,The setting of the simple QA corresponds to the elementary operation of performing a single lookup in the memory .,Introduction,Introduction,natural_language_inference,1,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",18,0.12,25,0.09157509157509157,18,0.75,1,1,model
229,"The embedding dimension and the learning rate were chosen among { 64 , 128 , 256 } and { 1 , 0.1 , ... , 1.0e ? 4 } respectively , and the margin ?",Experimental setup,Experimental setup,natural_language_inference,1,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'O']",3,0.25,228,0.8351648351648352,3,0.25,1,1,hyperparameters
230,was set to 0.1 .,Experimental setup,Experimental setup,natural_language_inference,1,"['O', 'B', 'I', 'B', 'O']","['O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-p', 'I-p', 'B-ob', 'O']",4,0.3333333333333333,229,0.8388278388278388,4,0.3333333333333333,1,1,hyperparameters
254,"On WebQuestions , not specifically designed as a simple QA dataset , 86 % of the questions can now be answered with a single supporting fact , and performance increases significantly ( from 36.2 % to 41.0 % F1-score ) .",Comparative results,Comparative results,natural_language_inference,1,"['B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O']","['B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O']","['B-p', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",14,0.5,253,0.9267399267399268,10,0.9090909090909091,1,1,results
255,"Using the bigger FB5M as KB does not change performance on SimpleQuestions because it was based on FB2M , but the results show that our model is robust to the addition of more entities than necessary .",Comparative results,Comparative results,natural_language_inference,1,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.5357142857142857,254,0.9304029304029304,11,1.0,1,1,results
256,Transfer learning on Reverb,Comparative results,,natural_language_inference,1,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",16,0.5714285714285714,255,0.9340659340659341,0,0.0,1,1,results
259,"Our best results are 67 % accuracy ( and 68 % for the ensemble of 5 models ) , which are better than the 54 % of the original paper and close to the stateof - the - art 73 % of .",Comparative results,Transfer learning on Reverb,natural_language_inference,1,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.6785714285714286,258,0.945054945054945,3,0.25,1,1,results
262,"We first notice that models trained on a single QA dataset perform poorly on the other datasets ( e.g. 46.6 % accuracy on SimpleQuestions for the model trained on WebQuestions only ) , which shows that the performance on We-bQuestions does not necessarily guarantee high coverage for simple QA .",Comparative results,Transfer learning on Reverb,natural_language_inference,1,"['O', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.7857142857142857,261,0.9560439560439561,6,0.5,1,1,results
263,"On the other hand , training on both datasets only improves performance ; in particular , the model is able to capture all question patterns of the two datasets ; there is no "" negative interaction "" .",Comparative results,Transfer learning on Reverb,natural_language_inference,1,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",23,0.8214285714285714,262,0.9597069597069597,7,0.5833333333333334,1,1,results
264,Importance of data sources,Comparative results,Transfer learning on Reverb,natural_language_inference,1,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",24,0.8571428571428571,263,0.9633699633699634,8,0.6666666666666666,1,1,results
266,"While paraphrases do not seem to help much on WebQuestions and SimpleQuestions , except when training only with synthetic questions , they have a dramatic impact on the performance on Reverb .",Comparative results,Transfer learning on Reverb,natural_language_inference,1,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'O']",,,26,0.9285714285714286,265,0.9706959706959707,10,0.8333333333333334,1,1,results
2,Learning to Compose Task - Specific Tree Structures,title,,natural_language_inference,10,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004219409282700422,1,0.0,1,1,research-problem
6,"In this paper , we propose Gumbel Tree - LSTM , a novel tree - structured long short - term memory architecture that learns how to compose task - specific tree structures only from plain text data efficiently .",abstract,abstract,natural_language_inference,10,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",3,0.5,5,0.02109704641350211,3,0.5,1,1,research-problem
23,"In this paper , we propose Gumbel Tree - LSTM , which is a novel RvNN architecture that does not require structured data and learns to compose task - specific tree structures without explicit guidance .",Introduction,Introduction,natural_language_inference,10,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",13,0.4642857142857143,22,0.09282700421940929,13,0.4642857142857143,1,1,model
24,"Our Gumbel Tree - LSTM model is based on tree - structured long short - term memory ( Tree - LSTM ) architecture , which is one of the most renowned variants of RvNN .",Introduction,Introduction,natural_language_inference,10,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.5,23,0.0970464135021097,14,0.5,1,1,model
25,"To learn how to compose task - specific tree structures without depending on structured input , our model introduces composition query vector that measures validity of a composition .",Introduction,Introduction,natural_language_inference,10,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'O']",15,0.5357142857142857,24,0.10126582278481013,15,0.5357142857142857,1,1,model
26,"Using validity scores computed by the composition query vector , our model recursively selects compositions until only a single representation remains .",Introduction,Introduction,natural_language_inference,10,"['B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.5714285714285714,25,0.10548523206751055,16,0.5714285714285714,1,1,model
27,We use Straight - Through ( ST ) Gumbel - Softmax estimator to sample compositions in the training phase .,Introduction,Introduction,natural_language_inference,10,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",17,0.6071428571428571,26,0.10970464135021098,17,0.6071428571428571,1,1,model
28,"ST Gumbel - Softmax estimator relaxes the discrete sampling operation to be continuous in the backward pass , thus our model can be trained via the standard backpropagation .",Introduction,Introduction,natural_language_inference,10,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.6428571428571429,27,0.11392405063291139,18,0.6428571428571429,1,1,model
139,Natural Language Inference,Experiments,,natural_language_inference,10,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",4,0.04819277108433735,138,0.5822784810126582,0,0.0,1,1,experiments
150,"Similar to 100D experiments , we initialize the word embedding matrix with GloVe 300D pretrained vectors 4 , however we do not update the word representations during training .",Experiments,Natural Language Inference,natural_language_inference,10,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.18072289156626506,149,0.6286919831223629,11,0.4230769230769231,1,1,experiments
153,The dropout probability is set to 0.2 and word embeddings are not updated during training .,Experiments,Natural Language Inference,natural_language_inference,10,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.21686746987951808,152,0.6413502109704642,14,0.5384615384615384,1,1,experiments
154,"The size of mini-batches is set to 128 in all experiments , and hyperparameters are tuned using the validation split .",Experiments,Natural Language Inference,natural_language_inference,10,"['O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-p', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.2289156626506024,153,0.6455696202531646,15,0.5769230769230769,1,1,experiments
155,"The temperature parameter ? of Gumbel - Softmax is set to 1.0 , and we did not find that temperature annealing improves performance .",Experiments,Natural Language Inference,natural_language_inference,10,"['O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.24096385542168675,154,0.6497890295358649,16,0.6153846153846154,1,1,experiments
156,"For training models , Adam optimizer is used .",Experiments,Natural Language Inference,natural_language_inference,10,"['B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O']","['B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O']","['B-p', 'I-p', 'B-b', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O']",21,0.25301204819277107,155,0.6540084388185654,17,0.6538461538461539,1,1,experiments
158,"First , we can see that LSTM - based leaf transformation has a clear advantage over the affine - transformation - based one .",Experiments,Natural Language Inference,natural_language_inference,10,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",23,0.27710843373493976,157,0.6624472573839663,19,0.7307692307692307,1,1,experiments
160,"Secondly , comparing ours with other models , we find that our 100D and 300D model outperform all other models of similar numbers of parameters .",Experiments,Natural Language Inference,natural_language_inference,10,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",25,0.30120481927710846,159,0.6708860759493671,21,0.8076923076923077,1,1,experiments
161,"Our 600D model achieves the accuracy of 86.0 % , which is comparable to that of the state - of - the - art model , while using far less parameters .",Experiments,Natural Language Inference,natural_language_inference,10,"['B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",26,0.3132530120481928,160,0.6751054852320675,22,0.8461538461538461,1,1,experiments
163,All of our models converged within a few hours on a machine with NVIDIA Titan Xp GPU .,Experiments,Natural Language Inference,natural_language_inference,10,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",28,0.3373493975903614,162,0.6835443037974683,24,0.9230769230769231,1,1,experiments
166,Sentiment Analysis,Experiments,,natural_language_inference,10,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",31,0.37349397590361444,165,0.6962025316455697,0,0.0,1,1,experiments
175,is a single - hidden layer MLP with the ReLU activation function .,Experiments,Sentiment Analysis,natural_language_inference,10,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",40,0.4819277108433735,174,0.7341772151898734,9,0.45,1,1,experiments
177,"We trained our SST - 2 model with hyperparameters D x = 300 , D h = 300 , D c = 300 .",Experiments,Sentiment Analysis,natural_language_inference,10,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",42,0.5060240963855421,176,0.7426160337552743,11,0.55,1,1,experiments
178,The word vectors are initialized with GloVe 300D pretrained vectors and fine - tuned during training .,Experiments,Sentiment Analysis,natural_language_inference,10,"['O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",43,0.5180722891566265,177,0.7468354430379747,12,0.6,1,1,experiments
179,We apply dropout ( p = 0.5 ) on the output of the word embedding layer and the input and the output of the MLP layer .,Experiments,Sentiment Analysis,natural_language_inference,10,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,44,0.5301204819277109,178,0.7510548523206751,13,0.65,1,1,experiments
180,The size of mini-batches is set to 32 and Adadelta optimizer is used for optimization .,Experiments,Sentiment Analysis,natural_language_inference,10,"['O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']",,,45,0.5421686746987951,179,0.7552742616033755,14,0.7,1,1,experiments
181,"For our SST - 5 model , hyperparameters are set to D x = 300 , D h = 300 , D c = 1024 . Similar to the SST - 2 model , we optimize the model using Adadelta optimizer with batch size 64 and apply dropout with p = 0.5 .",Experiments,Sentiment Analysis,natural_language_inference,10,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'O']",,,46,0.5542168674698795,180,0.759493670886076,15,0.75,1,1,experiments
183,"Our SST - 2 model outperforms all other models substantially except byte - m LSTM , where a byte - level language model trained on the large product review dataset is used to obtain sentence representations .",Experiments,Sentiment Analysis,natural_language_inference,10,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",48,0.5783132530120482,182,0.7679324894514767,17,0.85,1,1,experiments
184,"We also see that the performance of our SST - 5 model is on par with that of the current state - of - the - art model , which is pretrained on large parallel datasets and uses character n-gram embeddings alongside word embeddings , even though our model does not utilize external resources other than GloVe vectors and only uses wordlevel representations .",Experiments,Sentiment Analysis,natural_language_inference,10,"['O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",49,0.5903614457831325,183,0.7721518987341772,18,0.9,1,1,experiments
185,The authors of stated that utilizing pretraining and character n-gram embeddings improves validation accuracy by 2.8 % ( SST - 2 ) or 1.7 % ( SST - 5 ) .,Experiments,Sentiment Analysis,natural_language_inference,10,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",50,0.6024096385542169,184,0.7763713080168776,19,0.95,1,1,experiments
4,"As an alternative to question answering methods based on feature engineering , deep learning approaches such as convolutional neural networks ( CNNs ) and Long Short - Term Memory Models ( LSTMs ) have recently been proposed for semantic matching of questions and answers .",abstract,abstract,natural_language_inference,100,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.00819672131147541,1,0.14285714285714285,1,1,research-problem
12,"Question answering ( QA ) , which returns exact answers as either short facts or long passages to natural language questions issued by users , is a challenging task and plays a central role in the next generation of advanced web search .",INTRODUCTION,INTRODUCTION,natural_language_inference,100,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.00847457627118644,11,0.030054644808743168,1,0.018867924528301886,1,1,research-problem
13,"Many of current QA systems use a learning to rank approach that encodes question / answer pairs with complex linguistic features including lexical , syntactic and semantic features .",INTRODUCTION,INTRODUCTION,natural_language_inference,100,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.01694915254237288,12,0.03278688524590164,2,0.03773584905660377,1,1,research-problem
48,"To handle these issues in the existing deep learning architectures for ranking answers , we propose an attention based neural matching model ( a NMM ) .",INTRODUCTION,RQ2,natural_language_inference,100,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",37,0.3135593220338983,47,0.1284153005464481,37,0.6981132075471698,1,1,model
51,Deep neural network with value - shared weights :,INTRODUCTION,RQ2,natural_language_inference,100,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",40,0.3389830508474576,50,0.1366120218579235,40,0.7547169811320755,1,1,model
52,"We introduce a novel value - shared weighting scheme in deep neural networks as a counterpart of the position - shared weighting scheme in CNNs , based on the idea that semantic matching between a question and answer is mainly about the ( semantic similarity ) value regularities rather than spatial regularities .",INTRODUCTION,RQ2,natural_language_inference,100,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",41,0.3474576271186441,51,0.13934426229508196,41,0.7735849056603774,1,1,model
53,Incorporate attention scheme over question terms :,INTRODUCTION,RQ2,natural_language_inference,100,"['B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",42,0.3559322033898305,52,0.14207650273224043,42,0.7924528301886793,1,1,model
54,"We incorporate the attention scheme over the question terms using a gating function , so that we can explicitly discriminate the question term importance .",INTRODUCTION,RQ2,natural_language_inference,100,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",43,0.3644067796610169,53,0.1448087431693989,43,0.8113207547169812,1,1,model
248,"For the setting of hyper - parameters , we set the number of bins as 600 , word embedding dimension as 700 for a NNM - 1 , the number of bins as 200 , word embedding dimension as 700 for a NNM - 2 after we tune hyper - parameters on the provided DEV set of TREC QA data .",EXPERIMENTS,Data Set and Experiment Settings,natural_language_inference,100,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,9,1.0,247,0.674863387978142,8,1.0,1,1,hyperparameters
341,We can see a NMM trained with TRAIN - ALL set beats all the previous state - of - the art systems including both methods using feature engineering and deep learning models .,Results Summary,Results Summary,natural_language_inference,100,"['O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.07407407407407407,340,0.9289617486338798,2,0.5,1,1,results
343,"Furthermore , even without combining additional features , a NMM still performs well for answer ranking , showing significant improvements over previous deep learning model with no additional features and linguistic feature engineering methods .",Results Summary,Results Summary,natural_language_inference,100,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']",,,4,0.14814814814814814,342,0.9344262295081968,4,1.0,1,1,results
2,Dynamic Integration of Background Knowledge in Neural NLU Systems,title,,natural_language_inference,11,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",1,0.0,1,0.0036231884057971015,1,0.0,1,1,research-problem
4,"Common- sense and background knowledge is required to understand natural language , but in most neural natural language understanding ( NLU ) systems , this knowledge must be acquired from training corpora during learning , and then it is static at test time .",abstract,abstract,natural_language_inference,11,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.125,3,0.010869565217391304,1,0.125,1,1,research-problem
21,"In this paper , we develop a new architecture for dynamically incorporating external background knowledge in NLU models .",Introduction,Introduction,natural_language_inference,11,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",9,0.11538461538461539,20,0.07246376811594203,9,0.4090909090909091,1,1,model
22,"Rather than relying only on static knowledge implicitly present in the training data , supplementary knowledge is retrieved from external knowledge sources ( in this paper , ConceptNet and Wikipedia ) to assist with understanding text inputs .",Introduction,Introduction,natural_language_inference,11,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",10,0.1282051282051282,21,0.07608695652173914,10,0.45454545454545453,1,1,model
24,The retrieved supplementary texts are read together with the task inputs by an initial reading module whose outputs are contextually refined word embeddings ( 3 ) .,Introduction,Introduction,natural_language_inference,11,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']",,,12,0.15384615384615385,23,0.08333333333333333,12,0.5454545454545454,1,1,model
25,These refined embeddings are then used as input to a task - specific NLU architecture ( any architecture that reads text as a sequence of word embeddings can be used here ) .,Introduction,Introduction,natural_language_inference,11,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.16666666666666666,24,0.08695652173913043,13,0.5909090909090909,1,1,model
26,"The initial reading module and the task module are learnt jointly , end - to - end .",Introduction,Introduction,natural_language_inference,11,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.1794871794871795,25,0.09057971014492754,14,0.6363636363636364,1,1,model
101,All models are trained end - to - end jointly with the refinement module using a dimensionality of n = 300 for all but the TriviaQA experiments for which we had to reduce n to 150 due to memory constraints .,Models,Models,natural_language_inference,11,"['B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",6,0.16216216216216217,100,0.36231884057971014,10,0.7692307692307693,1,1,hyperparameters
102,All baselines operate on the unrefined word embeddings E 0 described in 3.1 .,Models,Models,natural_language_inference,11,"['B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.1891891891891892,101,0.36594202898550726,11,0.8461538461538461,1,1,hyperparameters
103,For the DQA baseline system we add the lemma in - question feature ( liq ) suggested in .,Models,Models,natural_language_inference,11,"['B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",8,0.21621621621621623,102,0.3695652173913043,12,0.9230769230769231,1,1,hyperparameters
138,"Wikipedia ( W ) yields further , significant improvements on TriviaQA , slightly outperforming the current state of the art model .",Model,Model,natural_language_inference,11,"['B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.043478260869565216,137,0.4963768115942029,2,0.08,1,1,results
147,shows the results of our RTE experiments .,Model,Model,natural_language_inference,11,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O']",11,0.2391304347826087,146,0.5289855072463768,11,0.44,1,1,results
148,"In general , the introduction of our refinement strategy almost always helps , both with and without external knowledge .",Model,Model,natural_language_inference,11,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",12,0.2608695652173913,147,0.532608695652174,12,0.48,1,1,results
149,"When providing additional background knowledge from ConceptNet , our BiLSTM based models improve substantially , while the ESIM - based models improve only on the more difficult MultiNLI dataset .",Model,Model,natural_language_inference,11,"['B', 'I', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.2826086956521739,148,0.5362318840579711,13,0.52,1,1,results
150,"Compared to previously published state of the art systems , our models acquit themselves quite well on the MultiNLI benchmark , and competitively on the SNLI benchmark .",Model,Model,natural_language_inference,11,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'O']",,,14,0.30434782608695654,149,0.5398550724637681,14,0.56,1,1,results
154,"We do find that there is little impact of using external knowledge on the RTE task with ESIM , although the refinement strategy helps using just p + q.",Model,Model,natural_language_inference,11,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.391304347826087,153,0.5543478260869565,18,0.72,1,1,results
157,"Nevertheless , both ESIM and our BiL - STM models when trained with knowledge from ConceptNet are sensitive to the semantics of the provided assertions as demonstrated in our analysis in 5.3 .",Model,Model,natural_language_inference,11,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.45652173913043476,156,0.5652173913043478,21,0.84,1,1,results
159,"Furthermore , increasing the coverage of assertions in ConceptNet would most likely yield improved performance even without retraining our models .",Model,Model,natural_language_inference,11,"['O', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",23,0.5,158,0.572463768115942,23,0.92,1,1,results
2,Shortcut - Stacked Sentence Encoders for Multi- Domain Inference,title,,natural_language_inference,12,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.011363636363636364,1,0.0,1,1,research-problem
4,We present a simple sequential sentence encoder for multi-domain natural language inference .,abstract,abstract,natural_language_inference,12,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.2,3,0.03409090909090909,1,0.038461538461538464,1,1,research-problem
10,Natural language inference ( NLI ) or recognizing textual entailment ( RTE ) is a fundamental semantic task in the field of natural language processing .,Introduction and Background,Introduction and Background,natural_language_inference,12,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.020833333333333332,9,0.10227272727272728,7,0.2692307692307692,0,1,research-problem
15,"In this paper , we follow the former approach of encoding - based models , and propose a novel yet simple sequential sentence encoder for the Multi - NLI problem .",Introduction and Background,Introduction and Background,natural_language_inference,12,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.125,14,0.1590909090909091,12,0.46153846153846156,0,1,model
18,It is basically a stacked ( multi-layered ) bidirectional LSTM - RNN with shortcut connections ( feeding all previous layers ' outputs and word embeddings to each layer ) and word embedding fine - tuning .,Introduction and Background,Introduction and Background,natural_language_inference,12,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.1875,17,0.19318181818181818,15,0.5769230769230769,0,1,model
19,"The over all supervised model uses these shortcutstacked encoders to encode two input sentences into two vectors , and then we use a classifier over the vector combination to label the relationship between these two sentences as that of entailment , contradiction , or neural ( similar to the classifier setup of and ) .",Introduction and Background,Introduction and Background,natural_language_inference,12,"['O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'O', 'B-n', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'O', 'B-ob', 'O', 'B-ob', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.20833333333333334,18,0.20454545454545456,16,0.6153846153846154,0,1,model
22,Github Code Link : https://github.com/ easonnie/multiNLI_encoder,Introduction and Background,Introduction and Background,natural_language_inference,12,"['O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob']",13,0.2708333333333333,21,0.23863636363636365,19,0.7307692307692307,0,1,code
52,We use cross - entropy loss as the training objective with Adam - based opti-Model Accuracy SNLI Multi - NLI Matched Multi - NLI Mismatched CBOW 80.6 65.2 64.6 biLSTM Encoder 81.5 67.5 67.1 300D Tree - CNN Encoder 82.1 --300D SPINN - PI Encoder 83.2 --300D NSE Encoder 84.6 --biLSTM -Max Encoder 84 . mization with 32 batch size .,Introduction and Background,Parameter Settings,natural_language_inference,12,"['O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O']",,,43,0.8958333333333334,51,0.5795454545454546,1,0.16666666666666666,0,1,hyperparameters
53,The starting learning rate is 0.0002 with half decay every two epochs .,Introduction and Background,Parameter Settings,natural_language_inference,12,"['O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",44,0.9166666666666666,52,0.5909090909090909,2,0.3333333333333333,0,1,hyperparameters
54,The number of hidden units for MLP in classifier is 1600 .,Introduction and Background,Parameter Settings,natural_language_inference,12,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'B', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'B-p', 'B-ob', 'O']",45,0.9375,53,0.6022727272727273,3,0.5,0,1,hyperparameters
55,"Dropout layer is also applied on the output of each layer of MLP , with dropout rate set to 0.1 .",Introduction and Background,Parameter Settings,natural_language_inference,12,"['B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",46,0.9583333333333334,54,0.6136363636363636,4,0.6666666666666666,0,1,hyperparameters
56,We used pre-trained 300D Glove 840B vectors to initialize the word embeddings .,Introduction and Background,Parameter Settings,natural_language_inference,12,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",47,0.9791666666666666,55,0.625,5,0.8333333333333334,0,1,hyperparameters
61,"These ablation results are shown in and 4 , all based on the Multi - NLI development sets .",Ablation Analysis Results,Ablation Analysis Results,natural_language_inference,12,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.09523809523809523,60,0.6818181818181818,2,0.09523809523809523,1,1,ablation-analysis
65,"As shown , each added layer model improves the accuracy and we achieve a substantial improvement in accuracy ( around 2 % ) on both matched and mismatched settings , compared to the single - layer biLSTM in .",Ablation Analysis Results,Ablation Analysis Results,natural_language_inference,12,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",6,0.2857142857142857,64,0.7272727272727273,6,0.2857142857142857,1,1,ablation-analysis
67,"Next , in , we show that the shortcut connections among the biLSTM layers is also an important contributor to accuracy improvement ( around 1.5 % on top of the full 3 - layered stacked - RNN model ) .",Ablation Analysis Results,Ablation Analysis Results,natural_language_inference,12,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",8,0.38095238095238093,66,0.75,8,0.38095238095238093,1,1,ablation-analysis
69,"Next , in , we show that fine - tuning the word embeddings also improves results , again for both the in - domain task and cross - domain tasks ( the ablation results are based on a smaller model with a 128 +256 2 - layer biLSTM ) .",Ablation Analysis Results,Ablation Analysis Results,natural_language_inference,12,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.47619047619047616,68,0.7727272727272727,10,0.47619047619047616,1,1,ablation-analysis
71,The last ablation in shows that a classifier with two layers of relu is preferable than other options .,Ablation Analysis Results,Ablation Analysis Results,natural_language_inference,12,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O']",12,0.5714285714285714,70,0.7954545454545454,12,0.5714285714285714,1,1,ablation-analysis
75,"First for Multi - NLI , we improve substantially over the CBOW and biL - STM Encoder baselines reported in the dataset paper .",Ablation Analysis Results,Ablation Analysis Results,natural_language_inference,12,"['O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.7619047619047619,74,0.8409090909090909,16,0.7619047619047619,1,1,results
76,We also show that our final shortcut - based stacked encoder achieves around 3 % improvement as compared to the 1 layer biLSTM - Max Encoder in the second last row ( using the exact same classifier and optimizer settings ) .,Ablation Analysis Results,Ablation Analysis Results,natural_language_inference,12,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.8095238095238095,75,0.8522727272727273,17,0.8095238095238095,1,1,results
77,Our shortcut - encoder was also the top singe - model ( non-ensemble ) result on the EMNLP RepEval Shared Task leaderboard .,Ablation Analysis Results,Ablation Analysis Results,natural_language_inference,12,"['O', 'B', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.8571428571428571,76,0.8636363636363636,18,0.8571428571428571,1,1,results
78,"Next , for SNLI , we compare our shortcutstacked encoder with the current state - of - the - art encoders from the SNLI leaderboard ( https :// nlp.stanford.edu/projects/snli/ ) .",Ablation Analysis Results,Ablation Analysis Results,natural_language_inference,12,"['O', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.9047619047619048,77,0.875,19,0.9047619047619048,1,1,results
79,"We also compare to the recent biLSTM - Max Encoder of , which served as our model 's 1 - layer starting point .",Ablation Analysis Results,Ablation Analysis Results,natural_language_inference,12,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.9523809523809523,78,0.8863636363636364,20,0.9523809523809523,1,1,results
80,"The results indicate that ' Our Shortcut - Stacked Encoder ' sur-passes all the previous state - of - the - art encoders , and achieves the new best encoding - based result on SNLI , suggesting the general effectiveness of simple shortcut - connected stacked layers in sentence encoders .",Ablation Analysis Results,Ablation Analysis Results,natural_language_inference,12,"['O', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,1.0,79,0.8977272727272727,21,1.0,1,1,results
2,Multi-range Reasoning for Machine Comprehension,title,,natural_language_inference,13,"['O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.004366812227074236,1,0.0,1,1,research-problem
4,"We propose MRU ( Multi - Range Reasoning Units ) , a new fast compositional encoder for machine comprehension ( MC ) .",abstract,abstract,natural_language_inference,13,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.1111111111111111,3,0.013100436681222707,1,0.1111111111111111,1,1,research-problem
19,"While the usage of recurrent encoder is often regarded as indispensable in highly complex MC tasks , there are still several challenges and problems pertaining to it 's usage in modern MC tasks .",Introduction,Introduction,natural_language_inference,13,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.0759493670886076,18,0.07860262008733625,6,0.18181818181818182,1,1,research-problem
24,"To this end , we propose a new compositional encoder that can either be used in - place of standard RNN encoders or serve as a new module that is complementary to existing neural architectures .",Introduction,Introduction,natural_language_inference,13,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",11,0.13924050632911392,23,0.10043668122270742,11,0.3333333333333333,1,1,model
25,Our proposed MRU encoders learns gating vectors via multiple contract - and - expand layers at multiple dilated resolutions .,Introduction,Introduction,natural_language_inference,13,"['B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.1518987341772152,24,0.10480349344978165,12,0.36363636363636365,1,1,model
26,"Specifically , we compress the input document an arbitrary k times at multi-ranges ( e.g. , 1 , 2 , 4 , 10 , 25 ) into a neural bag - of - words ( summed ) representation .",Introduction,Introduction,natural_language_inference,13,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",13,0.16455696202531644,25,0.1091703056768559,13,0.3939393939393939,1,1,model
27,The compact sequence is then passed through affine transformation layers and then re-expanded to the original sequence length .,Introduction,Introduction,natural_language_inference,13,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",14,0.17721518987341772,26,0.11353711790393013,14,0.42424242424242425,1,1,model
28,The k document representations ( at multiple ranges and n-gram blocks ) are then combined and modeled with fully connected layers to form the final compositional gate which are applied onto the original input document .,Introduction,Introduction,natural_language_inference,13,"['O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",15,0.189873417721519,27,0.11790393013100436,15,0.45454545454545453,1,1,model
153,"RACE - the key competitors are the Stanford Attention Reader ( Stanford AR ) , Gated Attention Reader ( GA ) , and Dynamic Fusion Networks ( DFN ) .",Competitor Methods,Competitor Methods,natural_language_inference,13,"['B', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.16666666666666666,152,0.6637554585152838,2,0.16666666666666666,1,1,baselines
157,Search QA - the main competitor baseline is the AMANDA model proposed by .,Competitor Methods,Competitor Methods,natural_language_inference,13,"['B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O']",6,0.5,156,0.6812227074235808,6,0.5,1,1,baselines
161,NarrativeQA,Competitor Methods,,natural_language_inference,13,['B'],['B-n'],['B-b'],10,0.8333333333333334,160,0.6986899563318777,10,0.8333333333333334,1,1,baselines
163,"We compete on the summaries setting , in which the baselines are a context - less sequence to sequence ( seq2seq ) model , ASR and BiDAF .",Competitor Methods,NarrativeQA,natural_language_inference,13,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'B-ob', 'O']",12,1.0,162,0.7074235807860262,12,1.0,1,1,baselines
176,We implement all models in TensorFlow .,Implementation Details,Implementation Details,natural_language_inference,13,"['O', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",1,0.25,175,0.7641921397379913,1,0.25,1,1,experimental-setup
177,Word embeddings are initialized with 300d Glo Ve vectors and are not fine - tuned during training .,Implementation Details,Implementation Details,natural_language_inference,13,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'O']",2,0.5,176,0.7685589519650655,2,0.5,1,1,experimental-setup
178,"Dropout rate is tuned amongst { 0.1 , 0.2 , 0.3 } on all layers including the embedding layer .",Implementation Details,Implementation Details,natural_language_inference,13,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",3,0.75,177,0.7729257641921398,3,0.75,1,1,experimental-setup
185,We adopt the Adam optimizer with a learning rate of 0.0003/ 0.001/0.001 for RACE / SearchQA / NarrativeQA respectively .,Dev Test Model,Dev Test Model,natural_language_inference,13,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",5,0.38461538461538464,184,0.8034934497816594,5,0.38461538461538464,1,1,experimental-setup
186,The batch size is set to 64/256/32 accordingly .,Dev Test Model,Dev Test Model,natural_language_inference,13,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O']",6,0.46153846153846156,185,0.8078602620087336,6,0.46153846153846156,1,1,experimental-setup
187,The maximum sequence lengths are 500/200/1100 respectively .,Dev Test Model,Dev Test Model,natural_language_inference,13,"['O', 'B', 'I', 'I', 'B', 'B', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O']",7,0.5384615384615384,186,0.8122270742358079,7,0.5384615384615384,1,1,experimental-setup
189,All models are trained and all runtime benchmarks are based on a TitanXP GPU .,Dev Test Model,Dev Test Model,natural_language_inference,13,"['B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O']",9,0.6923076923076923,188,0.8209606986899564,9,0.6923076923076923,1,1,experimental-setup
190,"Overall , there is a 6 % improvement on the RACE - H dataset and 1.8 % improvement on the RACE - M dataset .",Dev Test Model,Dev Test Model,natural_language_inference,13,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']",,,10,0.7692307692307693,189,0.8253275109170306,10,0.7692307692307693,1,1,results
194,Experimental Results on RACE,,,natural_language_inference,13,"['O', 'O', 'B', 'B']","['O', 'O', 'B-p', 'B-n']","['O', 'O', 'B-p', 'B-b']",0,0.0,193,0.8427947598253275,0,0.0,1,1,results
195,"In general , we also found that the usage of a recurrent cell is not really crucial on this dataset since ( 1 ) Sim . MRU and MRU can achieve comparable performance to each other , ( 2 ) GRU and LSTM models do not have a competitive edge and ( 3 ) Using no encoder already achieves comparable 1 performance to DFN .",Experimental Results on RACE,Experimental Results on RACE,natural_language_inference,13,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'O']",,,1,0.07692307692307693,194,0.8471615720524017,1,0.07692307692307693,1,1,results
196,"Finally , an ensemble of Sim . MRU models achieve state - of - the - art performance on the RACE dataset , achieving and over all score of 53.3 % . :",Experimental Results on RACE,Experimental Results on RACE,natural_language_inference,13,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O']",2,0.15384615384615385,195,0.851528384279476,2,0.15384615384615385,1,1,results
198,are baselines reported by . reports our results on the Narrative QA benchmark .,Experimental Results on RACE,Experimental Results on RACE,natural_language_inference,13,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O']",4,0.3076923076923077,197,0.8602620087336245,4,0.3076923076923077,1,1,results
199,"First , we observe that 300d MRU can achieve comparable performance with BiDAF .",Experimental Results on RACE,Experimental Results on RACE,natural_language_inference,13,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",5,0.38461538461538464,198,0.8646288209606987,5,0.38461538461538464,1,1,results
200,"When compared with a BiLSTM of equal output dimensions ( 150 d ) , we find that our MRU model performs competitively , with less than 1 % deprovement across all metrics .",Experimental Results on RACE,Experimental Results on RACE,natural_language_inference,13,"['O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",6,0.46153846153846156,199,0.868995633187773,6,0.46153846153846156,1,1,results
202,The performance of our model is significantly better than 300d LSTM model while also being significantly faster .,Experimental Results on RACE,Experimental Results on RACE,natural_language_inference,13,"['O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",8,0.6153846153846154,201,0.8777292576419214,8,0.6153846153846154,1,1,results
206,"Finally , the MRU - LSTM significantly outperforms all models , including BiDAF on this dataset .",Experimental Results on RACE,Experimental Results on RACE,natural_language_inference,13,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-b', 'I-b', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'O']",12,0.9230769230769231,205,0.8951965065502183,12,0.9230769230769231,1,1,results
207,"Performance improvement over the vanilla BiLSTM model ranges from 1 % ? 3 % across all metrics , suggesting that MRU encoders are also effective as a complementary neural building block .",Experimental Results on RACE,Experimental Results on RACE,natural_language_inference,13,"['B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,1.0,206,0.8995633187772926,13,1.0,1,1,results
2,CODAH : An Adversarially - Authored Question Answering Dataset for Common Sense,title,title,natural_language_inference,14,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.005847953216374269,1,0.0,1,1,research-problem
4,"Commonsense reasoning is a critical AI capability , but it is difficult to construct challenging datasets that test commonsense .",abstract,abstract,natural_language_inference,14,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.1,3,0.017543859649122806,1,0.1,1,1,research-problem
16,The rise of datadriven methods has led to interest in developing large datasets for commonsense reasoning over text .,Introduction,Introduction,natural_language_inference,14,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.1111111111111111,15,0.08771929824561403,2,0.1111111111111111,1,1,research-problem
24,"In this work , we introduce the COmmonsense Dataset Adversarially - authored by Humans ( CODAH ) for commonsense question answering in the style of SWAG multiple choice sentence completion .",Introduction,Introduction,natural_language_inference,14,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.5555555555555556,23,0.13450292397660818,10,0.5555555555555556,1,1,research-problem
25,"We propose a novel method for question generation , in which human annotators are educated on the workings of a state - of - the - art question answering model , and are asked to submit questions that adversarially target the weaknesses .",Introduction,Introduction,natural_language_inference,14,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",11,0.6111111111111112,24,0.14035087719298245,11,0.6111111111111112,1,1,model
26,"Annotators are rewarded for submissions in which the model fails to identify the correct sentence completion both before and after fine - tuning on a sample of the submitted questions , encouraging the creation of questions that are not easily learnable .",Introduction,Introduction,natural_language_inference,14,"['B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.6666666666666666,25,0.14619883040935672,12,0.6666666666666666,1,1,model
51,The full dataset is available at https://github.com/Websail-NU /CODAH .,Related Work,The CODAH Dataset,natural_language_inference,14,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",18,0.47368421052631576,50,0.29239766081871343,5,1.0,0,1,code
114,"Also , when training the initial SWAG model we use the hyperparameters recommended in the BERT paper , namely a batch size of 16 , learning rate of 2 e - 5 , and 3 epochs .",Model Evaluation,Hyperparameter Search,natural_language_inference,14,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'O']",,,23,0.8214285714285714,113,0.6608187134502924,23,0.8214285714285714,1,1,hyperparameters
115,"In our initial experiments , we found that a lower learning rate and more training epochs produced higher accuracy on CODAH , so we replaced the 5e - 5 learning rate in the original grid search with 1 e - 5 , and we added a 6 - epoch setting .",Model Evaluation,Hyperparameter Search,natural_language_inference,14,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",24,0.8571428571428571,114,0.6666666666666666,24,0.8571428571428571,1,1,hyperparameters
116,The final hyperparameter grid is as follows :,Model Evaluation,Hyperparameter Search,natural_language_inference,14,"['O', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O']",25,0.8928571428571429,115,0.672514619883041,25,0.8928571428571429,1,1,hyperparameters
117,"Batch size : 16 , 32 Learning rate : 1 e - 5 , 2 e - 5 , 3 e - 5 Number of epochs : 3 , 4 , 6 In addition , we observed that in rare cases BERT fails to train ; that is , after several training epochs it has accuracy approximately equal to that of random guessing .",Model Evaluation,Hyperparameter Search,natural_language_inference,14,"['B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",26,0.9285714285714286,116,0.6783625730994152,26,0.9285714285714286,1,1,hyperparameters
122,"As a baseline , we evaluate both models on the full SWAG training and validation sets , providing an accuracy of 84.2 % on BERT and 80.2 % on GPT .",Results,Results,natural_language_inference,14,"['B', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,2,0.3333333333333333,121,0.7076023391812866,2,0.3333333333333333,1,1,results
123,"To adjust for the difference in size between our dataset and SWAG , we also train the models on a sample of 2,241 SWAG questions ( the size of the training set in each of CODAH 's crossvalidation folds ) and evaluate them on the full SWAG validation set .",Results,Results,natural_language_inference,14,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']",,,3,0.5,122,0.7134502923976608,3,0.5,1,1,results
124,This produces an accuracy of 75.2 % for BERT ( using the cross-validation grid search ) and 63.6 % for GPT . :,Results,Results,natural_language_inference,14,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'O']",,,4,0.6666666666666666,123,0.7192982456140351,4,0.6666666666666666,1,1,results
2,Semantic Sentence Matching with Densely - connected Recurrent and Co - attentive Information,title,title,natural_language_inference,15,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.004424778761061947,1,0.0,1,1,research-problem
4,"Sentence matching is widely used in various natural language tasks such as natural language inference , paraphrase identification , and question answering .",abstract,abstract,natural_language_inference,15,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.125,3,0.01327433628318584,1,0.125,1,1,research-problem
31,"Inspired by Densenet ) , we propose a densely - connected recurrent network where the recurrent hidden features are retained to the uppermost layer .",Introduction,Introduction,natural_language_inference,15,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",19,0.6551724137931034,30,0.13274336283185842,19,0.6551724137931034,1,1,model
32,"In addition , instead of the conventional summation operation , the concatenation operation is used in combination with the attention mechanism to preserve co-attentive information better .",Introduction,Introduction,natural_language_inference,15,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'B-ob', 'O']",20,0.6896551724137931,31,0.13716814159292035,20,0.6896551724137931,1,1,model
33,The proposed architecture shown in is called DRCN which is an abbreviation for Densely - connected Recurrent and Co -attentive neural Network .,Introduction,Introduction,natural_language_inference,15,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",21,0.7241379310344828,32,0.1415929203539823,21,0.7241379310344828,1,1,model
34,The proposed DRCN can utilize the increased representational power of deeper recurrent networks and attentive information .,Introduction,Introduction,natural_language_inference,15,"['O', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",22,0.7586206896551724,33,0.14601769911504425,22,0.7586206896551724,1,1,model
35,"Furthermore , to alleviate the problem of an ever- increasing feature vector size due to concatenation operations , we adopted an autoencoder and forwarded a fixed length vector to the higher layer recurrent module as shown in the figure .",Introduction,Introduction,natural_language_inference,15,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",23,0.7931034482758621,34,0.1504424778761062,23,0.7931034482758621,1,1,model
113,"We initialized word embedding with 300d Glo Ve vectors pre-trained from the 840B Common Crawl corpus ( Pennington , Socher , and Manning 2014 ) , while the word embeddings for the out - of - vocabulary words were initialized randomly .",Implementation Details,Implementation Details,natural_language_inference,15,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'O']",,,1,0.07142857142857142,112,0.49557522123893805,1,0.07142857142857142,1,1,hyperparameters
114,We also randomly initialized character embedding with a 16d vector and extracted 32d character representation with a convolutional network .,Implementation Details,Implementation Details,natural_language_inference,15,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,2,0.14285714285714285,113,0.5,2,0.14285714285714285,1,1,hyperparameters
115,"For the densely - connected recurrent layers , we stacked 5 layers each of which have 100 hidden units .",Implementation Details,Implementation Details,natural_language_inference,15,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.21428571428571427,114,0.504424778761062,3,0.21428571428571427,1,1,hyperparameters
116,We set 1000 hidden units with respect to the fullyconnected layers .,Implementation Details,Implementation Details,natural_language_inference,15,"['O', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",4,0.2857142857142857,115,0.5088495575221239,4,0.2857142857142857,1,1,hyperparameters
117,The dropout was applied after the word and character embedding layers with a keep rate of 0.5 .,Implementation Details,Implementation Details,natural_language_inference,15,"['O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",5,0.35714285714285715,116,0.5132743362831859,5,0.35714285714285715,1,1,hyperparameters
118,It was also applied before the fully - connected layers with a keep rate of 0.8 .,Implementation Details,Implementation Details,natural_language_inference,15,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",6,0.42857142857142855,117,0.5176991150442478,6,0.42857142857142855,1,1,hyperparameters
119,"For the bottleneck component , we set 200 hidden units as encoded features of the autoencoder with a dropout rate of 0.2 .",Implementation Details,Implementation Details,natural_language_inference,15,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,7,0.5,118,0.5221238938053098,7,0.5,1,1,hyperparameters
120,"The batch normalization was applied on the fully - connected layers , only for the one - way type datasets .",Implementation Details,Implementation Details,natural_language_inference,15,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.5714285714285714,119,0.5265486725663717,8,0.5714285714285714,1,1,hyperparameters
121,The RMSProp optimizer with an initial learning rate of 0.001 was applied .,Implementation Details,Implementation Details,natural_language_inference,15,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O']",9,0.6428571428571429,120,0.5309734513274337,9,0.6428571428571429,1,1,hyperparameters
122,The learning rate was decreased by a factor of 0.85 when the dev accuracy does not improve .,Implementation Details,Implementation Details,natural_language_inference,15,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.7142857142857143,121,0.5353982300884956,10,0.7142857142857143,1,1,hyperparameters
123,All weights except embedding matrices are constrained by L2 regularization with a regularization constant ? = 10 ?6 .,Implementation Details,Implementation Details,natural_language_inference,15,"['O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.7857142857142857,122,0.5398230088495575,11,0.7857142857142857,1,1,hyperparameters
124,"The sequence lengths of the sentence are all different for each dataset : 35 for SNLI , 55 for MultiNLI , 25 for Quora question pair and 50 for TrecQA .",Implementation Details,Implementation Details,natural_language_inference,15,"['O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'O']",,,12,0.8571428571428571,123,0.5442477876106194,12,0.8571428571428571,1,1,hyperparameters
133,The proposed DRCN obtains an accuracy of 88.9 % which is a competitive score although we do not use any external knowledge like ESIM + ELMo and LM - Transformer .,Experimental Results,Experimental Results,natural_language_inference,15,"['O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.25,132,0.584070796460177,5,0.22727272727272727,1,1,results
134,"The ensemble model achieves an accuracy of 90.1 % , which sets the new state - of the - art performance .",Experimental Results,Experimental Results,natural_language_inference,15,"['O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.2916666666666667,133,0.588495575221239,6,0.2727272727272727,1,1,results
135,Our ensemble model with 53 m parameters ( 6.7 m 8 ) outperforms the LM - Transformer whose the number of parameters is 85 m .,Experimental Results,Experimental Results,natural_language_inference,15,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.3333333333333333,134,0.5929203539823009,7,0.3181818181818182,1,1,results
136,"Furthermore , in case of the encoding - based method , we obtain the best performance of 86.5 % without the co-attention and exact match flag .",Experimental Results,Experimental Results,natural_language_inference,15,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.375,135,0.5973451327433629,8,0.36363636363636365,1,1,results
137,shows the results on MATCHED and MISMATCHED problems of MultiNLI dataset .,Experimental Results,Experimental Results,natural_language_inference,15,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O']",10,0.4166666666666667,136,0.6017699115044248,9,0.4090909090909091,1,1,results
138,Our plain DRCN has a competitive performance without any contextualized knowledge .,Experimental Results,Experimental Results,natural_language_inference,15,"['B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",11,0.4583333333333333,137,0.6061946902654868,10,0.45454545454545453,1,1,results
139,"And , by combining DRCN with the ELMo , one of the contextualized embeddings from language models , our model outperforms the LM - Transformer which has 85 m parameters with fewer parameters of 61 m .",Experimental Results,Experimental Results,natural_language_inference,15,"['O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O']",,,12,0.5,138,0.6106194690265486,11,0.5,1,1,results
145,Pair shows our results on the Quora question pair dataset .,Experimental Results,Quora Question,natural_language_inference,15,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",18,0.75,144,0.6371681415929203,17,0.7727272727272727,1,1,results
147,"We obtained accuracies of 90.15 % and 91.30 % in single and ensemble methods , respectively , surpassing the previous state - of - the - art model of DIIN .",Experimental Results,Quora Question,natural_language_inference,15,"['O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O']",,,20,0.8333333333333334,146,0.6460176991150443,19,0.8636363636363636,1,1,results
148,TrecQA and SelQA shows the performance of different models on TrecQA and SelQA datasets for answer sentence selection task that aims to select a set of candidate answer sentences given a question .,Experimental Results,Quora Question,natural_language_inference,15,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.875,147,0.6504424778761062,20,0.9090909090909091,1,1,results
150,"However , the proposed DRCN using collective attentions over multiple layers , achieves the new state - of the - art performance , exceeding the current state - of - the - art performance significantly on both datasets .",Experimental Results,Quora Question,natural_language_inference,15,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-ob', 'O', 'O', 'O', 'O']",23,0.9583333333333334,149,0.6592920353982301,22,1.0,1,1,results
156,"Although the number of parameters in the DRCN significantly decreased as shown in , we could see that the performance was rather higher because of the regularization effect .",Ablation study,Ablation study,natural_language_inference,15,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",4,0.08695652173913043,155,0.6858407079646017,5,0.12195121951219512,1,1,ablation-analysis
162,The result shows that the dense connections over attentive features are more effective .,Ablation study,Ablation study,natural_language_inference,15,"['O', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",10,0.21739130434782608,161,0.7123893805309734,11,0.2682926829268293,1,1,ablation-analysis
163,"In , we removed dense connections over both co-attentive and recurrent features , and the performance degraded to 88.5 % .",Ablation study,Ablation study,natural_language_inference,15,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.2391304347826087,162,0.7168141592920354,12,0.2926829268292683,1,1,ablation-analysis
167,"The results of ( 8 - 9 ) demonstrate that the dense connection using concatenation operation over deeper layers , has more powerful capability retaining collective knowledge to learn textual semantics .",Ablation study,Ablation study,natural_language_inference,15,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",15,0.32608695652173914,166,0.7345132743362832,16,0.3902439024390244,1,1,ablation-analysis
169,The result of ( 10 ) shows that the connections among the layers are important to help gradient flow .,Ablation study,Ablation study,natural_language_inference,15,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",17,0.3695652173913043,168,0.7433628318584071,18,0.43902439024390244,1,1,ablation-analysis
170,"And , the result of ( 11 ) shows that the attentive information functioning as a soft - alignment is significantly effective in semantic sentence matching .",Ablation study,Ablation study,natural_language_inference,15,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",18,0.391304347826087,169,0.7477876106194691,19,0.4634146341463415,1,1,ablation-analysis
172,"The models ( 5 - 9 ) which have connections between layers , are more robust to the increased depth of network , however , the performances of ( 10 - 11 ) tend to degrade as layers get deeper .",Ablation study,Ablation study,natural_language_inference,15,"['O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'B', 'O']",,,20,0.43478260869565216,171,0.7566371681415929,21,0.5121951219512195,1,1,ablation-analysis
173,"In addition , the models with dense connections rather than residual connections , have higher performance in general .",Ablation study,Ablation study,natural_language_inference,15,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O']",21,0.45652173913043476,172,0.7610619469026548,22,0.5365853658536586,1,1,ablation-analysis
174,"shows that the connection between layers is essential , especially in deep models , endowing more representational power , and the dense connection is more effective than the residual connection .",Ablation study,Ablation study,natural_language_inference,15,"['O', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,22,0.4782608695652174,173,0.7654867256637168,23,0.5609756097560976,1,1,ablation-analysis
4,Natural language sentence matching is a fundamental technology for a variety of tasks .,abstract,abstract,natural_language_inference,16,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.1,3,0.014084507042253521,1,0.1,1,1,research-problem
15,Natural language sentence matching ( NLSM ) is the task of comparing two sentences and identifying the relationship between them .,Introduction,Introduction,natural_language_inference,16,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.02631578947368421,14,0.06572769953051644,1,0.03225806451612903,1,1,research-problem
17,"For example , in a paraphrase identification task , NLSM is used to determine whether two sentences are paraphrase or not .",Introduction,Introduction,natural_language_inference,16,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.07894736842105263,16,0.07511737089201878,3,0.0967741935483871,1,1,research-problem
32,"In this paper , to tackle these limitations , we propose a bilateral multi-perspective matching ( BiMPM ) model for NLSM tasks .",Introduction,Introduction,natural_language_inference,16,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",18,0.47368421052631576,31,0.14553990610328638,18,0.5806451612903226,1,1,model
33,"Our model essentially belongs to the "" matching aggregation "" framework .",Introduction,Introduction,natural_language_inference,16,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.5,32,0.15023474178403756,19,0.6129032258064516,1,1,model
39,"Then , another BiLSTM layer is utilized to aggregate the matching results into a fixed - length matching vector .",Introduction,Q .,natural_language_inference,16,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",25,0.6578947368421053,38,0.1784037558685446,25,0.8064516129032258,1,1,model
40,"Finally , based on the matching vector , a decision is made through a fully connected layer .",Introduction,Q .,natural_language_inference,16,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",26,0.6842105263157895,39,0.18309859154929578,26,0.8387096774193549,1,1,model
130,We initialize word embeddings in the word representation layer with the 300 - dimensional GloVe word vectors pretrained from the 840B Common Crawl corpus .,Experiment Settings,Experiment Settings,natural_language_inference,16,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.1111111111111111,129,0.6056338028169014,1,0.1111111111111111,1,1,hyperparameters
131,"For the out - of - vocabulary ( OOV ) words , we initialize the word embeddings randomly .",Experiment Settings,Experiment Settings,natural_language_inference,16,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-ob', 'O']",2,0.2222222222222222,130,0.6103286384976526,2,0.2222222222222222,1,1,hyperparameters
132,"For the charactercomposed embeddings , we initialize each character as a 20 - dimensional vector , and compose each word into a 50 dimensional vector with a LSTM layer .",Experiment Settings,Experiment Settings,natural_language_inference,16,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",3,0.3333333333333333,131,0.6150234741784038,3,0.3333333333333333,1,1,hyperparameters
133,We set the hidden size as 100 for all BiLSTM layers .,Experiment Settings,Experiment Settings,natural_language_inference,16,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.4444444444444444,132,0.6197183098591549,4,0.4444444444444444,1,1,hyperparameters
134,"We apply dropout to every layers in , and set the dropout ratio as 0.1 .",Experiment Settings,Experiment Settings,natural_language_inference,16,"['O', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",5,0.5555555555555556,133,0.6244131455399061,5,0.5555555555555556,1,1,hyperparameters
135,"To train the model , we minimize the cross entropy of the training set , and use the ADAM optimizer [ Kingma and Ba , 2014 ] to update parameters .",Experiment Settings,Experiment Settings,natural_language_inference,16,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",6,0.6666666666666666,134,0.6291079812206573,6,0.6666666666666666,1,1,hyperparameters
136,We set the learning rate as 0.001 .,Experiment Settings,Experiment Settings,natural_language_inference,16,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",7,0.7777777777777778,135,0.6338028169014085,7,0.7777777777777778,1,1,hyperparameters
137,"During training , we do not update the pre-trained word embeddings .",Experiment Settings,Experiment Settings,natural_language_inference,16,"['B', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.8888888888888888,136,0.6384976525821596,8,0.8888888888888888,1,1,hyperparameters
163,"In this Sub-section , we compare our model with state - of - theart models on the paraphrase identification task .",Experiments on Paraphrase Identification,Experiments on Paraphrase Identification,natural_language_inference,16,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-s', 'I-s', 'I-s', 'O']",1,0.03225806451612903,162,0.7605633802816901,1,0.06666666666666667,1,1,experiments
164,"We still experiment on the "" Quora Question Pairs "" dataset , and use the same dataset partition as Sub-section 4.2 .",Experiments on Paraphrase Identification,Experiments on Paraphrase Identification,natural_language_inference,16,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.06451612903225806,163,0.7652582159624414,2,0.13333333333333333,1,1,experiments
167,"First , under the Siamese framework , we implement two baseline models : "" Siamese - CNN "" and "" Siamese - LSTM "" .",Experiments on Paraphrase Identification,Experiments on Paraphrase Identification,natural_language_inference,16,"['O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",5,0.16129032258064516,166,0.7793427230046949,5,0.3333333333333333,1,1,experiments
171,"Second , based on the two baseline models , we implement two more baseline models "" Multi - Perspective - CNN "" and "" Multi - Perspective - LSTM "" .",Experiments on Paraphrase Identification,Experiments on Paraphrase Identification,natural_language_inference,16,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O']",,,9,0.2903225806451613,170,0.7981220657276995,9,0.6,1,1,experiments
173,"Third , we re-implement the "" L.D.C. "" model proposed by , which is a model under the "" matchingaggregation "" framework and acquires the state - of - the - art performance on several tasks .",Experiments on Paraphrase Identification,Experiments on Paraphrase Identification,natural_language_inference,16,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O']",,,11,0.3548387096774194,172,0.8075117370892019,11,0.7333333333333333,1,1,experiments
175,"We can see that "" Multi - Perspective - CNN "" ( or "" Multi- Perspective - LSTM "" ) works much better than "" Siamese - CNN "" ( or "" Siamese - LSTM "" ) , which further indicates that our multi-perspective cosine matching func - Models Accuracy 81.4 82.1 83.5 85.0 85.1 86.1 86.3 86.8 87.3 87.5 tion ( Eq. ) is very effective for matching vectors .",Experiments on Paraphrase Identification,Experiments on Paraphrase Identification,natural_language_inference,16,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.41935483870967744,174,0.8169014084507042,13,0.8666666666666667,1,1,experiments
176,"Our "" BiMPM "" model outperforms the "" L.D.C. "" model by more than two percent .",Experiments on Paraphrase Identification,Experiments on Paraphrase Identification,natural_language_inference,16,"['B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.45161290322580644,175,0.8215962441314554,14,0.9333333333333333,1,1,experiments
179,"In this Sub-section , we evaluate our model on the natural language inference task over the SNLI dataset .",Experiments on Paraphrase Identification,Experiments on Natural Language Inference,natural_language_inference,16,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O']",17,0.5483870967741935,178,0.8356807511737089,1,0.125,1,1,experiments
183,"First , we can see that "" Only P ? Q "" works significantly better than "" Only P ? Q "" , which tells us that , for natural language inference , matching the hypothesis against the premise is more effective than the other way around .",Experiments on Paraphrase Identification,Experiments on Natural Language Inference,natural_language_inference,16,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']",,,21,0.6774193548387096,182,0.8544600938967136,5,0.625,1,1,experiments
184,"Second , our "" BiMPM "" model works much better than "" Only P ? Q "" , which reveals that matching premise against the hypothesis can also bring some benefits .",Experiments on Paraphrase Identification,Experiments on Natural Language Inference,natural_language_inference,16,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.7096774193548387,183,0.8591549295774648,6,0.75,1,1,experiments
185,"Finally , comparing our models with all the state - of - the - art models , we can observe that our single model "" BiMPM "" is on par with the state - of - the - art single models , and our ' BiMPM ( Ensemble ) "" works much better than "" ( Ensemble ) "" .",Experiments on Paraphrase Identification,Experiments on Natural Language Inference,natural_language_inference,16,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'O', 'O', 'B', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'O', 'B-ob', 'O', 'O', 'O']",23,0.7419354838709677,184,0.863849765258216,7,0.875,1,1,experiments
186,"Therefore , our models achieve the state - of - the - art performance in both single and ensemble scenarios for the natural language inference task .",Experiments on Paraphrase Identification,Experiments on Natural Language Inference,natural_language_inference,16,"['O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",24,0.7741935483870968,185,0.8685446009389671,8,1.0,1,1,experiments
188,"In this Sub-section , we study the effectiveness of our model for answer sentence selection tasks .",Experiments on Paraphrase Identification,Experiments on Answer Sentence Selection,natural_language_inference,16,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",26,0.8387096774193549,187,0.8779342723004695,1,0.16666666666666666,1,1,experiments
190,We experiment on two datasets : TREC - QA and WikiQA .,Experiments on Paraphrase Identification,Experiments on Answer Sentence Selection,natural_language_inference,16,"['O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O']",28,0.9032258064516129,189,0.8873239436619719,3,0.5,1,1,experiments
192,We can see that the performance from our model is on par with the state - of - the - art models .,Experiments on Paraphrase Identification,Experiments on Answer Sentence Selection,natural_language_inference,16,"['O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",30,0.967741935483871,191,0.8967136150234741,5,0.8333333333333334,1,1,experiments
2,Reinforced Mnemonic Reader for Machine Reading Comprehension,title,,natural_language_inference,17,"['O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0038461538461538464,1,0.0,1,1,research-problem
27,"To address the first problem , we present a reattention mechanism that temporally memorizes past attentions and uses them to refine current attentions in a multi-round alignment architecture .",Introduction,Introduction,natural_language_inference,17,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.5151515151515151,26,0.1,17,0.5862068965517241,1,1,model
28,"The computation is based on the fact that two words should share similar semantics if their attentions about same texts are highly overlapped , and be less similar vice versa .",Introduction,Introduction,natural_language_inference,17,"['O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O']",18,0.5454545454545454,27,0.10384615384615385,18,0.6206896551724138,1,1,model
29,"Therefore , the reattention can be more concentrated if past attentions focus on same parts of the input , or be relatively more distracted so as to focus on new regions if past attentions are not overlapped at all .",Introduction,Introduction,natural_language_inference,17,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']",,,19,0.5757575757575758,28,0.1076923076923077,19,0.6551724137931034,1,1,model
30,"As for the second problem , we extend the traditional training method with a novel approach called dynamic - critical reinforcement learning .",Introduction,Introduction,natural_language_inference,17,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",20,0.6060606060606061,29,0.11153846153846154,20,0.6896551724137931,1,1,model
31,"Unlike the traditional reinforcement learning algorithm where the reward and baseline are statically sampled , our approach dynamically decides the reward and the baseline according to two sampling strategies , Context : The American Football Conference ( AFC ) champion Denver Broncos defeated the National Football Conference ( NFC ) champion Carolina Panthers 24 - 10 to earn their third Super Bowl title .",Introduction,Introduction,natural_language_inference,17,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.6363636363636364,30,0.11538461538461539,21,0.7241379310344828,1,1,model
190,"We use the Adam optimizer [ Kingma and Ba , 2014 ] for both ML and DCRL training .",Implementation Details,Implementation Details,natural_language_inference,17,"['O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.6153846153846154,189,0.7269230769230769,8,0.6153846153846154,1,1,hyperparameters
191,"The initial learning rates are 0.0008 and 0.0001 respectively , and are halved whenever meeting a bad iteration .",Implementation Details,Implementation Details,natural_language_inference,17,"['O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.6923076923076923,190,0.7307692307692307,9,0.6923076923076923,1,1,hyperparameters
192,The batch size is 48 and a dropout rate of 0.3 is used to prevent overfitting .,Implementation Details,Implementation Details,natural_language_inference,17,"['O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'B-b', 'O']",10,0.7692307692307693,191,0.7346153846153847,10,0.7692307692307693,1,1,hyperparameters
193,Word embeddings remain fixed during training .,Implementation Details,Implementation Details,natural_language_inference,17,"['B', 'I', 'B', 'B', 'B', 'B', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O']",11,0.8461538461538461,192,0.7384615384615385,11,0.8461538461538461,1,1,hyperparameters
194,"For out of vocabulary words , we set the embeddings from Gaussian distributions and keep them trainable .",Implementation Details,Implementation Details,natural_language_inference,17,"['B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'O']",12,0.9230769230769231,193,0.7423076923076923,12,0.9230769230769231,1,1,hyperparameters
195,"The size of character embedding and corresponding LSTMs is 50 , the main hidden size is 100 , and the hyperparameter ? is 3 .",Implementation Details,Implementation Details,natural_language_inference,17,"['O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O']",,,13,1.0,194,0.7461538461538462,13,1.0,1,1,hyperparameters
198,We submitted our model on the hidden test set of SQuAD for evaluation .,Overall Results,Overall Results,natural_language_inference,17,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'O', 'O']",1,0.14285714285714285,197,0.7576923076923077,1,0.14285714285714285,1,1,results
200,"As shown in , R.M - Reader achieves an EM score of 79.5 % and F1 score of 86.6 % .",Overall Results,Overall Results,natural_language_inference,17,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']",,,3,0.42857142857142855,199,0.7653846153846153,3,0.42857142857142855,1,1,results
202,"Our ensemble model improves the metrics to 82.3 % and 88.5 % respectively 2 . shows the performance comparison on two adversarial datasets , Add Sent and Add OneSent .",Overall Results,Overall Results,natural_language_inference,17,"['B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.7142857142857143,201,0.7730769230769231,5,0.7142857142857143,1,1,results
204,"As we can see , R.M - Reader comfortably outperforms all previous models by more than 6 % in both EM and F 1 scores , indicating that our model is more robust against adversarial attacks .",Overall Results,Overall Results,natural_language_inference,17,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,1.0,203,0.7807692307692308,7,1.0,1,1,results
208,"We notice that reattention has more influences on EM score while DCRL contributes more to F1 metric , and removing both of them results in huge drops on both metrics .",Ablation Study,Ablation Study,natural_language_inference,17,"['O', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O']",,,3,0.06382978723404255,207,0.7961538461538461,3,0.23076923076923078,1,1,ablation-analysis
209,Replacing DCRL with SCST also causes a marginal decline of performance on both metrics .,Ablation Study,Ablation Study,natural_language_inference,17,"['B', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'B-p', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",4,0.0851063829787234,208,0.8,4,0.3076923076923077,1,1,ablation-analysis
210,"Next , we relace the default attention function with the dot product : f ( u , v ) = u v ( 5 ) , and both metrics suffer from degradations .",Ablation Study,Ablation Study,natural_language_inference,17,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",5,0.10638297872340426,209,0.8038461538461539,5,0.38461538461538464,1,1,ablation-analysis
212,"Removing any of the two heuristics leads to some performance declines , and heuristic subtraction is more effective than multiplication .",Ablation Study,Ablation Study,natural_language_inference,17,"['B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",7,0.14893617021276595,211,0.8115384615384615,7,0.5384615384615384,1,1,ablation-analysis
214,In both cases the highway - like function has outperformed its simpler variants .,Ablation Study,Ablation Study,natural_language_inference,17,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'O']",9,0.19148936170212766,213,0.8192307692307692,9,0.6923076923076923,1,1,ablation-analysis
216,"We notice that using 2 blocks causes a slight performance drop , while increasing to 4 blocks barely affects the SoTA result .",Ablation Study,Ablation Study,natural_language_inference,17,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",11,0.23404255319148937,215,0.8269230769230769,11,0.8461538461538461,1,1,ablation-analysis
217,"Interestingly , a very deep alignment with 5 blocks results in a significant performance decline .",Ablation Study,Ablation Study,natural_language_inference,17,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.2553191489361702,216,0.8307692307692308,12,0.9230769230769231,1,1,ablation-analysis
2,Neural Variational Inference for Text Processing Phil Blunsom 12,title,,natural_language_inference,18,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.003663003663003663,1,0.0,1,1,research-problem
22,"This paper introduces a neural variational framework for generative models of text , inspired by the variational autoencoder .",Introduction,Introduction,natural_language_inference,18,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",11,0.1774193548387097,21,0.07692307692307693,11,0.3793103448275862,1,1,model
23,"The principle idea is to build an inference network , implemented by a deep neural network conditioned on text , to approximate the intractable distributions over the latent variables .",Introduction,Introduction,natural_language_inference,18,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",12,0.1935483870967742,22,0.08058608058608059,12,0.41379310344827586,1,1,model
24,"Instead of providing an analytic approximation , as in traditional variational Bayes , neural variational inference learns to model the posterior probability , thus endowing the model with strong generalis ation abilities .",Introduction,Introduction,natural_language_inference,18,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.20967741935483872,23,0.08424908424908426,13,0.4482758620689655,1,1,model
27,"By using the reparameteris ation method , the inference network is trained through back - propagating unbiased and low variance gradients w.r.t. the latent variables .",Introduction,Introduction,natural_language_inference,18,"['O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",16,0.25806451612903225,26,0.09523809523809523,16,0.5517241379310345,1,1,model
28,"Within this framework , we propose a Neural Variational Document Model ( NVDM ) for document modelling and a Neural Answer Selection Model ( NASM ) for question answering , a task that selects the sentences that correctly answer a factoid question from a set of candidate sentences .",Introduction,Introduction,natural_language_inference,18,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,17,0.27419354838709675,27,0.0989010989010989,17,0.5862068965517241,1,1,model
31,A primary feature of NVDM is that each word is generated directly from a dense continuous document representation instead of the more common binary semantic vector .,Introduction,Introduction,natural_language_inference,18,"['O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",20,0.3225806451612903,30,0.10989010989010989,20,0.6896551724137931,1,1,model
33,The NASM ( is a supervised conditional model which imbues LSTMs with a latent stochastic attention mechanism to model the semantics of question - answer pairs and predict their relatedness .,Introduction,Introduction,natural_language_inference,18,"['O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",22,0.3548387096774194,32,0.11721611721611722,22,0.7586206896551724,1,1,model
34,The attention model is designed to focus on the phrases of an answer that are strongly connected to the question semantics and is modelled by a latent distribution .,Introduction,Introduction,natural_language_inference,18,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",23,0.3709677419354839,33,0.12087912087912088,23,0.7931034482758621,1,1,model
36,"Bayesian inference provides a natural safeguard against overfitting , especially as the training sets available for this task are small .",Introduction,Introduction,natural_language_inference,18,"['B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",25,0.4032258064516129,35,0.1282051282051282,25,0.8620689655172413,1,1,model
141,Experiments on Document Modelling,,,natural_language_inference,18,"['O', 'B', 'B', 'I']","['O', 'B-p', 'B-n', 'I-n']","['O', 'B-p', 'B-b', 'I-b']",0,0.0,140,0.5128205128205128,0,0.0,1,1,experiments
145,The experimental results indicate that NVDM achieves the best performance on both datasets .,Experiments on Document Modelling,Experiments on Document Modelling,natural_language_inference,18,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",4,0.2,144,0.5274725274725275,4,0.5714285714285714,1,1,experiments
146,"For the experiments on RCV1 - v2 dataset , the NVDM with latent variable of 50 dimension performs even better than the fDARN with 200 dimension .",Experiments on Document Modelling,Experiments on Document Modelling,natural_language_inference,18,"['B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O']",,,5,0.25,145,0.5311355311355311,5,0.7142857142857143,1,1,experiments
155,Dataset & Setup for Answer Sentence Selection,Experiments on Document Modelling,,natural_language_inference,18,"['O', 'O', 'O', 'B', 'B', 'I', 'I']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b']",14,0.7,154,0.5641025641025641,0,0.0,1,1,experiments
173,The word embeddings ( K = 50 ) are obtained by running the word2vec tool on the English Wikipedia dump and the AQUAINT 5 corpus .,Model +,Model +,natural_language_inference,18,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",11,0.16176470588235295,172,0.63003663003663,18,0.6428571428571429,1,1,experiments
174,"We use LSTMs with 3 layers and 50 hidden units , and apply 40 % dropout after the embedding layer .",Model +,Model +,natural_language_inference,18,"['O', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",12,0.17647058823529413,173,0.6336996336996337,19,0.6785714285714286,1,1,experiments
175,"For the construction of the inference network , we use an MLP ( Eq. 10 ) with 2 layers and tanh units of 50 dimension , and an MLP ( Eq. 17 ) with 2 layers and tanh units of 150 dimension for modelling the joint representation .",Model +,Model +,natural_language_inference,18,"['B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']",,,13,0.19117647058823528,174,0.6373626373626373,20,0.7142857142857143,1,1,experiments
176,"During training we carry out stochastic estimation by taking one sample for computing the gradients , while in prediction we use 20 samples to calculate the expectation of the lower bound .",Model +,Model +,natural_language_inference,18,"['B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'B-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",14,0.20588235294117646,175,0.6410256410256411,21,0.75,1,1,experiments
187,"The LSTM + Att performs slightly better than the vanilla LSTM model , and our NASM improves the results further .",Model +,Experiments on Answer Sentence Selection,natural_language_inference,18,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O']",25,0.36764705882352944,186,0.6813186813186813,3,0.42857142857142855,1,1,experiments
188,"Since the QASent dataset is biased towards lexical overlapping features , after combining with a co-occurrence word count feature , our best model NASM outperforms all the previous models , including both neural network based models and classifiers with a set of hand - crafted features ( e.g. LCLR ) .",Model +,Experiments on Answer Sentence Selection,natural_language_inference,18,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",26,0.38235294117647056,187,0.684981684981685,4,0.5714285714285714,1,1,experiments
189,"Similarly , on the Wik - iQA dataset , all of our models outperform the previous distributional models by a large margin .",Model +,Experiments on Answer Sentence Selection,natural_language_inference,18,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",27,0.39705882352941174,188,0.6886446886446886,5,0.7142857142857143,1,1,experiments
190,"By including a word count feature , our models improve further and achieve the state - of - the - art .",Model +,Experiments on Answer Sentence Selection,natural_language_inference,18,"['O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",28,0.4117647058823529,189,0.6923076923076923,6,0.8571428571428571,1,1,experiments
2,Distance - based Self - Attention Network for Natural Language Inference,title,title,natural_language_inference,19,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.00392156862745098,1,0.0,1,1,research-problem
10,"Our model shows good performance with NLI data , and it records the new state - of - the - art result with SNLI data .",abstract,abstract,natural_language_inference,19,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.5833333333333334,9,0.03529411764705882,7,0.5833333333333334,1,1,research-problem
18,"More recently , models incorporating attention mechanisms have shown good performance in machine translation , Natural Language Inference ( NLI ) , and Question Answering ( QA ) etc .",Introduction,Introduction,natural_language_inference,19,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.1,17,0.06666666666666667,2,0.1,1,1,research-problem
32,"To tackle this limitation , we propose Distancebased Self - Attention Network which introduces a distance mask which models the relative distance between words .",Introduction,Introduction,natural_language_inference,19,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",16,0.8,31,0.12156862745098039,16,0.8,1,1,model
33,"In conjunction with a directional mask , the distance mask allows us to incorporate complete positional information of words in our model .",Introduction,Introduction,natural_language_inference,19,"['B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",17,0.85,32,0.12549019607843137,17,0.85,1,1,model
165,We used the Glove 840B 300D 1 ( d e = 300 ) for the pre-trained word embedding without any finetuning .,Training Details,Training Details,natural_language_inference,19,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",1,0.125,164,0.6431372549019608,1,0.125,1,1,experimental-setup
166,This is to train the more universally usable sentence encoder .,Training Details,Training Details,natural_language_inference,19,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.25,165,0.6470588235294118,2,0.25,1,1,experimental-setup
167,"Layer normalization was applied to all linear projections of masked multihead attention , fusion gate , and multi-dimensional attention .",Training Details,Training Details,natural_language_inference,19,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O']",3,0.375,166,0.6509803921568628,3,0.375,1,1,experimental-setup
168,"We applied residual dropout as used in , with dropout to the output of masked multi-head attention and SF +H F +b F of fusion gate .",Training Details,Training Details,natural_language_inference,19,"['O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.5,167,0.6549019607843137,4,0.5,1,1,experimental-setup
170,"We set h = 5 , ? = 1.5 in the masked multi-head attention , and the dropout probability was set to 0.1 .",Training Details,Training Details,natural_language_inference,19,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']",,,6,0.75,169,0.6627450980392157,6,0.75,1,1,experimental-setup
171,"Batch size was 64 , and the model was trained with Adam optimizer , with a learning rate of 0.001 .",Training Details,Training Details,natural_language_inference,19,"['B', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",7,0.875,170,0.6666666666666666,7,0.875,1,1,experimental-setup
172,All models were implemented via Tensorflow on single Nvidia Geforce GTX 1080 Ti GPU .,Training Details,Training Details,natural_language_inference,19,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,1.0,171,0.6705882352941176,8,1.0,1,1,experimental-setup
174,Experimental results of SNLI data compared with the existing models on the SNLI leader - board 2 are shown in .,SNLI Results,SNLI Results,natural_language_inference,19,"['O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.09090909090909091,173,0.6784313725490196,1,0.09090909090909091,1,1,results
175,"Compared with the existing state - of - the - art model , the number of parameters and the training time increased , but our results show the new state - of - theart record .",SNLI Results,SNLI Results,natural_language_inference,19,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.18181818181818182,174,0.6823529411764706,2,0.18181818181818182,1,1,results
177,Results show that the addition of the distance mask improved the performance without significantly affecting the training time or increasing the number of parameters . 49.4 50.4 + Unigram and bigram features 99.7 78.2 Sentence encoding - based models 100D LSTM encoders 220 k 84.8 77.6 300D LSTM encoders 3.0 m 83.9 80.6 1024D GRU encoders 15 m 98.8 81.4 300D Tree - based CNN encoders 3.5 m 83.3 82.1 300D SPINN - PI encoders 3.7 m 89.2 83.2 600D Bi- LSTM encoders 2.0 m 86.4 83.3 300D NTI - SLSTM - LSTM encoders 4.0 m 82.5 83.4 600D Bi-LSTM encoders+intra-attention 2.8 m 84.5 84.2 300D NSE encoders 3.0 m 86.2 84.6 600D,SNLI Results,SNLI Results,natural_language_inference,19,"['O', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'B-b', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.36363636363636365,176,0.6901960784313725,4,0.36363636363636365,1,1,results
180,"2 The improvement of the test accuracy by introducing the distance mask is only by 0.3 % point , potentially because SNLI data mostly consist of short sentences .",SNLI Results,Directional Self - Attention Network,natural_language_inference,19,"['O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.6363636363636364,179,0.7019607843137254,7,0.6363636363636364,1,1,results
186,The results of applying SNLI best model to MultiNLI dataset without additional parameter tuning are presented in .,MultiNLI Results,MultiNLI Results,natural_language_inference,19,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.014285714285714285,185,0.7254901960784313,1,0.1,1,1,results
188,"Compared with the result of RepEVAL 2017 , we can see that the Distance - based Self - Attention Network performs well .",MultiNLI Results,MultiNLI Results,natural_language_inference,19,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",3,0.04285714285714286,187,0.7333333333333333,3,0.3,1,1,results
189,"When compared with the model of , our model showed similar average test accuracy with much lower number of parameters .",MultiNLI Results,MultiNLI Results,natural_language_inference,19,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.05714285714285714,188,0.7372549019607844,4,0.4,1,1,results
2,A Question - Focused Multi- Factor Attention Network for Question Answering,title,title,natural_language_inference,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.0037313432835820895,1,0.0,1,1,research-problem
4,Neural network models recently proposed for question answering ( QA ) primarily focus on capturing the passagequestion relation .,abstract,abstract,natural_language_inference,2,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.125,3,0.011194029850746268,1,0.125,1,1,research-problem
6,They also do not explicitly focus on the question and answer type which often plays a critical role in QA .,abstract,abstract,natural_language_inference,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O']",3,0.375,5,0.018656716417910446,3,0.375,1,1,research-problem
13,"In machine comprehension - based ( MC ) question answering ( QA ) , a machine is expected to provide an answer for a given question by understanding texts .",Introduction,Introduction,natural_language_inference,2,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.030303030303030304,12,0.04477611940298507,1,0.037037037037037035,1,1,research-problem
33,"In this work , we propose an end - to - end question - focused multi-factor attention network for document - based question answering ( AMANDA ) , which learns to aggregate evidence distributed across multiple sentences and identifies the important question words to help extract the answer .",Introduction,Trivia,natural_language_inference,2,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'O', 'B-ob', 'O']",21,0.6363636363636364,32,0.11940298507462686,21,0.7777777777777778,1,1,model
34,"Intuitively , AMANDA extracts the answer not only by synthesizing relevant facts from the passage but also by implicitly determining the suitable answer type during prediction .",Introduction,Trivia,natural_language_inference,2,"['O', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",22,0.6666666666666666,33,0.12313432835820895,22,0.8148148148148148,1,1,model
174,We tokenize the corpora with NLTK 2 .,Experimental Settings,Experimental Settings,natural_language_inference,2,"['O', 'B', 'O', 'B', 'B', 'B', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O']",1,0.05555555555555555,173,0.6455223880597015,1,0.05555555555555555,1,1,experimental-setup
175,"We use the 300 dimension pre-trained word vectors from GloVe ( Pennington , Socher , and Manning 2014 ) and we do not update them during training .",Experimental Settings,Experimental Settings,natural_language_inference,2,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.1111111111111111,174,0.6492537313432836,2,0.1111111111111111,1,1,experimental-setup
176,The out - of - vocabulary words are initialized with zero vectors .,Experimental Settings,Experimental Settings,natural_language_inference,2,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",3,0.16666666666666666,175,0.6529850746268657,3,0.16666666666666666,1,1,experimental-setup
177,We use 50 - dimension character - level embedding vectors .,Experimental Settings,Experimental Settings,natural_language_inference,2,"['O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.2222222222222222,176,0.6567164179104478,4,0.2222222222222222,1,1,experimental-setup
178,The number of hidden units in all the LSTMs is 150 .,Experimental Settings,Experimental Settings,natural_language_inference,2,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'O']",5,0.2777777777777778,177,0.6604477611940298,5,0.2777777777777778,1,1,experimental-setup
179,We use dropout ) with probability 0.3 for every learnable layer .,Experimental Settings,Experimental Settings,natural_language_inference,2,"['O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.3333333333333333,178,0.664179104477612,6,0.3333333333333333,1,1,experimental-setup
180,"For multi-factor attentive encoding , we choose 4 factors ( m ) based on our experimental findings ( refer to ) .",Experimental Settings,Experimental Settings,natural_language_inference,2,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.3888888888888889,179,0.667910447761194,7,0.3888888888888889,1,1,experimental-setup
181,"During training , the minibatch size is fixed at 60 .",Experimental Settings,Experimental Settings,natural_language_inference,2,"['B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",8,0.4444444444444444,180,0.6716417910447762,8,0.4444444444444444,1,1,experimental-setup
182,We use the Adam optimizer with learning rate of 0.001 and clipnorm of 5 .,Experimental Settings,Experimental Settings,natural_language_inference,2,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'B', 'O']",,,9,0.5,181,0.6753731343283582,9,0.5,1,1,experimental-setup
185,shows that AMANDA outperforms all the stateof - the - art models by a significant margin on the New s QA dataset .,Experimental Settings,Experimental Settings,natural_language_inference,2,"['B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.6666666666666666,184,0.6865671641791045,12,0.6666666666666666,1,1,results
186,shows the results on the TriviaQA dataset .,Experimental Settings,Experimental Settings,natural_language_inference,2,"['B', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'O']",13,0.7222222222222222,185,0.6902985074626866,13,0.7222222222222222,1,1,results
191,shows that AMANDA achieves state - of the - art results in both Wikipedia and Web domain on distantly supervised and verified data .,Experimental Settings,Experimental Settings,natural_language_inference,2,"['B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']",,,18,1.0,190,0.7089552238805971,18,1.0,1,1,results
193,Results on the Search QA dataset are shown in .,Results,Results,natural_language_inference,2,"['O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O']",1,0.017241379310344827,192,0.7164179104477612,1,0.047619047619047616,1,1,results
200,"AMANDA outperforms both systems , especially for multi-word - answer questions by a huge margin .",Results,Results,natural_language_inference,2,"['B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",8,0.13793103448275862,199,0.7425373134328358,8,0.38095238095238093,1,1,results
202,"shows that AMANDA performs better than any of the ablated models which include the ablation of multifactor attentive encoding , max - attentional question aggregation ( q ma ) , and question type representation ( q f ) .",Results,Results,natural_language_inference,2,"['O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.1724137931034483,201,0.75,10,0.47619047619047616,1,1,results
2,Sentence Embeddings in NLI with Iterative Refinement Encoders,title,,natural_language_inference,20,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.00411522633744856,1,0.0,1,1,research-problem
4,Sentence - level representations are necessary for various NLP tasks .,abstract,abstract,natural_language_inference,20,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.012345679012345678,1,0.2,1,1,research-problem
20,"With the goal of obtaining general - purpose sentence representations in mind , we opt for the sentence encoding approach .",Introduction,Introduction,natural_language_inference,20,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",11,0.6875,19,0.07818930041152264,11,0.6875,1,1,model
21,Motivated by the success of the InferSent architecture we extend their architecture with a hierarchylike structure of bidirectional LSTM ( BiLSTM ) layers with max pooling .,Introduction,Introduction,natural_language_inference,20,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']",,,12,0.75,20,0.0823045267489712,12,0.75,1,1,model
71,The architecture was implemented using PyTorch .,Training Details,Training Details,natural_language_inference,20,"['O', 'B', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",1,0.08333333333333333,70,0.2880658436213992,1,0.08333333333333333,1,1,experimental-setup
72,We have published our code in GitHub : https://github.com/Helsinki-NLP/HBMP.,Training Details,Training Details,natural_language_inference,20,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.16666666666666666,71,0.29218106995884774,2,0.16666666666666666,1,1,code
73,"For all of our models we used a gradient descent optimization algorithm based on the Adam update rule , which is pre-implemented in PyTorch .",Training Details,Training Details,natural_language_inference,20,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",3,0.25,72,0.2962962962962963,3,0.25,1,1,experimental-setup
74,We used a learning rate of 5e - 4 for all our models .,Training Details,Training Details,natural_language_inference,20,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",4,0.3333333333333333,73,0.3004115226337449,4,0.3333333333333333,1,1,experimental-setup
75,The learning rate was decreased by the factor of 0.2 after each epoch if the model did not improve .,Training Details,Training Details,natural_language_inference,20,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'O', 'B-p', 'B-ob', 'O']",5,0.4166666666666667,74,0.3045267489711934,5,0.4166666666666667,1,1,experimental-setup
76,We used a batch size of 64 .,Training Details,Training Details,natural_language_inference,20,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",6,0.5,75,0.30864197530864196,6,0.5,1,1,experimental-setup
79,"We use pre-trained Glo Ve word embeddings of size 300 dimensions ( Glo Ve 840B 300D ; , which were fine - tuned during training .",Training Details,Training Details,natural_language_inference,20,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.75,78,0.32098765432098764,9,0.75,1,1,experimental-setup
80,"The sentence embeddings have hidden size of 600 for both direction ( except for SentEval test , where we test models with 600D and 1200D per direction ) and the 3 - layer multilayer perceptron ( MLP ) have the size of 600 dimensions .",Training Details,Training Details,natural_language_inference,20,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O']",,,10,0.8333333333333334,79,0.32510288065843623,10,0.8333333333333334,1,1,experimental-setup
81,We use a dropout of 0.1 between the MLP layers ( except just before the final layer ) .,Training Details,Training Details,natural_language_inference,20,"['O', 'O', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.9166666666666666,80,0.3292181069958848,11,0.9166666666666666,1,1,experimental-setup
82,Our models were trained using one NVIDIA Tesla P100 GPU .,Training Details,Training Details,natural_language_inference,20,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,1.0,81,0.3333333333333333,12,1.0,1,1,experimental-setup
124,It clearly outperforms the similar but non-hierarchical BiLSTM models reported in the literature and fares well in comparison to other state of the art architectures in the sentence encoding category .,Evaluation Benchmarks,Model Performance on the NLI task,natural_language_inference,20,"['O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",41,0.44086021505376344,123,0.5061728395061729,3,0.42857142857142855,1,1,results
125,"In particular , our results are close to the current state of the art on SNLI in this category and strong on both , the matched and mismatched test sets of MultiNLI .",Evaluation Benchmarks,Model Performance on the NLI task,natural_language_inference,20,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",42,0.45161290322580644,124,0.5102880658436214,4,0.5714285714285714,1,1,results
126,"Finally , on SciTail , we achieve the new state of the art with an accuracy of 86.0 % .",Evaluation Benchmarks,Model Performance on the NLI task,natural_language_inference,20,"['O', 'O', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",43,0.46236559139784944,125,0.51440329218107,5,0.7142857142857143,1,1,results
130,"For the SNLI dataset , our model provides the test accuracy of 86.6 % after 4 epochs of training .",Evaluation Benchmarks,SNLI,natural_language_inference,20,"['B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O']",,,47,0.5053763440860215,129,0.5308641975308642,1,0.5,1,1,results
133,"For the MultiNLI matched test set ( MultiNLI - m ) our model achieves a test accuracy of 73.7 % after 3 epochs of training , which is 0.8 % points lower than the state of the art 74.5 % by .",Evaluation Benchmarks,MultiNLI,natural_language_inference,20,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O']",,,50,0.5376344086021505,132,0.5432098765432098,1,0.25,1,1,results
134,"For the mismatched test set ( MultiNLI - mm ) our model achieves a test accuracy of 73.0 % after 3 epochs of training , which is 0.6 % points lower than the state of the art 73.6 % by Chen , Zhu , Ling , Wei , Jiang , and Inkpen ( 2017 b ) .",Evaluation Benchmarks,MultiNLI,natural_language_inference,20,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,51,0.5483870967741935,133,0.5473251028806584,2,0.5,1,1,results
138,"On the SciTail dataset we compared our model also against non-sentence embedding - based models , as no results have been previously published which are based on independent sentence embeddings .",Evaluation Benchmarks,SciTail,natural_language_inference,20,"['B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",55,0.5913978494623656,137,0.5637860082304527,1,0.14285714285714285,1,1,results
139,"We obtain a score of 86.0 % after 4 epochs of training , which is + 2.7 % points absolute improvement on the previous published state of the art by .",Evaluation Benchmarks,SciTail,natural_language_inference,20,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O']",,,56,0.6021505376344086,138,0.5679012345679012,2,0.2857142857142857,1,1,results
140,Our model also outperforms In - fer Sent which achieves an accuracy of 85.1 % in our experiments .,Evaluation Benchmarks,SciTail,natural_language_inference,20,"['B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",57,0.6129032258064516,139,0.5720164609053497,3,0.42857142857142855,1,1,results
142,The results achieved by our proposed model are significantly higher than the previously published results .,Evaluation Benchmarks,SciTail,natural_language_inference,20,"['O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",59,0.6344086021505376,141,0.5802469135802469,5,0.7142857142857143,1,1,results
2,DiSAN : Directional Self - Attention Network for RNN / CNN - Free Language Understanding,title,title,natural_language_inference,21,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0034482758620689655,1,0.0,1,1,research-problem
31,"We propose a novel attention mechanism that differs from previous ones in that it is 1 ) multi-dimensional : the attention w.r.t. each pair of elements from the source ( s ) is a vector , where each entry is the attention computed on each feature ; and 2 ) directional : it uses one or multiple positional masks to model the asymmetric attention between two elements .",abstract,abstract,natural_language_inference,21,"['O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",28,0.6511627906976745,30,0.10344827586206896,28,0.6511627906976745,1,1,model
32,"We compute feature - wise attention since each element in a sequence is usually represented by a vector , e.g. , word / character embedding , and attention on different features can contain different information about dependency , thus to handle the variation of contexts around the same word .",abstract,abstract,natural_language_inference,21,"['O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",29,0.6744186046511628,31,0.10689655172413794,29,0.6744186046511628,1,1,model
33,We apply positional masks to attention distribution since they can easily encode prior structure knowledge such as temporal order and dependency parsing .,abstract,abstract,natural_language_inference,21,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",30,0.6976744186046512,32,0.1103448275862069,30,0.6976744186046512,1,1,model
35,"We then build a light - weight and RNN / CNN - free neural network , "" Directional Self - Attention Network ( DiSAN ) "" , for sentence encoding .",abstract,abstract,natural_language_inference,21,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",32,0.7441860465116279,34,0.11724137931034483,32,0.7441860465116279,1,1,model
37,"In DiSAN , the input sequence is processed by directional ( forward and backward ) self - attentions to model context dependency and produce context - aware representations for all tokens .",abstract,abstract,natural_language_inference,21,"['B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",34,0.7906976744186046,36,0.12413793103448276,34,0.7906976744186046,1,1,model
38,"Then , a multi-dimensional attention computes a vector representation of the entire sequence , which can be passed into a classification / regression module to compute the final prediction for a particular task .",abstract,abstract,natural_language_inference,21,"['O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",35,0.813953488372093,37,0.12758620689655173,35,0.813953488372093,1,1,model
180,We use cross-entropy loss plus L2 regularization penalty as optimization objective .,Experiments,Experiments,natural_language_inference,21,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'O']",5,0.09803921568627451,179,0.6172413793103448,5,0.2631578947368421,1,1,experimental-setup
181,We minimize it by Adadelta ) ( an optimizer of mini - batch SGD ) with batch size of 64 .,Experiments,Experiments,natural_language_inference,21,"['O', 'B', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'O']","['O', 'B-n', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'O']","['O', 'B-b', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-ob', 'O']",6,0.11764705882352941,180,0.6206896551724138,6,0.3157894736842105,1,1,experimental-setup
183,Initial learning rate is set to 0.5 .,Experiments,Experiments,natural_language_inference,21,"['B', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",8,0.1568627450980392,182,0.6275862068965518,8,0.42105263157894735,1,1,experimental-setup
184,"All weight matrices are initialized by Glorot Initialization , and the biases are initialized with 0 .",Experiments,Experiments,natural_language_inference,21,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",9,0.17647058823529413,183,0.6310344827586207,9,0.47368421052631576,1,1,experimental-setup
185,We initialize the word embedding in x by 300D Glo Ve 6B pre-trained vectors .,Experiments,Experiments,natural_language_inference,21,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.19607843137254902,184,0.6344827586206897,10,0.5263157894736842,1,1,experimental-setup
186,"The Out - of - Vocabulary words in training set are randomly initialized by uniform distribution between ( ? 0.05 , 0.05 ) .",Experiments,Experiments,natural_language_inference,21,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.21568627450980393,185,0.6379310344827587,11,0.5789473684210527,1,1,experimental-setup
188,We use Dropout ) with keep probability 0.75 for language inference and 0.8 for sentiment analysis .,Experiments,Experiments,natural_language_inference,21,"['O', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']",,,13,0.2549019607843137,187,0.6448275862068965,13,0.6842105263157895,1,1,experimental-setup
189,"The L2 regularization decay factors ? are 5 10 ?5 and 10 ? 4 for language inference and sentiment analysis , respectively .",Experiments,Experiments,natural_language_inference,21,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",14,0.27450980392156865,188,0.6482758620689655,14,0.7368421052631579,1,1,experimental-setup
192,Hidden units number d h is set to 300 .,Experiments,Experiments,natural_language_inference,21,"['B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",17,0.3333333333333333,191,0.6586206896551724,17,0.8947368421052632,1,1,experimental-setup
193,"Activation functions ? ( ) are ELU ( exponential linear unit ) ( Clevert , Unterthiner , and Hochreiter 2016 ) if not specified .",Experiments,Experiments,natural_language_inference,21,"['B', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.35294117647058826,192,0.6620689655172414,18,0.9473684210526315,1,1,experimental-setup
194,All models are implemented with TensorFlow 2 and run on sin - 3.0 m 83.9 80.6 1024D GRU encoders 15 m 98.8 81.4 300D Tree - based CNN encoders 3.5 m 83.3 82.1 300D SPINN - PI encoders 3.7 m 89.2 83.2 600D Bi- LSTM encoders 2.0 m 86.4 83.3 300D NTI - SLSTM - LSTM encoders 4.0 m 82.5 83.4 600D Bi-LSTM encoders+intra-attention 2.8 m 84.5 84.2 300D NSE encoders 3 gle Nvidia GTX 1080 Ti graphic card .,Experiments,Experiments,natural_language_inference,21,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.37254901960784315,193,0.6655172413793103,19,1.0,1,1,experimental-setup
195,Natural Language Inference,Experiments,,natural_language_inference,21,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",20,0.39215686274509803,194,0.6689655172413793,0,0.0,1,1,results
215,"Compared to the results from the official leaderboard of SNLI in , DiSAN outperforms previous works and improves the best latest test accuracy ( achieved by a memory - based NSE encoder network ) by a remarkable margin of 1.02 % .",Experiments,Word,natural_language_inference,21,"['B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",40,0.7843137254901961,214,0.7379310344827587,20,0.6666666666666666,1,1,results
216,"DiSAN surpasses the RNN / CNN based models with more complicated architecture and more parameters by large margins , e.g. , + 2.32 % to Bi - LSTM , + 1.42 % to Bi - LSTM with additive attention .",Experiments,Word,natural_language_inference,21,"['B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",41,0.803921568627451,215,0.7413793103448276,21,0.7,1,1,results
217,"It even outperforms models with the assistance of a semantic parsing tree , e.g. , + 3.52 % to Tree - based CNN , + 2.42 % to SPINN - PI .",Experiments,Word,natural_language_inference,21,"['O', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",42,0.8235294117647058,216,0.7448275862068966,22,0.7333333333333333,1,1,results
219,"First , a comparison between the first two models shows that changing token - wise attention to multi-dimensional / feature - wise attention leads to 3.31 % improvement on a word embedding based model .",Experiments,Word,natural_language_inference,21,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",44,0.8627450980392157,218,0.7517241379310344,24,0.8,1,1,results
220,"Also , a comparison between the third baseline and DiSAN shows that DiSAN can substantially outperform multi-head attention by 1.45 % .",Experiments,Word,natural_language_inference,21,"['O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'O', 'B-b', 'I-b', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",45,0.8823529411764706,219,0.7551724137931034,25,0.8333333333333334,1,1,results
221,"Moreover , a comparison between the forth baseline and DiSAN shows that the DiSA block can even outperform Bi - LSTM layer in context encoding , improving test accuracy by 0.64 % .",Experiments,Word,natural_language_inference,21,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",46,0.9019607843137255,220,0.7586206896551724,26,0.8666666666666667,1,1,results
222,A comparison between the fifth baseline and DiSAN shows that directional self - attention with forward and backward masks ( with temporal order encoded ) can bring 0.96 % improvement .,Experiments,Word,natural_language_inference,21,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",47,0.9215686274509803,221,0.7620689655172413,27,0.9,1,1,results
226,Sentiment Analysis,Experiments,,natural_language_inference,21,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",51,1.0,225,0.7758620689655172,0,0.0,1,1,results
235,"To the best of our knowledge , DiSAN improves the last best accuracy ( given by CNN - Tensor ) by 0.52 % .",Model,Model,natural_language_inference,21,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.14035087719298245,234,0.8068965517241379,8,0.4,1,1,results
236,"Compared to tree - based models with heavy use of the prior structure , e.g. , MV - RNN , RNTN and Tree - LSTM , DiSAN outperforms them by 7.32 % , 6.02 % and 0.72 % , respectively .",Model,Model,natural_language_inference,21,"['B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'B-s', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",9,0.15789473684210525,235,0.8103448275862069,9,0.45,1,1,results
237,"Additionally , DiSAN achieves better performance than CNN - based models .",Model,Model,natural_language_inference,21,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.17543859649122806,236,0.8137931034482758,10,0.5,1,1,results
240,"Nonetheless , DiSAN still outperforms these fancy models , such as NCSL ( + 0.62 % ) and LR- Bi- LSTM ( + 1.12 % ) . :",Model,Model,natural_language_inference,21,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",13,0.22807017543859648,239,0.8241379310344827,13,0.65,1,1,results
4,"To answer the question in machine comprehension ( MC ) task , the models need to establish the interaction between the question and the context .",abstract,abstract,natural_language_inference,22,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.013636363636363636,1,0.14285714285714285,1,1,research-problem
10,1 The latest results are listed at https://rajpurkar.github.io/SQuAD -explorer/,abstract,abstract,natural_language_inference,22,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",7,1.0,9,0.04090909090909091,7,1.0,1,1,code
14,Machine comprehension ( MC ) - especially in the form of question answering ( QA ) - is therefore attracting a significant amount of attention from the machine learning community .,Introduction,Introduction,natural_language_inference,22,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.03,13,0.05909090909090909,3,0.13043478260869565,1,1,research-problem
23,"We propose an extension of BIDAF , called Ruminating Reader , which uses a second pass of reading and reasoning to allow it to learn to avoid mistakes and to ensure that it is able to effectively use the full context when selecting an answer .",Introduction,Introduction,natural_language_inference,22,"['O', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'O']",,,12,0.12,22,0.1,12,0.5217391304347826,1,1,model
24,"In addition to adding a second pass , we also introduce two novel layer types , the ruminate layers , which use gating mechanisms to fuse the obtained from the first and second passes .",Introduction,Introduction,natural_language_inference,22,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.13,23,0.10454545454545454,13,0.5652173913043478,1,1,model
26,"In addition , we introduce an answer-question similarity loss to penalize overlap between question and predicted answer , a common feature in the errors of our base model .",Introduction,Introduction,natural_language_inference,22,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.15,25,0.11363636363636363,15,0.6521739130434783,1,1,model
148,"In the character encoding layer , we use 100 filters of width 5 .",Implementation details,Implementation details,natural_language_inference,22,"['B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",2,0.1,147,0.6681818181818182,2,0.1,1,1,experimental-setup
149,"In the remainder of the model , we set the hidden layer dimension ( d ) to 100 .",Implementation details,Implementation details,natural_language_inference,22,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",3,0.15,148,0.6727272727272727,3,0.15,1,1,experimental-setup
150,We use pretrained 100D Glo Ve vectors ( 6B - token version ) as word embeddings .,Implementation details,Implementation details,natural_language_inference,22,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",4,0.2,149,0.6772727272727272,4,0.2,1,1,experimental-setup
151,"Out - of - vocobulary tokens are represented by an UNK symbol in the word embedding layer , but treated normally by the character embedding layer .",Implementation details,Implementation details,natural_language_inference,22,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",5,0.25,150,0.6818181818181818,5,0.25,1,1,experimental-setup
153,"We use the AdaDelta optimizer ( Zeiler , 2012 ) for optimization .",Implementation details,Implementation details,natural_language_inference,22,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'O']",7,0.35,152,0.6909090909090909,7,0.35,1,1,experimental-setup
154,We selected hyperparameter values through random search .,Implementation details,Implementation details,natural_language_inference,22,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.4,153,0.6954545454545454,8,0.4,1,1,experimental-setup
155,Batch size is 30 .,Implementation details,Implementation details,natural_language_inference,22,"['B', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'B-p', 'B-ob', 'O']",9,0.45,154,0.7,9,0.45,1,1,experimental-setup
156,"Learning rate starts at 0.5 , and decreases to 0.2 once the model stops improving .",Implementation details,Implementation details,natural_language_inference,22,"['B', 'I', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'B-n', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'B-b', 'O', 'O', 'B-ob', 'B-b', 'I-b', 'O']",10,0.5,155,0.7045454545454546,10,0.5,1,1,experimental-setup
157,"The L2-regularization weight is 1 e - 4 , AQSL weight is 1 and dropout with a drop rate of 0.2 is A typical model run converges in about 40 k steps .",Implementation details,Implementation details,natural_language_inference,22,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'O']",,,11,0.55,156,0.7090909090909091,11,0.55,1,1,experimental-setup
158,This takes two days using Tensorflow and a single NVIDIA K80 GPU . provide an official evaluation script that allows us to measure F 1 score and EM score by comparing the prediction and ground truth answers .,Implementation details,Implementation details,natural_language_inference,22,"['O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.6,157,0.7136363636363636,12,0.6,1,1,experimental-setup
169,"At the time of submission , our model is tied in accuracy on the hidden test set with the bestperforming published single model .",Results,Results,natural_language_inference,22,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.2,168,0.7636363636363637,1,0.25,1,1,results
170,We achieve an F 1 score of 79.5 and EM score of 70.6 .,Results,Results,natural_language_inference,22,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,2,0.4,169,0.7681818181818182,2,0.5,1,1,results
180,Experiments 3 and 4 show that the two ruminate layers are both important and helpful in contributing performance .,Layer Ablation Analysis,Layer Ablation Analysis,natural_language_inference,22,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",6,0.15,179,0.8136363636363636,7,0.17073170731707318,1,1,ablation-analysis
181,It is worth noting that the BiLSTM in the context ruminate layer contributes substantially to model performance .,Layer Ablation Analysis,Layer Ablation Analysis,natural_language_inference,22,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.175,180,0.8181818181818182,8,0.1951219512195122,1,1,ablation-analysis
2,FUSIONNET : FUSING VIA FULLY - AWARE ATTENTION WITH APPLICATION TO MACHINE COMPREHENSION,title,title,natural_language_inference,23,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.001949317738791423,1,0.0,1,1,research-problem
24,"Teaching machines to read , process and comprehend text and then answer questions is one of key problems in artificial intelligence .",INTRODUCTION,INTRODUCTION,natural_language_inference,23,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.12727272727272726,23,0.04483430799220273,7,0.18421052631578946,1,1,research-problem
29,Many neural network models have been proposed for this challenge and they generally frame this problem as a machine reading comprehension ( MRC ) task .,INTRODUCTION,INTRODUCTION,natural_language_inference,23,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",12,0.21818181818181817,28,0.05458089668615984,12,0.3157894736842105,1,1,research-problem
35,We argue that this hypothesis also holds in language understanding and MRC .,INTRODUCTION,INTRODUCTION,natural_language_inference,23,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'O']",18,0.32727272727272727,34,0.06627680311890838,18,0.47368421052631576,1,1,research-problem
39,"To alleviate this challenge , we identify an attention scoring function utilizing all layers of representation with less training burden .",INTRODUCTION,INTRODUCTION,natural_language_inference,23,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",22,0.4,38,0.07407407407407407,22,0.5789473684210527,1,1,model
40,This leads to an attention that thoroughly captures the complete information between the question and the context .,INTRODUCTION,INTRODUCTION,natural_language_inference,23,"['O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",23,0.41818181818181815,39,0.07602339181286549,23,0.6052631578947368,1,1,model
41,"With this fully - aware attention , we put forward a multi -level attention mechanism to understand the information in the question , and exploit it layer by layer on the context side .",INTRODUCTION,INTRODUCTION,natural_language_inference,23,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",24,0.43636363636363634,40,0.07797270955165692,24,0.631578947368421,1,1,model
42,"All of these innovations are integrated into a new end - to - end structure called FusionNet in , with details described in Section 3 .",INTRODUCTION,INTRODUCTION,natural_language_inference,23,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",25,0.45454545454545453,41,0.07992202729044834,25,0.6578947368421053,1,1,model
238,"From the results , we can see that our models not only perform well on the original SQuAD dataset , but also outperform all previous models by more than 5 % in EM score on the adversarial datasets .",EXPERIMENTS,DATASETS,natural_language_inference,23,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,23,0.3026315789473684,237,0.4619883040935672,9,0.9,1,1,results
239,This shows that FusionNet is better at language understanding of both the context and question .,EXPERIMENTS,DATASETS,natural_language_inference,23,"['O', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",24,0.3157894736842105,238,0.46393762183235865,10,1.0,1,1,results
2,Stochastic Answer Networks for Machine Reading Comprehension,title,title,natural_language_inference,24,"['O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004273504273504274,1,0.0,1,1,research-problem
8,Machine reading comprehension ( MRC ) is a challenging task : the goal is to have machines read a text passage and then answer any question about the passage .,Introduction,Introduction,natural_language_inference,24,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.05,7,0.029914529914529916,1,0.009009009009009009,1,1,research-problem
10,It has been hypothesized that difficult MRC problems require some form of multi-step synthesis and reasoning .,Introduction,Introduction,natural_language_inference,24,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.15,9,0.038461538461538464,3,0.02702702702702703,1,1,research-problem
18,"In this work , we derive an alternative multi-step reasoning neural network for MRC .",Introduction,Introduction,natural_language_inference,24,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",11,0.55,17,0.07264957264957266,11,0.0990990990990991,1,1,model
19,"During training , we fix the number of reasoning steps , but perform stochastic dropout on the answer module ( final layer predictions ) .",Introduction,Introduction,natural_language_inference,24,"['B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.6,18,0.07692307692307693,12,0.10810810810810811,1,1,model
20,"During decoding , we generate answers based on the average of predictions in all steps , rather than the final step .",Introduction,Introduction,natural_language_inference,24,"['O', 'B', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",13,0.65,19,0.0811965811965812,13,0.11711711711711711,1,1,model
21,"We call this a stochastic answer network ( SAN ) because the stochastic dropout is applied to the answer module ; albeit simple , this technique significantly improves the robustness and over all accuracy of the model .",Introduction,Introduction,natural_language_inference,24,"['O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.7,20,0.08547008547008547,14,0.12612612612612611,1,1,model
127,"The spaCy tool 2 is used to tokenize the both passages and questions , and generate lemma , part - of - speech and named entity tags .",Experiment Setup,This contains about 23K passages and 100K questions .,natural_language_inference,24,"['O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.6153846153846154,126,0.5384615384615384,8,0.6153846153846154,1,1,experimental-setup
128,We use 2 - layer BiLSTM with d = 128 hidden units for both passage and question encoding .,Experiment Setup,This contains about 23K passages and 100K questions .,natural_language_inference,24,"['O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.6923076923076923,127,0.5427350427350427,9,0.6923076923076923,1,1,experimental-setup
129,The mini-batch size is set to 32 and Adamax is used as our optimizer .,Experiment Setup,This contains about 23K passages and 100K questions .,natural_language_inference,24,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",10,0.7692307692307693,128,0.5470085470085471,10,0.7692307692307693,1,1,experimental-setup
130,The learning rate is set to 0.002 at first and decreased by half after every 10 epochs .,Experiment Setup,This contains about 23K passages and 100K questions .,natural_language_inference,24,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",11,0.8461538461538461,129,0.5512820512820513,11,0.8461538461538461,1,1,experimental-setup
131,"We set the dropout rate for all the hidden units of LSTM , and the answer module output layer to 0.4 .",Experiment Setup,This contains about 23K passages and 100K questions .,natural_language_inference,24,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'O']",12,0.9230769230769231,130,0.5555555555555556,12,0.9230769230769231,1,1,experimental-setup
132,"To prevent degenerate output , we ensure that at least one step in the answer module is active during training .",Experiment Setup,This contains about 23K passages and 100K questions .,natural_language_inference,24,"['B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-b', 'B-p', 'B-ob', 'O']",13,1.0,131,0.5598290598290598,13,1.0,1,1,experimental-setup
146,"We observe that SAN achieves 76.235 EM and 84.056 F1 , outperforming all other models .",Results,Results,natural_language_inference,24,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'O']",13,0.16455696202531644,145,0.6196581196581197,13,0.19696969696969696,1,1,results
147,Standard 1 - step model only achieves 75.139 EM and dynamic steps ( via ReasoNet ) achieves only 75.355 EM .,Results,Results,natural_language_inference,24,"['B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']",,,14,0.17721518987341772,146,0.6239316239316239,14,0.21212121212121213,1,1,results
148,"SAN also outperforms a 5 - step memory net with averaging , which implies averaging predictions is not the only thing that led to SAN 's superior results ; indeed , stochastic prediction dropout is an effective technique .",Results,Results,natural_language_inference,24,"['B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.189873417721519,147,0.6282051282051282,15,0.22727272727272727,1,1,results
152,SAN also outperforms the other models in terms of K- best oracle scores .,Results,The K-best oracle results is shown in .,natural_language_inference,24,"['O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.24050632911392406,151,0.6452991452991453,19,0.2878787878787879,1,1,results
156,We see that SAN is very competitive in both single and ensemble settings ( ranked in second ) despite its simplicity .,Results,The K-best oracle results is shown in .,natural_language_inference,24,"['O', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O']",23,0.2911392405063291,155,0.6623931623931624,23,0.3484848484848485,1,1,results
2,Contextualized Word Representations for Reading Comprehension,title,title,natural_language_inference,25,"['O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.009615384615384616,1,0.0,1,1,research-problem
8,Reading comprehension ( RC ) is a high - level task in natural language understanding that requires reading a document and answering questions about its content .,Introduction,Introduction,natural_language_inference,25,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.02631578947368421,7,0.0673076923076923,1,0.09090909090909091,1,1,research-problem
9,"RC has attracted substantial attention over the last few years with the advent of large annotated datasets , computing resources , and neural network models and optimization procedures .",Introduction,Introduction,natural_language_inference,25,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.05263157894736842,8,0.07692307692307693,2,0.18181818181818182,1,1,research-problem
14,"To illustrate this idea , we take a model that carries out only basic question - document interaction and prepend to it a module that produces token embeddings by explicitly gating between contextual and non-contextual representations ( for both the document and question ) .",Introduction,Introduction,natural_language_inference,25,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.18421052631578946,13,0.125,7,0.6363636363636364,1,1,model
16,"Motivated by these findings , we turn to a semisupervised setting in which we leverage a language model , pre-trained on large amounts of data , as a sequence encoder which forcibly facilitates context utilization .",Introduction,Introduction,natural_language_inference,25,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",9,0.23684210526315788,15,0.14423076923076922,9,0.8181818181818182,1,1,model
68,"In we compare these two variants over the development set and observe superior performance by the contextual one , illustrating the benefit of contextualization and specifically per-sequence contextualization which is done separately for the question and for the passage .",Evaluation and Analysis,Importance of context,natural_language_inference,25,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.4117647058823529,67,0.6442307692307693,5,0.3333333333333333,1,1,results
76,"On average , the less frequent a word - type is , the smaller are its gate activations , i.e. , the reembedded representation of a rare word places less weight on its fixed word - embedding and more on its contextual representation , compared to a common word .",Evaluation and Analysis,Results on SQuAD 's development set .,natural_language_inference,25,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-ob', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.8823529411764706,75,0.7211538461538461,13,0.8666666666666667,1,1,results
80,Supplementing the calculation of token reembeddings with the hidden states of a strong language model proves to be highly effective .,Incorporating language model representations,Incorporating language model representations,natural_language_inference,25,"['B', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'O']",,,1,0.1111111111111111,79,0.7596153846153846,1,0.1111111111111111,1,1,results
83,"Overall , we observe a significant improvement with all three configurations , effectively showing the benefit of training a QA model in a semisupervised fashion with a large language model .",Incorporating language model representations,Incorporating language model representations,natural_language_inference,25,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.4444444444444444,82,0.7884615384615384,4,0.4444444444444444,1,1,results
84,"Besides a crosscutting boost in results , we note that the performance due to utilizing the LM hidden states of the first LSTM layer significantly surpasses the other two variants .",Incorporating language model representations,Incorporating language model representations,natural_language_inference,25,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",5,0.5555555555555556,83,0.7980769230769231,5,0.5555555555555556,1,1,results
90,We use pre-trained GloVe embeddings of dimension d w = 300 and produce character - based word representations via dc = 100 convolutional filters over character embeddings as in .,Experimental setup,Experimental setup,natural_language_inference,25,"['O', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O']",1,0.0,89,0.8557692307692307,1,0.0,1,1,hyperparameters
4,"The latest work on language representations carefully integrates contextualized features into language model training , which enables a series of success especially in various machine reading comprehension and natural language inference tasks .",abstract,abstract,natural_language_inference,26,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.014150943396226415,1,0.14285714285714285,1,1,research-problem
12,"Recently , deep contextual language model ( LM ) has been shown effective for learning universal language representations , achieving state - of - the - art results in a series of flagship natural language understanding ( NLU ) tasks .",Introduction,Introduction,natural_language_inference,26,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.045454545454545456,11,0.05188679245283019,1,0.045454545454545456,1,1,research-problem
26,"Thus we are motivated to enrich the sentence contextual semantics in multiple predicate - specific argument sequences by presenting SemBERT : Semantics - aware BERT , which is a fine - tuned BERT with explicit contextual semantic clues .",Introduction,Introduction,natural_language_inference,26,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.6818181818181818,25,0.1179245283018868,15,0.6818181818181818,1,1,model
27,The proposed SemBERT learns the representation in a fine - grained manner and takes both strengths of BERT on plain context representation and explicit semantics for deeper meaning representation .,Introduction,Introduction,natural_language_inference,26,"['O', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",16,0.7272727272727273,26,0.12264150943396226,16,0.7272727272727273,1,1,model
28,Our model consists of three components :,Introduction,Introduction,natural_language_inference,26,"['O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O']",17,0.7727272727272727,27,0.12735849056603774,17,0.7727272727272727,1,1,model
29,1 ) an out - ofshelf semantic role labeler to annotate the input sentences with a variety of semantic role labels ; 2 ) an sequence encoder where a pre-trained language model is used to build representation for input raw texts and the semantic role labels are mapped to embedding in parallel ; 3 ) a semantic integration component to integrate the text representation with the contextual explicit semantic embedding to obtain the joint representation for downstream tasks .,Introduction,Introduction,natural_language_inference,26,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']",,,18,0.8181818181818182,28,0.1320754716981132,18,0.8181818181818182,1,1,model
124,Our implementation is based on the PyTorch implementation of BERT 6 .,Experiments,Setup,natural_language_inference,26,"['B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O']",2,0.046511627906976744,123,0.5801886792452831,1,0.125,1,1,experimental-setup
125,"We use the pre-trained weights of BERT and follow the same fine - tuning procedure as BERT without any modification , and all the layers are tuned with moderate model size increasing , as the extra SRL embedding volume is less than 15 % of the original encoder size .",Experiments,Setup,natural_language_inference,26,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']",,,3,0.06976744186046512,124,0.5849056603773585,2,0.25,1,1,experimental-setup
126,"We set the initial learning rate in { 8e -6 , 1 e - 5 , 2 e - 5 , 3 e - 5 } with warm - up rate of 0.1 and L2 weight decay of 0.01 .",Experiments,Setup,natural_language_inference,26,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']",,,4,0.09302325581395349,125,0.589622641509434,3,0.375,1,1,experimental-setup
127,"The batch size is selected in { 16 , 24 , 32 } .",Experiments,Setup,natural_language_inference,26,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.11627906976744186,126,0.5943396226415094,4,0.5,1,1,experimental-setup
128,"The maximum number of epochs is set in [ 2 , 5 ] depending on tasks .",Experiments,Setup,natural_language_inference,26,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'O']",6,0.13953488372093023,127,0.5990566037735849,5,0.625,1,1,experimental-setup
129,"Texts are tokenized using wordpieces , with maximum length of 384 for SQuAD and 128 or 200 for other tasks .",Experiments,Setup,natural_language_inference,26,"['B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']",,,7,0.16279069767441862,128,0.6037735849056604,6,0.75,1,1,experimental-setup
130,The dimension of SRL embedding is set to 10 .,Experiments,Setup,natural_language_inference,26,"['O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",8,0.18604651162790697,129,0.6084905660377359,7,0.875,1,1,experimental-setup
131,The default maximum number of predicateargument structures m is set to 3 .,Experiments,Setup,natural_language_inference,26,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",9,0.20930232558139536,130,0.6132075471698113,8,1.0,1,1,experimental-setup
171,"From the results , we observe that the concatenation would yield an improvement , verifying that integrating contextual semantics would be quite useful for language understanding .",Ablation Study,Since,natural_language_inference,26,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'O', 'B-p', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",4,0.36363636363636365,170,0.8018867924528302,4,0.8,1,1,ablation-analysis
172,"However , SemBERT still outperforms the simple BERT + SRL model just like the latter outperforms the original BERT by a large performance margin , which shows that SemBERT works more effectively for integrating both plain contextual representation and contextual semantics at the same time .",Ablation Study,Since,natural_language_inference,26,"['O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O']",,,5,0.45454545454545453,171,0.8066037735849056,5,1.0,1,1,ablation-analysis
3,COMBINING LOCAL CONVOLUTION WITH GLOBAL SELF - ATTENTION FOR READING COMPRE - HENSION,,,natural_language_inference,27,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob']",3,0.25,2,0.005917159763313609,2,1.0,1,1,research-problem
5,Current end - to - end machine reading and question answering ( Q&A ) models are primarily based on recurrent neural networks ( RNNs ) with attention .,,,natural_language_inference,27,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.4166666666666667,4,0.011834319526627219,1,0.125,1,1,research-problem
14,There is growing interest in the tasks of machine reading comprehension and automated question answering .,INTRODUCTION,INTRODUCTION,natural_language_inference,27,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.03225806451612903,13,0.038461538461538464,1,0.03225806451612903,1,1,research-problem
21,"In this paper , aiming to make the machine comprehension fast , we propose to remove the recurrent nature of these models .",INTRODUCTION,INTRODUCTION,natural_language_inference,27,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.25806451612903225,20,0.05917159763313609,8,0.25806451612903225,1,1,research-problem
22,We instead exclusively use convolutions and self - attentions as the building blocks of encoders that separately encodes the query and context .,INTRODUCTION,INTRODUCTION,natural_language_inference,27,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.2903225806451613,21,0.0621301775147929,9,0.2903225806451613,1,1,model
23,Then we learn the interactions between context and question by standard attentions .,INTRODUCTION,INTRODUCTION,natural_language_inference,27,"['O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",10,0.3225806451612903,22,0.0650887573964497,10,0.3225806451612903,1,1,model
24,The resulting representation is encoded again with our recurrency - free encoder before finally decoding to the probability of each position being the start or end of the answer span .,INTRODUCTION,INTRODUCTION,natural_language_inference,27,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,11,0.3548387096774194,23,0.06804733727810651,11,0.3548387096774194,1,1,model
25,"We call this architecture QANet , which is shown in .",INTRODUCTION,INTRODUCTION,natural_language_inference,27,"['O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.3870967741935484,24,0.07100591715976332,12,0.3870967741935484,1,1,model
182,EXPERIMENTS ON SQUAD,,,natural_language_inference,27,"['O', 'B', 'B']","['O', 'B-p', 'B-n']","['O', 'B-p', 'B-b']",0,0.0,181,0.5355029585798816,0,0.0,1,1,experiments
201,We employ two types of standard regularizations .,DATASET AND EXPERIMENTAL SETTINGS,DATASET AND EXPERIMENTAL SETTINGS,natural_language_inference,27,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",18,0.6428571428571429,200,0.591715976331361,18,0.6428571428571429,1,1,experiments
202,"First , we use L2 weight decay on all the trainable variables , with parameter ? = 3 10 ?7 .",DATASET AND EXPERIMENTAL SETTINGS,DATASET AND EXPERIMENTAL SETTINGS,natural_language_inference,27,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.6785714285714286,201,0.5946745562130178,19,0.6785714285714286,1,1,experiments
203,"We additionally use dropout on word , character embeddings and between layers , where the word and character dropout rates are 0.1 and 0.05 respectively , and the dropout rate between every two layers is 0.1 .",DATASET AND EXPERIMENTAL SETTINGS,DATASET AND EXPERIMENTAL SETTINGS,natural_language_inference,27,"['O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",20,0.7142857142857143,202,0.5976331360946746,20,0.7142857142857143,1,1,experiments
204,"We also adopt the stochastic depth method ( layer dropout ) within each embedding or model encoder layer , where sublayer l has survival probability pl = 1 ? l L ( 1 ? p L ) where L is the last layer and p L = 0.9 .",DATASET AND EXPERIMENTAL SETTINGS,DATASET AND EXPERIMENTAL SETTINGS,natural_language_inference,27,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O']",,,21,0.75,203,0.6005917159763313,21,0.75,1,1,experiments
205,"The hidden size and the convolution filter number are all 128 , the batch size is 32 , training steps are 150 K for original data , 250 K for "" data augmentation 2 "" , and 340 K for "" data augmentation 3 "" .",DATASET AND EXPERIMENTAL SETTINGS,DATASET AND EXPERIMENTAL SETTINGS,natural_language_inference,27,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O']",,,22,0.7857142857142857,204,0.6035502958579881,22,0.7857142857142857,1,1,experiments
206,"The numbers of convolution layers in the embedding and modeling encoder are 4 and 2 , kernel sizes are 7 and 5 , and the block numbers for the encoders are 1 and 7 , respectively .",DATASET AND EXPERIMENTAL SETTINGS,DATASET AND EXPERIMENTAL SETTINGS,natural_language_inference,27,"['O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O']",,,23,0.8214285714285714,205,0.606508875739645,23,0.8214285714285714,1,1,experiments
207,"We use the ADAM optimizer ( Kingma & Ba , 2014 ) with ? 1 = 0.8 , ? 2 = 0.999 , = 10 ?7 .",DATASET AND EXPERIMENTAL SETTINGS,DATASET AND EXPERIMENTAL SETTINGS,natural_language_inference,27,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",24,0.8571428571428571,206,0.6094674556213018,24,0.8571428571428571,1,1,experiments
208,"We use a learning rate warm - up scheme with an inverse exponential increase from 0.0 to 0.001 in the first 1000 steps , and then maintain a constant learning rate for the remainder of training .",DATASET AND EXPERIMENTAL SETTINGS,DATASET AND EXPERIMENTAL SETTINGS,natural_language_inference,27,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",25,0.8928571428571429,207,0.6124260355029586,25,0.8928571428571429,1,1,experiments
209,Exponential moving average is applied on all trainable variables with a decay rate 0.9999 .,DATASET AND EXPERIMENTAL SETTINGS,DATASET AND EXPERIMENTAL SETTINGS,natural_language_inference,27,"['B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",26,0.9285714285714286,208,0.6153846153846154,26,0.9285714285714286,1,1,experiments
210,"Finally , we implement our model in Python using Tensorflow and carry out our experiments on an NVIDIA p 100 GPU .",DATASET AND EXPERIMENTAL SETTINGS,DATASET AND EXPERIMENTAL SETTINGS,natural_language_inference,27,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,0.9642857142857143,209,0.6183431952662722,27,0.9642857142857143,1,1,experiments
219,"As can be seen from the table , the accuracy ( EM / F1 ) performance of our model is on par with the state - of - the - art models .",RESULTS,RESULTS,natural_language_inference,27,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.10294117647058823,218,0.6449704142011834,7,0.22580645161290322,1,1,experiments
220,"In particular , our model trained on the original dataset outperforms all the documented results in the literature , in terms of both EM and F1 scores ( see second column of ) .",RESULTS,RESULTS,natural_language_inference,27,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.11764705882352941,219,0.6479289940828402,8,0.25806451612903225,1,1,experiments
221,"When trained with the augmented data with proper sampling scheme , our model can get significant gain 1.5/1.1 on EM / F1 .",RESULTS,RESULTS,natural_language_inference,27,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.1323529411764706,220,0.650887573964497,9,0.2903225806451613,1,1,experiments
222,"Finally , our result on the official test set is 76.2/84.6 , which significantly outperforms the best documented result 73.2/81.8 .",RESULTS,RESULTS,natural_language_inference,27,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.14705882352941177,221,0.6538461538461539,10,0.3225806451612903,1,1,experiments
247,"As can be seen from the table , the use of convolutions in the encoders is crucial : both F1 and EM drop drastically by almost 3 percent if it is removed .",RESULTS,ABALATION STUDY AND ANALYSIS,natural_language_inference,27,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'B-p', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-ob', 'O']",35,0.5147058823529411,246,0.727810650887574,3,0.14285714285714285,1,1,ablation-analysis
248,Self- attention in the encoders is also a necessary component that contributes 1.4/1.3 gain of EM / F1 to the ultimate performance .,RESULTS,ABALATION STUDY AND ANALYSIS,natural_language_inference,27,"['B', 'I', 'B', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",36,0.5294117647058824,247,0.7307692307692307,4,0.19047619047619047,1,1,ablation-analysis
254,"As the last block of rows in the table shows , data augmentation proves to be helpful in further boosting performance .",RESULTS,ABALATION STUDY AND ANALYSIS,natural_language_inference,27,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",42,0.6176470588235294,253,0.7485207100591716,10,0.47619047619047616,1,1,ablation-analysis
255,"Making the training data twice as large by adding the En - Fr - En data only ( ratio 1:1 between original training data and augmented data , as indicated by row "" data augmentation 2 ( 1:1:0 ) "" ) yields an increase in the F1 by 0.5 percent .",RESULTS,ABALATION STUDY AND ANALYSIS,natural_language_inference,27,"['B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'O']",43,0.6323529411764706,254,0.7514792899408284,11,0.5238095238095238,1,1,ablation-analysis
259,"Although injecting more data beyond 3 does not benefit the model , we observe that a good sampling ratio between the original and augmented data during training can further boost the model performance .",RESULTS,ABALATION STUDY AND ANALYSIS,natural_language_inference,27,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'I-p', 'B-b', 'O', 'B-ob', 'I-ob', 'O']",47,0.6911764705882353,258,0.7633136094674556,15,0.7142857142857143,1,1,ablation-analysis
260,"In particular , when we increase the sampling weight of augmented data from ( 1:1:1 ) to ( 1:2:1 ) , the EM / F1 performance drops by 0.5/0.3 .",RESULTS,ABALATION STUDY AND ANALYSIS,natural_language_inference,27,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-b', 'B-p', 'B-ob', 'O']",48,0.7058823529411765,259,0.7662721893491125,16,0.7619047619047619,1,1,ablation-analysis
264,"Empirically , the ratio ( 3:1:1 ) yields the best performance , with 1.5/1.1 gain over the base model on EM / F1 .",RESULTS,ABALATION STUDY AND ANALYSIS,natural_language_inference,27,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",52,0.7647058823529411,263,0.7781065088757396,20,0.9523809523809523,1,1,ablation-analysis
4,The concepts of unitary evolution matrices and associative memory have boosted the field of Recurrent Neural Networks ( RNN ) to state - of - the - art performance in a variety of sequential tasks .,,ROTATIONAL UNIT OF MEMORY,natural_language_inference,28,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.26666666666666666,3,0.01107011070110701,1,0.08333333333333333,1,1,research-problem
5,"However , RNN still have a limited capacity to manipulate long - term memory .",,ROTATIONAL UNIT OF MEMORY,natural_language_inference,28,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.3333333333333333,4,0.014760147601476014,2,0.16666666666666666,1,1,research-problem
27,"Here , we propose a novel RNN cell that resolves simultaneously those weaknesses of basic RNN .",INTRODUCTION,INTRODUCTION,natural_language_inference,28,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.4782608695652174,26,0.0959409594095941,11,0.4782608695652174,1,1,model
28,The Rotational Unit of Memory is a modified gated model whose rotational operation acts as associative memory and is strictly an orthogonal matrix .,INTRODUCTION,INTRODUCTION,natural_language_inference,28,"['O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",12,0.5217391304347826,27,0.0996309963099631,12,0.5217391304347826,1,1,model
146,COPYING MEMORY TASK,EXPERIMENTS,,natural_language_inference,28,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",6,0.11538461538461539,145,0.5350553505535055,0,0.0,1,1,experiments
151,"1 . RUM utilizes a different representation of memory that outperforms those of LSTM and GRU ; 2 . RUM solves the task completely , despite its update gate , which does not allow all of the information encoded in the hidden stay to pass through .",EXPERIMENTS,COPYING MEMORY TASK,natural_language_inference,28,"['O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.21153846153846154,150,0.5535055350553506,5,0.2777777777777778,1,1,experiments
165,ASSOCIATIVE RECALL TASK,EXPERIMENTS,,natural_language_inference,28,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",25,0.4807692307692308,164,0.6051660516605166,0,0.0,1,1,experiments
175,All the models have the same hidden state N h = 50 for different lengths T .,EXPERIMENTS,ASSOCIATIVE RECALL TASK,natural_language_inference,28,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",35,0.6730769230769231,174,0.6420664206642066,10,0.7142857142857143,1,1,experiments
176,We use a batch size 128 .,EXPERIMENTS,ASSOCIATIVE RECALL TASK,natural_language_inference,28,"['O', 'B', 'O', 'B', 'I', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-ob', 'O']",36,0.6923076923076923,175,0.6457564575645757,11,0.7857142857142857,1,1,experiments
177,The optimizer is RMSProp with a learning rate 0.001 .,EXPERIMENTS,ASSOCIATIVE RECALL TASK,natural_language_inference,28,"['O', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-ob', 'O']",37,0.7115384615384616,176,0.6494464944649446,12,0.8571428571428571,1,1,experiments
178,"We find that LSTM fails to learn the task , because of its lack of sufficient memory capacity .",EXPERIMENTS,ASSOCIATIVE RECALL TASK,natural_language_inference,28,"['O', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,38,0.7307692307692307,177,0.6531365313653137,13,0.9285714285714286,1,1,experiments
179,"NTM and Fast - weight RNN fail longer tasks , which means they can not learn to manipulate their memory efficiently .",EXPERIMENTS,ASSOCIATIVE RECALL TASK,natural_language_inference,28,"['B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",39,0.75,178,0.6568265682656826,14,1.0,1,1,experiments
180,QUESTION ANSWERING,EXPERIMENTS,,natural_language_inference,28,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",40,0.7692307692307693,179,0.6605166051660517,0,0.0,1,1,experiments
187,"We compare our model with several baselines : a simple LSTM , an End - to - end Memory Network ) and a GORU .",EXPERIMENTS,QUESTION ANSWERING,natural_language_inference,28,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'O']",47,0.9038461538461539,186,0.6863468634686347,7,0.7,1,1,experiments
188,"We find that RUM outperforms significantly LSTM and GORU and achieves competitive result with those of MemN2N , which has an attention mechanism .",EXPERIMENTS,QUESTION ANSWERING,natural_language_inference,28,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'B-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",48,0.9230769230769231,187,0.6900369003690037,8,0.8,1,1,experiments
193,CHARACTER LEVEL LANGUAGE MODELING,,,natural_language_inference,28,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",0,0.0,192,0.7084870848708487,0,0.0,1,1,experiments
196,PENN TREEBANK CORPUS DATA SET,CHARACTER LEVEL LANGUAGE MODELING,,natural_language_inference,28,"['B', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b']",3,0.038461538461538464,195,0.7195571955719557,0,0.0,1,1,experiments
215,"FS - RUM - 2 generalizes better than other gated models , such as GRU and LSTM , because it learns efficient patterns for activation in its kernels .",CHARACTER LEVEL LANGUAGE MODELING,PENN TREEBANK CORPUS DATA SET,natural_language_inference,28,"['B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.28205128205128205,214,0.7896678966789668,19,0.9047619047619048,1,1,experiments
2,Product - Aware Answer Generation in E - Commerce Question - Answering,title,title,natural_language_inference,29,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.0027397260273972603,1,0.0,1,1,research-problem
14,"In recent years , the explosive popularity of question - answering ( QA ) is revitalizing the task of reading comprehension with promising results .",INTRODUCTION,INTRODUCTION,natural_language_inference,29,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.004132231404958678,13,0.03561643835616438,1,0.025,1,1,research-problem
38,"In this paper , we propose the product - aware answer generator ( PAAG ) , a product related question answering model which incorporates customer reviews with product attributes .",INTRODUCTION,INTRODUCTION,natural_language_inference,29,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",25,0.10330578512396695,37,0.10136986301369863,25,0.625,1,1,model
39,"Specifically , at the beginning we employ an attention mechanism to model interactions between a question and reviews .",INTRODUCTION,INTRODUCTION,natural_language_inference,29,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",26,0.10743801652892562,38,0.10410958904109589,26,0.65,1,1,model
40,"Simultaneously , we employ a key - value memory network to store the product attributes and extract the relevance values according to the question .",INTRODUCTION,INTRODUCTION,natural_language_inference,29,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",27,0.1115702479338843,39,0.10684931506849316,27,0.675,1,1,model
41,"Eventually , we propose a recurrent neural network ( RNN ) based decoder , which combines product - aware review representation and attributes to generate the answer .",INTRODUCTION,INTRODUCTION,natural_language_inference,29,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",28,0.11570247933884298,40,0.1095890410958904,28,0.7,1,1,model
42,"More importantly , to tackle the problem of meaningless answers , we propose an adversarial learning mechanism in the loss calculation for optimizing parameters .",INTRODUCTION,INTRODUCTION,natural_language_inference,29,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'O']",29,0.11983471074380166,41,0.11232876712328767,29,0.725,1,1,model
269,( 1 ) S2SA : Sequence - to - sequence framework has been proposed for language generation task .,Evaluation metrics,Comparisons,natural_language_inference,29,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",13,0.5,268,0.7342465753424657,3,0.1875,1,1,baselines
272,( 2 ) S2SAR : We implement a simple method which can incorporate the review information when generating the answer .,Evaluation metrics,Comparisons,natural_language_inference,29,"['O', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",16,0.6153846153846154,271,0.7424657534246575,6,0.375,1,1,baselines
274,( 3 ) SNet : S- Net is a two - stage state - of - the - art model which extracts some text spans from multiple documents context and synthesis the answer from those spans .,Evaluation metrics,Comparisons,natural_language_inference,29,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'O']",,,18,0.6923076923076923,273,0.7479452054794521,8,0.5,1,1,baselines
277,( 4 ) QS : We implement the query - based summarization model proposed by Hasselqvist et al ..,Evaluation metrics,Comparisons,natural_language_inference,29,"['O', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.8076923076923077,276,0.7561643835616438,11,0.6875,1,1,baselines
279,( 5 ) BM25 : BM25 is a bag - of - words retrieval function that ranks a set of reviews based on the question terms appearing in each review .,Evaluation metrics,Comparisons,natural_language_inference,29,"['O', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",23,0.8846153846153846,278,0.7616438356164383,13,0.8125,1,1,baselines
281,( 6 ) TF - IDF : Term Frequency - Inverse Document Frequency is a numerical statistic that is intended to reflect how important a question word is to a review .,Evaluation metrics,Comparisons,natural_language_inference,29,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'O']",25,0.9615384615384616,280,0.7671232876712328,15,0.9375,1,1,baselines
284,"Without using pre-trained embeddings , we randomly initialize the network parameters at the beginning of our experiments .",Implementation details,Implementation details,natural_language_inference,29,"['B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O']","['B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O']",1,0.029411764705882353,283,0.7753424657534247,1,0.16666666666666666,1,1,experimental-setup
285,All the RNN networks have 512 hidden units and the dimension of word embedding is 256 .,Implementation details,Implementation details,natural_language_inference,29,"['B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",2,0.058823529411764705,284,0.7780821917808219,2,0.3333333333333333,1,1,experimental-setup
286,"To produce better answers , we use beam search with beam size",Implementation details,Implementation details,natural_language_inference,29,"['B', 'I', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n']","['B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b']",3,0.08823529411764706,285,0.7808219178082192,3,0.5,1,1,experimental-setup
287,4 .,Implementation details,Implementation details,natural_language_inference,29,"['B', 'O']","['B-n', 'O']","['B-ob', 'O']",4,0.11764705882352941,286,0.7835616438356164,4,0.6666666666666666,1,1,experimental-setup
288,Adagrad with learning rate 0.1 is used to optimize the parameters and batch size is 64 .,Implementation details,Implementation details,natural_language_inference,29,"['B', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'B-n', 'B-p', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'B-b', 'B-p', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'O']",5,0.14705882352941177,287,0.7863013698630137,5,0.8333333333333334,1,1,experimental-setup
289,We implement our model using TensorFlow framework and train our model and all baseline models on NVIDIA Tesla P40 GPU .,Implementation details,Implementation details,natural_language_inference,29,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.17647058823529413,288,0.7890410958904109,6,1.0,1,1,experimental-setup
294,"In these experimental results , we see that PAAG achieves a 111 % , 8 % and 62.73 % increment over the stateof - the - art baseline SNet in terms of BLEU , embedding greedy and consistency score , respectively .",Implementation details,Implementation details,natural_language_inference,29,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O']",11,0.3235294117647059,293,0.8027397260273973,4,0.14814814814814814,1,1,results
295,"In , we see that our PAAG outperforms all the baseline significantly in semantic distance with respect to the ground truth .",Implementation details,Implementation details,natural_language_inference,29,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-b', 'I-b', 'I-b', 'B-ob', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",12,0.35294117647058826,294,0.8054794520547945,5,0.18518518518518517,1,1,results
299,"In , we can see that PAAG outperforms other baseline models in both sentence fluency and consistency with the facts .",Implementation details,Implementation details,natural_language_inference,29,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",16,0.47058823529411764,298,0.8164383561643835,9,0.3333333333333333,1,1,results
305,"Although there is a small increment of S2 SAR with respect to S2SA in all metrics , we still find a noticeable gap between S2SAR and PAAG .",Implementation details,Implementation details,natural_language_inference,29,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",22,0.6470588235294118,304,0.8328767123287671,15,0.5555555555555556,1,1,results
323,"There is a slight increment from RAGF to RAGFD , which demonstrates the effectiveness of discriminator .",Ablation studies,Ablation studies,natural_language_inference,29,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O']",5,0.13157894736842105,322,0.8821917808219178,5,0.625,1,1,ablation-analysis
324,"From , we find that RAGFWD achieves a 4.3 % improvement over RAGFD in terms of BLEU , and PAAG outperforms RAGFWD 4.1 % in terms of BLEU .",Ablation studies,Ablation studies,natural_language_inference,29,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'B', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'O']",,,6,0.15789473684210525,323,0.8849315068493151,6,0.75,1,1,ablation-analysis
325,"Accordingly , we conclude that the performance of PAAG benefits from using Wasserstein distance based adversarial learning with gradient penalty .",Ablation studies,Ablation studies,natural_language_inference,29,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'I-p', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'I-p', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.18421052631578946,324,0.8876712328767123,7,0.875,1,1,ablation-analysis
326,This approach can help our model to achieve a better performance than the model using the vanilla GAN architecture .,Ablation studies,Ablation studies,natural_language_inference,29,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.21052631578947367,325,0.8904109589041096,8,1.0,1,1,ablation-analysis
2,Modelling Interaction of Sentence Pair with Coupled- LSTMs,title,,natural_language_inference,3,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",1,0.0,1,0.004807692307692308,1,0.0,1,1,research-problem
4,"Recently , there is rising interest in modelling the interactions of two sentences with deep neural networks .",abstract,abstract,natural_language_inference,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.16666666666666666,3,0.014423076923076924,1,0.16666666666666666,1,1,research-problem
12,"Among these tasks , a common problem is modelling the relevance / similarity of the sentence pair , which is also called text semantic matching .",Introduction,Introduction,natural_language_inference,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.2222222222222222,11,0.052884615384615384,2,0.0625,1,1,research-problem
28,"In this paper , we propose a new deep neural network architecture to model the strong interactions of two sentences .",Strong Interaction Models,Strong Interaction Models,natural_language_inference,3,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",4,0.2222222222222222,27,0.12980769230769232,18,0.5625,1,1,model
29,"Different with modelling two sentences with separated LSTMs , we utilize two interdependent LSTMs , called coupled - LSTMs , to fully affect each other at different time steps .",Strong Interaction Models,Strong Interaction Models,natural_language_inference,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",5,0.2777777777777778,28,0.1346153846153846,19,0.59375,1,1,model
30,The output of coupled - LSTMs at each step depends on both sentences .,Strong Interaction Models,Strong Interaction Models,natural_language_inference,3,"['O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",6,0.3333333333333333,29,0.13942307692307693,20,0.625,1,1,model
31,"Specifically , we propose two interdependent ways for the coupled - LSTMs : loosely coupled model ( LC - LSTMs ) and tightly coupled model ( TC - LSTMs ) .",Strong Interaction Models,Strong Interaction Models,natural_language_inference,3,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.3888888888888889,30,0.14423076923076922,21,0.65625,1,1,model
33,"To utilize all the information of four directions of coupled - LSTMs , we aggregate them and adopt a dynamic pooling strategy to automatically select the most informative interaction signals .",Strong Interaction Models,Strong Interaction Models,natural_language_inference,3,"['O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O']",,,9,0.5,32,0.15384615384615385,23,0.71875,1,1,model
34,"Finally , we feed them into a fully connected layer , followed by an output layer to compute the matching score .",Strong Interaction Models,Strong Interaction Models,natural_language_inference,3,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",10,0.5555555555555556,33,0.15865384615384615,24,0.75,1,1,model
151,"The word embeddings for all of the models are initialized with the 100d GloVe vectors ( 840B token version , ) and fine - tuned during training to improve the performance .",Hyperparameters and Training,Hyperparameters and Training,natural_language_inference,3,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",1,0.3333333333333333,150,0.7211538461538461,1,0.3333333333333333,1,1,hyperparameters
152,"The other parameters are initialized by randomly sampling from uniform distribution in [ ? 0.1 , 0.1 ] .",Hyperparameters and Training,Hyperparameters and Training,natural_language_inference,3,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.6666666666666666,151,0.7259615384615384,2,0.6666666666666666,1,1,hyperparameters
153,"For each task , we take the hyperparameters which achieve the best performance on the development set via an small grid search over combinations of the initial learning rate [ 0.05 , 0.0005 , 0.0001 ] , l 2 regularization [ 0.0 , 5 E? 5 , 1E? 5 , 1E? 6 ] and the threshold value",Hyperparameters and Training,Hyperparameters and Training,natural_language_inference,3,"['B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob']",3,1.0,152,0.7307692307692307,3,1.0,1,1,hyperparameters
155,Neural bag - of - words ( NBOW ) :,Competitor Methods,Competitor Methods,natural_language_inference,3,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",1,0.07692307692307693,154,0.7403846153846154,1,0.07692307692307693,1,1,baselines
156,"Each sequence as the sum of the embeddings of the words it contains , then they are concatenated and fed to a MLP .",Competitor Methods,Competitor Methods,natural_language_inference,3,"['B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O']","['B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",2,0.15384615384615385,155,0.7451923076923077,2,0.15384615384615385,1,1,baselines
157,"Single LSTM : A single LSTM to encode the two sequences , which is used in .",Competitor Methods,Competitor Methods,natural_language_inference,3,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.23076923076923078,156,0.75,3,0.23076923076923078,1,1,baselines
158,"Parallel LSTMs : Two sequences are encoded by two LSTMs separately , then they are concatenated and fed to a MLP .",Competitor Methods,Competitor Methods,natural_language_inference,3,"['B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O']",,,4,0.3076923076923077,157,0.7548076923076923,4,0.3076923076923077,1,1,baselines
159,"Attention LSTMs : An attentive LSTM to encode two sentences into a semantic space , which used in .",Competitor Methods,Competitor Methods,natural_language_inference,3,"['B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",5,0.38461538461538464,158,0.7596153846153846,5,0.38461538461538464,1,1,baselines
160,Experiment - I : Recognizing Textual Entailment,Competitor Methods,,natural_language_inference,3,"['B', 'I', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",6,0.46153846153846156,159,0.7644230769230769,6,0.46153846153846156,1,1,results
169,"Our proposed two C - LSTMs models with four stacked blocks outperform all the competitor models , which indicates that our thinner and deeper network does work effectively .",Results,Results,natural_language_inference,3,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.025,168,0.8076923076923077,1,0.041666666666666664,1,1,results
172,"Compared with attention LSTMs , our two models achieve comparable results to them using much fewer parameters ( nearly 1 / 5 ) .",Results,Results,natural_language_inference,3,"['B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.1,171,0.8221153846153846,4,0.16666666666666666,1,1,results
173,"By stacking C - LSTMs , the performance of them are improved significantly , and the four stacked TC - LSTMs achieve 85.1 % accuracy on this dataset .",Results,Results,natural_language_inference,3,"['B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'O', 'O', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.125,172,0.8269230769230769,5,0.20833333333333334,1,1,results
2,Open Question Answering with Weakly Supervised Embedding Models,title,title,natural_language_inference,30,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.003875968992248062,1,0.0,1,1,research-problem
12,"This paper addresses the challenging problem of open - domain question answering , which consists of building systems able to answer questions from any domain .",Introduction,Introduction,natural_language_inference,30,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.03333333333333333,11,0.04263565891472868,1,0.03333333333333333,1,1,research-problem
16,Question answering is then defined as the task of retrieving the correct entity or set of entities from a KB given a query expressed as a question in natural language .,Introduction,Introduction,natural_language_inference,30,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.16666666666666666,15,0.05813953488372093,5,0.16666666666666666,1,1,research-problem
23,"In this paper , we instead take the approach of converting questions to ( uninterpretable ) vectorial representations which require no pre-defined grammars or lexicons and can query any KB independent of its schema .",Introduction,Introduction,natural_language_inference,30,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'O']",,,12,0.4,22,0.08527131782945736,12,0.4,1,1,approach
24,"Following , we focus on answering simple factual questions on a broad range of topics , more specifically , those for which single KB triples stand for both the question and an answer ( of which there maybe many ) .",Introduction,Introduction,natural_language_inference,30,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.43333333333333335,23,0.08914728682170543,13,0.43333333333333335,1,1,approach
31,Our approach is based on learning low - dimensional vector embeddings of words and of KB triples so that representations of questions and corresponding answers end up being similar in the embedding space .,Introduction,Introduction,natural_language_inference,30,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O']",,,20,0.6666666666666666,30,0.11627906976744186,20,0.6666666666666666,1,1,approach
33,"In order to avoid transferring the cost of manual intervention to the one of labeling large amounts of data , we make use of weak supervision .",Introduction,Introduction,natural_language_inference,30,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",22,0.7333333333333333,32,0.12403100775193798,22,0.7333333333333333,1,1,approach
34,We show empirically that our model is able to take advantage of noisy and indirect supervision by ( i ) automatically generating questions from KB triples and treating this as training data ; and ( ii ) supplementing this with a data set of questions collaboratively marked as paraphrases but with no associated answers .,Introduction,Introduction,natural_language_inference,30,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'O', 'B-b', 'I-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",23,0.7666666666666667,33,0.12790697674418605,23,0.7666666666666667,1,1,approach
35,We end up learning meaningful vectorial representations for questions involving up to 800 k words and for triples of an mostly automatically created KB with 2.4 M entities and 600 k relationships .,Introduction,Introduction,natural_language_inference,30,"['O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",24,0.8,34,0.13178294573643412,24,0.8,1,1,approach
201,"First , we can see that multitasking with paraphrase data is essential since it improves F1 from 0.60 to 0.68 .",Results,This section now discusses our empirical performance .,natural_language_inference,30,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O']",4,0.17391304347826086,200,0.7751937984496124,4,0.2,1,1,results
207,Fine - tuning the embedding model is very beneficial to optimize the top of the list and grants a bump of 5 points of F1 : carefully tuning the similarity makes a clear difference .,Results,This section now discusses our empirical performance .,natural_language_inference,30,"['B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,10,0.43478260869565216,206,0.7984496124031008,10,0.5,1,1,results
208,"All versions of our system greatly outperform paralex : the fine - tuned model improves the F1 - score by almost 20 points and , according to , is better in precision for all levels of recall .",Results,This section now discusses our empirical performance .,natural_language_inference,30,"['B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'I-b', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.4782608695652174,207,0.8023255813953488,11,0.55,1,1,results
231,"As expected , string matching greatly improves results , both in precision and recall , and also significantly reduces evaluation time .",R:wide-range-of-application.e can-be-useful-for.r,L:x - ray.e L:gamma - ray .,natural_language_inference,30,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-b', 'I-b', 'B-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'B-ob', 'I-ob', 'O']",10,0.625,230,0.8914728682170543,13,0.6842105263157895,1,1,results
232,"The final F1 obtained by our fine - tuned model is even better then the result of paralex in reranking , which is pretty remarkable , because this time , this setting advantages it quite a lot .",R:wide-range-of-application.e can-be-useful-for.r,L:x - ray.e L:gamma - ray .,natural_language_inference,30,"['O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.6875,231,0.8953488372093024,14,0.7368421052631579,1,1,results
2,Simple and Effective Text Matching with Richer Alignment Features,title,title,natural_language_inference,31,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.0036231884057971015,1,0.0,1,1,research-problem
21,"This paper presents RE2 , a fast and strong neural architecture with multiple alignment processes for general purpose text matching .",Introduction,Introduction,natural_language_inference,31,"['O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.4642857142857143,20,0.07246376811594203,13,0.4642857142857143,1,1,model
25,"These components , which the name RE2 stands for , are previous aligned features ( Residual vectors ) , original point - wise features ( Embedding vectors ) , and contextual features ( Encoded vectors ) .",Introduction,Introduction,natural_language_inference,31,"['O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O']","['O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O']","['O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'O']",17,0.6071428571428571,24,0.08695652173913043,17,0.6071428571428571,1,1,model
28,An embedding layer first embeds discrete tokens .,Introduction,,natural_language_inference,31,"['O', 'B', 'I', 'O', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",20,0.7142857142857143,27,0.09782608695652174,20,0.7142857142857143,1,1,model
29,"Several same - structured blocks consisting of encoding , alignment and fusion layers then process the sequences consecutively .",Introduction,An embedding layer first embeds discrete tokens .,natural_language_inference,31,"['O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'B-ob', 'O']",21,0.75,28,0.10144927536231885,21,0.75,1,1,model
30,These blocks are connected by an augmented version of residual connections ( see section 2.1 ) .,Introduction,An embedding layer first embeds discrete tokens .,natural_language_inference,31,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.7857142857142857,29,0.10507246376811594,22,0.7857142857142857,1,1,model
31,A pooling layer aggregates sequential representations into vectors which are finally processed by a prediction layer to give the final prediction .,Introduction,An embedding layer first embeds discrete tokens .,natural_language_inference,31,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",23,0.8214285714285714,30,0.10869565217391304,23,0.8214285714285714,1,1,model
32,"The implementation of each layer is kept as simple as possible , and the whole model , as a well - organized combination , is quite powerful and lightweight at the same time .",Introduction,An embedding layer first embeds discrete tokens .,natural_language_inference,31,"['O', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",24,0.8571428571428571,31,0.11231884057971014,24,0.8571428571428571,1,1,model
127,We implement our model with TensorFlow and train on Nvidia P100 GPUs .,Implementation Details,Implementation Details,natural_language_inference,31,"['O', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.038461538461538464,126,0.45652173913043476,1,0.045454545454545456,1,1,experimental-setup
128,"We tokenize sentences with the NLTK toolkit , convert them to lower cases and remove all punctuations .",Implementation Details,Implementation Details,natural_language_inference,31,"['O', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",2,0.07692307692307693,127,0.4601449275362319,2,0.09090909090909091,1,1,experimental-setup
130,Word embeddings are initialized with 840B - 300d,Implementation Details,,natural_language_inference,31,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob']",4,0.15384615384615385,129,0.4673913043478261,4,0.18181818181818182,1,1,experimental-setup
131,Glo Ve word vectors and fixed during training .,Implementation Details,,natural_language_inference,31,"['B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",5,0.19230769230769232,130,0.47101449275362317,5,0.22727272727272727,1,1,experimental-setup
132,Embeddings of out - ofvocabulary words are initialized to zeros and fixed as well .,Implementation Details,Glo Ve word vectors and fixed during training .,natural_language_inference,31,"['B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O']",6,0.23076923076923078,131,0.4746376811594203,6,0.2727272727272727,1,1,experimental-setup
133,All other parameters are initialized with He initialization and normalized by weight normalization .,Implementation Details,Glo Ve word vectors and fixed during training .,natural_language_inference,31,"['B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.2692307692307692,132,0.4782608695652174,7,0.3181818181818182,1,1,experimental-setup
134,Dropout with a keep probability of 0.8 is applied before every fully - connected or convolutional layer .,Implementation Details,Glo Ve word vectors and fixed during training .,natural_language_inference,31,"['B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",8,0.3076923076923077,133,0.48188405797101447,8,0.36363636363636365,1,1,experimental-setup
135,The kernel size of the convolutional encoder is set to 3 .,Implementation Details,Glo Ve word vectors and fixed during training .,natural_language_inference,31,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'O']",9,0.34615384615384615,134,0.4855072463768116,9,0.4090909090909091,1,1,experimental-setup
136,The prediction layer is a two - layer feed - forward network .,Implementation Details,Glo Ve word vectors and fixed during training .,natural_language_inference,31,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.38461538461538464,135,0.4891304347826087,10,0.45454545454545453,1,1,experimental-setup
137,The hidden size is set to 150 in all experiments .,Implementation Details,Glo Ve word vectors and fixed during training .,natural_language_inference,31,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O']",11,0.4230769230769231,136,0.4927536231884058,11,0.5,1,1,experimental-setup
138,"Activations in all feed - forward networks are GeLU activations , and we use ?",Implementation Details,Glo Ve word vectors and fixed during training .,natural_language_inference,31,"['B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",12,0.46153846153846156,137,0.4963768115942029,12,0.5454545454545454,1,1,experimental-setup
140,We scale the summation in augmented residual connections by 1 / ? 2 when n ? 3 to preserve the variance under the assumption that the two addends have the same variance .,Implementation Details,Glo Ve word vectors and fixed during training .,natural_language_inference,31,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",14,0.5384615384615384,139,0.5036231884057971,14,0.6363636363636364,1,1,experimental-setup
141,The number of blocks is tuned in a range from 1 to 3 .,Implementation Details,Glo Ve word vectors and fixed during training .,natural_language_inference,31,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",15,0.5769230769230769,140,0.5072463768115942,15,0.6818181818181818,1,1,experimental-setup
142,The number of layers of the convolutional encoder is tuned from 1 to 3 .,Implementation Details,Glo Ve word vectors and fixed during training .,natural_language_inference,31,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O']",16,0.6153846153846154,141,0.5108695652173914,16,0.7272727272727273,1,1,experimental-setup
144,"We use the Adam optimizer ( Kingma and Ba , 2015 ) and an exponentially decaying learning rate with a linear warmup .",Implementation Details,Glo Ve word vectors and fixed during training .,natural_language_inference,31,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",18,0.6923076923076923,143,0.5181159420289855,18,0.8181818181818182,1,1,experimental-setup
145,The initial learning rate is tuned from 0.0001 to 0.003 .,Implementation Details,Glo Ve word vectors and fixed during training .,natural_language_inference,31,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",19,0.7307692307692307,144,0.5217391304347826,19,0.8636363636363636,1,1,experimental-setup
146,The batch size is tuned from 64 to 512 .,Implementation Details,Glo Ve word vectors and fixed during training .,natural_language_inference,31,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",20,0.7692307692307693,145,0.5253623188405797,20,0.9090909090909091,1,1,experimental-setup
147,The threshold for gradient clipping is set to 5 .,Implementation Details,Glo Ve word vectors and fixed during training .,natural_language_inference,31,"['O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",21,0.8076923076923077,146,0.5289855072463768,21,0.9545454545454546,1,1,experimental-setup
160,Results on WikiQA dataset are listed in .,Results on Answer Selection,,natural_language_inference,31,"['O', 'B', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O']",1,0.04,159,0.5760869565217391,1,0.16666666666666666,1,1,results
163,We obtain a result on par with the state - of - the - art reported on this dataset .,Results on Answer Selection,Results on WikiQA dataset are listed in .,natural_language_inference,31,"['O', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",4,0.16,162,0.5869565217391305,4,0.6666666666666666,1,1,results
165,Our method can perform well in the answer selection task without any taskspecific modifications .,Results on Answer Selection,Results on WikiQA dataset are listed in .,natural_language_inference,31,"['O', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-n', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.24,164,0.5942028985507246,6,1.0,1,1,results
198,"The first ablation baseline shows that without richer features as the alignment input , the performance on all datasets degrades significantly .",Ablation study .,The result is shown in .,natural_language_inference,31,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-ob', 'I-ob', 'O']",13,0.22033898305084745,197,0.7137681159420289,14,0.23333333333333334,1,1,ablation-analysis
200,The results of the second baseline show that vanilla residual connections without direct access to the original pointwise features are not enough to model the relations in many text matching tasks .,Ablation study .,The result is shown in .,natural_language_inference,31,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.2542372881355932,199,0.7210144927536232,16,0.26666666666666666,1,1,ablation-analysis
201,"The simpler implementation of the fusion layer leads to evidently worse performance , indicating that the fu- sion layer can not be further simplified .",Ablation study .,The result is shown in .,natural_language_inference,31,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.2711864406779661,200,0.7246376811594203,17,0.2833333333333333,1,1,ablation-analysis
203,"In the last ablation study , we can see that parallel blocks perform worse than stacked blocks , which supports the preference for deeper models over wider ones .",Ablation study .,The result is shown in .,natural_language_inference,31,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",18,0.3050847457627119,202,0.7318840579710145,19,0.31666666666666665,1,1,ablation-analysis
2,FLOWQA : GRASPING FLOW IN HISTORY FOR CONVERSATIONAL MACHINE COMPREHENSION,title,title,natural_language_inference,32,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.002288329519450801,1,0.0,1,1,research-problem
13,"We present FLOWQA , a model designed for conversational machine comprehension .",abstract,abstract,natural_language_inference,32,"['O', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.07575757575757576,12,0.02745995423340961,10,0.2777777777777778,1,1,model
14,FLOWQA consists of two main components : a base neural model for single - turn MC and a FLOW mechanism that encodes the conversation history .,abstract,abstract,natural_language_inference,32,"['B', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'O']","['B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",11,0.08333333333333333,13,0.029748283752860413,11,0.3055555555555556,1,1,model
15,"Instead of using the shallow history , i.e. , previous questions and answers , we feed the model with the entire hidden representations generated during the process of answering previous questions .",abstract,abstract,natural_language_inference,32,"['O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.09090909090909091,14,0.032036613272311214,12,0.3333333333333333,1,1,model
17,"This FLOW mechanism is also remarkably effective at tracking the world states for sequential instruction understanding ( Long et al. , 2016 ) : after mapping world states as context and instructions as questions , FLOWQA can interpret a sequence of inter-connected instructions and generate corresponding world state changes as answers .",abstract,abstract,natural_language_inference,32,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.10606060606060606,16,0.036613272311212815,14,0.3888888888888889,1,1,model
18,"The FLOW mechanism can be viewed as stacking single - turn QA models along the dialog progression ( i.e. , the question turns ) and building information flow along the dialog .",abstract,abstract,natural_language_inference,32,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'O']",,,15,0.11363636363636363,17,0.038901601830663615,15,0.4166666666666667,1,1,model
19,"This information transfer happens for each context word , allowing rich information in the reasoning process to flow .",abstract,abstract,natural_language_inference,32,"['O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'O']",16,0.12121212121212122,18,0.041189931350114416,16,0.4444444444444444,1,1,model
22,"To handle this issue , we propose an alternating parallel processing structure , which alternates between sequentially processing one dimension in parallel of the other dimension , and thus speeds up training significantly .",abstract,abstract,natural_language_inference,32,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'B-n', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'B-b', 'B-ob', 'O']",19,0.14393939393939395,21,0.04805491990846682,19,0.5277777777777778,1,1,model
29,Recently proposed conversational machine comprehension ( MC ) datasets aim to enable models to assist in such information seeking dialogs .,abstract,Machine Reasoning,natural_language_inference,32,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",26,0.19696969696969696,28,0.06407322654462243,26,0.7222222222222222,1,1,research-problem
37,Our code can be found in https://github.com/momohuang/FlowQA.,abstract,Machine Reasoning,natural_language_inference,32,"['O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O']",34,0.25757575757575757,36,0.08237986270022883,34,0.9444444444444444,1,1,code
151,"applied BiDAF ++ , a strong extractive QA model to QuAC dataset .",Comparison Systems,Comparison Systems,natural_language_inference,32,"['B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",3,0.06521739130434782,150,0.34324942791762014,3,0.06666666666666667,1,1,baselines
156,"Here we briefly describe the ablated systems : "" - FLOW "" removes the flow component from IF layer ( Eq. 2 in Section 3.2 ) , "" - QHIER - RNN "" removes the hierarchical LSTM layers on final question vectors ( Eq. 7 in Section 3.3 ) .",Comparison Systems,Comparison Systems,natural_language_inference,32,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,8,0.17391304347826086,155,0.35469107551487417,8,0.17777777777777778,1,1,baselines
158,"FLOWQA yields substantial improvement over existing models on both datasets ( + 7.2 % F 1 on CoQA , + 4.0 % F 1 on QuAC ) .",Comparison Systems,Comparison Systems,natural_language_inference,32,"['B', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O']",,,10,0.21739130434782608,157,0.35926773455377575,10,0.2222222222222222,1,1,results
161,We find that FLOW is a critical component .,Comparison Systems,Comparison Systems,natural_language_inference,32,"['O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",13,0.2826086956521739,160,0.36613272311212813,13,0.28888888888888886,1,1,results
162,"Removing QHier - RNN has a minor impact ( 0.1 % on both datasets ) , while removing FLOW results in a substantial performance drop , with or without using QHierRNN ( 2 - 3 % on QuAC , 4.1 % on CoQA ) .",Comparison Systems,Comparison Systems,natural_language_inference,32,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O']",,,14,0.30434782608695654,161,0.3684210526315789,14,0.3111111111111111,1,1,results
166,"By comparing 0 - Ans and 1 - Ans on two datasets , we can see that providing gold answers is more crucial for QuAC .",Comparison Systems,Comparison Systems,natural_language_inference,32,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",18,0.391304347826087,165,0.37757437070938216,18,0.4,1,1,results
171,"Based on the training time each epoch takes ( i.e. , time needed for passing through the data once ) , the speedup is 8.1x on CoQA and 4.2 x on QuAC .",Comparison Systems,Comparison Systems,natural_language_inference,32,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,23,0.5,170,0.3890160183066362,23,0.5111111111111111,1,1,results
2,Published as a conference paper at ICLR 2018 LEARNING GENERAL PURPOSE DISTRIBUTED SEN - TENCE REPRESENTATIONS VIA LARGE SCALE MULTI - TASK LEARNING,,,natural_language_inference,33,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.16666666666666666,1,0.0038314176245210726,1,0.0,1,1,research-problem
4,A lot of the recent success in natural language processing ( NLP ) has been driven by distributed vector representations of words trained on large amounts of text in an unsupervised manner .,,,natural_language_inference,33,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.3333333333333333,3,0.011494252873563218,1,0.1111111111111111,1,1,research-problem
6,"However , extending this success to learning representations of sequences of words , such as sentences , remains an open problem .",,,natural_language_inference,33,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.5,5,0.019157088122605363,3,0.3333333333333333,1,1,research-problem
18,Some recent work has addressed this by learning general - purpose sentence representations .,INTRODUCTION,INTRODUCTION,natural_language_inference,33,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.23809523809523808,17,0.06513409961685823,5,0.23809523809523808,1,1,research-problem
26,"Our work exploits this in the context of a simple one - to - many multi -task learning ( MTL ) framework , wherein a single recurrent sentence encoder is shared across multiple tasks .",INTRODUCTION,INTRODUCTION,natural_language_inference,33,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",13,0.6190476190476191,25,0.09578544061302682,13,0.6190476190476191,1,1,approach
29,"While our work aims at learning fixed - length distributed sentence representations , it is not always practical to assume that the entire "" meaning "" of a sentence can be encoded into a fixed - length vector .",INTRODUCTION,INTRODUCTION,natural_language_inference,33,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.7619047619047619,28,0.10727969348659004,16,0.7619047619047619,1,1,approach
31,The primary contribution of our work is to combine the benefits of diverse sentence - representation learning objectives into a single multi-task framework .,INTRODUCTION,INTRODUCTION,natural_language_inference,33,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",18,0.8571428571428571,30,0.11494252873563218,18,0.8571428571428571,1,1,approach
136,It is evident from that adding more tasks improves the transfer performance of our model .,EXPERIMENTAL RESULTS & DISCUSSION,EXPERIMENTAL RESULTS & DISCUSSION,natural_language_inference,33,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",1,0.03333333333333333,135,0.5172413793103449,1,0.03333333333333333,1,1,results
137,Increasing the capacity our sentence encoder with more hidden units ( + L ) as well as an additional layer ( + 2L ) also lead to improved transfer performance .,EXPERIMENTAL RESULTS & DISCUSSION,EXPERIMENTAL RESULTS & DISCUSSION,natural_language_inference,33,"['B', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.06666666666666667,136,0.5210727969348659,2,0.06666666666666667,1,1,results
138,"We observe gains of 1.1 - 2.0 % on the sentiment classification tasks ( MR , CR , SUBJ & MPQA ) over Infersent .",EXPERIMENTAL RESULTS & DISCUSSION,EXPERIMENTAL RESULTS & DISCUSSION,natural_language_inference,33,"['O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-p', 'B-ob', 'O']",3,0.1,137,0.524904214559387,3,0.1,1,1,results
139,"We demonstrate substantial gains on TREC ( 6 % over Infersent and roughly 2 % over the CNN - LSTM ) , outperforming even a competitive supervised baseline .",EXPERIMENTAL RESULTS & DISCUSSION,EXPERIMENTAL RESULTS & DISCUSSION,natural_language_inference,33,"['O', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O']",,,4,0.13333333333333333,138,0.5287356321839081,4,0.13333333333333333,1,1,results
140,"We see similar gains ( 2.3 % ) on paraphrase identification ( MPRC ) , closing the gap on supervised approaches trained from scratch .",EXPERIMENTAL RESULTS & DISCUSSION,EXPERIMENTAL RESULTS & DISCUSSION,natural_language_inference,33,"['O', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'O']",,,5,0.16666666666666666,139,0.5325670498084292,5,0.16666666666666666,1,1,results
141,The addition of constituency parsing improves performance on sentence relatedness ( SICK - R ) and entailment ( SICK - E ) consistent with observations made by .,EXPERIMENTAL RESULTS & DISCUSSION,EXPERIMENTAL RESULTS & DISCUSSION,natural_language_inference,33,"['O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.2,140,0.5363984674329502,6,0.2,1,1,results
142,"In , we show that simply training an MLP on top of our fixed sentence representations outperforms several strong & complex supervised approaches that use attention mechanisms , even on this fairly large dataset .",EXPERIMENTAL RESULTS & DISCUSSION,EXPERIMENTAL RESULTS & DISCUSSION,natural_language_inference,33,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-b', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.23333333333333334,141,0.5402298850574713,7,0.23333333333333334,1,1,results
143,"For example , we observe a 0.2-0.5 % improvement over the decomposable attention model .",EXPERIMENTAL RESULTS & DISCUSSION,EXPERIMENTAL RESULTS & DISCUSSION,natural_language_inference,33,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.26666666666666666,142,0.5440613026819924,8,0.26666666666666666,1,1,results
144,"When using only a small fraction of the training data , indicated by the columns 1 k - 25 k , we are able to outperform the Siamese and Multi - Perspective CNN using roughly 6 % of the available training set .",EXPERIMENTAL RESULTS & DISCUSSION,EXPERIMENTAL RESULTS & DISCUSSION,natural_language_inference,33,"['B', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']",,,9,0.3,143,0.5478927203065134,9,0.3,1,1,results
145,We also outperform the Deconv LVM model proposed by in this low - resource setting .,EXPERIMENTAL RESULTS & DISCUSSION,EXPERIMENTAL RESULTS & DISCUSSION,natural_language_inference,33,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.3333333333333333,144,0.5517241379310345,10,0.3333333333333333,1,1,results
147,"Somewhat surprisingly , in we observe that the learned word embeddings are competitive with popular methods such as GloVe , word2vec , and fasttext on the benchmarks presented by and .",EXPERIMENTAL RESULTS & DISCUSSION,EXPERIMENTAL RESULTS & DISCUSSION,natural_language_inference,33,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'B-ob', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.4,146,0.5593869731800766,12,0.4,1,1,results
150,Representations learned solely from NLI do appear to encode syntax but incorporation into our multi-task framework does not amplify this signal .,EXPERIMENTAL RESULTS & DISCUSSION,EXPERIMENTAL RESULTS & DISCUSSION,natural_language_inference,33,"['B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'O']","['B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'O']","['B-b', 'B-p', 'I-p', 'I-p', 'B-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'O', 'B-ob', 'O']",15,0.5,149,0.5708812260536399,15,0.5,1,1,results
151,"Similarly , we observe that sentence characteristics such as length and word order are better encoded with the addition of parsing .",EXPERIMENTAL RESULTS & DISCUSSION,EXPERIMENTAL RESULTS & DISCUSSION,natural_language_inference,33,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",16,0.5333333333333333,150,0.5747126436781609,16,0.5333333333333333,1,1,results
2,Dynamically Fused Graph Network for Multi-hop Reasoning,title,,natural_language_inference,34,"['O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.003389830508474576,1,0.0,1,1,research-problem
4,Text - based question answering ( TBQA ) has been studied extensively in recent years .,abstract,abstract,natural_language_inference,34,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.125,3,0.010169491525423728,1,0.125,1,1,research-problem
13,Question answering ( QA ) has been a popular topic in natural language processing .,Introduction,Introduction,natural_language_inference,34,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.01818181818181818,12,0.04067796610169491,1,0.06666666666666667,1,1,research-problem
14,QA provides a quantifiable way to evaluate an NLP system 's capability on language understanding and reasoning .,Introduction,Introduction,natural_language_inference,34,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.03636363636363636,13,0.04406779661016949,2,0.13333333333333333,1,1,research-problem
50,"In this paper , we propose Dynamically Fused Graph Network ( DFGN ) , a novel method to address the aforementioned concerns for multi-hop text - based QA .",Introduction,Original Entity Graph,natural_language_inference,34,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",38,0.6909090909090909,49,0.16610169491525423,22,0.5641025641025641,1,1,model
51,"For the first challenge , DFGN constructs a dynamic entity graph based on entity mentions in the query and documents .",Introduction,Original Entity Graph,natural_language_inference,34,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",39,0.7090909090909091,50,0.1694915254237288,23,0.5897435897435898,1,1,model
52,This process iterates in multiple rounds to achieve multihop reasoning .,Introduction,Original Entity Graph,natural_language_inference,34,"['O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",40,0.7272727272727273,51,0.17288135593220338,24,0.6153846153846154,1,1,model
53,"In each round , DFGN generates and reasons on a dynamic graph , where irrelevant entities are masked out while only reasoning sources are preserved , via a mask prediction module .",Introduction,Original Entity Graph,natural_language_inference,34,"['B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'O']",,,41,0.7454545454545455,52,0.17627118644067796,25,0.6410256410256411,1,1,model
56,"To solve the second challenge , we propose a fusion process in DFGN to solve the unrestricted QA challenge .",Introduction,Original Entity Graph,natural_language_inference,34,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",44,0.8,55,0.1864406779661017,28,0.717948717948718,1,1,model
57,"We not only aggregate information from documents to the entity graph ( doc2 graph ) , but also propagate the information of the entity graph back to document representations ( graph2doc ) .",Introduction,Original Entity Graph,natural_language_inference,34,"['O', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O']",,,45,0.8181818181818182,56,0.18983050847457628,29,0.7435897435897436,1,1,model
58,"The fusion process is iteratively performed at each hop through the document tokens and entities , and the final resulting answer is then obtained from document tokens .",Introduction,Original Entity Graph,natural_language_inference,34,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",46,0.8363636363636363,57,0.19322033898305085,30,0.7692307692307693,1,1,model
59,"The fusion process of doc2 graph and graph2doc along with the dynamic entity graph jointly improve the interaction between the information of documents and the entity graph , leading to a less noisy entity graph and thus more accurate answers .",Introduction,Original Entity Graph,natural_language_inference,34,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O']",,,47,0.8545454545454545,58,0.19661016949152543,31,0.7948717948717948,1,1,model
209,"In paragraph selection stage , we use the uncased version of BERT Tokenizer to tokenize all passages and questions .",Implementation Details,Implementation Details,natural_language_inference,34,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.08333333333333333,208,0.7050847457627119,1,0.08333333333333333,1,1,hyperparameters
210,The encoding vectors of sentence pairs are generated from a pre-trained BERT model .,Implementation Details,Implementation Details,natural_language_inference,34,"['O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.16666666666666666,209,0.7084745762711865,2,0.16666666666666666,1,1,hyperparameters
211,We set a relatively low threshold during selection to keep a high recall ( 97 % ) and a reasonable precision ( 69 % ) on supporting facts .,Implementation Details,Implementation Details,natural_language_inference,34,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'O']",3,0.25,210,0.711864406779661,3,0.25,1,1,hyperparameters
212,"In graph construction stage , we use a pretrained NER model from Stanford CoreNLP Toolkits 1 to extract named entities .",Implementation Details,Implementation Details,natural_language_inference,34,"['O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",4,0.3333333333333333,211,0.7152542372881356,4,0.3333333333333333,1,1,hyperparameters
213,The maximum number of entities in a graph is set to be 40 .,Implementation Details,Implementation Details,natural_language_inference,34,"['O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",5,0.4166666666666667,212,0.7186440677966102,5,0.4166666666666667,1,1,hyperparameters
214,Each entity node in the entity graphs has an average degree of 3.52 .,Implementation Details,Implementation Details,natural_language_inference,34,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",6,0.5,213,0.7220338983050848,6,0.5,1,1,hyperparameters
215,"In the encoding stage , we also use a pre-trained BERT model as the encoder , thus d 1 is 768 .",Implementation Details,Implementation Details,natural_language_inference,34,"['O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",7,0.5833333333333334,214,0.7254237288135593,7,0.5833333333333334,1,1,hyperparameters
216,All the hidden state dimensions d 2 are set to 300 .,Implementation Details,Implementation Details,natural_language_inference,34,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",8,0.6666666666666666,215,0.7288135593220338,8,0.6666666666666666,1,1,hyperparameters
217,We set the dropout rate for all hidden units of LSTM and dynamic graph attention to 0.3 and 0.5 respectively .,Implementation Details,Implementation Details,natural_language_inference,34,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",9,0.75,216,0.7322033898305085,9,0.75,1,1,hyperparameters
218,"For optimization , we use Adam Optimizer with an initial learning rate of 1 e ?4 .",Implementation Details,Implementation Details,natural_language_inference,34,"['B', 'B', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.8333333333333334,217,0.735593220338983,10,0.8333333333333334,1,1,hyperparameters
222,We first present a comparison between baseline models and our DFGN 2 . shows the performance of different models in the private test set of Hotpot QA .,Main Results,Main Results,natural_language_inference,34,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'O']",1,0.013513513513513514,221,0.7491525423728813,1,0.07692307692307693,1,1,results
223,From the table we can see that our model achieves the second best result on the leaderboard now 3 ( on March 1st ) .,Main Results,Main Results,natural_language_inference,34,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O']",2,0.02702702702702703,222,0.752542372881356,2,0.15384615384615385,1,1,results
224,"Besides , the answer performance and the joint performance of our model are competitive against state - of - the - art unpublished models .",Main Results,Main Results,natural_language_inference,34,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.04054054054054054,223,0.7559322033898305,3,0.23076923076923078,1,1,results
227,The results show that our model achieves a 1.5 % gain in the joint F1 - score with the entity graph built from a better entity recognizer .,Main Results,Main Results,natural_language_inference,34,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.08108108108108109,226,0.7661016949152543,6,0.46153846153846156,1,1,results
230,The ablation results of QA performances in the development set of Hotpot QA are shown in .,Main Results,Main Results,natural_language_inference,34,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O']",,,9,0.12162162162162163,229,0.7762711864406779,9,0.6923076923076923,1,1,ablation-analysis
231,From the table we can see that each of our model components can provide from 1 % to 2 % relative gain over the QA performance .,Main Results,Main Results,natural_language_inference,34,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",10,0.13513513513513514,230,0.7796610169491526,10,0.7692307692307693,1,1,ablation-analysis
232,"Particularly , using a 1 - layer fusion block leads to an obvious performance loss , which implies the significance of performing multi-hop reasoning in Hotpot QA .",Main Results,Main Results,natural_language_inference,34,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.14864864864864866,231,0.7830508474576271,11,0.8461538461538461,1,1,ablation-analysis
233,"Besides , the dataset abla-tion results show that our model is not very sensitive to the noisy paragraphs comparing with the baseline model which can achieve a more than 5 % performance gain in the "" gold paragraphs only "" and "" supporting facts only "" settings .",Main Results,Main Results,natural_language_inference,34,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",12,0.16216216216216217,232,0.7864406779661017,12,0.9230769230769231,1,1,ablation-analysis
2,Multi - Style Generative Reading Comprehension,title,title,natural_language_inference,35,"['O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0038022813688212928,1,0.0,1,1,research-problem
4,"This study tackles generative reading comprehension ( RC ) , which consists of answering questions based on textual evidence and natural language generation ( NLG ) .",abstract,abstract,natural_language_inference,35,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.1111111111111111,3,0.011406844106463879,1,0.1111111111111111,1,1,research-problem
15,"Recently , reading comprehension ( RC ) , a challenge to answer a question given textual evidence provided in a document set , has received much attention .",Introduction,Introduction,natural_language_inference,35,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.07692307692307693,14,0.053231939163498096,2,0.1,1,1,research-problem
16,"Current mainstream studies have treated RC as a process of extracting an answer span from one passage or multiple passages , which is usually done by predicting the start and end positions of the answer .",Introduction,Introduction,natural_language_inference,35,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.11538461538461539,15,0.057034220532319393,3,0.15,1,1,research-problem
24,"In this study , we propose Masque , a generative model for multi-passage RC .",Introduction,Introduction,natural_language_inference,35,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.4230769230769231,23,0.08745247148288973,11,0.55,1,1,research-problem
28,"We introduce the pointer - generator mechanism for generating an abstractive answer from the question and multiple passages , which covers various answer styles .",Introduction,Multi - source abstractive summarization .,natural_language_inference,35,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",15,0.5769230769230769,27,0.10266159695817491,15,0.75,1,1,model
29,We extend the mechanism to a Transformer based one that allows words to be generated from a vocabulary and to be copied from the question and passages .,Introduction,Multi - source abstractive summarization .,natural_language_inference,35,"['O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'O', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'O', 'B-ob', 'O']",16,0.6153846153846154,28,0.10646387832699619,16,0.8,1,1,model
31,We introduce multi-style learning that enables our model to control answer styles and improves RC for all styles involved .,Introduction,Multi- style learning for style control and transfer .,natural_language_inference,35,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",18,0.6923076923076923,30,0.11406844106463879,18,0.9,1,1,model
32,"We also extend the pointer - generator to a conditional decoder by introducing an artificial token corresponding to each style , as in .",Introduction,Multi- style learning for style control and transfer .,natural_language_inference,35,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",19,0.7307692307692307,31,0.11787072243346007,19,0.95,1,1,model
33,"For each decoding step , it controls the mixture weights over three distributions with the given style ( ) .",Introduction,Multi- style learning for style control and transfer .,natural_language_inference,35,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.7692307692307693,32,0.12167300380228137,20,1.0,1,1,model
182,"shows that our single model , trained with two styles and controlled with the NQA style , pushed forward the state - of - the - art by a significant margin .",Results,Results,natural_language_inference,35,"['B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,2,0.4,181,0.688212927756654,2,0.4,1,1,results
183,The evaluation scores of the model controlled with the NLG style were low because the two styles are different .,Results,Results,natural_language_inference,35,"['O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.6,182,0.6920152091254753,3,0.6,1,1,results
184,"Also , our model without multi-style learning ( trained with only the NQA style ) outperformed the baselines in terms of ROUGE - L .",Results,Results,natural_language_inference,35,"['O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-ob', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.8,183,0.6958174904942965,4,0.8,1,1,results
186,Experiments on NarrativeQA,,,natural_language_inference,35,"['B', 'O', 'O']",,,0,0.0,185,0.7034220532319392,0,0.0,1,1,
2,Explicit Contextual Semantics for Text Comprehension,title,,natural_language_inference,36,"['O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.004761904761904762,1,0.0,1,1,research-problem
12,"This paper focuses on two core text comprehension ( TC ) tasks , machine reading comprehension ( MRC ) and textual entailment ( TE ) .",Introduction,Introduction,natural_language_inference,36,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.08,11,0.05238095238095238,2,0.08,1,1,research-problem
26,"In this work , to alleviate such an obvious shortcoming about semantics , we make attempt to explore integrative models for finer - grained text comprehension and inference .",Introduction,Introduction,natural_language_inference,36,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.64,25,0.11904761904761904,16,0.64,1,1,model
27,"In this work , we propose a semantics enhancement framework for TC tasks , which boosts the strong baselines effectively .",Introduction,Introduction,natural_language_inference,36,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.68,26,0.12380952380952381,17,0.68,1,1,model
28,We implement an easy and feasible scheme to integrate semantic signals in downstream neural models in end - to - end manner to boost strong baselines effectively .,Introduction,Introduction,natural_language_inference,36,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'O']",,,18,0.72,27,0.12857142857142856,18,0.72,1,1,model
168,Textual Entailment,Evaluation,,natural_language_inference,36,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",8,0.18181818181818182,167,0.7952380952380952,0,0.0,1,1,experiments
172,Results in show that SRL embedding can boost the ESIM + ELMo model by + 0.7 % improvement .,Evaluation,Textual Entailment,natural_language_inference,36,"['O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.2727272727272727,171,0.8142857142857143,4,0.3333333333333333,1,1,experiments
173,"With the semantic cues , the simple sequential encoding model yields substantial gains , and our single BERT LARGE model also achieves a new stateof - the - art , even outperforms all the ensemble models in the leaderboard 8 .",Evaluation,Textual Entailment,natural_language_inference,36,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O']",13,0.29545454545454547,172,0.819047619047619,5,0.4166666666666667,1,1,experiments
181,Machine Reading Comprehension,Evaluation,,natural_language_inference,36,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",21,0.4772727272727273,180,0.8571428571428571,0,0.0,1,1,experiments
186,"Our baseline includes MQAN for single task and multi-task with SRL , BiDAF + ELMo , R.M. Reader and BERT .",Evaluation,Machine Reading Comprehension,natural_language_inference,36,"['O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'O']",26,0.5909090909090909,185,0.8809523809523809,5,0.7142857142857143,1,1,experiments
188,"9 . The SRL embeddings give substantial performance gains over all the strong baselines , showing it is also quite effective for more complex document and question encoding .",Evaluation,Machine Reading Comprehension,natural_language_inference,36,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",28,0.6363636363636364,187,0.8904761904761904,7,1.0,1,1,experiments
2,Simple and Effective Multi - Paragraph Reading Comprehension,title,,natural_language_inference,37,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0038910505836575876,1,0.0,1,1,research-problem
4,We consider the problem of adapting neural paragraph - level question answering models to the case where entire documents are given as input .,abstract,abstract,natural_language_inference,37,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.16666666666666666,3,0.011673151750972763,1,0.16666666666666666,1,1,research-problem
14,The recent success of neural models at answering questions given a related paragraph suggests neural models have the potential to be a key part of a solution to this problem .,Introduction,Introduction,natural_language_inference,37,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.14285714285714285,13,0.05058365758754864,4,0.14285714285714285,1,1,research-problem
21,In this paper we start by proposing an improved pipelined method which achieves state - of - the - art results .,Introduction,Introduction,natural_language_inference,37,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.39285714285714285,20,0.07782101167315175,11,0.39285714285714285,1,1,model
22,"Then we introduce a method for training models to produce accurate per-paragraph confidence scores , and we show how combining this method with multiple paragraph selection further increases performance .",Introduction,Introduction,natural_language_inference,37,"['O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.42857142857142855,21,0.08171206225680934,12,0.42857142857142855,1,1,model
24,We propose a TF - IDF heuristic to select which paragraphs to train and test on .,Introduction,Introduction,natural_language_inference,37,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.5,23,0.08949416342412451,14,0.5,1,1,model
26,"To handle the noise this creates , we use a summed objective function that marginalizes the model 's output over all locations the answer text occurs .",Introduction,Introduction,natural_language_inference,37,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'B-p', 'O']",16,0.5714285714285714,25,0.09727626459143969,16,0.5714285714285714,1,1,model
31,"We resolve these problems by sampling paragraphs from the context documents , including paragraphs that do not contain an answer , to train on .",Introduction,Introduction,natural_language_inference,37,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'I', 'O']",,,21,0.75,30,0.11673151750972763,21,0.75,1,1,model
32,"We then use a shared - normalization objective where paragraphs are processed independently , but the probability of an answer candidate is marginalized over all paragraphs sampled from the same document .",Introduction,Introduction,natural_language_inference,37,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",22,0.7857142857142857,31,0.12062256809338522,22,0.7857142857142857,1,1,model
164,"We train the model with the Adadelta optimizer ( Zeiler , 2012 ) with a batch size 60 for Triv - ia QA and 45 for SQuAD .",Implementation,Implementation,natural_language_inference,37,"['O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'O']",,,1,0.1111111111111111,163,0.6342412451361867,1,0.1111111111111111,1,1,hyperparameters
168,The Glo Ve 300 dimensional word vectors released by are used for word embeddings .,Implementation,Implementation,natural_language_inference,37,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",5,0.5555555555555556,167,0.6498054474708171,5,0.5555555555555556,1,1,hyperparameters
169,"On SQuAD , we use a dimensionality of size 100 for the GRUs and of size 200 for the linear layers employed after each attention mechanism .",Implementation,Implementation,natural_language_inference,37,"['B', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']",,,6,0.6666666666666666,168,0.6536964980544747,6,0.6666666666666666,1,1,hyperparameters
170,"We find for TriviaQA , likely because there is more data , using a larger dimensionality of 140 for each GRU and 280 for the linear layers is beneficial .",Implementation,Implementation,natural_language_inference,37,"['O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'O']",,,7,0.7777777777777778,169,0.6575875486381323,7,0.7777777777777778,1,1,hyperparameters
171,"During training , we maintain an exponential moving average of the weights with a decay rate of 0.999 .",Implementation,Implementation,natural_language_inference,37,"['B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,8,0.8888888888888888,170,0.6614785992217899,8,0.8888888888888888,1,1,hyperparameters
174,Trivia QA Web,Results,,natural_language_inference,37,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",1,0.016666666666666666,173,0.6731517509727627,1,0.045454545454545456,1,1,results
180,We find both TF - IDF ranking and the sum objective to be effective ; even without changing the model we achieve state - of - the - art results .,Results,Trivia QA Web,natural_language_inference,37,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.11666666666666667,179,0.6964980544747081,7,0.3181818181818182,1,1,results
181,Using our refined model increases the gain by another 4 points .,Results,Trivia QA Web,natural_language_inference,37,"['B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'B-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'B-b', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.13333333333333333,180,0.7003891050583657,8,0.36363636363636365,1,1,results
186,"The shared - norm , merge , and no-answer training methods improve the model 's ability to utilize more text , with the shared - norm method being significantly ahead of the others on the verified set and tied with the merge approach on the general set .",Results,Trivia QA Web,natural_language_inference,37,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,13,0.21666666666666667,185,0.7198443579766537,13,0.5909090909090909,1,1,results
187,Trivia QA Unfiltered,Results,,natural_language_inference,37,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",14,0.23333333333333334,186,0.7237354085603113,14,0.6363636363636364,1,1,results
192,"Note the base model starts to lose performance as more paragraphs are used , showing that errors are being caused by the model being overly confident in incorrect extractions . :",Results,Trivia QA Unfiltered,natural_language_inference,37,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-ob', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.31666666666666665,191,0.7431906614785992,19,0.8636363636363636,1,1,results
196,SQuAD,Results,,natural_language_inference,37,['B'],['B-n'],['B-b'],23,0.38333333333333336,195,0.7587548638132295,0,0.0,1,1,results
210,"While all our approaches had some benefit , the shared - norm model is the strongest , and is the only one to not lose performance as large numbers of paragraphs are used .",Results,SQuAD,natural_language_inference,37,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",37,0.6166666666666667,209,0.8132295719844358,14,0.4666666666666667,1,1,results
216,"Our paragraph - level model is competitive on this task , and our variations to handle the multi-paragraph setting only cause a minor loss of performance .",Results,SQuAD,natural_language_inference,37,"['B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",43,0.7166666666666667,215,0.8365758754863813,20,0.6666666666666666,1,1,results
219,The base model starts to drop in performance once more than two paragraphs are used .,Results,SQuAD,natural_language_inference,37,"['O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",46,0.7666666666666667,218,0.8482490272373541,23,0.7666666666666667,1,1,results
220,"However , the shared - norm approach is able to reach a peak performance of 72.37 F1 and 64.08 EM given 15 paragraphs .",Results,SQuAD,natural_language_inference,37,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",47,0.7833333333333333,219,0.8521400778210116,24,0.8,1,1,results
2,MEMEN : Multi-layer Embedding with Memory Networks for Machine Comprehension,title,title,natural_language_inference,38,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.005291005291005291,1,0.0,1,1,research-problem
4,Machine comprehension ( MC ) style question answering is a representative problem in natural language processing .,abstract,abstract,natural_language_inference,38,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.015873015873015872,1,0.14285714285714285,1,1,research-problem
12,Machine comprehension ( MC ) has gained significant popularity over the past few years and it is a coveted goal in the field of natural language processing and artificial intelligence .,Introduction,Introduction,natural_language_inference,38,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.03333333333333333,11,0.0582010582010582,1,0.03333333333333333,1,1,research-problem
27,"In this paper , we introduce the Multi - layer Embedding with Memory Networks ( MEMEN ) , an end - to - end neural network for machine comprehension task .",Introduction,Introduction,natural_language_inference,38,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",16,0.5333333333333333,26,0.13756613756613756,16,0.5333333333333333,1,1,model
28,Our model consists of three parts :,Introduction,Introduction,natural_language_inference,38,"['O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O']",17,0.5666666666666667,27,0.14285714285714285,17,0.5666666666666667,1,1,model
29,"1 ) the encoding of context and query , in which we add useful syntactic and semantic information in the embedding of every word , 2 ) the high - efficiency multilayer memory network of full - orientation matching to match the question and context , 3 ) the pointer - network based answer boundary prediction layer to get the location of the answer in the passage .",Introduction,Introduction,natural_language_inference,38,"['O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'O']",,,18,0.6,28,0.14814814814814814,18,0.6,1,1,model
110,The tokenizers we use in the step of preprocessing data are from Stanford CoreNLP .,Experiment Implementation,Settings,natural_language_inference,38,"['O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'B', 'I', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'B-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",2,0.2,109,0.5767195767195767,10,0.2631578947368421,1,1,experimental-setup
111,We also use part - of - speech tagger and named - entity recognition tagger in Stanford CoreNLP utilities to transform the passage and question .,Experiment Implementation,Settings,natural_language_inference,38,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O']",3,0.3,110,0.582010582010582,11,0.2894736842105263,1,1,experimental-setup
112,"For the skip - gram model , our model refers to the word2 vec module in open source software library , Tensorflow , the skip window is set as 2 .",Experiment Implementation,Settings,natural_language_inference,38,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",4,0.4,111,0.5873015873015873,12,0.3157894736842105,1,1,experimental-setup
114,"To improve the reliability and stabllity , we screen out the sentences whose length are shorter than 9 .",Experiment Implementation,Settings,natural_language_inference,38,"['B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.6,113,0.5978835978835979,14,0.3684210526315789,1,1,experimental-setup
115,"We use 100 one dimensional filters for CNN in the character level embedding , with width of 5 for each one .",Experiment Implementation,Settings,natural_language_inference,38,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'I', 'O']",,,7,0.7,114,0.6031746031746031,15,0.39473684210526316,1,1,experimental-setup
116,We set the hidden size as 100 for all the LSTM and GRU layers and apply dropout between layers with a dropout ratio as 0.2 .,Experiment Implementation,Settings,natural_language_inference,38,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,8,0.8,115,0.6084656084656085,16,0.42105263157894735,1,1,experimental-setup
117,"We use the AdaDelta ( Zeiler , 2012 ) optimizer with a initial learning rate as 0.001 .",Experiment Implementation,Settings,natural_language_inference,38,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",9,0.9,116,0.6137566137566137,17,0.4473684210526316,1,1,experimental-setup
118,"For the memory networks , we set the number of layer as 3 .",Experiment Implementation,Settings,natural_language_inference,38,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",10,1.0,117,0.6190476190476191,18,0.47368421052631576,1,1,experimental-setup
129,"As we can see in , our model outperforms all other baselines and achieves the state - of - the - art result on all subsets on TriviaQA .",Trivia QA Results,Trivia,natural_language_inference,38,"['O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-n', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.9090909090909091,128,0.6772486772486772,29,0.7631578947368421,1,1,results
132,We also use the Stanford Question Answering Dataset ( SQuAD ) v 1.1 to conduct our experiments .,Results,Results,natural_language_inference,38,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'O', 'O']",1,0.03225806451612903,131,0.6931216931216931,32,0.8421052631578947,1,1,results
138,"The results of this dataset are all exhibited on a leaderboard , and top methods are almost all ensemble models , our model achieves an exact match score of 75.37 % and an F1 score of 82 . 66 % , which is competitive to state - of - the - art method .",Results,Results,natural_language_inference,38,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,7,0.22580645161290322,137,0.7248677248677249,38,1.0,1,1,results
156,We also run the ablations of our single model on SQ u AD dev set to evaluate the individual contribution .,Results,Speed and Efficiency,natural_language_inference,38,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",25,0.8064516129032258,155,0.8201058201058201,10,0.625,1,1,ablation-analysis
157,"As shows , both syntactic embeddings and semantic embeddings contribute towards the model 's performance and the POS tags seem to be more important .",Results,Speed and Efficiency,natural_language_inference,38,"['O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",26,0.8387096774193549,156,0.8253968253968254,11,0.6875,1,1,ablation-analysis
160,"For ablating integral query matching , the result drops about 2 % on both metrics and it shows that the integral information of query for each word in passage is crucial .",Results,Speed and Efficiency,natural_language_inference,38,"['B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'O']",29,0.9354838709677419,159,0.8412698412698413,14,0.875,1,1,ablation-analysis
161,"The query - based similarity matching accounts for about 10 % performance degradation , which proves the effectiveness of alignment context words against query .",Results,Speed and Efficiency,natural_language_inference,38,"['O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",30,0.967741935483871,160,0.8465608465608465,15,0.9375,1,1,ablation-analysis
162,"For context - based similarity matching , we simply took out the M 3 from the linear function and it is proved to be contributory to the performance of full - orientation matching .",Results,Speed and Efficiency,natural_language_inference,38,"['B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",31,1.0,161,0.8518518518518519,16,1.0,1,1,ablation-analysis
2,Pairwise Word Interaction Modeling with Deep Neural Networks for Semantic Similarity Measurement,title,title,natural_language_inference,39,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0048543689320388345,1,0.0,1,1,research-problem
4,"Textual similarity measurement is a challenging problem , as it requires understanding the semantics of input sentences .",abstract,abstract,natural_language_inference,39,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.25,3,0.014563106796116505,1,0.25,1,1,research-problem
9,"Given two pieces of text , measuring their semantic textual similarity ( STS ) remains a fundamental problem in language research and lies at the core of many language processing tasks , including question answering , query ranking , and paraphrase generation .",Introduction,Introduction,natural_language_inference,39,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0625,8,0.038834951456310676,1,0.0625,1,1,research-problem
16,"In contrast , we focus on capturing fine - grained word - level information directly .",Introduction,Introduction,natural_language_inference,39,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",8,0.5,15,0.07281553398058252,8,0.5,1,1,approach
18,"First , instead of using sentence modeling , we propose pairwise word interaction modeling that encourages explicit word context interactions across sentences .",Introduction,Introduction,natural_language_inference,39,"['O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",10,0.625,17,0.0825242718446602,10,0.625,1,1,approach
20,"Second , based on the pairwise word interactions , we describe a novel similarity focus layer which helps the model selectively identify important word interactions depending on their importance for similarity measurement .",Introduction,Introduction,natural_language_inference,39,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",12,0.75,19,0.09223300970873786,12,0.75,1,1,approach
155,"For the SICK and MSRVID experiments , we used 300 - dimension Glo Ve word embeddings .",Training .,Settings .,natural_language_inference,39,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.34782608695652173,154,0.7475728155339806,24,0.6153846153846154,1,1,experimental-setup
156,"For the STS2014 , WikiQA , and TrecQA experiments , we used 300 dimension PARAGRAM - SL999 embeddings from and the PARAGRAM - PHRASE embeddings from , trained on word pairs from the Paraphrase Database ( PPDB ) .",Training .,Settings .,natural_language_inference,39,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",9,0.391304347826087,155,0.7524271844660194,25,0.6410256410256411,1,1,experimental-setup
161,Our timing experiments were conducted on an Intel Xeon E5 - 2680 CPU .,Training .,Settings .,natural_language_inference,39,"['B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.6086956521739131,160,0.7766990291262136,30,0.7692307692307693,1,1,experimental-setup
162,"Due to sentence length variations , for the SICK and MSRVID data we padded the sentences to 32 words ; for the STS2014 , WikiQA , and TrecQA data , we padded the sentences to 48 words ..",Training .,Settings .,natural_language_inference,39,"['B', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O']",,,15,0.6521739130434783,161,0.7815533980582524,31,0.7948717948717948,1,1,experimental-setup
176,Wiki QA Results .,Results,Results,natural_language_inference,39,"['B', 'I', 'O', 'O']","['B-n', 'I-n', 'O', 'O']","['B-b', 'I-b', 'O', 'O']",1,0.09090909090909091,175,0.8495145631067961,1,0.037037037037037035,1,1,results
178,"The neural network models in the table , paragraph vector ( PV ) , CNN , and PV - Cnt / CNN - Cnt with word matching features , are mostly based on sentence modeling .",Results,Results,natural_language_inference,39,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.2727272727272727,177,0.8592233009708737,3,0.1111111111111111,1,1,results
179,Our model outperforms them all .,Results,Results,natural_language_inference,39,"['B', 'I', 'B', 'O', 'O', 'O']","['B-n', 'I-n', 'B-n', 'O', 'O', 'O']","['B-b', 'I-b', 'B-ob', 'O', 'O', 'O']",4,0.36363636363636365,178,0.8640776699029126,4,0.14814814814814814,1,1,results
190,"We found large drops when removing the context modeling component , indicating that the context information provided by the Bi - LSTMs is crucial for the following components ( e.g. , interaction modeling ) .",Ablation Studies .,Ablation Studies .,natural_language_inference,39,"['O', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.2,189,0.9174757281553398,15,0.5555555555555556,1,1,ablation-analysis
191,"The use of our similarity focus layer is also beneficial , especially on the WikiQA data .",Ablation Studies .,Ablation Studies .,natural_language_inference,39,"['O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",4,0.26666666666666666,190,0.9223300970873787,16,0.5925925925925926,1,1,ablation-analysis
192,"When we replaced the entire similarity focus layer with a random dropout layer ( p = 0.3 ) , the dropout layer hurts accuracy ; this shows the importance of directing the model to focus on important pairwise word interactions , to better capture similarity .",Ablation Studies .,Ablation Studies .,natural_language_inference,39,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-b', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.3333333333333333,191,0.9271844660194175,17,0.6296296296296297,1,1,ablation-analysis
2,DCN + : MIXED OBJECTIVE AND DEEP RESIDUAL COATTENTION FOR QUESTION ANSWERING,title,title,natural_language_inference,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.005050505050505051,1,0.0,1,1,research-problem
18,"To address this problem , we propose a mixed objective that combines traditional cross entropy loss over positions with a measure of word overlap trained with reinforcement learning .",INTRODUCTION,INTRODUCTION,natural_language_inference,4,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",8,0.07142857142857142,17,0.08585858585858586,8,0.5333333333333333,1,1,model
19,We obtain the latter objective using self - critical policy learning in which the reward is based on word overlap between the proposed answer and the ground truth answer .,INTRODUCTION,INTRODUCTION,natural_language_inference,4,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.08035714285714286,18,0.09090909090909091,9,0.6,1,1,model
22,"In addition to our mixed training objective , we extend the Dynamic Coattention Network ( DCN ) by with a deep residual coattention encoder .",INTRODUCTION,INTRODUCTION,natural_language_inference,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.10714285714285714,21,0.10606060606060606,12,0.8,1,1,model
126,"To preprocess the corpus , we use the reversible tokenizer from Stanford CoreNLP .",EXPERIMENTS,EXPERIMENTS,natural_language_inference,4,"['O', 'B', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",3,0.21428571428571427,125,0.6313131313131313,3,0.07894736842105263,1,1,experimental-setup
127,"For word embeddings , we use GloVe embeddings pretrained on the 840B Common Crawl corpus as well as character ngram embeddings by .",EXPERIMENTS,EXPERIMENTS,natural_language_inference,4,"['B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.2857142857142857,126,0.6363636363636364,4,0.10526315789473684,1,1,experimental-setup
128,"In addition , we concatenate these embeddings with context vectors ( CoVe ) trained on .",EXPERIMENTS,EXPERIMENTS,natural_language_inference,4,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",5,0.35714285714285715,127,0.6414141414141414,5,0.13157894736842105,1,1,experimental-setup
129,"For out of vocabulary words , we set the embeddings and context vectors to zero .",EXPERIMENTS,EXPERIMENTS,natural_language_inference,4,"['O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",6,0.42857142857142855,128,0.6464646464646465,6,0.15789473684210525,1,1,experimental-setup
130,We perform word dropout on the document which zeros a word embedding with probability 0.075 .,EXPERIMENTS,EXPERIMENTS,natural_language_inference,4,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.5,129,0.6515151515151515,7,0.18421052631578946,1,1,experimental-setup
131,"In addition , we swap the first maxout layer of the highway maxout network in the DCN decoder with a sparse mixture of experts layer .",EXPERIMENTS,EXPERIMENTS,natural_language_inference,4,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']",,,8,0.5714285714285714,130,0.6565656565656566,8,0.21052631578947367,1,1,experimental-setup
135,Comparison to baseline DCN with CoVe. DCN + outperforms the baseline by 3.2 % exact match accuracy and 3.2 % F1 on the SQuAD development set .,EXPERIMENTS,EXPERIMENTS,natural_language_inference,4,"['B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O']",12,0.8571428571428571,134,0.6767676767676768,12,0.3157894736842105,1,1,results
136,"shows the consistent performance gain of DCN + over the baseline across question types , question lengths , and answer lengths .",EXPERIMENTS,EXPERIMENTS,natural_language_inference,4,"['B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O']",13,0.9285714285714286,135,0.6818181818181818,13,0.34210526315789475,1,1,results
137,"In particular , DCN + provides a significant advantage for long questions .",EXPERIMENTS,EXPERIMENTS,natural_language_inference,4,"['O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",14,1.0,136,0.6868686868686869,14,0.3684210526315789,1,1,results
140,"We note that the deep residual coattention yielded the highest contribution to model performance , followed by the mixed objective .",Ablation study .,Ablation study .,natural_language_inference,4,"['O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",2,0.043478260869565216,139,0.702020202020202,17,0.4473684210526316,1,1,ablation-analysis
141,The sparse mixture of experts layer in the decoder added minor improvements to the model performance . :,Ablation study .,Ablation study .,natural_language_inference,4,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O']",3,0.06521739130434782,140,0.7070707070707071,18,0.47368421052631576,1,1,ablation-analysis
2,Linguistic Knowledge as Memory for Recurrent Neural Networks,title,,natural_language_inference,40,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0036101083032490976,1,0.0,1,1,research-problem
4,Training recurrent neural networks to model long term dependencies is difficult .,abstract,abstract,natural_language_inference,40,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",1,0.14285714285714285,3,0.010830324909747292,1,0.14285714285714285,1,1,research-problem
40,"Instead , we utilize the order inherent in the the unaugmented sequence to decompose the graph into two Directed Acyclic Graphs ( DAGs ) with a topological ordering .",Introduction,Introduction,natural_language_inference,40,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",29,0.7631578947368421,39,0.1407942238267148,29,0.7631578947368421,1,1,approach
41,"We introduce the Memory as Acyclic Graph Encoding RNN ( MAGE - RNN ) framework to compute the representation of such graphs while touching every node only once , and implement a GRU version of it called MAGE - GRU .",Introduction,Introduction,natural_language_inference,40,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'B-p', 'B-b', 'B-p', 'B-ob', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",30,0.7894736842105263,40,0.1444043321299639,30,0.7894736842105263,1,1,approach
42,"MAGE - RNN learns separate representations for propagation along each edge type , which leads to superior performance empirically .",Introduction,Introduction,natural_language_inference,40,"['B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",31,0.8157894736842105,41,0.148014440433213,31,0.8157894736842105,1,1,approach
44,"We use MAGE - RNN to model coreference relations for text comprehension tasks , where answers to a query have to be extracted from a context document .",Introduction,Introduction,natural_language_inference,40,"['O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",33,0.868421052631579,43,0.1552346570397112,33,0.868421052631579,1,1,approach
45,Tokens in a document are connected by a coreference relation if they refer to the same underlying entity .,Introduction,Introduction,natural_language_inference,40,"['B', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",34,0.8947368421052632,44,0.1588447653429603,34,0.8947368421052632,1,1,approach
171,Story Based,Experiments,,natural_language_inference,40,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",28,0.5,170,0.6137184115523465,1,0.034482758620689655,1,1,results
182,"Our model achieves new state - of - the - art results , outperforming strong baselines such as QRNs .",Experiments,Story Based,natural_language_inference,40,"['B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",39,0.6964285714285714,181,0.6534296028880866,12,0.41379310344827586,1,1,results
183,"Moreover , we observe that the proposed MAGE architecture can substantially improve the performance for both bi - GRUs and GAs .",Experiments,Story Based,natural_language_inference,40,"['O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",40,0.7142857142857143,182,0.6570397111913358,13,0.4482758620689655,1,1,results
184,"Adding the same information as one - hot features fails to improve the performance , which indicates that the inductive bias we employ on MAGE is useful .",Experiments,Story Based,natural_language_inference,40,"['B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",41,0.7321428571428571,183,0.6606498194945848,14,0.4827586206896552,1,1,results
185,"The DAG - RNN baseline from and the shared version of MAGE ( where edge representations are tied ) also perform worse , showing that our proposed architecture is superior .",Experiments,Story Based,natural_language_inference,40,"['O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",42,0.75,184,0.6642599277978339,15,0.5172413793103449,1,1,results
203,"Both variants of MAGE substantially outperform QRNs , which are the current state - of - the - art models on the bAbi dataset .",Model,Model,natural_language_inference,40,"['B', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-b', 'I-b', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",3,0.04918032786885246,202,0.7292418772563177,3,0.05,1,1,results
220,Broad Context Language Modeling :,Model,Model,natural_language_inference,40,"['B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O']",20,0.32786885245901637,219,0.7906137184115524,20,0.3333333333333333,1,1,results
221,"For our second benchmark we pick the LAMBADA dataset from , where the task is to predict the last word in a given passage .",Model,Model,natural_language_inference,40,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.3442622950819672,220,0.7942238267148014,21,0.35,1,1,results
232,"Our implementation of GA gave higher performance than that reported by , without the use of linguistic features .",Model,Model,natural_language_inference,40,"['B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",32,0.5245901639344263,231,0.8339350180505415,32,0.5333333333333333,1,1,results
234,"On the simple bi - GRU architecture we see an improvement of 1.7 % by incorporating coreference edges in the graph , whereas the one - hot baseline does not lead to any improvement .",Model,Model,natural_language_inference,40,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",34,0.5573770491803278,233,0.8411552346570397,34,0.5666666666666667,1,1,results
236,"On the multi - layer GA architecture , the coreference edges again lead to an improvement of 2 % , setting a new state - of - theart on this dataset .",Model,Model,natural_language_inference,40,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",36,0.5901639344262295,235,0.8483754512635379,36,0.6,1,1,results
245,"Cloze - style QA : Lastly , we test our models on the CNN dataset from , which consists of pairs of news articles and a cloze - style question over the contents .",Model,Model,natural_language_inference,40,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",45,0.7377049180327869,244,0.8808664259927798,45,0.75,1,1,results
257,Augmenting the bi - GRU model with MAGE leads to an improvement of 2.5 % on the test set .,Model,Model,natural_language_inference,40,"['B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",57,0.9344262295081968,256,0.924187725631769,57,0.95,1,1,results
258,"The previous best results for this dataset were achieved by the GA Reader , and we see that adding MAGE to it leads to a further improvement of 0.7 % , setting a new state of the art .",Model,Model,natural_language_inference,40,"['O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",58,0.9508196721311475,257,0.927797833935018,58,0.9666666666666667,1,1,results
2,"BART : Denoising Sequence - to - Sequence Pre-training for Natural Language Generation , Translation , and Comprehension",title,title,natural_language_inference,41,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.0038910505836575876,1,0.0,1,1,research-problem
4,"We present BART , a denoising autoencoder for pretraining sequence - to - sequence models .",abstract,abstract,natural_language_inference,41,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.125,3,0.011673151750972763,1,0.125,1,1,research-problem
17,"In this paper , we present BART , which pre-trains a model combining Bidirectional and Auto - Regressive Transformers .",Introduction,Introduction,natural_language_inference,41,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.22727272727272727,16,0.0622568093385214,5,0.22727272727272727,1,1,model
18,BART is a denoising autoencoder built with a sequence - to - sequence model that is applicable to a very wide range of end tasks .,Introduction,Introduction,natural_language_inference,41,"['B', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.2727272727272727,17,0.06614785992217899,6,0.2727272727272727,1,1,model
19,"Pretraining has two stages ( 1 ) text is corrupted with an arbitrary noising function , and ( 2 ) a sequence - to - sequence model is learned to reconstruct the original text .",Introduction,Introduction,natural_language_inference,41,"['B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'B-p', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-b', 'B-p', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",7,0.3181818181818182,18,0.07003891050583658,7,0.3181818181818182,1,1,model
20,"BART uses a standard Tranformer - based neural machine translation architecture which , despite its simplicity , can be seen as generalizing BERT ( due to the bidirectional encoder ) , GPT ( with the left - to - right decoder ) , and many other more recent pretraining schemes ( see .",Introduction,Introduction,natural_language_inference,41,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.36363636363636365,19,0.07392996108949416,8,0.36363636363636365,1,1,model
154,"We pre-train a large model with 12 layers in each of the encoder and decoder , and a hidden size of 1024 .",Experimental Setup,Experimental Setup,natural_language_inference,41,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'O']",1,0.03225806451612903,153,0.5953307392996109,1,0.07692307692307693,1,1,experiments
155,"Following RoBERTa , we use a batch size of 8000 , and train the model for 500000 steps .",Experimental Setup,Experimental Setup,natural_language_inference,41,"['B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",2,0.06451612903225806,154,0.5992217898832685,2,0.15384615384615385,1,1,experiments
156,Documents are tokenized with the same byte - pair encoding as GPT - 2 .,Experimental Setup,Experimental Setup,natural_language_inference,41,"['B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.0967741935483871,155,0.603112840466926,3,0.23076923076923078,1,1,experiments
157,"Based on the results in Section 4 , we use a combination of text infilling and sentence permutation .",Experimental Setup,Experimental Setup,natural_language_inference,41,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",4,0.12903225806451613,156,0.6070038910505836,4,0.3076923076923077,1,1,experiments
158,"We mask 30 % of tokens in each document , and permute all sentences .",Experimental Setup,Experimental Setup,natural_language_inference,41,"['O', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",5,0.16129032258064516,157,0.6108949416342413,5,0.38461538461538464,1,1,experiments
160,"To help the model better fit the data , we dis abled dropout for the final 10 % of training steps .",Experimental Setup,Experimental Setup,natural_language_inference,41,"['B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.22580645161290322,159,0.6186770428015564,7,0.5384615384615384,1,1,experiments
163,"The most directly comparable baseline is RoBERTa , which was pre-trained with the same resources , but a different objective .",Experimental Setup,Experimental Setup,natural_language_inference,41,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",10,0.3225806451612903,162,0.6303501945525292,10,0.7692307692307693,1,1,experiments
169,We also experiment with several text generation tasks .,Experimental Setup,Generation Tasks,natural_language_inference,41,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",16,0.5161290322580645,168,0.6536964980544747,1,0.25,1,1,experiments
175,"To provide a comparison with the state - of - the - art in summarization , we present results on two summarization datasets , CNN / DailyMail and XSum , which have distinct properties .",Experimental Setup,Valid Summarization,natural_language_inference,41,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.7096774193548387,174,0.6770428015564203,2,0.14285714285714285,1,1,experiments
178,"Nevertheless , BART outperforms all existing work .",Experimental Setup,Valid Summarization,natural_language_inference,41,"['O', 'O', 'B', 'B', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'B-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'B-b', 'O', 'O', 'O', 'O']",25,0.8064516129032258,177,0.688715953307393,5,0.35714285714285715,1,1,experiments
180,"BART outperforms the best previous work , which leverages BERT , by roughly 6.0 points on all ROUGE metrics - representing a significant advance in performance on this problem .",Experimental Setup,Valid Summarization,natural_language_inference,41,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O']",27,0.8709677419354839,179,0.6964980544747081,7,0.5,1,1,experiments
183,"We evaluate dialogue response generation on CONVAI2 , in which agents must generate responses conditioned on both the previous context and a textually - specified persona .",Experimental Setup,Dialogue,natural_language_inference,41,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",30,0.967741935483871,182,0.708171206225681,10,0.7142857142857143,1,1,experiments
184,BART outperforms previous work on two automated metrics .,Experimental Setup,Dialogue,natural_language_inference,41,"['B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'B-n', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-ob', 'B-s', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",31,1.0,183,0.7120622568093385,11,0.7857142857142857,1,1,experiments
186,We use the recently proposed ELI5 dataset to test the model 's ability to generate long freeform answers .,Abstractive QA,Abstractive QA,natural_language_inference,41,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.043478260869565216,185,0.7198443579766537,13,0.9285714285714286,1,1,experiments
187,"We find BART outperforms the best previous work by 1.2 ROUGE - L , but the dataset remains a challenging , because answers are only weakly specified by the question .",Abstractive QA,Abstractive QA,natural_language_inference,41,"['O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,2,0.08695652173913043,186,0.7237354085603113,14,1.0,1,1,experiments
194,For each row we experiment on the original WMT16 Romanian - English augmented with back - translation data .,Abstractive QA,Translation,natural_language_inference,41,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.391304347826087,193,0.7509727626459144,6,0.75,1,1,experiments
196,"1 . Preliminary results suggested that our approach was less effective without back - translation data , and prone to overfitting - future work should explore additional regularization techniques .",Abstractive QA,Translation,natural_language_inference,41,"['O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.4782608695652174,195,0.7587548638132295,8,1.0,1,1,experiments
2,A Fully Attention - Based Information Retriever,title,,natural_language_inference,42,"['O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.0034602076124567475,1,0.0,1,1,research-problem
9,Question - answering ( QA ) systems that can answer queries expressed in natural language have been a perennial goal of the artificial intelligence community .,I. INTRODUCTION,I. INTRODUCTION,natural_language_inference,42,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.004608294930875576,8,0.02768166089965398,6,0.16216216216216217,1,1,research-problem
12,"That is , in fact , the proposed focus of recent open - domain QA datasets , such as SQuAD .",I. INTRODUCTION,I. INTRODUCTION,natural_language_inference,42,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.018433179723502304,11,0.03806228373702422,9,0.24324324324324326,1,1,research-problem
13,"In SQuAD , each problem instance consists of a passage P and a question Q. A QA system must then provide an answer A by selecting a snippet from P .",I. INTRODUCTION,I. INTRODUCTION,natural_language_inference,42,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.02304147465437788,12,0.04152249134948097,10,0.2702702702702703,1,1,research-problem
20,"Inspired by the positive results of Vaswani et al. in machine translation , we have applied a similar architecture to the domain of question - answering , a model that we have named Fully Attention - Based Information Retriever ( FABIR ) .",I. INTRODUCTION,I. INTRODUCTION,natural_language_inference,42,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.055299539170506916,19,0.0657439446366782,17,0.4594594594594595,1,1,model
21,"Our goal then was to verify how much performance we can get exclusively from the attention mechanism , without combining it with several other techniques .",I. INTRODUCTION,I. INTRODUCTION,natural_language_inference,42,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",13,0.059907834101382486,20,0.06920415224913495,18,0.4864864864864865,1,1,model
24,"Convolutional attention : a novel attention mechanism that encodes many - to - many relationships between words , enabling richer contextual representations .",I. INTRODUCTION,I. INTRODUCTION,natural_language_inference,42,"['B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",16,0.07373271889400922,23,0.07958477508650519,21,0.5675675675675675,1,1,model
25,Reduction layer : a new layer design that fits the pipeline proposed by Vaswani et al .,I. INTRODUCTION,I. INTRODUCTION,natural_language_inference,42,"['B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I']","['B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob']",17,0.07834101382488479,24,0.08304498269896193,22,0.5945945945945946,1,1,model
27,Column - wise cross - attention : we modify the crossattention operation by and propose a new technique that is better suited to question - answering .,I. INTRODUCTION,I. INTRODUCTION,natural_language_inference,42,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",19,0.08755760368663594,26,0.08996539792387544,24,0.6486486486486487,1,1,model
217,We have trained our FABIR model during 54 epochs with a batch size of 75 in a GPU NVidia Titan X with 12 GB of RAM .,I. INTRODUCTION,G. Answer Selection,natural_language_inference,42,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'O']",,,209,0.9631336405529954,216,0.7474048442906575,20,0.7142857142857143,1,1,experimental-setup
218,We developed our model in Tensorflow and made it available at https://worksheets.codalab.org/worksheets/ 0xee647ea284674396831ecb5aae9ca297 / for replicability .,I. INTRODUCTION,G. Answer Selection,natural_language_inference,42,"['O', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",210,0.967741935483871,217,0.7508650519031141,21,0.75,1,1,experimental-setup
219,We pre-processed the texts with the NLTK Tokenizer .,I. INTRODUCTION,G. Answer Selection,natural_language_inference,42,"['O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",211,0.9723502304147466,218,0.754325259515571,22,0.7857142857142857,1,1,experimental-setup
221,"For regularization , we applied residual and attention dropout of 0.9 in processing layers and of 0.8 in the reduction layer .",I. INTRODUCTION,G. Answer Selection,natural_language_inference,42,"['B', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'O']",,,213,0.9815668202764977,220,0.7612456747404844,24,0.8571428571428571,1,1,experimental-setup
222,"In the character - level embedding process , a dropout of 0.75 was added before the convolution .",I. INTRODUCTION,G. Answer Selection,natural_language_inference,42,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",214,0.9861751152073732,221,0.7647058823529411,25,0.8928571428571429,1,1,experimental-setup
223,"Additionally , a dropout of 0.8 was added before each convolutional layer in the answer selector .",I. INTRODUCTION,G. Answer Selection,natural_language_inference,42,"['O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",215,0.9907834101382489,222,0.7681660899653979,26,0.9285714285714286,1,1,experimental-setup
224,"We set processing layers dimension d model to 100 , the number of heads n heads in each attention sublayer to 4 , the feed - forward hidden size to 200 in processing layers and 400 in the reduction layer .",I. INTRODUCTION,G. Answer Selection,natural_language_inference,42,"['O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O']",,,216,0.9953917050691244,223,0.7716262975778547,27,0.9642857142857143,1,1,experimental-setup
229,"This analysis confirms the effectiveness of char- embeddings , as its addition increased the F1 and EM scores , by 2.7 % and 3.1 % , respectively .",A. Architecture Evaluation,A. Architecture Evaluation,natural_language_inference,42,"['O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",3,0.047619047619047616,228,0.7889273356401384,3,0.2727272727272727,1,1,ablation-analysis
230,"Most importantly , when the convolutional attention was replaced by the standard attention mechanism proposed in , the performance dropped by 2.4 % in F1 and 2.5 % in EM .",A. Architecture Evaluation,A. Architecture Evaluation,natural_language_inference,42,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'O']",,,4,0.06349206349206349,229,0.7923875432525952,4,0.36363636363636365,1,1,ablation-analysis
232,"Moreover , the tests also indicate that the reduction layer is capable of producing useful word representations when compressing the embeddings .",A. Architecture Evaluation,A. Architecture Evaluation,natural_language_inference,42,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'B-ob', 'O']",6,0.09523809523809523,231,0.7993079584775087,6,0.5454545454545454,1,1,ablation-analysis
233,"Indeed , when we replaced that layer by a standard feedforward layer with the same reduction ratio , there was a drop of 2.1 % and 2.5 % in the F1 and EM scores , respectively .",A. Architecture Evaluation,A. Architecture Evaluation,natural_language_inference,42,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",7,0.1111111111111111,232,0.8027681660899654,7,0.6363636363636364,1,1,ablation-analysis
245,"Regarding EM and F 1 scores , FABIR and BiDAF showed similar performances .",A. Architecture Evaluation,A. Architecture Evaluation,natural_language_inference,42,"['B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",19,0.30158730158730157,244,0.8442906574394463,7,0.4666666666666667,1,1,results
255,In this section we analyze the performance of FABIR and BiDAF in the different types of question in SQuAD .,A. Architecture Evaluation,A. Architecture Evaluation,natural_language_inference,42,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",29,0.4603174603174603,254,0.8788927335640139,1,0.02857142857142857,1,1,results
256,"shows that shorter answers are easier for both models : while they reach more than 75 % F1 for answers that are shorter than four words , for answers longer than ten words these scores drop to 60.4 % and 67.3 % for FABIR and BiDAF , respectively .",A. Architecture Evaluation,A. Architecture Evaluation,natural_language_inference,42,"['B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",30,0.47619047619047616,255,0.8823529411764706,2,0.05714285714285714,1,1,results
262,"shows that both models had their best performance with "" when "" questions .",A. Architecture Evaluation,A. Architecture Evaluation,natural_language_inference,42,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",36,0.5714285714285714,261,0.903114186851211,8,0.22857142857142856,1,1,results
264,"Together with "" when "" questions , "" how long "" and "" how many "" also proved easier to respond , as they possess the same property of having a smaller universe of possible answers .",A. Architecture Evaluation,A. Architecture Evaluation,natural_language_inference,42,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",38,0.6031746031746031,263,0.9100346020761245,10,0.2857142857142857,1,1,results
265,"In contrast to these , "" how "" and "" why "" questions resulted in considerably lower F1 and EM scores , as they can be answered by any sentence , and hence require a deeper understanding of the text .",A. Architecture Evaluation,A. Architecture Evaluation,natural_language_inference,42,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",39,0.6190476190476191,264,0.9134948096885813,11,0.3142857142857143,1,1,results
270,"Questions which expect a "" yes "" or a "" no "" as an answer are also difficult because it is not always possible to find those words in a snippet from the passage .",A. Architecture Evaluation,A. Architecture Evaluation,natural_language_inference,42,"['B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",44,0.6984126984126984,269,0.9307958477508651,16,0.45714285714285713,1,1,results
272,It is curious that shorter passages showed the worst performance for both models .,A. Architecture Evaluation,A. Architecture Evaluation,natural_language_inference,42,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",46,0.7301587301587301,271,0.9377162629757786,18,0.5142857142857142,1,1,results
2,Evaluating Semantic Parsing against a Simple Web - based Question Answering Model,title,title,natural_language_inference,43,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.0064516129032258064,1,0.0,1,1,research-problem
18,"We develop a simple log - linear model , in the spirit of traditional web - based QA systems , that answers questions by querying the web and extracting the answer from returned web snippets .",Introduction,Introduction,natural_language_inference,43,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.1323529411764706,17,0.10967741935483871,9,0.4090909090909091,1,1,model
19,"Thus , our evaluation scheme is suitable for semantic parsing benchmarks in which the knowledge required for answering questions is covered by the web ( in contrast with virtual assitants for which the knowledge is specific to an application ) .",Introduction,Introduction,natural_language_inference,43,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.14705882352941177,18,0.11612903225806452,10,0.45454545454545453,1,1,model
108,"We compare our model , WEBQA , to STAGG and COMPQ , which are to the best of our knowledge the highest performing semantic parsing models on both COMPLEXQUESTIONS and WEBQUES - TIONS .",Experiments,COMPLEXQUESTIONS,natural_language_inference,43,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.17073170731707318,107,0.6903225806451613,7,0.21212121212121213,1,1,experiments
117,"WEBQA obtained 32.6 F 1 ( 33.5 p@1 , 42.4 MRR ) compared to 40.9 F 1 of COMPQ .",Experiments,COMPLEXQUESTIONS,natural_language_inference,43,"['B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",16,0.3902439024390244,116,0.7483870967741936,16,0.48484848484848486,1,1,experiments
118,Our candidate extraction step finds the correct answer in the top - K candidates in 65.9 % of development examples and 62.7 % of test examples .,Experiments,COMPLEXQUESTIONS,natural_language_inference,43,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']",,,17,0.4146341463414634,117,0.7548387096774194,17,0.5151515151515151,1,1,experiments
119,"Thus , our test F 1 on examples for which candidate extraction succeeded ( WEBQA - SUBSET ) is 51.9 ( 53.4 p@1 , 67.5 MRR ) .",Experiments,COMPLEXQUESTIONS,natural_language_inference,43,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.43902439024390244,118,0.7612903225806451,18,0.5454545454545454,1,1,experiments
121,"In this setup , COMPQ obtained 42.2 F 1 on the test set ( compared to 40.9 F 1 , when training on COM - PLEXQUESTIONS only , as we do ) .",Experiments,COMPLEXQUESTIONS,natural_language_inference,43,"['O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.4878048780487805,120,0.7741935483870968,20,0.6060606060606061,1,1,experiments
122,"Restricting the predictions to the subset for which candidate extraction succeeded , the F 1 of COMPQ - SUBSET is 48.5 , which is 3.4 F 1 points lower than WEBQA - SUBSET , which was trained on less data .",Experiments,COMPLEXQUESTIONS,natural_language_inference,43,"['B', 'O', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,21,0.5121951219512195,121,0.7806451612903226,21,0.6363636363636364,1,1,experiments
133,"Note that TF - IDF is by far the most impactful feature , leading to a large drop of 12 points in performance .",Experiments,COMPLEXQUESTIONS,natural_language_inference,43,"['O', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O']",32,0.7804878048780488,132,0.8516129032258064,32,0.9696969696969697,1,1,ablation-analysis
155,"Code , data , annotations , and experiments for this paper are available on the CodaLab platform at https://worksheets. codalab.org/worksheets/ 0x91d77db37e0a4bbbaeb37b8972f4784f/.",Conclusion,Reproducibility,natural_language_inference,43,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,1.0,154,0.9935483870967742,5,1.0,0,1,code
2,Efficient and Robust Question Answering from Minimal Context over Documents,title,title,natural_language_inference,44,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.0034965034965034965,1,0.0,1,1,research-problem
4,Neural models for question answering ( QA ) over documents have achieved significant performance improvements .,abstract,abstract,natural_language_inference,44,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.01048951048951049,1,0.14285714285714285,1,1,research-problem
8,"Inspired by this observation , we propose a simple sentence selector to select the minimal set of sentences to feed into the QA model .",abstract,abstract,natural_language_inference,44,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O']",5,0.7142857142857143,7,0.024475524475524476,5,0.7142857142857143,1,1,research-problem
20,"In this paper , we aim to develop a QA system that is scalable to large documents as well as robust to adversarial inputs .",Introduction,Introduction,natural_language_inference,44,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",9,0.20454545454545456,19,0.06643356643356643,9,0.5294117647058824,1,1,model
21,"First , we study the context required to answer the question by sampling examples in the dataset and carefully analyzing them .",Introduction,Introduction,natural_language_inference,44,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O']",10,0.22727272727272727,20,0.06993006993006994,10,0.5882352941176471,1,1,model
24,"Second , inspired by this observation , we propose a sentence selector to select the minimal set of sentences to give to the QA model in order to answer the question .",Introduction,Introduction,natural_language_inference,44,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",13,0.29545454545454547,23,0.08041958041958042,13,0.7647058823529411,1,1,model
25,"Since the minimum number of sentences depends on the question , our sentence selector chooses a different number of sentences for each question , in contrast with previous models that select a fixed number of sentences .",Introduction,Introduction,natural_language_inference,44,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.3181818181818182,24,0.08391608391608392,14,0.8235294117647058,1,1,model
26,"Our sentence selector leverages three simple techniques - weight transfer , data modification and score normalization , which we show to be highly effective on the task of sentence selection .",Introduction,Introduction,natural_language_inference,44,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.3409090909090909,25,0.08741258741258741,15,0.8823529411764706,1,1,model
110,"Results shows results in the task of sentence selection on SQuAD and New s QA . First , our selector outperforms TF - IDF method and the previous state - of - the - art by large margin ( up to 2.9 % MAP ) .",Dataset and Evaluation Metrics,SQuAD,natural_language_inference,44,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-b', 'B-b', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",18,0.1956521739130435,109,0.3811188811188811,6,0.075,1,1,experiments
111,"Second , our three training techniques - weight transfer , data modification and score normalization - improve performance by up to 5.6 % MAP .",Dataset and Evaluation Metrics,SQuAD,natural_language_inference,44,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.20652173913043478,110,0.38461538461538464,7,0.0875,1,1,experiments
112,"Finally , our Dyn method achieves higher accuracy with less sentences than the Top k method .",Dataset and Evaluation Metrics,SQuAD,natural_language_inference,44,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",20,0.21739130434782608,111,0.3881118881118881,8,0.1,1,1,experiments
116,"On News QA , Top 4 achieves 92.5 accuracy , whereas Dyn achieves 94.6 accuracy with 3.9 sentences per example .",Dataset and Evaluation Metrics,SQuAD,natural_language_inference,44,"['B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']",,,24,0.2608695652173913,115,0.4020979020979021,12,0.15,1,1,experiments
121,"On SQuAD , S - Reader achieves 6.7 training and 3.6 inference speedup on SQuAD , and 15.0 training and 6.9 inference speedup on News QA .",Dataset and Evaluation Metrics,SQuAD,natural_language_inference,44,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,29,0.31521739130434784,120,0.4195804195804196,17,0.2125,1,1,experiments
153,Trivia QA and SQuAD - Open,Dataset and Evaluation Metrics,SQuAD,natural_language_inference,44,"['B', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",61,0.6630434782608695,152,0.5314685314685315,49,0.6125,1,1,experiments
171,We compare with the results from the sentences selected by TF - IDF method and our selector ( Dyn ) .,Dataset and Evaluation Metrics,SQuAD,natural_language_inference,44,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",79,0.8586956521739131,170,0.5944055944055944,67,0.8375,1,1,experiments
172,We also compare with published Rank1 - 3 models .,Dataset and Evaluation Metrics,SQuAD,natural_language_inference,44,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",80,0.8695652173913043,171,0.5979020979020979,68,0.85,1,1,experiments
173,"Results shows results on Trivia QA ( Wikipedia ) and SQuAD - Open. First , MINI - MAL obtains higher F1 and EM over FULL , with the inference speedup of up to 13.8 .",Dataset and Evaluation Metrics,SQuAD,natural_language_inference,44,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",81,0.8804347826086957,172,0.6013986013986014,69,0.8625,1,1,experiments
174,"Second , the model with our sentence selector with Dyn achieves higher F1 and EM over the model with TF - IDF selector .",Dataset and Evaluation Metrics,SQuAD,natural_language_inference,44,"['O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O']",,,82,0.8913043478260869,173,0.6048951048951049,70,0.875,1,1,experiments
176,"Third , we outperforms the published state - of - the - art on both dataset .",Dataset and Evaluation Metrics,SQuAD,natural_language_inference,44,"['O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",84,0.9130434782608695,175,0.6118881118881119,72,0.9,1,1,experiments
177,SQuAD - Adversarial,Dataset and Evaluation Metrics,SQuAD,natural_language_inference,44,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",85,0.9239130434782609,176,0.6153846153846154,73,0.9125,1,1,experiments
181,"Results shows that MINIMAL outperforms FULL , achieving the new state - of - the - art by large margin ( + 11.1 and + 11.5 F1 on AddSent and Add OneSent , respectively ) .",Dataset and Evaluation Metrics,SQuAD,natural_language_inference,44,"['O', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'B-n', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'B-b', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",89,0.967391304347826,180,0.6293706293706294,77,0.9625,1,1,experiments
2,Published as a conference paper at ICLR 2017 WORDS OR CHARACTERS ? FINE - GRAINED GATING FOR READING COMPREHENSION,title,title,natural_language_inference,45,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.005025125628140704,1,0.0,1,1,research-problem
28,"In this work , we present a fine - grained gating mechanism to combine the word - level and characterlevel representations .",INTRODUCTION,INTRODUCTION,natural_language_inference,45,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.14754098360655737,27,0.135678391959799,18,0.46153846153846156,1,1,model
29,We compute a vector gate as a linear projection of the token features followed 1 Code is available at https://github.com/kimiyoung/fg-gating 1 ar Xiv: 1611.01724v2 [ cs.CL ] 11 Sep 2017,INTRODUCTION,INTRODUCTION,natural_language_inference,45,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.1557377049180328,28,0.1407035175879397,19,0.48717948717948717,1,1,model
31,We then multiplicatively apply the gate to the character - level and wordlevel representations .,INTRODUCTION,INTRODUCTION,natural_language_inference,45,"['O', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",21,0.1721311475409836,30,0.1507537688442211,21,0.5384615384615384,1,1,model
32,Each dimension of the gate controls how much information is flowed from the word - level and character - level representations respectively .,INTRODUCTION,INTRODUCTION,natural_language_inference,45,"['B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",22,0.18032786885245902,31,0.15577889447236182,22,0.5641025641025641,1,1,model
33,"We use named entity tags , part - ofspeech tags , document frequencies , and word - level representations as the features for token properties which determine the gate .",INTRODUCTION,INTRODUCTION,natural_language_inference,45,"['O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'O']","['O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'O']",23,0.1885245901639344,32,0.16080402010050251,23,0.5897435897435898,1,1,model
34,"More generally , our fine - grained gating mechanism can be used to model multiple levels of structure in language , including words , characters , phrases , sentences and paragraphs .",INTRODUCTION,INTRODUCTION,natural_language_inference,45,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O']",24,0.19672131147540983,33,0.1658291457286432,24,0.6153846153846154,1,1,model
2,The NarrativeQA Reading Comprehension Challenge,title,,natural_language_inference,46,"['O', 'O', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-ob', 'I-ob', 'O']",1,0.0,1,0.003367003367003367,1,0.0,1,1,research-problem
4,"Reading comprehension ( RC ) - in contrast to information retrieval - requires integrating information and reasoning about events , entities , and their relations across a full document .",abstract,abstract,natural_language_inference,46,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.010101010101010102,1,0.14285714285714285,1,1,research-problem
5,"Question answering is conventionally used to assess RC ability , in both artificial agents and children learning to read .",abstract,abstract,natural_language_inference,46,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.2857142857142857,4,0.013468013468013467,2,0.2857142857142857,1,1,research-problem
39,"We present a new task and dataset , which we call NarrativeQA , which will test and reward artificial agents approaching this level of competence ( Section 3 ) .",Introduction,Frank .,natural_language_inference,46,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",28,0.3146067415730337,38,0.12794612794612795,28,0.7777777777777778,1,1,dataset
40,"The dataset consists of stories , which are books and movie scripts , with human written questions and answers based solely on human - generated abstractive summaries .",Introduction,Frank .,natural_language_inference,46,"['O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",29,0.3258426966292135,39,0.13131313131313133,29,0.8055555555555556,1,1,dataset
41,"For the RC tasks , questions maybe answered using just the summaries or the full story text .",Introduction,Frank .,natural_language_inference,46,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'O', 'O', 'B-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",30,0.33707865168539325,40,0.13468013468013468,30,0.8333333333333334,1,1,dataset
196,Reading Summaries Only,Experiments,,natural_language_inference,46,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",8,0.11764705882352941,195,0.6565656565656566,0,0.0,1,1,experiments
201,"This is indeed the case , with the neural span prediction model significantly outperforming all other proposed methods .",Experiments,Reading Summaries Only,natural_language_inference,46,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.19117647058823528,200,0.6734006734006734,5,0.2777777777777778,1,1,experiments
203,"Both the plain sequence to sequence model and the AS Reader , successfully applied to the CNN / DailyMail reading comprehension task , also perform well on this task .",Experiments,Reading Summaries Only,natural_language_inference,46,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'O']",15,0.22058823529411764,202,0.6801346801346801,7,0.3888888888888889,1,1,experiments
205,An additional inductive bias results in higher performance for the span prediction model .,Experiments,Reading Summaries Only,natural_language_inference,46,"['O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.25,204,0.6868686868686869,9,0.5,1,1,experiments
208,"summarizes the results on the full Narra - tive QA task , where the context documents are full stories .",Experiments,Reading Summaries Only,natural_language_inference,46,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",20,0.29411764705882354,207,0.696969696969697,12,0.6666666666666666,1,1,experiments
209,"As expected ( and desired ) , we observe a decline in performance of the span- selection oracle IR model , compared with the results on summaries .",Experiments,Reading Summaries Only,natural_language_inference,46,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.3088235294117647,208,0.7003367003367004,13,0.7222222222222222,1,1,experiments
215,Reading Full Stories Only,Experiments,,natural_language_inference,46,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",27,0.39705882352941174,214,0.7205387205387206,0,0.0,1,1,experiments
224,"The AS Reader , which was the better - performing model on the summaries task , underperforms the simple no -context Seq2Seq baseline ( shown in ) in terms of MRR .",Experiments,Reading Full Stories Only,natural_language_inference,46,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'O']",36,0.5294117647058824,223,0.7508417508417509,9,0.6,1,1,experiments
229,"As with the AS Reader , we observed no significant differences for varying number of chunks .",Experiments,Reading Full Stories Only,natural_language_inference,46,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'O']",41,0.6029411764705882,228,0.7676767676767676,14,0.9333333333333333,1,1,experiments
2,A large annotated corpus for learning natural language inference,title,title,natural_language_inference,47,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004651162790697674,1,0.0,1,1,research-problem
11,"Thus , natural language inference ( NLI ) - characterizing and using these relations in computational systems ) - is essential in tasks ranging from information retrieval to semantic parsing to commonsense reasoning .",Introduction,Introduction,natural_language_inference,47,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.01904761904761905,10,0.046511627906976744,2,0.07692307692307693,1,1,research-problem
12,"NLI has been addressed using a variety of techniques , including those based on symbolic logic , knowledge bases , and neural networks .",Introduction,Introduction,natural_language_inference,47,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.02857142857142857,11,0.05116279069767442,3,0.11538461538461539,1,1,research-problem
19,"To address this , this paper introduces the Stanford Natural Language Inference ( SNLI ) corpus , a collection of sentence pairs labeled for entailment , contradiction , and semantic independence .",Introduction,Introduction,natural_language_inference,47,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'B-ob', 'O', 'O', 'B-ob', 'I-ob', 'O']",10,0.09523809523809523,18,0.08372093023255814,10,0.38461538461538464,1,1,dataset
20,"At 570,152 sentence pairs , SNLI is two orders of magnitude larger than all other resources of its type .",Introduction,Introduction,natural_language_inference,47,"['B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.10476190476190476,19,0.08837209302325581,11,0.4230769230769231,1,1,dataset
21,"And , in contrast to many such resources , all of its sentences and labels were written by humans in a grounded , naturalistic context .",Introduction,Introduction,natural_language_inference,47,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.11428571428571428,20,0.09302325581395349,12,0.46153846153846156,1,1,dataset
22,"In a separate validation phase , we collected four additional judgments for each label for 56,941 of the examples .",Introduction,Introduction,natural_language_inference,47,"['B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'O']",,,13,0.12380952380952381,21,0.09767441860465116,13,0.5,1,1,dataset
23,"Of these , 98 % of cases emerge with a threeannotator consensus , and 58 % see a unanimous consensus from all five annotators .",Introduction,Introduction,natural_language_inference,47,"['B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",14,0.13333333333333333,22,0.10232558139534884,14,0.5384615384615384,1,1,dataset
163,"The sum of words model performed slightly worse than the fundamentally similar lexicalized classifier while the sum of words model can use pretrained word embeddings to better handle rare words , it lacks even the rudimentary sensitivity to word order that the lexicalized model 's bigram features provide .",Excitement Open Platform models,Lexicalized Classifier,natural_language_inference,47,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",48,0.5161290322580645,162,0.7534883720930232,17,0.7727272727272727,1,1,results
164,"Of the two RNN models , the LSTM 's more robust ability to learn long - term dependencies serves it well , giving it a substantial advantage over the plain RNN , and resulting in performance that is essentially equivalent to the lexicalized classifier on the test set ( LSTM performance near the stopping iteration varies by up to 0.5 % between evaluation steps ) .",Excitement Open Platform models,Lexicalized Classifier,natural_language_inference,47,"['B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",49,0.5268817204301075,163,0.7581395348837209,18,0.8181818181818182,1,1,results
165,"While the lexicalized model fits the training set almost perfectly , the gap between train and test set accuracy is relatively small for all three neural network models , suggesting that research into significantly higher capacity versions of these models would be productive .",Excitement Open Platform models,Lexicalized Classifier,natural_language_inference,47,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",50,0.5376344086021505,164,0.7627906976744186,19,0.8636363636363636,1,1,results
168,"In addition , though the LSTM and the lexicalized model show similar performance when trained on the current full corpus , the somewhat steeper slope for the LSTM hints that its ability to learn arbitrarily structured representations of sentence meaning may give it an advantage over the more constrained lexicalized model on still larger datasets .",Excitement Open Platform models,Lexicalized Classifier,natural_language_inference,47,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'O']",53,0.5698924731182796,167,0.7767441860465116,22,1.0,1,1,results
2,Iterative Alternating Neural Attention for Machine Reading,title,,natural_language_inference,48,"['O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.004524886877828055,1,0.0,1,1,research-problem
4,"We propose a novel neural attention architecture to tackle machine comprehension tasks , such as answering Cloze - style queries with respect to a document .",abstract,abstract,natural_language_inference,48,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.3333333333333333,3,0.013574660633484163,1,0.3333333333333333,1,1,research-problem
19,"Encouraged by the recent success of deep learning attention architectures , we propose a novel neural attention - based inference model designed to perform machine reading comprehension tasks .",Introduction,Introduction,natural_language_inference,48,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.13186813186813187,18,0.08144796380090498,12,0.5454545454545454,1,1,model
20,The model first reads the document and the query using a recurrent neural network .,Introduction,Introduction,natural_language_inference,48,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",13,0.14285714285714285,19,0.08597285067873303,13,0.5909090909090909,1,1,model
21,"Then , it deploys an iterative inference process to uncover the inferential links that exist between the missing query word , the query , and the document .",Introduction,Introduction,natural_language_inference,48,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O', 'O', 'O', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'B-ob', 'O']",14,0.15384615384615385,20,0.09049773755656108,14,0.6363636363636364,1,1,model
22,"This phase involves a novel alternating attention mechanism ; it first attends to some parts of the query , then finds their corresponding matches by attending to the document .",Introduction,Introduction,natural_language_inference,48,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'B-ob', 'O']",15,0.16483516483516483,21,0.09502262443438914,15,0.6818181818181818,1,1,model
23,The result of this alternating search is fed back into the iterative inference process to seed the next search step .,Introduction,Introduction,natural_language_inference,48,"['O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",16,0.17582417582417584,22,0.09954751131221719,16,0.7272727272727273,1,1,model
25,"After a fixed number of iterations , the model uses a summary of its inference process to predict the answer .",Introduction,Introduction,natural_language_inference,48,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'O']",18,0.1978021978021978,24,0.1085972850678733,18,0.8181818181818182,1,1,model
118,"To train our model , we used stochastic gradient descent with the ADAM optimizer ( Kingma and Ba , 2014 ) , with an initial learning rate of 0.001 .",Training Details,Training Details,natural_language_inference,48,"['B', 'I', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",1,0.08333333333333333,117,0.5294117647058824,1,0.08333333333333333,1,1,experimental-setup
119,"We set the batch size to 32 and we decay the learning rate by 0.8 if the accuracy on the validation set does not increase after a half - epoch , i.e. 2000 batches ( for CBT ) and 5000 batches for ( CNN ) .",Training Details,Training Details,natural_language_inference,48,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O']",,,2,0.16666666666666666,118,0.5339366515837104,2,0.16666666666666666,1,1,experimental-setup
120,"We initialize all weights of our model by sampling from the normal distribution N ( 0 , 0.05 ) .",Training Details,Training Details,natural_language_inference,48,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.25,119,0.5384615384615384,3,0.25,1,1,experimental-setup
121,"Following , the GRU recurrent weights are initialized to be orthogonal and biases are initialized to zero .",Training Details,Training Details,natural_language_inference,48,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'O']",,,4,0.3333333333333333,120,0.5429864253393665,4,0.3333333333333333,1,1,experimental-setup
122,"In order to stabilize the learning , we clip the gradients if their norm is greater than 5 and those marked with 2 are from .",Training Details,Training Details,natural_language_inference,48,"['O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.4166666666666667,121,0.5475113122171946,5,0.4166666666666667,1,1,experimental-setup
124,"We found that setting embedding regularization to 0.0001 , T = 8 , d = 384 , h = 128 , s = 512 worked robustly across the datasets .",Training Details,Training Details,natural_language_inference,48,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'O']",7,0.5833333333333334,123,0.5565610859728507,7,0.5833333333333334,1,1,experimental-setup
125,"Our model is implemented in Theano , using the Keras library .",Training Details,Training Details,natural_language_inference,48,"['B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",8,0.6666666666666666,124,0.5610859728506787,8,0.6666666666666666,1,1,experimental-setup
2,Published as a conference paper at ICLR 2018 NATURAL LANGUAGE INFERENCE OVER INTERACTION SPACE,,,natural_language_inference,49,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",2,0.25,1,0.003937007874015748,1,0.0,1,1,research-problem
10,"Natural Language Inference ( NLI also known as recognizing textual entiailment , or RTE ) task requires one to determine whether the logical relationship between two sentences is among entailment ( if the premise is true , then the hypothesis must be true ) , contradiction ( if the premise is true , then the hypothesis must be false ) and neutral ( neither entailment nor contradiction ) .",INTRODUCTION,INTRODUCTION,natural_language_inference,49,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.041666666666666664,9,0.03543307086614173,1,0.041666666666666664,1,1,research-problem
23,"In this work , we push the multi-head attention to a extreme by building a word - by - word dimension - wise alignment tensor which we call interaction tensor .",INTRODUCTION,INTRODUCTION,natural_language_inference,49,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",14,0.5833333333333334,22,0.08661417322834646,14,0.5833333333333334,1,1,model
24,The interaction tensor encodes the high - order alignment relationship between sentences pair .,INTRODUCTION,INTRODUCTION,natural_language_inference,49,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",15,0.625,23,0.09055118110236221,15,0.625,1,1,model
26,We dub the general framework as Interactive Inference Network ( IIN ) .,INTRODUCTION,INTRODUCTION,natural_language_inference,49,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.7083333333333334,25,0.0984251968503937,17,0.7083333333333334,1,1,model
137,We implement our algorithm with Tensorflow framework .,EXPERIMENTS SETTING,EXPERIMENTS SETTING,natural_language_inference,49,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']",,,1,0.045454545454545456,136,0.5354330708661418,1,0.045454545454545456,1,1,
138,"An Adadelta optimizer ( Zeiler , 2012 ) with ? as 0.95 and as 1e ? 8 is used to optimize all the trainable weights .",EXPERIMENTS SETTING,EXPERIMENTS SETTING,natural_language_inference,49,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']",,,2,0.09090909090909091,137,0.5393700787401575,2,0.09090909090909091,1,1,
139,The initial learning rate is set to 0.5 and batch size to 70 .,EXPERIMENTS SETTING,EXPERIMENTS SETTING,natural_language_inference,49,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,3,0.13636363636363635,138,0.5433070866141733,3,0.13636363636363635,1,1,
140,"When the model does not improve best in domain performance for 30,000 steps , an SGD optimizer with learning rate of 3e ? 4 is used to help model to find a better local optimum .",EXPERIMENTS SETTING,EXPERIMENTS SETTING,natural_language_inference,49,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O']",,,4,0.18181818181818182,139,0.547244094488189,4,0.18181818181818182,1,1,
141,Dropout layers are applied before all linear layers and after word - embedding layer .,EXPERIMENTS SETTING,EXPERIMENTS SETTING,natural_language_inference,49,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O']",,,5,0.22727272727272727,140,0.5511811023622047,5,0.22727272727272727,1,1,
142,"We use an exponential decayed keep rate during training , where the initial keep rate is 1.0 and the decay rate is 0.977 for every 10,000 step .",EXPERIMENTS SETTING,EXPERIMENTS SETTING,natural_language_inference,49,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O']",,,6,0.2727272727272727,141,0.5551181102362205,6,0.2727272727272727,1,1,
143,We initialize our word embeddings with pre-trained 300D Glo Ve 840B vectors while the out - of - vocabulary word are randomly initialized with uniform distribution .,EXPERIMENTS SETTING,EXPERIMENTS SETTING,natural_language_inference,49,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O']",,,7,0.3181818181818182,142,0.5590551181102362,7,0.3181818181818182,1,1,
144,The character embeddings are randomly initialized with 100D .,EXPERIMENTS SETTING,EXPERIMENTS SETTING,natural_language_inference,49,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O']",,,8,0.36363636363636365,143,0.562992125984252,8,0.36363636363636365,1,1,
145,We crop or pad each token to have 16 characters .,EXPERIMENTS SETTING,EXPERIMENTS SETTING,natural_language_inference,49,"['O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'I', 'O']",,,9,0.4090909090909091,144,0.5669291338582677,9,0.4090909090909091,1,1,
146,The 1D convolution kernel size for character embedding is 5 .,EXPERIMENTS SETTING,EXPERIMENTS SETTING,natural_language_inference,49,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'O']",,,10,0.45454545454545453,145,0.5708661417322834,10,0.45454545454545453,1,1,
147,"All weights are constraint by L2 regularization , and the L2 regularization at step t is calculated as follows :",EXPERIMENTS SETTING,EXPERIMENTS SETTING,natural_language_inference,49,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,11,0.5,146,0.5748031496062992,11,0.5,1,1,
152,The first scale down ratio ?,EXPERIMENTS SETTING,EXPERIMENTS SETTING,natural_language_inference,49,"['O', 'B', 'I', 'I', 'I', 'O']",,,16,0.7272727272727273,151,0.594488188976378,16,0.7272727272727273,1,1,
153,in feature extraction layer is set to 0.3 and transitional scale down ratio ?,EXPERIMENTS SETTING,EXPERIMENTS SETTING,natural_language_inference,49,"['B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']",,,17,0.7727272727272727,152,0.5984251968503937,17,0.7727272727272727,1,1,
154,is set to 0.5 .,EXPERIMENTS SETTING,EXPERIMENTS SETTING,natural_language_inference,49,"['O', 'B', 'I', 'B', 'O']",,,18,0.8181818181818182,153,0.6023622047244095,18,0.8181818181818182,1,1,
155,"The sequence length is set as a hard cutoff on all experiments : 48 for MultiNLI , 32 for SNLI and 24 for Quora Question Pair Dataset .",EXPERIMENTS SETTING,EXPERIMENTS SETTING,natural_language_inference,49,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O']",,,19,0.8636363636363636,154,0.6062992125984252,19,0.8636363636363636,1,1,
159,EXPERIMENT ON MULTINLI,,,natural_language_inference,49,"['O', 'O', 'B']","['O', 'O', 'B-n']","['O', 'O', 'B-b']",0,0.0,158,0.6220472440944882,0,0.0,1,1,results
164,"Our approach , without using any recurrent structure , achieves the new state - of - the - art performance of 80.0 % , exceeding current state - of - the - art performance by more than 5 % .",EXPERIMENT ON MULTINLI,EXPERIMENT ON MULTINLI,natural_language_inference,49,"['B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.7142857142857143,163,0.6417322834645669,5,0.7142857142857143,1,1,results
165,"Unlike the observation from , we find the out - of - domain test performance is consistently lower than in - domain test performance .",EXPERIMENT ON MULTINLI,EXPERIMENT ON MULTINLI,natural_language_inference,49,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.8571428571428571,164,0.6456692913385826,6,0.8571428571428571,1,1,results
167,EXPERIMENT ON SNLI,,,natural_language_inference,49,"['O', 'O', 'B']","['O', 'O', 'B-n']","['O', 'O', 'B-b']",0,0.0,166,0.6535433070866141,0,0.0,1,1,results
175,"We show our model , DIIN , achieves state - of - the - art performance on the competitive leaderboard .",EXPERIMENT ON SNLI,EXPERIMENT ON SNLI,natural_language_inference,49,"['O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",8,0.10126582278481013,174,0.6850393700787402,8,0.7272727272727273,1,1,results
179,EXPERIMENT ON QUORA QUESTION PAIR DATASET,EXPERIMENT ON SNLI,,natural_language_inference,49,"['O', 'O', 'B', 'I', 'I', 'I']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b']",12,0.1518987341772152,178,0.7007874015748031,0,0.0,1,1,results
182,"BIMPM models different perspective of matching between sentence pair on both direction , then aggregates matching vector with LSTM .",EXPERIMENT ON SNLI,EXPERIMENT ON QUORA QUESTION PAIR DATASET,natural_language_inference,49,"['B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",15,0.189873417721519,181,0.7125984251968503,3,0.6,1,1,results
183,DECATT word and DECATT char uses automatically collected in - domain paraphrase data to noisy pretrain n-gram word embedding and ngram subword embedding correspondingly on decomposable attention model proposed by .,EXPERIMENT ON SNLI,EXPERIMENT ON QUORA QUESTION PAIR DATASET,natural_language_inference,49,"['B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",16,0.20253164556962025,182,0.7165354330708661,4,0.8,1,1,results
192,"After removing the exact match binary feature , we find the performance degrade to 78.2 on matched score on development set and 78.0 on mismatched score .",EXPERIMENT ON SNLI,ANALYSIS,natural_language_inference,49,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']",,,25,0.31645569620253167,191,0.7519685039370079,7,0.11475409836065574,1,1,ablation-analysis
197,We obtain 73.2 for matched score and 73.6 on mismatched data .,EXPERIMENT ON SNLI,ANALYSIS,natural_language_inference,49,"['O', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",30,0.379746835443038,196,0.7716535433070866,12,0.19672131147540983,1,1,ablation-analysis
200,"If we remove encoding layer completely , then we 'll obtain a 73.5 for matched score and 73.2 for mismatched score .",EXPERIMENT ON SNLI,ANALYSIS,natural_language_inference,49,"['O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']",,,33,0.4177215189873418,199,0.7834645669291339,15,0.2459016393442623,1,1,ablation-analysis
201,The result demonstrate the feature extraction layer have powerful capability to capture the semantic feature .,EXPERIMENT ON SNLI,ANALYSIS,natural_language_inference,49,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",34,0.43037974683544306,200,0.7874015748031497,16,0.26229508196721313,1,1,ablation-analysis
202,"In experiment 5 , we remove both self - attention and fuse gate , thus retaining only highway network .",EXPERIMENT ON SNLI,ANALYSIS,natural_language_inference,49,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",35,0.4430379746835443,201,0.7913385826771654,17,0.2786885245901639,1,1,ablation-analysis
203,The result improves to 77.7 and 77.3 respectively on matched and mismatched development set .,EXPERIMENT ON SNLI,ANALYSIS,natural_language_inference,49,"['O', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",36,0.45569620253164556,202,0.7952755905511811,18,0.29508196721311475,1,1,ablation-analysis
204,"However , in experiment 6 , when we only remove fuse gate , to our surprise , the performance degrade to 73.5 for matched score and 73.8 for mismatched .",EXPERIMENT ON SNLI,ANALYSIS,natural_language_inference,49,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'O']",,,37,0.46835443037974683,203,0.7992125984251969,19,0.3114754098360656,1,1,ablation-analysis
205,"On the other hand , if we use the addition of the representation after highway network and the representation after self - attention as skip connection as in experiment 7 , the performance increase to 77.3 and 76.3 .",EXPERIMENT ON SNLI,ANALYSIS,natural_language_inference,49,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']",,,38,0.4810126582278481,204,0.8031496062992126,20,0.32786885245901637,1,1,ablation-analysis
2,A Compare - Aggregate Model with Latent Clustering for Answer Selection,title,title,natural_language_inference,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.006802721088435374,1,0.0,1,1,research-problem
4,"In this paper , we propose a novel method for a sentence - level answer- selection task that is a fundamental problem in natural language processing .",abstract,abstract,natural_language_inference,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.02040816326530612,1,0.2,1,1,research-problem
10,Automatic question answering ( QA ) is a primary objective of artificial intelligence .,INTRODUCTION,INTRODUCTION,natural_language_inference,5,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.027777777777777776,9,0.061224489795918366,1,0.045454545454545456,1,1,research-problem
21,"First , we explore the effect of additional information by adopting a pretrained language model ( LM ) to compute the vector representation of the input text .",INTRODUCTION,INTRODUCTION,natural_language_inference,5,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,12,0.3333333333333333,20,0.1360544217687075,12,0.5454545454545454,1,1,approach
23,"Following this study , we select an ELMo language model for this study .",INTRODUCTION,INTRODUCTION,natural_language_inference,5,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",14,0.3888888888888889,22,0.14965986394557823,14,0.6363636363636364,1,1,approach
24,"We investigate the applicability of transfer learning ( TL ) using a large - scale corpus that is created for a relevant - sentence - selection task ( i.e. , question - answering NLI ( QNLI ) dataset ) .",INTRODUCTION,INTRODUCTION,natural_language_inference,5,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",15,0.4166666666666667,23,0.1564625850340136,15,0.6818181818181818,1,1,approach
25,"Second , we further enhance one of the baseline models , Comp - Clip ( refer to the discussion in 3.1 ) , for the target QA task by proposing a novel latent clustering ( LC ) method .",INTRODUCTION,INTRODUCTION,natural_language_inference,5,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.4444444444444444,24,0.16326530612244897,16,0.7272727272727273,1,1,approach
26,The LC method computes latent cluster information for target samples by creating a latent memory space and calculating the similarity between the sample and the memory .,INTRODUCTION,INTRODUCTION,natural_language_inference,5,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-ob', 'O']",17,0.4722222222222222,25,0.17006802721088435,17,0.7727272727272727,1,1,approach
27,"By an endto - end learning process with the answer-selection task , the LC method assigns true - label question - answer pairs to similar clusters .",INTRODUCTION,INTRODUCTION,natural_language_inference,5,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O']",18,0.5,26,0.17687074829931973,18,0.8181818181818182,1,1,approach
29,"Last , we explore the effect of different objective functions ( listwise and pointwise learning ) .",INTRODUCTION,INTRODUCTION,natural_language_inference,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",20,0.5555555555555556,28,0.19047619047619047,20,0.9090909090909091,1,1,approach
112,"To implement the Comp - Clip model , we apply a context projection weight matrix with 100 dimensions that are shared between the question part and the answer part ( eq. 1 ) .",Implementation Details,Implementation Details,natural_language_inference,5,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.07142857142857142,111,0.7551020408163265,1,0.07142857142857142,1,1,hyperparameters
113,"In the aggregation part , we use 1 - D CNN with a total of 500 filters , which involves five types of filters K ? R {1,2,3,4,5}100 , 100 per type .",Implementation Details,Implementation Details,natural_language_inference,5,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.14285714285714285,112,0.7619047619047619,2,0.14285714285714285,1,1,hyperparameters
117,"We select k ( for the kmax - pool in equation 5 ) as 6 and 4 for the WikiQA and TREC - QA case , respectively .",Implementation Details,Implementation Details,natural_language_inference,5,"['O', 'B', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O']",6,0.42857142857142855,116,0.7891156462585034,6,0.42857142857142855,1,1,hyperparameters
118,"In both datasets , we apply 8 latent clusters .",Implementation Details,Implementation Details,natural_language_inference,5,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",7,0.5,117,0.7959183673469388,7,0.5,1,1,hyperparameters
119,"The vocabulary size in the WiKiQA , TREC - QA and QNLI dataset are 30,104 , 56,908 and 154,442 , respectively .",Implementation Details,Implementation Details,natural_language_inference,5,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",8,0.5714285714285714,118,0.8027210884353742,8,0.5714285714285714,1,1,hyperparameters
120,"When applying the TL , the vocabulary size is set to 154,442 , and the dimension of the context projection weight matrix is set to 300 .",Implementation Details,Implementation Details,natural_language_inference,5,"['O', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O']",,,9,0.6428571428571429,119,0.8095238095238095,9,0.6428571428571429,1,1,hyperparameters
121,"We use the Adam optimizer , including gradient clipping , by the norm at a threshold of 5 .",Implementation Details,Implementation Details,natural_language_inference,5,"['O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O']",10,0.7142857142857143,120,0.8163265306122449,10,0.7142857142857143,1,1,hyperparameters
122,"For the purpose of regularization , we applied a dropout with a ratio of 0.5 ..",Implementation Details,Implementation Details,natural_language_inference,5,"['B', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'O']","['B-p', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O', 'B-n', 'O']","['B-p', 'O', 'O', 'B-p', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'O', 'B-ob', 'O']",11,0.7857142857142857,121,0.8231292517006803,11,0.7857142857142857,1,1,hyperparameters
127,"Wiki QA : For the WikiQA dataset , the pointwise learning approach shows a better performance than the listwise learning approach .",Comparison with Other Methods,Comparison with Other Methods,natural_language_inference,5,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.058823529411764705,126,0.8571428571428571,1,0.1,1,1,results
128,We combine LM with the base model ( Comp - Clip + LM ) and observe a significant improvement in performance in terms of MAP ( 0.714 to 0.746 absolute ) .,Comparison with Other Methods,Comparison with Other Methods,natural_language_inference,5,"['O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.11764705882352941,127,0.8639455782312925,2,0.2,1,1,results
129,"When we add the LC method ( Comp - Clip + LM + LC ) , the best previous results are surpassed in terms of MAP ( 0.718 to 0.764 absolute ) .",Comparison with Other Methods,Comparison with Other Methods,natural_language_inference,5,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.17647058823529413,128,0.8707482993197279,3,0.3,1,1,results
132,The pointwise learning approach also shows excellent performance with the TREC - QA dataset .,Comparison with Other Methods,Comparison with Other Methods,natural_language_inference,5,"['O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",6,0.35294117647058826,131,0.891156462585034,6,0.6,1,1,results
135,"As in the WikiQA case , we achieve additional performance gains in terms of the MAP as we apply LM , LC , and TL ( 0.850 , 0.868 and 0.875 , respectively ) .",Comparison with Other Methods,Comparison with Other Methods,natural_language_inference,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",9,0.5294117647058824,134,0.9115646258503401,9,0.9,1,1,results
136,"In particular , our model outperforms the best previous result when we add LC method , ( Comp - Clip + LM + LC ) in terms of MAP ( 0.865 to 0.868 ) .",Comparison with Other Methods,Comparison with Other Methods,natural_language_inference,5,"['O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'B-b', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O']",10,0.5882352941176471,135,0.9183673469387755,10,1.0,1,1,results
2,Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering,title,title,natural_language_inference,50,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0031545741324921135,1,0.0,1,1,research-problem
24,"In this paper , we propose an extremely simple neural ranking model for question answering that achieves highly competitive results on several benchmarks with only a fraction of the runtime and only 40K - 90 K parameters ( as opposed to millions ) .",abstract,abstract,natural_language_inference,50,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.12804878048780488,23,0.07255520504731862,21,0.4666666666666667,1,1,model
25,Our neural ranking models the relationships between QA pairs in Hyperbolic space instead of Euclidean space .,abstract,abstract,natural_language_inference,50,"['O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",22,0.13414634146341464,24,0.07570977917981073,22,0.4888888888888889,1,1,model
26,Hyperbolic space is an embedding space with a constant negative curvature in which the distance towards the border is increasing exponentially .,abstract,abstract,natural_language_inference,50,"['B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'O']",,,23,0.1402439024390244,25,0.07886435331230283,23,0.5111111111111111,1,1,model
187,YahooCQA,Compared Baselines,,natural_language_inference,50,['B'],['B-n'],['B-b'],2,0.2,186,0.5867507886435331,2,0.2,1,1,baselines
188,- The key competitors of this dataset are the Neural Tensor LSTM ( NTN - LSTM ) and HD - LSTM from Tay et al.,Compared Baselines,YahooCQA,natural_language_inference,50,"['O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n']","['O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob']",3,0.3,187,0.5899053627760252,3,0.3,1,1,baselines
189,"along with their implementation of the Convolutional Neural Tensor Network , vanilla CNN model , and the Okapi BM - 25 benchmark .",Compared Baselines,YahooCQA,natural_language_inference,50,"['O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.4,188,0.5930599369085173,4,0.4,1,1,baselines
190,"Additionally , we also report our own implementations of QA - BiLSTM , QA - CNN , AP - BiLSTM and AP - CNN on this dataset based on our experimental setup . WikiQA",Compared Baselines,YahooCQA,natural_language_inference,50,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b']",5,0.5,189,0.5962145110410094,5,0.5,1,1,baselines
191,"- The key competitors of this dataset are the Paragraph Vector ( PV ) and PV + Cnt models of Le and Mikolv , CNN + Cnt model from Yu et al. and LCLR ( Yih et al . ) .",Compared Baselines,YahooCQA,natural_language_inference,50,"['O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.6,190,0.5993690851735016,6,0.6,1,1,baselines
194,"For the clean version of this dataset , we also compare with AP - CNN and QA - BiLSTM / CNN .",Compared Baselines,YahooCQA,natural_language_inference,50,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.9,193,0.6088328075709779,9,0.9,1,1,baselines
210,Hyper QA is implemented in Tensor - Flow .,Hyperparameters .,Hyperparameters .,natural_language_inference,50,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.07142857142857142,209,0.6593059936908517,7,0.35,1,1,hyperparameters
211,"We adopt the AdaGrad optimizer with initial learning rate tuned amongst { 0.2 , 0.1 , 0.05 , 0.01 } .",Hyperparameters .,Hyperparameters .,natural_language_inference,50,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.14285714285714285,210,0.6624605678233438,8,0.4,1,1,hyperparameters
212,"The batch size is tuned amongst { 50 , 100 , 200 } .",Hyperparameters .,Hyperparameters .,natural_language_inference,50,"['O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.21428571428571427,211,0.6656151419558359,9,0.45,1,1,hyperparameters
213,Models are trained for 25 epochs and the model parameters are saved each time the performance on the validation set is topped .,Hyperparameters .,Hyperparameters .,natural_language_inference,50,"['B', 'B', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['B-n', 'B-p', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'B-p', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'O']",4,0.2857142857142857,212,0.668769716088328,10,0.5,1,1,hyperparameters
214,"The dimension of the projection layer is tuned amongst { 100 , 200 , 300 , 400 } .",Hyperparameters .,Hyperparameters .,natural_language_inference,50,"['O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.35714285714285715,213,0.6719242902208202,11,0.55,1,1,hyperparameters
215,"L2 regularization is tuned amongst { 0.001 , 0.0001 , 0.00001 }.",Hyperparameters .,Hyperparameters .,natural_language_inference,50,"['B', 'I', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.42857142857142855,214,0.6750788643533123,12,0.6,1,1,hyperparameters
216,The negative sampling rate is tuned from 2 to 8 .,Hyperparameters .,Hyperparameters .,natural_language_inference,50,"['O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",7,0.5,215,0.6782334384858044,13,0.65,1,1,hyperparameters
227,reports the experimental results on SemEvalCQA .,Results and Analysis,Results and Analysis,natural_language_inference,50,"['O', 'O', 'O', 'O', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'O']",3,0.03488372093023256,226,0.7129337539432177,3,0.07142857142857142,1,1,results
228,Our proposed approach achieves highly competitive performance on this dataset .,Results and Analysis,Results and Analysis,natural_language_inference,50,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",4,0.046511627906976744,227,0.7160883280757098,4,0.09523809523809523,1,1,results
229,"Specifically , we have obtained the best P@1 performance over all , outperforming the state - of - the - art AI - CNN model by 3 % in terms of P@1 .",Results and Analysis,Results and Analysis,natural_language_inference,50,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'O']",5,0.05813953488372093,228,0.7192429022082019,5,0.11904761904761904,1,1,results
230,The performance of our model on MAP is marginally short from the best performing model .,Results and Analysis,Results and Analysis,natural_language_inference,50,"['O', 'B', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.06976744186046512,229,0.722397476340694,6,0.14285714285714285,1,1,results
239,reports the results on TrecQA ( raw ) .,Results and Analysis,Results and Analysis,natural_language_inference,50,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",15,0.1744186046511628,238,0.750788643533123,15,0.35714285714285715,1,1,results
240,Hyper QA achieves very competitive performance on both MAP and MRR metrics .,Results and Analysis,Results and Analysis,natural_language_inference,50,"['B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.18604651162790697,239,0.7539432176656151,16,0.38095238095238093,1,1,results
241,"Specifically , Hyper QA outperforms the basic CNN model of ( S&M ) by 2 % ? 3 % in terms of MAP / MRR .",Results and Analysis,Results and Analysis,natural_language_inference,50,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.19767441860465115,240,0.7570977917981072,17,0.40476190476190477,1,1,results
247,"Similarly , reports the results on TrecQA ( clean ) .",Results and Analysis,Results and Analysis,natural_language_inference,50,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",23,0.26744186046511625,246,0.7760252365930599,23,0.5476190476190477,1,1,results
248,"Similarly , Hyper QA also outperforms MP - CNN , AP - CNN and QA - CNN .",Results and Analysis,Results and Analysis,natural_language_inference,50,"['O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-ob', 'I-ob', 'O', 'B-s', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",24,0.27906976744186046,247,0.7791798107255521,24,0.5714285714285714,1,1,results
2,Neural Stored - program Memory,title,title,natural_language_inference,51,"['B', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0037735849056603774,1,0.0,1,1,research-problem
6,"In this paper , we introduce a new memory to store weights for the controller , analogous to the stored - program memory in modern computer architectures .",abstract,abstract,natural_language_inference,51,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",3,0.6,5,0.018867924528301886,3,0.6,1,1,research-problem
21,Our goal is to advance a step further towards UTM by coupling a MANN with an external program memory .,Introduction,Introduction,natural_language_inference,51,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.5454545454545454,20,0.07547169811320754,12,0.5454545454545454,1,1,model
22,"The program memory co-exists with the data memory in the MANN , providing more flexibility , reuseability and modularity in learning complicated tasks .",Introduction,Introduction,natural_language_inference,51,"['O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-ob', 'I-ob', 'O']",13,0.5909090909090909,21,0.07924528301886792,13,0.5909090909090909,1,1,model
23,"The program memory stores the weights of the MANN 's controller network , which are retrieved quickly via a key - value attention mechanism across timesteps yet updated slowly via backpropagation .",Introduction,Introduction,natural_language_inference,51,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'B', 'B', 'O']",,,14,0.6363636363636364,22,0.0830188679245283,14,0.6363636363636364,1,1,model
24,"By introducing a meta network to moderate the operations of the program memory , our model , henceforth referred to as Neural Stored - program Memory ( NSM ) , can learn to switch the programs / weights in the controller network appropriately , adapting to different functionalities aligning with different parts of a sequential task , or different tasks in continual and few - shot learning .",Introduction,Introduction,natural_language_inference,51,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']",,,15,0.6818181818181818,23,0.08679245283018867,15,0.6818181818181818,1,1,model
148,"Except for the Copy task , which is too simple , other tasks observe convergence speed improvement of NUTM over that of NTM , thereby validating the benefit of using two programs across timesteps even for the single task setting .",Results,Single Tasks,natural_language_inference,51,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'O', 'B-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",14,0.2028985507246377,147,0.5547169811320755,14,0.6363636363636364,1,1,results
149,NUTM requires fewer training samples to converge and it generalizes better to unseen sequences that are longer than training sequences .,Results,Single Tasks,natural_language_inference,51,"['B', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'O']",,,15,0.21739130434782608,148,0.5584905660377358,15,0.6818181818181818,1,1,results
159,"We run the task with three additional baselines : NUTM using direct attention ( DA ) , NUTM using key - value without regularization ( KV ) , NUTM using fixed , uniform program distribution ( UP ) and a vanilla NTM with 2 memory heads ( h = 2 ) .",Results,Ablation study on Associative Recall,natural_language_inference,51,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,25,0.36231884057971014,158,0.5962264150943396,2,0.16666666666666666,1,1,ablation-analysis
163,The results demonstrate that DA exhibits fast yet shallow convergence .,Results,Ablation study on Associative Recall,natural_language_inference,51,"['O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",29,0.42028985507246375,162,0.6113207547169811,6,0.5,1,1,ablation-analysis
164,"It tends to fall into local minima , which finally fails to reach zero loss .",Results,Ablation study on Associative Recall,natural_language_inference,51,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",30,0.43478260869565216,163,0.6150943396226415,7,0.5833333333333334,1,1,ablation-analysis
165,Key- value attention helps NUTM converge completely with fewer iterations .,Results,Ablation study on Associative Recall,natural_language_inference,51,"['B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",31,0.4492753623188406,164,0.6188679245283019,8,0.6666666666666666,1,1,ablation-analysis
166,The performance is further improved with the proposed regularization loss .,Results,Ablation study on Associative Recall,natural_language_inference,51,"['O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",32,0.463768115942029,165,0.6226415094339622,9,0.75,1,1,ablation-analysis
167,UP underperforms NUTM as it lacks dynamic programs .,Results,Ablation study on Associative Recall,natural_language_inference,51,"['B', 'B', 'B', 'B', 'O', 'B', 'B', 'I', 'O']","['B-n', 'B-n', 'B-n', 'B-p', 'O', 'B-n', 'B-n', 'I-n', 'O']","['B-b', 'B-b', 'B-ob', 'B-p', 'O', 'B-b', 'B-ob', 'I-ob', 'O']",33,0.4782608695652174,166,0.6264150943396226,10,0.8333333333333334,1,1,ablation-analysis
168,"The NTM with 2 heads shows slightly better convergence compared to the NTM , yet obviously underperforms NUTM ( p = 2 ) with 1 head and fewer parameters .",Results,Ablation study on Associative Recall,natural_language_inference,51,"['O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']",,,34,0.4927536231884058,167,0.630188679245283,11,0.9166666666666666,1,1,ablation-analysis
2,Tell Me Why : Using Question Answering as Distant Supervision for Answer Justification,title,title,natural_language_inference,52,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.0038314176245210726,1,0.0,1,1,research-problem
11,"Developing interpretable machine learning ( ML ) models , that is , models where a human user can understand what the model is learning , is considered by many to be crucial for ensuring usability and accelerating progress .",Introduction,Introduction,natural_language_inference,52,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.02857142857142857,10,0.038314176245210725,1,0.02857142857142857,1,1,research-problem
32,"Within this domain , we propose an approach that learns to both select and explain answers , when the only supervision available is for which answer is correct ( but not how to explain it ) .",Introduction,Introduction,natural_language_inference,52,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",22,0.6285714285714286,31,0.11877394636015326,22,0.6285714285714286,1,1,approach
33,"Intuitively , our approach chooses the justifications that provide the most help towards ranking the correct answers higher than incorrect ones .",Introduction,Introduction,natural_language_inference,52,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'B-b', 'I-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",23,0.6571428571428571,32,0.12260536398467432,23,0.6571428571428571,1,1,approach
34,"More formally , our neural network approach alternates between using the current model with max - pooling to choose the highest scoring justifications for correct answers , and optimizing the answer ranking model given these justifications .",Introduction,Introduction,natural_language_inference,52,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",24,0.6857142857142857,33,0.12643678160919541,24,0.6857142857142857,1,1,approach
148,IR Baseline :,Baselines,Baselines,natural_language_inference,52,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-b', 'I-b', 'O']",2,0.14285714285714285,147,0.5632183908045977,2,0.4,1,1,baselines
149,"For this baseline , we rank answer candidates by the maximum tf .idf document retrieval score using an unboosted query of question and answer terms ( see Section 4.1 for retrieval details ) .",Baselines,Baselines,natural_language_inference,52,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.21428571428571427,148,0.5670498084291188,3,0.6,1,1,baselines
150,IR ++ :,Baselines,Baselines,natural_language_inference,52,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-b', 'I-b', 'O']",4,0.2857142857142857,149,0.5708812260536399,4,0.8,1,1,baselines
151,"This baseline uses the same architecture as the full model , as described in Section 4.3 , but with only the IR ++ feature group .",Baselines,Baselines,natural_language_inference,52,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.35714285714285715,150,0.5747126436781609,5,1.0,1,1,baselines
171,QA Performance,Results,,natural_language_inference,52,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",4,0.07692307692307693,170,0.6513409961685823,0,0.0,1,1,results
177,"Our full model that combines IR ++ , lexical overlap , discourse , and embeddings - based features , has a P@1 of 53.3 % ( line 7 ) , an absolute gain of 6.3 % over the strong IR baseline despite using the same background knowledge .",Results,QA Performance,natural_language_inference,52,"['B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,10,0.19230769230769232,176,0.6743295019157088,6,0.24,1,1,results
183,also tackle the AI2 Kaggle question set with an approach that learns alignments between questions and structured and semistructured KB data .,Results,QA Performance,natural_language_inference,52,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.3076923076923077,182,0.6973180076628352,12,0.48,1,1,results
185,"By way of a loose comparison ( since we are evaluating on different data partitions ) , our model has approximately 5 % higher performance despite our simpler set of features and unstructured KB .",Results,QA Performance,natural_language_inference,52,"['B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.34615384615384615,184,0.7049808429118773,14,0.56,1,1,results
192,"In comparison to other systems that competed in the Kaggle challenge , our system comes in in 7th place out of 170 competitors ( top 4 % ) .",Results,QA Performance,natural_language_inference,52,"['B', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",25,0.4807692307692308,191,0.7318007662835249,21,0.84,1,1,results
197,Justification Performance,Results,,natural_language_inference,52,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",30,0.5769230769230769,196,0.7509578544061303,0,0.0,1,1,results
228,"Note that 61 % of the top - ranked justifications from our system were rated as Good as compared to 52 % from the IR baseline ( a gain of 9 % ) , despite the systems using identical corpora .",Model,Model,natural_language_inference,52,"['O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,8,0.21621621621621623,227,0.8697318007662835,8,0.5333333333333333,1,1,results
2,Supervised Learning of Universal Sentence Representations from Natural Language Inference Data,title,title,natural_language_inference,53,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.004807692307692308,1,0.0,1,1,research-problem
15,"In this paper , we study the task of learning universal representations of sentences , i.e. , a sentence encoder model that is trained on a large corpus and subsequently transferred to other tasks .",Introduction,Introduction,natural_language_inference,53,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",5,0.35714285714285715,14,0.0673076923076923,5,0.35714285714285715,1,1,approach
18,"Here , we investigate whether supervised learning can be leveraged instead , taking inspiration from previous results in computer vision , where many models are pretrained on the ImageNet ) before being transferred .",Introduction,Introduction,natural_language_inference,53,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.5714285714285714,17,0.08173076923076923,8,0.5714285714285714,1,1,approach
22,"Hence , we investigate the impact of the sentence encoding architecture on representational transferability , and compare convolutional , recurrent and even simpler word composition schemes .",Introduction,Introduction,natural_language_inference,53,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.8571428571428571,21,0.10096153846153846,12,0.8571428571428571,1,1,approach
88,"For all our models trained on SNLI , we use SGD with a learning rate of 0.1 and a weight decay of 0.99 .",Training details,Training details,natural_language_inference,53,"['B', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O']",,,1,0.2,87,0.4182692307692308,1,0.2,1,1,hyperparameters
89,"At each epoch , we divide the learning rate by 5 if the dev accuracy decreases .",Training details,Training details,natural_language_inference,53,"['B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-b', 'I-b', 'B-ob', 'O']",2,0.4,88,0.4230769230769231,2,0.4,1,1,hyperparameters
90,We use minibatches of size 64 and training is stopped when the learning rate goes under the threshold of 10 ?5 .,Training details,Training details,natural_language_inference,53,"['O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.6,89,0.42788461538461536,3,0.6,1,1,hyperparameters
91,"For the classifier , we use a multi - layer perceptron with 1 hidden - layer of 512 hidden units .",Training details,Training details,natural_language_inference,53,"['O', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.8,90,0.4326923076923077,4,0.8,1,1,hyperparameters
92,We use opensource GloVe vectors trained on Common Crawl 840B with 300 dimensions as fixed word embeddings .,Training details,Training details,natural_language_inference,53,"['O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",5,1.0,91,0.4375,5,1.0,1,1,hyperparameters
141,Architecture impact,,,natural_language_inference,53,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",0,0.0,140,0.6730769230769231,0,0.0,1,1,results
144,The BiLSTM - 4096 with the max - pooling operation performs best on both SNLI and transfer tasks .,Model,Model,natural_language_inference,53,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.03333333333333333,143,0.6875,3,0.3,1,1,results
145,"Looking at the micro and macro averages , we see that it performs significantly better than the other models LSTM , GRU , BiGRU - last , BiLSTM - Mean , inner-attention and the hierarchical - ConvNet. also shows that better performance on the training task does not necessarily translate in better results on the transfer tasks like when comparing inner-attention and BiLSTM - Mean for instance .",Model,Model,natural_language_inference,53,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.05,144,0.6923076923076923,4,0.4,1,1,results
150,"For a given model , the transfer quality is also sensitive to the optimization algorithm : when training with Adam instead of SGD , we observed that the BiLSTM - max converged faster on SNLI ( 5 epochs instead of 10 ) , but obtained worse results on the transfer tasks , most likely because of the model and classifier 's increased capability to over-specialize on the training task .",Model,Model,natural_language_inference,53,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,8,0.13333333333333333,149,0.7163461538461539,9,0.9,1,1,results
152,Embedding size,Model,,natural_language_inference,53,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",10,0.16666666666666666,151,0.7259615384615384,0,0.0,1,1,results
153,"Since it is easier to linearly separate in high dimension , especially with logistic regression , it is not surprising that increased embedding sizes lead to increased performance for almost all models .",Model,Embedding size,natural_language_inference,53,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",11,0.18333333333333332,152,0.7307692307692307,1,0.1111111111111111,1,1,results
170,Comparison with SkipThought,Model,,natural_language_inference,53,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",28,0.4666666666666667,169,0.8125,8,0.2,1,1,results
172,"With much less data ( 570 k compared to 64M sentences ) but with high - quality supervision from the SNLI dataset , we are able to consistently outperform the results obtained by SkipThought vectors .",Model,Comparison with SkipThought,natural_language_inference,53,"['B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",30,0.5,171,0.8221153846153846,10,0.25,1,1,results
174,"Our BiLSTM - max trained on SNLI performs much better than released SkipThought vectors on MR , CR , MPQA , SST , MRPC - accuracy , SICK - R , SICK - E and STS14 ( see ) .",Model,Comparison with SkipThought,natural_language_inference,53,"['B', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",32,0.5333333333333333,173,0.8317307692307693,12,0.3,1,1,results
175,"Except for the SUBJ dataset , it also performs better than SkipThought - LN on MR , CR and MPQA .",Model,Comparison with SkipThought,natural_language_inference,53,"['B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O']","['B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'O', 'O', 'B-p', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O']",33,0.55,174,0.8365384615384616,13,0.325,1,1,results
176,We also observe by looking at the STS14 results that the cosine metrics in our embedding space is much more semantically informative than in SkipThought embedding space ( pearson score of 0.68 compared to 0.29 and 0.44 for ST and ST - LN ) .,Model,Comparison with SkipThought,natural_language_inference,53,"['O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",34,0.5666666666666667,175,0.8413461538461539,14,0.35,1,1,results
178,NLI as a supervised training set,Model,,natural_language_inference,53,"['B', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",36,0.6,177,0.8509615384615384,16,0.4,1,1,results
179,"Our findings indicate that our model trained on SNLI obtains much better over all results than models trained on other supervised tasks such as COCO , dictionary definitions , NMT , PPDB and SST .",Model,NLI as a supervised training set,natural_language_inference,53,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'O']",,,37,0.6166666666666667,178,0.8557692307692307,17,0.425,1,1,results
183,Domain adaptation on SICK tasks,Model,,natural_language_inference,53,"['B', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b']",41,0.6833333333333333,182,0.875,21,0.525,1,1,results
184,Our transfer learning approach obtains better results than previous state - of - the - art on the SICK task - can be seen as an out - domain version of SNLI - for both entailment and relatedness .,Model,Domain adaptation on SICK tasks,natural_language_inference,53,"['B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",42,0.7,183,0.8798076923076923,22,0.55,1,1,results
185,"We obtain a pearson score of 0.885 on SICK - R while obtained 0.868 , and we obtain 86.3 % test accuracy on SICK - E while previous best handengineered models obtained 84.5 % .",Model,Domain adaptation on SICK tasks,natural_language_inference,53,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O']",,,43,0.7166666666666667,184,0.8846153846153846,23,0.575,1,1,results
186,"We also significantly outperformed previous transfer learning approaches on SICK - E ( Bowman et al. , 2015 ) that used the parameters of an LSTM model trained on SNLI to fine - tune on SICK ( 80.8 % accuracy ) .",Model,Domain adaptation on SICK tasks,natural_language_inference,53,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O']",44,0.7333333333333333,185,0.8894230769230769,24,0.6,1,1,results
188,Image - caption retrieval results,Model,,natural_language_inference,53,"['B', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b']",46,0.7666666666666667,187,0.8990384615384616,26,0.65,1,1,results
191,"When trained with ResNet features and 30 k more training data , the SkipThought vectors perform significantly better than the original setting , going from 33.8 to 37.9 for caption retrieval R@1 , and from 25.9 to 30.6 on image retrieval R@1 .",Model,Image - caption retrieval results,natural_language_inference,53,"['O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",49,0.8166666666666667,190,0.9134615384615384,29,0.725,1,1,results
192,"Our approach pushes the results even further , from 37.9 to 42.4 on cap-tion retrieval , and 30.6 to 33.2 on image retrieval .",Model,Image - caption retrieval results,natural_language_inference,53,"['B', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'O']",,,50,0.8333333333333334,191,0.9182692307692307,30,0.75,1,1,results
195,MultiGenre NLI,Model,Image - caption retrieval results,natural_language_inference,53,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",53,0.8833333333333333,194,0.9326923076923077,33,0.825,1,1,results
199,We observe a significant boost in performance over all compared to the model trained only on SLNI .,Model,Image - caption retrieval results,natural_language_inference,53,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'O']",57,0.95,198,0.9519230769230769,37,0.925,1,1,results
200,"Our model even reaches AdaSent performance on CR , suggesting that having a larger coverage for the training task helps learn even better general representations .",Model,Image - caption retrieval results,natural_language_inference,53,"['B', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",58,0.9666666666666667,199,0.9567307692307693,38,0.95,1,1,results
2,Structural Embedding of Syntactic Trees for Machine Comprehension,title,,natural_language_inference,54,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.004366812227074236,1,0.0,1,1,research-problem
9,"Reading comprehension such as SQuAD or News QA requires identifying a span from a given context , which is an extension to the traditional question answering task , aiming at responding questions posed by human with natural language .",Introduction,Introduction,natural_language_inference,54,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.047619047619047616,8,0.034934497816593885,1,0.047619047619047616,1,1,research-problem
26,"In this paper , we propose Structural Embedding of Syntactic Trees ( SEST ) that encode syntactic information structured by constituency tree and dependency tree into neural attention models for the question answering task .",Introduction,Introduction,natural_language_inference,54,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",18,0.8571428571428571,25,0.1091703056768559,18,0.8571428571428571,1,1,model
124,We run our experiments on a machine that contains a single GTX 1080 GPU with 8 GB VRAM .,Experiment Setting,Experiment Setting,natural_language_inference,54,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.0125,123,0.537117903930131,1,0.06666666666666667,1,1,experimental-setup
126,"As introduced in Section 2 , we use a variable character embedding with a fixed pre-trained word embedding to serve as part of the input into the model .",Experiment Setting,Experiment Setting,natural_language_inference,54,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O']",3,0.0375,125,0.5458515283842795,3,0.2,1,1,experimental-setup
127,The character embedding is implemented using CNN with a one -dimensional layer consists of 100 units with a channel size of 5 .,Experiment Setting,Experiment Setting,natural_language_inference,54,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,4,0.05,126,0.5502183406113537,4,0.26666666666666666,1,1,experimental-setup
128,It has an input depth of 8 .,Experiment Setting,Experiment Setting,natural_language_inference,54,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",5,0.0625,127,0.5545851528384279,5,0.3333333333333333,1,1,experimental-setup
129,The max length of SQuAD is 16 which means there are a maximum 16 words in a sentence .,Experiment Setting,Experiment Setting,natural_language_inference,54,"['O', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.075,128,0.5589519650655022,6,0.4,1,1,experimental-setup
130,"The fixed word embedding has a dimension of 100 , which is provided by the GloVe data set .",Experiment Setting,Experiment Setting,natural_language_inference,54,"['O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",7,0.0875,129,0.5633187772925764,7,0.4666666666666667,1,1,experimental-setup
133,The POS model contains syntactic information with 39 different POS tags that serve as both input and output .,Experiment Setting,Experiment Setting,natural_language_inference,54,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.125,132,0.5764192139737991,10,0.6666666666666666,1,1,experimental-setup
134,For SECT and SEDT the input of the model has a size of 8 with 30 units to be output .,Experiment Setting,Experiment Setting,natural_language_inference,54,"['B', 'B', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'O']",,,11,0.1375,133,0.5807860262008734,11,0.7333333333333333,1,1,experimental-setup
135,"Both of them has a maximum length size that is set to be 10 and 20 respectively , which values will be further discussed in Section 4.5 .",Experiment Setting,Experiment Setting,natural_language_inference,54,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.15,134,0.5851528384279476,12,0.8,1,1,experimental-setup
139,Predictive Performance,Experiment Setting,,natural_language_inference,54,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",16,0.2,138,0.6026200873362445,0,0.0,1,1,experiments
140,"We first compared the performance of single models between the baseline approach BiDAF and the proposed SEST approaches , including SE - POS , SECT - LSTM , SECT - CNN , SEDT - LSTM , and SEDT - CNN , on the development dataset of SQuAD .",Experiment Setting,Predictive Performance,natural_language_inference,54,"['O', 'O', 'B', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'O']",17,0.2125,139,0.6069868995633187,1,0.08333333333333333,1,1,experiments
145,"Another observation is that our propose models achieve higher relative improvements in EM scores than F 1 scores over the baseline methods , providing the evidence that syntactic information can accurately locate the boundaries of the answer .",Experiment Setting,Predictive Performance,natural_language_inference,54,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.275,144,0.62882096069869,6,0.5,1,1,experiments
146,"Moreover , we found that both SECT - LSTM and SEDT - LSTM have better performance than their CNN counterparts , which suggests that LSTM can more effectively preserve the syntactic information .",Experiment Setting,Predictive Performance,natural_language_inference,54,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",23,0.2875,145,0.6331877729257642,7,0.5833333333333334,1,1,experiments
152,Contribution of Syntactic Sequence,Experiment Setting,,natural_language_inference,54,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",29,0.3625,151,0.6593886462882096,0,0.0,1,1,experiments
160,From the table we see that both the ordering and the contents of the syntactic tree are important for the models to work properly : constituency and dependency trees achieved over 20 % boost on performance compared to the randomly generated ones and our proposed ordering also out - performed the random ordering .,Experiment Setting,Contribution of Syntactic Sequence,natural_language_inference,54,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",37,0.4625,159,0.6943231441048034,8,0.7272727272727273,1,1,experiments
161,It also worth mentioning that the ordering of dependency trees seems to have less impact on the performance compared to that of the constituency trees .,Experiment Setting,Contribution of Syntactic Sequence,natural_language_inference,54,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'I-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",38,0.475,160,0.6986899563318777,9,0.8181818181818182,1,1,experiments
164,Window Size Analysis,Experiment Setting,,natural_language_inference,54,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",41,0.5125,163,0.7117903930131004,0,0.0,1,1,experiments
166,"In practice , we found that limiting the window size also benefits the performance of our models .",Experiment Setting,Window Size Analysis,natural_language_inference,54,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-b', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",43,0.5375,165,0.7205240174672489,2,0.15384615384615385,1,1,experiments
169,In general the results illustrate that performances of the models increase with the length of the window .,Experiment Setting,Window Size Analysis,natural_language_inference,54,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'O']",,,46,0.575,168,0.7336244541484717,5,0.38461538461538464,1,1,experiments
171,We also observed that larger window size does not generate predictive results that is as good as the one with window size set to 10 .,Experiment Setting,Window Size Analysis,natural_language_inference,54,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",48,0.6,170,0.74235807860262,7,0.5384615384615384,1,1,experiments
2,Question Answering with Subgraph Embeddings,title,,natural_language_inference,55,"['B', 'I', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O']",1,0.0,1,0.006802721088435374,1,0.0,1,1,research-problem
4,This paper presents a system which learns to answer questions on a broad range of topics from a knowledge base using few handcrafted features .,abstract,abstract,natural_language_inference,55,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.3333333333333333,3,0.02040816326530612,1,0.3333333333333333,1,1,research-problem
8,Teaching machines how to automatically answer questions asked in natural language on any topic or in any domain has always been along standing goal in Artificial Intelligence .,Introduction,Introduction,natural_language_inference,55,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.011904761904761904,7,0.047619047619047616,1,0.05555555555555555,1,1,research-problem
9,"With the rise of large scale structured knowledge bases ( KBs ) , this problem , known as open - domain question answering ( or open QA ) , boils down to being able to query efficiently such databases with natural language .",Introduction,Introduction,natural_language_inference,55,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.023809523809523808,8,0.05442176870748299,2,0.1111111111111111,1,1,research-problem
10,"These KBs , such as Freebase encompass huge ever growing amounts of information and ease open QA by organizing a great variety of answers in a structured format .",Introduction,Introduction,natural_language_inference,55,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.03571428571428571,9,0.061224489795918366,3,0.16666666666666666,1,1,research-problem
23,"In this paper , we improve the model of by providing the ability to answer more complicated questions .",Introduction,Introduction,natural_language_inference,55,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",16,0.19047619047619047,22,0.14965986394557823,16,0.8888888888888888,1,1,model
24,s The main contributions of the paper are : ( 1 ) a more sophisticated inference procedure that is both efficient and can consider longer paths ( considered only answers directly connected to the question in the graph ) ; and ( 2 ) a richer representation of the answers which encodes the question - answer path and surrounding subgraph of the KB .,Introduction,Introduction,natural_language_inference,55,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O']",,,17,0.20238095238095238,23,0.1564625850340136,17,0.9444444444444444,1,1,model
136,Replacing C 2 by C 1 induces a large drop in performance because many questions do not have answers that are directly connected to their inluded entity ( not in C 1 ) .,Experiments,Experiments,natural_language_inference,55,"['B', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.35714285714285715,135,0.9183673469387755,5,0.35714285714285715,1,1,results
137,"However , using all 2 - hops connections as a candidate set is also detrimental , because the larger number of candidates confuses ( and slows a lot ) our ranking based inference .",Experiments,Experiments,natural_language_inference,55,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.42857142857142855,136,0.9251700680272109,6,0.42857142857142855,1,1,results
138,"Our results also verify our hypothesis of Section 3.1 , that a richer representation for answers ( using the local subgraph ) can store more pertinent information .",Experiments,Experiments,natural_language_inference,55,"['O', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",7,0.5,137,0.9319727891156463,7,0.5,1,1,results
139,"Finally , we demonstrate that we greatly improve upon the model of , which actually corresponds to a setting with the Path representation and C 1 as candidate set .",Experiments,Experiments,natural_language_inference,55,"['O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.5714285714285714,138,0.9387755102040817,8,0.5714285714285714,1,1,results
145,"The ensemble improves the state - of - the - art , and indicates that our models are significantly different in their design .",Experiments,Experiments,natural_language_inference,55,"['O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,1.0,144,0.9795918367346939,14,1.0,1,1,results
2,Recurrent Relational Networks,title,title,natural_language_inference,56,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.002976190476190476,0,0.0,1,1,research-problem
5,"We introduce the recurrent relational network , a general purpose module that operates on a graph representation of objects .",abstract,abstract,natural_language_inference,56,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.2,4,0.011904761904761904,2,0.2,1,1,research-problem
25,"Toward generally realizing the ability to methodically reason about objects and their interactions over many steps , this paper introduces a composite function , the recurrent relational network .",Introduction,Introduction,natural_language_inference,56,"['B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",11,0.20754716981132076,24,0.07142857142857142,11,0.4074074074074074,1,1,model
26,It serves as a modular component for many - step relational reasoning in end - to - end differentiable learning systems .,Introduction,Introduction,natural_language_inference,56,"['O', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.22641509433962265,25,0.0744047619047619,12,0.4444444444444444,1,1,model
27,"It encodes the inductive biases that 1 ) objects exists in the world 2 ) they can be sufficiently described by properties 3 ) properties can changeover time 4 ) objects can affect each other and 5 ) given the properties , the effects object have on each other is invariant to time .",Introduction,Introduction,natural_language_inference,56,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O']",,,13,0.24528301886792453,26,0.07738095238095238,13,0.48148148148148145,1,1,model
28,"An important insight from the work of is to decompose a function for relational reasoning into two components or "" modules "" :",Introduction,Introduction,natural_language_inference,56,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O']",14,0.2641509433962264,27,0.08035714285714286,14,0.5185185185185185,1,1,model
29,"a perceptual front - end , which is tasked to recognize objects in the raw input and represent them as vectors , and a relational reasoning module , which uses the representation to reason about the objects and their interactions .",Introduction,Introduction,natural_language_inference,56,"['O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.2830188679245283,28,0.08333333333333333,15,0.5555555555555556,1,1,model
30,Both modules are trained jointly end - to - end .,Introduction,Introduction,natural_language_inference,56,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.3018867924528302,29,0.08630952380952381,16,0.5925925925925926,1,1,model
31,"In computer science parlance , the relational reasoning module implements an interface : it operates on a graph of nodes and directed edges , where the nodes are represented by real valued vectors , and is differentiable .",Introduction,Introduction,natural_language_inference,56,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-ob', 'O']",17,0.32075471698113206,30,0.08928571428571429,17,0.6296296296296297,1,1,model
42,Recurrent Relational Networks,Introduction,Introduction,natural_language_inference,56,"['B', 'I', 'I']",,,28,0.5283018867924528,41,0.12202380952380952,0,0.0,1,1,research-problem
81,Code to reproduce all experiments can be found at github.com/rasmusbergpalm/recurrent-relationalnetworks. designed as a set of prerequisite tasks for reasoning .,Experiments,Experiments,natural_language_inference,56,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.006097560975609756,80,0.23809523809523808,1,0.015625,1,1,code
90,bAbI question - answering tasks,Experiments,"Daniel put down the milk . """,natural_language_inference,56,"['B', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b']",10,0.06097560975609756,89,0.2648809523809524,10,0.15625,1,1,experiments
104,"Surprisingly , we find that we only need a single step of relational reasoning to solve all the bAbI tasks .",Experiments,See the supplementary material for details .,natural_language_inference,56,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",24,0.14634146341463414,103,0.30654761904761907,24,0.375,1,1,experiments
108,"Regardless , it appears multiple steps of relational reasoning are not important for the bAbI dataset .",Experiments,See the supplementary material for details .,natural_language_inference,56,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",28,0.17073170731707318,107,0.31845238095238093,28,0.4375,1,1,experiments
109,Pretty - CLEVR,Experiments,,natural_language_inference,56,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",29,0.17682926829268292,108,0.32142857142857145,29,0.453125,1,1,experiments
140,"Mirroring the results from the "" Sort - of - CLEVR "" dataset the MLP perfectly solves the non-relational questions , but struggle with even single jump questions and seem to lower bound the performance of the relational networks .",Experiments,For details see the supplementary material .,natural_language_inference,56,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",60,0.36585365853658536,139,0.41369047619047616,60,0.9375,1,1,experiments
141,"The relational network solves the non-relational questions as well as the ones requiring a single jump , but the accuracy sharply drops off with more jumps .",Experiments,For details see the supplementary material .,natural_language_inference,56,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",61,0.3719512195121951,140,0.4166666666666667,61,0.953125,1,1,experiments
145,Sudoku,Experiments,,natural_language_inference,56,['B'],['B-n'],['B-b'],65,0.39634146341463417,144,0.42857142857142855,0,0.0,1,1,experiments
153,Our network learns to solve 94.1 % of even the hardest 17 - givens Sudokus after 32 steps .,Experiments,For details see the supplementary material .,natural_language_inference,56,"['B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",73,0.4451219512195122,152,0.4523809523809524,8,0.24242424242424243,1,1,experiments
159,"See figure 4 . We can see that even simple Sudokus with 33 givens require upwards of 10 steps of relational reasoning , whereas the harder 17 givens continue to improve even after 32 steps .",Experiments,For an example of this see .,natural_language_inference,56,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",79,0.4817073170731707,158,0.47023809523809523,14,0.42424242424242425,1,1,experiments
162,At 64 steps the accuracy for the 17 givens puzzles increases to 96.6 % .,Experiments,For an example of this see .,natural_language_inference,56,"['B', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",82,0.5,161,0.4791666666666667,17,0.5151515151515151,1,1,experiments
172,"Our network outperforms loopy belief propagation , with parallel and random messages passing updates .",Experiments,For details see the supplementary material .,natural_language_inference,56,"['O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-b', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",92,0.5609756097560976,171,0.5089285714285714,27,0.8181818181818182,1,1,experiments
173,"It also outperforms a version of loopy belief propagation modified specifically for solving Sudokus that uses 250 steps , Sinkhorn balancing every two steps and iteratively picks the most probable digit .",Experiments,For details see the supplementary material .,natural_language_inference,56,"['O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",93,0.5670731707317073,172,0.5119047619047619,28,0.8484848484848485,1,1,experiments
176,"Finally we outperform Park which treats the Sudoku as a 9x9 image , uses 10 convolutional layers , iteratively picks the most probable digit , and evaluate on easier Sudokus with 24 - 36 givens .",Experiments,For details see the supplementary material .,natural_language_inference,56,"['O', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'B-p', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'B-p', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",96,0.5853658536585366,175,0.5208333333333334,31,0.9393939393939394,1,1,experiments
2,ORDER - EMBEDDINGS OF IMAGES AND LANGUAGE,,,natural_language_inference,57,"['B', 'I', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",2,0.2857142857142857,1,0.005813953488372093,1,0.0,1,1,research-problem
4,"Hypernymy , textual entailment , and image captioning can be seen as special cases of a single visual - semantic hierarchy over words , sentences , and images .",,ORDER - EMBEDDINGS OF IMAGES AND LANGUAGE,natural_language_inference,57,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.5714285714285714,3,0.01744186046511628,1,0.25,1,1,research-problem
15,"In fact , all three relations can be seen as special cases of a partial order over images and language , illustrated in , which we refer to as the visualsemantic hierarchy .",INTRODUCTION,INTRODUCTION,natural_language_inference,57,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",7,0.08139534883720931,14,0.08139534883720931,7,0.19444444444444445,1,1,research-problem
26,"In contrast , we propose to exploit the partial order structure of the visual - semantic hierarchy by learning a mapping which is not distance - preserving but order - preserving between the visualsemantic hierarchy and a partial order over the embedding space .",INTRODUCTION,INTRODUCTION,natural_language_inference,57,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,18,0.20930232558139536,25,0.14534883720930233,18,0.5,1,1,model
27,We call embeddings learned in this way order- embeddings .,INTRODUCTION,INTRODUCTION,natural_language_inference,57,"['O', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",19,0.22093023255813954,26,0.1511627906976744,19,0.5277777777777778,1,1,model
77,HYPERNYM PREDICTION,INTRODUCTION,,natural_language_inference,57,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",69,0.8023255813953488,76,0.4418604651162791,0,0.0,1,1,experiments
96,"To train the model , we use the standard pairwise ranking objective from Eq. ( 5 ) .",DETAILS OF TRAINING,DETAILS OF TRAINING,natural_language_inference,57,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,95,0.5523255813953488,1,0.14285714285714285,1,1,experiments
97,"We sample minibatches of 128 random image - caption pairs , and draw all contrastive terms from the minibatch , giving us 127 contrastive images for each caption and captions for each image .",DETAILS OF TRAINING,DETAILS OF TRAINING,natural_language_inference,57,"['O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']",,,2,0.2857142857142857,96,0.5581395348837209,2,0.2857142857142857,1,1,experiments
98,"We train for 15 - 30 epochs using the Adam optimizer with learning rate 0.001 , and early stopping on the validation set .",DETAILS OF TRAINING,DETAILS OF TRAINING,natural_language_inference,57,"['O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",3,0.42857142857142855,97,0.563953488372093,3,0.42857142857142855,1,1,experiments
99,"We set the dimension of the embedding space and the GRU hidden state N to 1024 , the dimension of the learned word embeddings to 300 , and the margin ? to 0.05 .",DETAILS OF TRAINING,DETAILS OF TRAINING,natural_language_inference,57,"['O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O']",,,4,0.5714285714285714,98,0.5697674418604651,4,0.5714285714285714,1,1,experiments
101,"For consistency with and to mitigate overfitting , we constrain the caption and image embeddings to have unit L2 norm .",DETAILS OF TRAINING,DETAILS OF TRAINING,natural_language_inference,57,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.8571428571428571,100,0.5813953488372093,6,0.8571428571428571,1,1,experiments
115,We see that order- embeddings outperform the skipthought baseline despite not using external text corpora .,RESULTS,RESULTS,natural_language_inference,57,"['O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-b', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.2727272727272727,114,0.6627906976744186,12,0.5454545454545454,1,1,experiments
144,TEXTUAL ENTAILMENT / NATURAL LANGUAGE INFERENCE,RESULTS,,natural_language_inference,57,"['B', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",41,0.9318181818181818,143,0.8313953488372093,0,0.0,1,1,experiments
149,"Just as for caption - image ranking , we set the dimensions of the embedding space and GRU hidden state to be 1024 , the dimension of the word embeddings to be 300 , and constrain the embeddings to have unit L2 norm .",IMPLEMENTATION DETAILS,IMPLEMENTATION DETAILS,natural_language_inference,57,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'O']",,,1,0.14285714285714285,148,0.8604651162790697,1,0.14285714285714285,1,1,experiments
150,We train for 10 epochs with batches of 128 sentence pairs .,IMPLEMENTATION DETAILS,IMPLEMENTATION DETAILS,natural_language_inference,57,"['O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.2857142857142857,149,0.8662790697674418,2,0.2857142857142857,1,1,experiments
151,We use the Adam optimizer with learning rate 0.001 and early stopping on the validation set .,IMPLEMENTATION DETAILS,IMPLEMENTATION DETAILS,natural_language_inference,57,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,3,0.42857142857142855,150,0.872093023255814,3,0.42857142857142855,1,1,experiments
2,ReasoNet : Learning to Stop Reading in Machine Comprehension,title,,natural_language_inference,58,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.0029850746268656717,1,0.0,1,1,research-problem
33,"With this motivation , we propose a novel neural network architecture called Reasoning Network ( ReasoNet ) .",INTRODUCTION,INTRODUCTION,natural_language_inference,58,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",23,0.19008264462809918,32,0.0955223880597015,23,0.6052631578947368,1,1,model
35,"With a question in mind , ReasoNets read a document repeatedly , each time focusing on di erent parts of the document until a satisfying answer is found or formed .",INTRODUCTION,INTRODUCTION,natural_language_inference,58,"['B', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']",,,25,0.2066115702479339,34,0.10149253731343283,25,0.6578947368421053,1,1,model
37,"Moreover , unlike previous approaches using xed number of hops or iterations , ReasoNets introduce a termination state in the inference .",INTRODUCTION,INTRODUCTION,natural_language_inference,58,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",27,0.2231404958677686,36,0.10746268656716418,27,0.7105263157894737,1,1,model
42,"Motivated by , we tackle this challenge by proposing a reinforcement learning approach , which utilizes an instance - dependent reward baseline , to successfully train ReasoNets .",INTRODUCTION,INTRODUCTION,natural_language_inference,58,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'O']",32,0.2644628099173554,41,0.12238805970149254,32,0.8421052631578947,1,1,model
146,CNN and Daily Mail Datasets,Training Details,,natural_language_inference,58,"['B', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b']",14,0.07,145,0.43283582089552236,0,0.0,1,1,experiments
149,"Vocab Size : For training our ReasoNet , we keep the most frequent | V | = 101 k words ( not including 584 entities and 1 placeholder marker ) in the CNN dataset , and | V | = 151 k words ( not including 530 entities and 1 placeholder marker ) in the Daily Mail dataset .",Training Details,CNN and Daily Mail Datasets,natural_language_inference,58,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O']",,,17,0.085,148,0.4417910447761194,3,0.047619047619047616,1,1,experiments
150,Embedding Layer :,Training Details,CNN and Daily Mail Datasets,natural_language_inference,58,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-b', 'I-b', 'O']",18,0.09,149,0.44477611940298506,4,0.06349206349206349,1,1,experiments
151,"We choose 300 - dimensional word embeddings , and use the 300 - dimensional pretrained Glove word embeddings for initialization .",Training Details,CNN and Daily Mail Datasets,natural_language_inference,58,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",19,0.095,150,0.44776119402985076,5,0.07936507936507936,1,1,experiments
152,We also apply dropout with probability 0.2 to the embedding layer .,Training Details,CNN and Daily Mail Datasets,natural_language_inference,58,"['O', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",20,0.1,151,0.4507462686567164,6,0.09523809523809523,1,1,experiments
173,"We use ADAM optimizer for parameter optimization with an initial learning rate of 0.0005 , ? 1 = 0.9 and ? 2 = 0.999 ;",Training Details,Bi-GRU,natural_language_inference,58,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",41,0.205,172,0.5134328358208955,27,0.42857142857142855,1,1,experiments
174,The absolute value of gradient on each parameter is clipped within 0.001 .,Training Details,Bi-GRU,natural_language_inference,58,"['O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-b', 'B-p', 'B-ob', 'O']",42,0.21,173,0.5164179104477612,28,0.4444444444444444,1,1,experiments
175,The batch size is 64 for both CNN and Daily Mail datasets .,Training Details,Bi-GRU,natural_language_inference,58,"['O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",43,0.215,174,0.5194029850746269,29,0.4603174603174603,1,1,experiments
179,Models are trained on GTX TitanX 12 GB .,Training Details,Bi-GRU,natural_language_inference,58,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",47,0.235,178,0.5313432835820896,33,0.5238095238095238,1,1,experiments
197,"Comparing with the AS Reader , ReasoNet shows the signi cant improvement by capturing multi-turn reasoning in the paragraph .",Training Details,Bi-GRU,natural_language_inference,58,"['B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O']",65,0.325,196,0.5850746268656717,51,0.8095238095238095,1,1,experiments
198,"Iterative Attention Reader , EpiReader and GA Reader are the three multi-turn reasoning models with xed reasoning steps .",Training Details,Bi-GRU,natural_language_inference,58,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",66,0.33,197,0.5880597014925373,52,0.8253968253968254,1,1,experiments
199,ReasoNet also outperforms all of them by integrating termination gate in the model which allows di erent reasoning steps for di erent test cases .,Training Details,Bi-GRU,natural_language_inference,58,"['B', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'O', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",67,0.335,198,0.591044776119403,53,0.8412698412698413,1,1,experiments
201,ReasoNet obtains comparable results with AoA Reader on CNN test set .,Training Details,Bi-GRU,natural_language_inference,58,"['B', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",69,0.345,200,0.5970149253731343,55,0.873015873015873,1,1,experiments
210,SQuAD Dataset,Training Details,,natural_language_inference,58,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",78,0.39,209,0.6238805970149254,0,0.0,1,1,experiments
217,Vocab Size :,Training Details,SQuAD Dataset,natural_language_inference,58,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-s', 'I-s', 'O']",85,0.425,216,0.6447761194029851,7,0.30434782608695654,1,1,experiments
218,"We use the python NLTK tokenizer 6 to preprocess passages and questions , and obtain about 100K words in the vocabulary .",Training Details,SQuAD Dataset,natural_language_inference,58,"['O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",86,0.43,217,0.6477611940298508,8,0.34782608695652173,1,1,experiments
219,Embedding Layer : We use the 100 - dimensional pretrained Glove vectors as word embeddings .,Training Details,SQuAD Dataset,natural_language_inference,58,"['B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-s', 'I-s', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",87,0.435,218,0.6507462686567164,9,0.391304347826087,1,1,experiments
247,The maximum reasoning step T max is set to 10 in SQuAD experiments .,Training Details,Small Graph Large Graph,natural_language_inference,58,"['O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O']",115,0.575,246,0.7343283582089553,13,0.1326530612244898,1,1,experiments
248,We use AdaDelta optimizer for parameter optimization with an initial learning rate of 0.5 and a batch size Results :,Training Details,Small Graph Large Graph,natural_language_inference,58,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O']",116,0.58,247,0.7373134328358208,14,0.14285714285714285,1,1,experiments
254,"In , we demonstrate that ReasoNet outperforms all existing published approaches .",Training Details,Small Graph Large Graph,natural_language_inference,58,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-ob', 'B-s', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",122,0.61,253,0.755223880597015,20,0.20408163265306123,1,1,experiments
255,"While we compare ReasoNet with BiDAF , ReasoNet exceeds BiDAF both in single model and ensemble model cases .",Training Details,Small Graph Large Graph,natural_language_inference,58,"['O', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'O', 'B-ob', 'O', 'O', 'B-p', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",123,0.615,254,0.7582089552238805,21,0.21428571428571427,1,1,experiments
257,"In the bottom part of , we compare ReasoNet with all unpublished methods at the time of this submission , ReasoNet holds the second position in all the competing approaches in the SQuAD leaderboard .",Training Details,Small Graph Large Graph,natural_language_inference,58,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,125,0.625,256,0.764179104477612,23,0.23469387755102042,1,1,experiments
258,Graph Reachability,Training Details,,natural_language_inference,58,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",126,0.63,257,0.7671641791044777,24,0.24489795918367346,1,1,experiments
283,Embedding Layer,Training Details,,natural_language_inference,58,"['B', 'I']","['B-n', 'I-n']","['B-s', 'I-s']",151,0.755,282,0.8417910447761194,49,0.5,1,1,experiments
284,We use a 100 - dimensional embedding vector for each symbol in the query and graph description .,Training Details,Embedding Layer,natural_language_inference,58,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",152,0.76,283,0.844776119402985,50,0.5102040816326531,1,1,experiments
300,"The maximum reasoning step T max is set to 15 and 25 for the small graph and large graph dataset , respectively .",Training Details,Bi-LSTM,natural_language_inference,58,"['O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'B-s', 'I-s', 'I-s', 'I-s', 'I-s', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",168,0.84,299,0.8925373134328358,66,0.673469387755102,1,1,experiments
301,We use AdaDelta optimizer for parameter optimization with an initial learning rate of 0.5 and a batch size of 32 .,Training Details,Bi-LSTM,natural_language_inference,58,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O']",,,169,0.845,300,0.8955223880597015,67,0.6836734693877551,1,1,experiments
307,"Deep LSTM Reader achieves 90.92 % and 71.55 % accuracy in the small and large graph dataset , respectively , which indicates the graph reachibility task is not trivial .",Training Details,Bi-LSTM,natural_language_inference,58,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",175,0.875,306,0.9134328358208955,73,0.7448979591836735,1,1,experiments
2,Neural Paraphrase Identification of Questions with Noisy Pretraining,title,,natural_language_inference,59,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",1,0.0,1,0.007407407407407408,1,0.0,1,1,research-problem
4,We present a solution to the problem of paraphrase identification of questions .,abstract,abstract,natural_language_inference,59,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.3333333333333333,3,0.022222222222222223,1,0.3333333333333333,1,1,research-problem
8,Question paraphrase identification is a widely useful NLP application .,Introduction,Introduction,natural_language_inference,59,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.08333333333333333,7,0.05185185185185185,1,0.08333333333333333,1,1,research-problem
14,"We examine a simple model family , the decomposable attention model of , that has shown promise in modeling natural language inference and has inspired recent work on similar tasks .",Introduction,Introduction,natural_language_inference,59,"['O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.5833333333333334,13,0.0962962962962963,7,0.5833333333333334,1,1,approach
16,"First , to mitigate data sparsity , we modify the input representation of the decomposable attention model to use sums of character n-gram embeddings instead of word embeddings .",Introduction,Introduction,natural_language_inference,59,"['O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O']",,,9,0.75,15,0.1111111111111111,9,0.75,1,1,approach
18,"Second , to significantly improve our model performance , we pretrain all our model parameters on the noisy , automatically collected question - paraphrase corpus Paralex , followed by fine - tuning the parameters on the Quora dataset .",Introduction,Introduction,natural_language_inference,59,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O']",,,11,0.9166666666666666,17,0.1259259259259259,11,0.9166666666666666,1,1,approach
99,"We tuned the following hyperparameters by grid search on the development set ( settings for our best model are in parenthesis ) : embedding dimension ( 300 ) , shape of all feedforward networks ( two layers with 400 and 200 width ) , character n -gram sizes ( 5 ) , context size ( 1 ) , learning rate ( 0.1 for both pretraining and tuning ) , batch size ( 256 for pretraining and 64 for tuning ) , dropout ratio ( 0.1 for tuning ) and prediction threshold ( positive paraphrase for a score ? 0.3 ) .",Implementation Details,Datasets,natural_language_inference,59,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O']",,,8,0.7272727272727273,98,0.725925925925926,8,0.38095238095238093,1,1,hyperparameters
115,"We observe that the simple FFNN baselines work better than more complex Siamese and Multi - Perspective CNN or LSTM models , more so if character n-gram based embeddings are used .",Results,Results,natural_language_inference,59,"['O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.13333333333333333,114,0.8444444444444444,2,0.13333333333333333,1,1,results
116,"Our basic decomposable attention model DECATT word without pre-trained embeddings is better than most of the models , all of which used GloVe embeddings .",Results,Results,natural_language_inference,59,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",3,0.2,115,0.8518518518518519,3,0.2,1,1,results
117,An interesting observation is that DECATT char model without any pretrained embeddings outperforms DE - CATT glove that uses task - agnostic GloVe embeddings .,Results,Results,natural_language_inference,59,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.26666666666666666,116,0.8592592592592593,4,0.26666666666666666,1,1,results
118,"Furthermore , when character n-gram embeddings are pre-trained in a task - specific manner in DECATT paralex ? char model , we observe a significant boost in performance .",Results,Results,natural_language_inference,59,"['O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,5,0.3333333333333333,117,0.8666666666666667,5,0.3333333333333333,1,1,results
122,"Finally , we note that our best performing model is pt - DECATT char , which leverages the full power of character embeddings and pretraining the model on Paralex .",Results,Results,natural_language_inference,59,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.6,121,0.8962962962962963,9,0.6,1,1,results
2,Massively Multilingual Sentence Embeddings for Zero - Shot Cross - Lingual Transfer and Beyond,title,title,natural_language_inference,6,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.004032258064516129,1,0.0,1,1,research-problem
4,"We introduce an architecture to learn joint multilingual sentence representations for 93 languages , belonging to more than 30 different families and written in 28 different scripts .",abstract,abstract,natural_language_inference,6,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.09090909090909091,3,0.012096774193548387,1,0.09090909090909091,1,1,research-problem
9,"Our implementation , the pretrained encoder and the multilingual test set are available at https://github.com / facebookresearch/LASER . . 2018 .",abstract,abstract,natural_language_inference,6,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",6,0.5454545454545454,8,0.03225806451612903,6,0.5454545454545454,1,1,code
21,"In this work , we are interested in universal language agnostic sentence embeddings , that is , vector representations of sentences that are general with respect to two dimensions : the input language and the NLP task .",Introduction,This approach was first popularized byword embeddings,natural_language_inference,6,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O']",6,0.15789473684210525,20,0.08064516129032258,6,0.15789473684210525,1,1,model
23,"To that end , we train a single encoder to handle multiple languages , so that semantically similar sentences in different languages are close in the embedding space .",Introduction,This approach was first popularized byword embeddings,natural_language_inference,6,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.21052631578947367,22,0.08870967741935484,8,0.21052631578947367,1,1,model
95,XNLI : cross - lingual NLI,Training data and pre-processing,,natural_language_inference,6,"['B', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",10,0.13157894736842105,94,0.3790322580645161,10,0.13157894736842105,1,1,experiments
106,9 Our proposed method obtains the best results in zero - shot cross - lingual transfer for all languages but Spanish .,Training data and pre-processing,XNLI : cross - lingual NLI,natural_language_inference,6,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",21,0.27631578947368424,105,0.42338709677419356,21,0.27631578947368424,1,1,experiments
107,"Moreover , our transfer results are strong and homogeneous across all languages :",Training data and pre-processing,XNLI : cross - lingual NLI,natural_language_inference,6,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",22,0.2894736842105263,106,0.4274193548387097,22,0.2894736842105263,1,1,experiments
110,"for 11 of them , the zero - short performance is ( at most ) 5 % lower than the one on English , including distant languages like Arabic , Chinese and Vietnamese , and we also achieve remarkable good results on low - resource languages like Swahili .",Training data and pre-processing,XNLI : cross - lingual NLI,natural_language_inference,6,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O']",,,25,0.32894736842105265,109,0.43951612903225806,25,0.32894736842105265,1,1,experiments
113,"10 Finally , we also outperform all baselines of Conneau et al. by a substantial margin , with the additional advantage that we use a single pre-trained encoder , whereas X - BiLSTM learns a separate encoder for each language .",Training data and pre-processing,XNLI : cross - lingual NLI,natural_language_inference,6,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",28,0.3684210526315789,112,0.45161290322580644,28,0.3684210526315789,1,1,experiments
125,MLDoc : cross - lingual classification,Training data and pre-processing,,natural_language_inference,6,"['B', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",40,0.5263157894736842,124,0.5,40,0.5263157894736842,1,1,experiments
131,"As shown in , our system obtains the best published results for 5 of the 7 transfer languages .",Training data and pre-processing,MLDoc : cross - lingual classification,natural_language_inference,6,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",46,0.6052631578947368,130,0.5241935483870968,46,0.6052631578947368,1,1,experiments
133,BUCC : bitext mining,Training data and pre-processing,,natural_language_inference,6,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",48,0.631578947368421,132,0.532258064516129,48,0.631578947368421,1,1,experiments
145,"As shown in , our system establishes a new state - of - the - art for all language pairs with the exception of English - Chinese test .",Training data and pre-processing,This notion of margin is related to .,natural_language_inference,6,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",60,0.7894736842105263,144,0.5806451612903226,60,0.7894736842105263,1,1,experiments
146,"We also outperform Artetxe and Schwenk ( 2018 ) themselves , who use two separate models covering 4 languages each .",Training data and pre-processing,This notion of margin is related to .,natural_language_inference,6,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",61,0.8026315789473685,145,0.5846774193548387,61,0.8026315789473685,1,1,experiments
148,Tatoeba : similarity search,Training data and pre-processing,,natural_language_inference,6,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",63,0.8289473684210527,147,0.592741935483871,63,0.8289473684210527,1,1,experiments
156,"Contrasting these results with those of XNLI , one would assume that similarity error rates below 5 % are indicative of strong downstream performance .",Training data and pre-processing,We report our results in .,natural_language_inference,6,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O']",,,71,0.9342105263157895,155,0.625,71,0.9342105263157895,1,1,experiments
157,"11 This is the case for 37 languages , while there are 48 languages with an error rate below 10 % and 55 with less than 20 % .",Training data and pre-processing,We report our results in .,natural_language_inference,6,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",72,0.9473684210526315,156,0.6290322580645161,72,0.9473684210526315,1,1,experiments
158,There are only 15 languages with error rates above 50 % .,Training data and pre-processing,We report our results in .,natural_language_inference,6,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",73,0.9605263157894737,157,0.6330645161290323,73,0.9605263157894737,1,1,experiments
167,We were notable to achieve good convergence with deeper models .,Ablation experiments,We report average results across all languages .,natural_language_inference,6,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",5,0.3333333333333333,166,0.6693548387096774,5,0.8333333333333334,1,1,ablation-analysis
168,"It can be seen that all tasks benefit from deeper models , in particular XNLI and Tatoeba , suggesting that a single layer BiLSTM has not enough capacity to encode so many languages .",Ablation experiments,We report average results across all languages .,natural_language_inference,6,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.4,167,0.6733870967741935,6,1.0,1,1,ablation-analysis
171,Multitask learning has been shown to be helpful to learn English sentence embeddings .,Ablation experiments,Multitask learning,natural_language_inference,6,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.6,170,0.6854838709677419,1,0.14285714285714285,1,1,ablation-analysis
173,"As shown in , the NLI objective leads to a better performance on the English NLI test set , but this comes at the cost of a worse cross - lingual transfer performance in XNLI and Tatoeba .",Ablation experiments,Multitask learning,natural_language_inference,6,"['O', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",11,0.7333333333333333,172,0.6935483870967742,3,0.42857142857142855,1,1,ablation-analysis
2,Dynamic Meta - Embeddings for Improved Sentence Representations,title,,natural_language_inference,60,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0051813471502590676,1,0.0,1,1,research-problem
18,"In this work , we explore the supervised learning of task - specific , dynamic meta-embeddings , and apply the technique to sentence representations .",Introduction,Introduction,natural_language_inference,60,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",10,0.45454545454545453,17,0.08808290155440414,10,0.3125,1,1,research-problem
22,"First , it is embedding - agnostic , meaning that one of the main ( and perhaps most important ) hyperparameters in NLP pipelines is made obsolete .",Introduction,Introduction,natural_language_inference,60,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.6363636363636364,21,0.10880829015544041,14,0.4375,1,1,approach
5,"is paper proposes an a ention boosted natural language inference model named a ESIM by adding word a ention and adaptive direction - oriented a ention mechanisms to the traditional Bi - LSTM layer of natural language inference models , e.g. ESIM . is makes the inference model a ESIM has the ability toe ectively learn the representation of words and model the local subsentential inference between pairs of premise and hypothesis .",abstract,abstract,natural_language_inference,61,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.5,4,0.02564102564102564,2,0.5,1,1,research-problem
9,Natural language inference ( NLI ) is an important and signicant task in natural language processing ( NLP ) .,INTRODUCTION,INTRODUCTION,natural_language_inference,61,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.018867924528301886,8,0.05128205128205128,1,0.02,1,1,research-problem
12,"In the literature , the task of NLI is usually viewed as a relation classi cation .",INTRODUCTION,INTRODUCTION,natural_language_inference,61,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.07547169811320754,11,0.07051282051282051,4,0.08,1,1,research-problem
51,"erefore , in this study , using ESIM model as the baseline , we add an a ention layer behind each Bi - LSTM layer , then use an adaptive orientation embedding layer to jointly represent the forward and backward vectors .",INTRODUCTION,Talman et al .,natural_language_inference,61,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",43,0.8113207547169812,50,0.32051282051282054,43,0.86,1,1,model
52,"We name this a ention boosted Bi - LSTM as Bi - a LSTM , and denote the modi ed ESIM as aESIM .",INTRODUCTION,Talman et al .,natural_language_inference,61,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']",,,44,0.8301886792452831,51,0.3269230769230769,44,0.88,1,1,model
121,We use the Adam method for optimization .,ESIM model,,natural_language_inference,61,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",59,0.8805970149253731,120,0.7692307692307693,3,0.2727272727272727,1,1,hyperparameters
123,"e initial learning rate is set to 0.0005 , and the batch size is 128 .",ESIM model,We use the Adam method for optimization .,natural_language_inference,61,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'O']",61,0.9104477611940298,122,0.782051282051282,5,0.45454545454545453,1,1,hyperparameters
124,e dimensions of all hidden states of Bi - aLSTM and word embedding are 300 .,ESIM model,We use the Adam method for optimization .,natural_language_inference,61,"['O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O']",,,62,0.9253731343283582,123,0.7884615384615384,6,0.5454545454545454,1,1,hyperparameters
125,We employ non-linearity function f = selu replacing recti ed linear unit ReLU on account of its faster convergence rate .,ESIM model,We use the Adam method for optimization .,natural_language_inference,61,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",63,0.9402985074626866,124,0.7948717948717948,7,0.6363636363636364,1,1,hyperparameters
126,Dropout rate is set to 0.2 during training .,ESIM model,,natural_language_inference,61,"['B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O']",64,0.9552238805970149,125,0.8012820512820513,8,0.7272727272727273,1,1,hyperparameters
127,We use pre-trained 300 - D Glove 840B vectors to initialize word embeddings .,ESIM model,Dropout rate is set to 0.2 during training .,natural_language_inference,61,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",65,0.9701492537313433,126,0.8076923076923077,9,0.8181818181818182,1,1,hyperparameters
128,Out - of - vocabulary ( OOV ) words are initialized randomly with Gaussian samples .,ESIM model,Dropout rate is set to 0.2 during training .,natural_language_inference,61,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",66,0.9850746268656716,127,0.8141025641025641,10,0.9090909090909091,1,1,hyperparameters
138,"According to the results in , a ESIM model achieved 88.1 % on SNLI corpus , elevating 0.8 percent higher than ESIM model .",Experiment results,Experiment results,natural_language_inference,61,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O']",,,8,0.6666666666666666,137,0.8782051282051282,8,0.8,1,1,results
139,It promoted almost 0.5 percent accuracy and outperformed the baselines on MultiNLI .,Experiment results,Experiment results,natural_language_inference,61,"['O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'O', 'B-b', 'B-p', 'B-ob', 'O']",9,0.75,138,0.8846153846153846,9,0.9,1,1,results
2,Explicit Utilization of General Knowledge in Machine Reading Comprehension,title,,natural_language_inference,62,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004464285714285714,1,0.0,1,1,research-problem
4,"To bridge the gap between Machine Reading Comprehension ( MRC ) models and human beings , which is mainly reflected in the hunger for data and the robustness to noise , in this paper , we explore how to integrate the neural networks of MRC models with the general knowledge of human beings .",abstract,abstract,natural_language_inference,62,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.013392857142857142,1,0.2,1,1,research-problem
41,"On the one hand , we propose a data enrichment method , which uses WordNet to extract inter-word semantic connections as general knowledge from each given passage - question pair .",Introduction,Passage Question,natural_language_inference,62,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",32,0.8888888888888888,40,0.17857142857142858,14,0.6666666666666666,1,1,approach
42,"On the other hand , we propose an end - to - end MRC model named as Knowledge Aided Reader ( KAR ) , which explicitly uses the above extracted general knowledge to assist its attention mechanisms .",Introduction,Passage Question,natural_language_inference,62,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",33,0.9166666666666666,41,0.18303571428571427,15,0.7142857142857143,1,1,approach
181,"We tokenize the MRC dataset with spa Cy 2.0.13 , manipulate WordNet 3.0 with NLTK 3.3 , and implement KAR with TensorFlow 1.11.0 .",Implementation Details .,Implementation Details .,natural_language_inference,62,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'O']",,,1,0.022727272727272728,180,0.8035714285714286,7,0.5384615384615384,1,1,experimental-setup
183,"For the dense layers and the BiLSTMs , we set the dimensionality unit d to 600 .",Implementation Details .,Implementation Details .,natural_language_inference,62,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",3,0.06818181818181818,182,0.8125,9,0.6923076923076923,1,1,experimental-setup
184,"For model optimization , we apply the Adam ( Kingma and Ba , 2014 ) optimizer with a learning rate of 0.0005 and a minibatch size of 32 .",Implementation Details .,Implementation Details .,natural_language_inference,62,"['O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O']",,,4,0.09090909090909091,183,0.8169642857142857,10,0.7692307692307693,1,1,experimental-setup
186,"To avoid overfitting , we apply dropout to the dense layers and the BiLSTMs with a dropout rate of 0.3 .",Implementation Details .,Implementation Details .,natural_language_inference,62,"['B', 'I', 'B', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['B-p', 'I-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'I-p', 'B-b', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",6,0.13636363636363635,185,0.8258928571428571,12,0.9230769230769231,1,1,experimental-setup
187,"To boost the performance , we apply exponential moving average with a decay rate of 0.999 .",Implementation Details .,Implementation Details .,natural_language_inference,62,"['B', 'I', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",7,0.1590909090909091,186,0.8303571428571429,13,1.0,1,1,experimental-setup
198,"Then we conduct an ablation study by replacing the knowledge aided attention mechanisms with the mutual attention proposed by and the self attention proposed by separately , and find that the F 1 score of KAR drops by 4.2 on the development set , 7.8 on AddSent , and 9.1 on AddOneSent .",Implementation Details .,Implementation Details .,natural_language_inference,62,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'O', 'O', 'B', 'B', 'B', 'O']",,,18,0.4090909090909091,197,0.8794642857142857,10,0.7142857142857143,1,1,ablation-analysis
199,"Finally we find that after only one epoch of training , KAR already achieves an EM of 71.9 and an F 1 score of 80.8 on the development set , which is even better than the final performance of several strong baselines , such as DCN ( EM / F1 : 65.4 / 75.6 ) and BiDAF ( EM / F1 : 67.7 / 77.3 ) .",Implementation Details .,Implementation Details .,natural_language_inference,62,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,19,0.4318181818181818,198,0.8839285714285714,11,0.7857142857142857,1,1,results
2,A Multi - Stage Memory Augmented Neural Network for Machine Reading Comprehension,title,title,natural_language_inference,63,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.005555555555555556,1,0.0,1,1,research-problem
4,Reading Comprehension ( RC ) of text is one of the fundamental tasks in natural language processing .,abstract,abstract,natural_language_inference,63,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.16666666666666666,3,0.016666666666666666,1,0.16666666666666666,1,1,research-problem
5,"In recent years , several end - to - end neural network models have been proposed to solve RC tasks .",abstract,abstract,natural_language_inference,63,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O']",2,0.3333333333333333,4,0.022222222222222223,2,0.3333333333333333,1,1,research-problem
12,"One possible way of measuring RC is by formulating it as answer span prediction style Question Answering ( QA ) task , which is finding an answer to the question based on the given document ( s ) .",Introduction,Introduction,natural_language_inference,63,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.1,11,0.06111111111111111,2,0.1,1,1,research-problem
13,"Recently , influential deep learning approaches have been proposed to solve this QA task . ; propose the attention mechanism between question and context for question - aware contextual representation .",Introduction,Introduction,natural_language_inference,63,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.15,12,0.06666666666666667,3,0.15,1,1,research-problem
24,"In this work , we build a QA model that can understand long documents by utilizing Memory Augmented Neural Networks ( MANNs ) .",Introduction,Introduction,natural_language_inference,63,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.7,23,0.12777777777777777,14,0.7,1,1,model
25,This type of neural networks decouples the memory capacity from the number of model parameters .,Introduction,Introduction,natural_language_inference,63,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.75,24,0.13333333333333333,15,0.75,1,1,model
137,We develop MAMCN using Tensorflow 1 deep learning framework and Sonnet 2 library .,Implementation Details,Implementation Details,natural_language_inference,63,"['O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.16666666666666666,136,0.7555555555555555,1,0.16666666666666666,1,1,experimental-setup
138,"For the word - level embedding , we tokenize the documents using NLTK toolkit and substitute words with GloVe 6B 43.16 46.90 49.28 55.83 BiDAF 40.32 45.91 44.86 50.71 hidden size is set to 200 for QUASAR - T and Triv - iaQA , and 100 for SQuAD .",Implementation Details,Implementation Details,natural_language_inference,63,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.3333333333333333,137,0.7611111111111111,2,0.3333333333333333,1,1,experimental-setup
139,"In the memory controller , we use 100 x 36 size memory initialized with zeros , 4 read heads and 1 write head .",Implementation Details,Implementation Details,natural_language_inference,63,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'B-n', 'I-n', 'O', 'B-n', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'B-b', 'B-ob', 'I-ob', 'O', 'B-b', 'B-ob', 'I-ob', 'O']",3,0.5,138,0.7666666666666667,3,0.5,1,1,experimental-setup
140,"The optimizer is AdaDelta ( Zeiler , 2012 ) with an initial learning rate of 0.5 .",Implementation Details,Implementation Details,natural_language_inference,63,"['O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",4,0.6666666666666666,139,0.7722222222222223,4,0.6666666666666666,1,1,experimental-setup
141,"We train our model for 12 epochs , and batch size is set to 30 .",Implementation Details,Implementation Details,natural_language_inference,63,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",5,0.8333333333333334,140,0.7777777777777778,5,0.8333333333333334,1,1,experimental-setup
142,"During the training , we keep the exponential moving average of weights with 0.001 decay and use these averages at test time .",Implementation Details,Implementation Details,natural_language_inference,63,"['B', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",6,1.0,141,0.7833333333333333,6,1.0,1,1,experimental-setup
147,QUASAR - T:,Results,Results,natural_language_inference,63,"['O', 'O', 'O']","['O', 'O', 'O']","['O', 'O', 'O']",4,0.125,146,0.8111111111111111,4,0.125,1,1,results
150,"As described in , the baseline ( BiDAF + DNC ) results in a reasonable gain , however , our proposed memory controller gives more performance improvement .",Results,Results,natural_language_inference,63,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O']",7,0.21875,149,0.8277777777777777,7,0.21875,1,1,results
151,We achieve 68.13 EM and 70.32 F1 for short documents and 63.44 and 65.19 for long documents which are the current best results .,Results,Results,natural_language_inference,63,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,8,0.25,150,0.8333333333333334,8,0.25,1,1,results
152,TriviaQA : We compare proposed model with all the previously suggested approaches as shown in .,Results,Results,natural_language_inference,63,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.28125,151,0.8388888888888889,9,0.28125,1,1,results
156,Our model achieves the state of the art performance over the existing approaches as shown in 77.58 84.16 O - QANet 76.24 84.60 O O SAN 76.83 84.40 O O Fusion Net 75.97 83.90 O O RaSoR + TR 75.79 83.26 O - Conducter- net 74.41 82.74 O O Reinforced Mnemonic Reader 73.20 81.80 O O BiDAF + Self-attention 72.14 81.05 - O MEMEN 70.98 80.36 O - MAMCN 70.99 79.94 -r- net 71.30 79.70 - O Document Reader 70.73 79.35 O - FastQAExt 70 .,Results,Results,natural_language_inference,63,"['B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.40625,155,0.8611111111111112,13,0.40625,1,1,results
161,"First , we add ELMo which is the weighted sum of hidden layers of language model with regularization as an additional feature to our word embeddings .",Results,Results,natural_language_inference,63,"['O', 'O', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O']",,,18,0.5625,160,0.8888888888888888,18,0.5625,1,1,ablation-analysis
162,This helped our model ( MAMCN + ELMo ) to improve F1 to 85.13 and EM to 77.44 and is the best among the models only with the additional feature augmentation .,Results,Results,natural_language_inference,63,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O', 'B-b', 'O', 'B-ob', 'O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",19,0.59375,161,0.8944444444444445,19,0.59375,1,1,ablation-analysis
168,We replace all the BiGRU units with this embedding block except the controller layer in our model ( MAMCN + ELMo + DC ) .,Results,Results,natural_language_inference,63,"['O', 'B', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",25,0.78125,167,0.9277777777777778,25,0.78125,1,1,ablation-analysis
169,"We achieve the state of the art performance , 86.73 F1 and 79.69 EM , with the help of this em-bedding block .",Results,Results,natural_language_inference,63,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",26,0.8125,168,0.9333333333333333,26,0.8125,1,1,ablation-analysis
2,TANDA : Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection,title,title,natural_language_inference,64,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.00398406374501992,1,0.0,1,1,research-problem
7,"We demonstrate the benefits of our approach for answer sentence selection , which is a well - known inference task in Question Answering .",abstract,abstract,natural_language_inference,64,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",4,0.4,6,0.02390438247011952,4,0.4,1,1,research-problem
17,"This has renewed the research interest in Question Answering ( QA ) and , in particular , in two main tasks :",Introduction,Introduction,natural_language_inference,64,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.07894736842105263,16,0.06374501992031872,3,0.07894736842105263,1,1,research-problem
18,"( i ) answer sentence selection ( AS2 ) , which , given a question and a set of answer sentence candidates , consists in selecting sentences ( e.g. , retrieved by a search engine ) correctly answering the question ; and ( ii ) machine reading ( MR ) or reading comprehension , which , given a question and a reference text , consists in finding a text span answering it .",Introduction,Introduction,natural_language_inference,64,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.10526315789473684,17,0.06772908366533864,4,0.10526315789473684,1,1,research-problem
19,"Even though the latter is gaining more and more popularity , AS2 is more relevant to a production scenario since , a combination of a search engine and an AS2 model already implements an initial QA system .",Introduction,Introduction,natural_language_inference,64,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O']",5,0.13157894736842105,18,0.07171314741035857,5,0.13157894736842105,1,1,research-problem
31,"In this paper , we study the use of Transformer - based models for AS2 and provide effective solutions to tackle the data scarceness problem for AS2 and the instability of the finetuning step .",Introduction,Introduction,natural_language_inference,64,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'O']",,,17,0.4473684210526316,30,0.11952191235059761,17,0.4473684210526316,1,1,model
33,"We improve stability of Transformer models by adding an intermediate fine - tuning step , which aims at specializing them to the target task ( AS2 ) , i.e. , this step transfers a pretrained language model to a model for the target task .",Introduction,Introduction,natural_language_inference,64,"['O', 'B', 'B', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.5,32,0.12749003984063745,19,0.5,1,1,model
34,"We show that the transferred model can be effectively adapted to the target domain with a subsequent finetuning step , even when using target data of small size .",Introduction,Introduction,natural_language_inference,64,"['O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",20,0.5263157894736842,33,0.13147410358565736,20,0.5263157894736842,1,1,model
36,"We built ASNQ , a dataset for AS2 , by transforming the recently released Natural Questions ( NQ ) corpus ) from MR to AS2 task .",Introduction,Introduction,natural_language_inference,64,"['O', 'B', 'B', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'O', 'O', 'O', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",22,0.5789473684210527,35,0.1394422310756972,22,0.5789473684210527,1,1,dataset
151,We adopt Adam optimizer ( Kingma and Ba 2014 ) with a learning rate of 2e - 5 for the transfer step on the ASNQ dataset and a learning rate of 1e - 6 for the adapt step on the target dataset .,Training,Training,natural_language_inference,64,"['O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,1,0.08333333333333333,150,0.5976095617529881,3,0.21428571428571427,1,1,hyperparameters
152,We apply early stopping on the dev. set of the target corpus for both steps based on the highest MAP score .,Training,Training,natural_language_inference,64,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.16666666666666666,151,0.601593625498008,4,0.2857142857142857,1,1,hyperparameters
153,"We set the max number of epochs equal to 3 and 9 for adapt and transfer steps , respectively .",Training,Training,natural_language_inference,64,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",3,0.25,152,0.6055776892430279,5,0.35714285714285715,1,1,hyperparameters
154,We set the maximum sequence length for BERT / RoBERTa to 128 tokens .,Training,Training,natural_language_inference,64,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",4,0.3333333333333333,153,0.6095617529880478,6,0.42857142857142855,1,1,hyperparameters
166,"TANDA provides a large improvement over the state of the art , which has been regularly contributed to by hundreds of researchers .",Main Results,Main Results,natural_language_inference,64,"['B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.04477611940298507,165,0.6573705179282868,3,0.15,1,1,results
167,RoBERTa- Large TANDA using ASNQ ?,Main Results,Main Results,natural_language_inference,64,"['B', 'I', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",4,0.05970149253731343,166,0.6613545816733067,4,0.2,1,1,results
168,"Wiki QA establish an impressive new state of the art for AS2 on WikiQA of 0.920 and 0.933 in MAP and MRR , respectively .",Main Results,Main Results,natural_language_inference,64,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",5,0.07462686567164178,167,0.6653386454183267,5,0.25,1,1,results
174,RoBERTa - Large TANDA with ASNQ ?,Main Results,Main Results,natural_language_inference,64,"['B', 'I', 'I', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",11,0.16417910447761194,173,0.6892430278884463,11,0.55,1,1,results
175,"TREC - QA again establishes an impressive performance of 0.943 in MAP and 0.974 in MRR , outperforming the previous state of the art by .",Main Results,Main Results,natural_language_inference,64,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O']",,,12,0.1791044776119403,174,0.6932270916334662,12,0.6,1,1,results
177,"TANDA improves all the models : BERT - Base , RoBERTa- Base , BERT - Large and RoBERTa - Large , outperforming the previous state of the art with all of them .",Main Results,Main Results,natural_language_inference,64,"['O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",14,0.208955223880597,176,0.701195219123506,14,0.7,1,1,results
10,"Neural networks ( NN ) with attention mechanisms have recently proven to be successful at different computer vision ( CV ) and natural language processing ( NLP ) tasks such as image captioning , machine translation and factoid question answering .",Introduction,Introduction,natural_language_inference,65,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.013888888888888888,9,0.0391304347826087,1,0.03125,1,1,research-problem
11,"However , most recent work on neural attention models have focused on one - way attention mechanisms based on recurrent neural networks designed . for generation tasks .",Introduction,Introduction,natural_language_inference,65,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.027777777777777776,10,0.043478260869565216,2,0.0625,1,1,research-problem
15,"The key contribution of this work is that we propose Attentive Pooling ( AP ) , a two - way attention mechanism , that significantly improves such discriminative models ' performance on pair - wise ranking or classification , by enabling a joint learning of the representations of both inputs as well as their similarity measurement .",Introduction,Introduction,natural_language_inference,65,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'O']",,,6,0.08333333333333333,14,0.06086956521739131,6,0.1875,1,1,model
16,"Specifically , AP enables the pooling layer to be aware of the current input pair , in a way that information from the two input items can directly influence the computation of each other 's representations .",Introduction,Introduction,natural_language_inference,65,"['O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.09722222222222222,15,0.06521739130434782,7,0.21875,1,1,model
17,"The main idea in AP consists of learning a similarity measure over projected segments ( e.g. trigrams ) of the two items in the input pair , and using the similarity scores between the segments to compute attention vectors in both directions .",Introduction,Introduction,natural_language_inference,65,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']",,,8,0.1111111111111111,16,0.06956521739130435,8,0.25,1,1,model
18,"Next , the attention vectors are used to perform pooling .",Introduction,Introduction,natural_language_inference,65,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",9,0.125,17,0.07391304347826087,9,0.28125,1,1,model
171,"We use a context window of size 3 for Insurance QA , while we set this parameter to 4 for TREC - QA and Wiki QA .",Experimental Setup,Neural Networks Setup,natural_language_inference,65,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O']",,,26,0.7878787878787878,170,0.7391304347826086,4,0.36363636363636365,1,1,experimental-setup
172,"Using the selected hyperparameters , the best results are normally achieved using between 15 and 25 training epochs .",Experimental Setup,Neural Networks Setup,natural_language_inference,65,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,0.8181818181818182,171,0.7434782608695653,5,0.45454545454545453,1,1,experimental-setup
173,"For AP - CNN , AP - biLSTM and QA - LSTM , we also use a learning rate schedule that decreases the learning rate ?",Experimental Setup,Neural Networks Setup,natural_language_inference,65,"['B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'O']","['B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'B-b', 'I-b', 'O']",28,0.8484848484848485,172,0.7478260869565218,6,0.5454545454545454,1,1,experimental-setup
178,"In our experiments , the four NN architectures QA - CNN , AP - CNN , QA - biLSTM and AP - biLSTM are implemented using Theano .",Experimental Setup,Neural Networks Setup,natural_language_inference,65,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'O']",33,1.0,177,0.7695652173913043,11,1.0,1,1,experimental-setup
181,"In , we present the experimental results of the four NNs for the Insurance QA dataset .",Experimental Results,InsuranceQA,natural_language_inference,65,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O']",2,0.044444444444444446,180,0.782608695652174,1,0.02857142857142857,1,1,results
183,"On the bottom part of this table , we can see that AP - CNN outperforms QA - CNN by a large margin in both test sets , as well as in the dev set .",Experimental Results,InsuranceQA,natural_language_inference,65,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-n', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",4,0.08888888888888889,182,0.7913043478260869,3,0.08571428571428572,1,1,results
185,AP - CNN and AP - biLSTM have similar performance .,Experimental Results,InsuranceQA,natural_language_inference,65,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",6,0.13333333333333333,184,0.8,5,0.14285714285714285,1,1,results
189,Both AP - CNN and AP - biLSTM outperform the state - of - the - art systems .,Experimental Results,InsuranceQA,natural_language_inference,65,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.2222222222222222,188,0.8173913043478261,9,0.2571428571428571,1,1,results
201,"In , we present the experimental results of the four NNs for the TREC - QA dataset .",Experimental Results,InsuranceQA,natural_language_inference,65,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",22,0.4888888888888889,200,0.8695652173913043,21,0.6,1,1,results
203,We use the official trec eval that AP - CNN outperforms QA - CNN by a large margin in both metrics .,Experimental Results,InsuranceQA,natural_language_inference,65,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']",,,24,0.5333333333333333,202,0.8782608695652174,23,0.6571428571428571,1,1,results
204,"AP - biLSTM outperforms the QA - biLSTM , but its performance is not as good as the of AP - CNN .",Experimental Results,InsuranceQA,natural_language_inference,65,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",25,0.5555555555555556,203,0.8826086956521739,24,0.6857142857142857,1,1,results
210,"AP - CNN outperforms the state - of - the - art systems in both metrics , MAP and MRR .",Experimental Results,InsuranceQA,natural_language_inference,65,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",31,0.6888888888888889,209,0.908695652173913,30,0.8571428571428571,1,1,results
211,shows the experimental results of the four NNs for the WikiQA dataset .,Experimental Results,InsuranceQA,natural_language_inference,65,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O']",32,0.7111111111111111,210,0.9130434782608695,31,0.8857142857142857,1,1,results
212,"Like in the other two datasets , AP - CNN outperforms QA - CNN , and AP - biLSTM outperforms the QA - biLSTM .",Experimental Results,InsuranceQA,natural_language_inference,65,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']",,,33,0.7333333333333333,211,0.9173913043478261,32,0.9142857142857143,1,1,results
213,The difference of performance between AP - CNN and QA - CNN is smaller than the one for the Insurance QA dataset .,Experimental Results,InsuranceQA,natural_language_inference,65,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",34,0.7555555555555555,212,0.9217391304347826,33,0.9428571428571428,1,1,results
2,Learning Natural Language Inference with LSTM,title,,natural_language_inference,66,"['O', 'B', 'I', 'I', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",1,0.0,1,0.0035842293906810036,1,0.0,1,1,research-problem
4,Natural language inference ( NLI ) is a fundamentally important task in natural language processing that has many applications .,abstract,abstract,natural_language_inference,66,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.09090909090909091,3,0.010752688172043012,1,0.09090909090909091,1,1,research-problem
6,"In this paper , we propose a special long short - term memory ( LSTM ) architecture for NLI .",abstract,abstract,natural_language_inference,66,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O']",3,0.2727272727272727,5,0.017921146953405017,3,0.2727272727272727,1,1,research-problem
32,"In this paper , we propose a new LSTM - based architecture for learning natural language inference .",Introduction,Introduction,natural_language_inference,66,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.6071428571428571,31,0.1111111111111111,17,0.6296296296296297,1,1,model
34,"Instead , we use an LSTM to perform word - by - word matching of the hypothesis with the premise .",Introduction,Introduction,natural_language_inference,66,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O']",19,0.6785714285714286,33,0.11827956989247312,19,0.7037037037037037,1,1,model
35,"Our LSTM sequentially processes the hypothesis , and at each position , it tries to match the current word in the hypothesis with an attention - weighted representation of the premise .",Introduction,Introduction,natural_language_inference,66,"['B', 'I', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O']",,,20,0.7142857142857143,34,0.12186379928315412,20,0.7407407407407407,1,1,model
37,"We refer to this architecture a match - LSTM , or m LSTM for short .",Introduction,Introduction,natural_language_inference,66,"['O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",22,0.7857142857142857,36,0.12903225806451613,22,0.8148148148148148,1,1,model
42,1 https://github.com/shuohangwang/,Introduction,Introduction,natural_language_inference,66,"['O', 'B']","['O', 'B-n']","['O', 'B-ob']",27,0.9642857142857143,41,0.14695340501792115,27,1.0,1,1,code
142,"We use the Adam method ( Kingma and Ba , 2014 ) with hyperparameters ?",Experiment Settings,Experiment Settings,natural_language_inference,66,"['O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'O']",8,0.2962962962962963,141,0.5053763440860215,8,0.2962962962962963,1,1,hyperparameters
143,1 set to 0.9 and ?,Experiment Settings,Experiment Settings,natural_language_inference,66,"['O', 'B', 'I', 'B', 'O', 'O']","['O', 'B-p', 'I-p', 'B-n', 'O', 'O']","['O', 'B-p', 'I-p', 'B-ob', 'O', 'O']",9,0.3333333333333333,142,0.5089605734767025,9,0.3333333333333333,1,1,hyperparameters
144,2 set to 0.999 for optimization .,Experiment Settings,Experiment Settings,natural_language_inference,66,"['O', 'O', 'O', 'B', 'B', 'B', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-ob', 'B-p', 'B-b', 'O']",10,0.37037037037037035,143,0.5125448028673835,10,0.37037037037037035,1,1,hyperparameters
145,The initial learning rate is set to be 0.001 with a decay ratio of 0.95 for each iteration .,Experiment Settings,Experiment Settings,natural_language_inference,66,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.4074074074074074,144,0.5161290322580645,11,0.4074074074074074,1,1,hyperparameters
146,The batch size is set to be 30 .,Experiment Settings,Experiment Settings,natural_language_inference,66,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",12,0.4444444444444444,145,0.5197132616487455,12,0.4444444444444444,1,1,hyperparameters
147,We experiment with d = 150 and d = 300 where d is the dimension of all the hidden states .,Experiment Settings,Experiment Settings,natural_language_inference,66,"['O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.48148148148148145,146,0.5232974910394266,13,0.48148148148148145,1,1,hyperparameters
163,"We have the following observations : ( 1 ) First of all , we can see that when we set d to 300 , our model achieves an accuracy of 86.1 % on the test data , which to the best of our knowledge is the highest on and |?| M is the number of parameters excluding the word embeddings .",Main Results,Main Results,natural_language_inference,66,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.010869565217391304,162,0.5806451612903226,1,0.25,1,1,results
182,"( 2 ) If we compare our m LSTM model with our implementation of the word - by - word attention model by under the same setting with d = 150 , we can see that our performance on the test data ( 85.7 % ) is higher than that of their model ( 82.6 % ) .",Main Results,Hypothesis Example,natural_language_inference,66,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']",,,20,0.21739130434782608,181,0.6487455197132617,15,0.6521739130434783,1,1,results
184,"( 3 ) The performance of mLSTM with bi - LSTM sentence modeling compared with the model with standard LSTM sentence modeling when d is set to 150 shows that using bi - LSTM to process the original sentences helps ( 86.0 % vs. 85.7 % on the test data ) , but the difference is small and the complexity of bi - LSTM is much higher than LSTM .",Main Results,Hypothesis Example,natural_language_inference,66,"['O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,22,0.2391304347826087,183,0.6559139784946236,17,0.7391304347826086,1,1,results
186,"( 4 ) Interestingly , when we experimented with the m LSTM model using the pre-trained word embeddings instead of LSTMgenerated hidden states as initial representations of the premise and the hypothesis , we were able to achieve an accuracy of 85.3 % on the test data , which is still better than previously reported state of the art .",Main Results,Hypothesis Example,natural_language_inference,66,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']",,,24,0.2608695652173913,185,0.6630824372759857,19,0.8260869565217391,1,1,results
2,End - to - End Answer Chunk Extraction and Ranking for Reading Comprehension,title,title,natural_language_inference,67,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.004901960784313725,1,0.0,1,1,research-problem
4,"This paper proposes dynamic chunk reader ( DCR ) , an end - toend neural reading comprehension ( RC ) model that is able to extract and rank a set of answer candidates from a given document to answer questions .",abstract,abstract,natural_language_inference,67,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.25,3,0.014705882352941176,1,0.25,1,1,research-problem
9,Reading comprehension - based question answering ( RCQA ) is the task of answering a question with a chunk of text taken from related document ( s ) .,Introduction,Introduction,natural_language_inference,67,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.007936507936507936,8,0.0392156862745098,1,0.03125,1,1,research-problem
12,"Different from the above two assumptions for RCQA , in the real - world QA scenario , people may ask questions about both entities ( factoid ) and non-entities such as explanations and reasons ( non -factoid ) ( see for examples ) .",Introduction,Introduction,natural_language_inference,67,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.031746031746031744,11,0.05392156862745098,4,0.125,1,1,research-problem
25,"Our proposed model , called dynamic chunk reader ( DCR ) , not only significantly differs from both the above systems in the way that answer candidates are generated and ranked , but also shares merits with both works .",Introduction,Introduction,natural_language_inference,67,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.1349206349206349,24,0.11764705882352941,17,0.53125,1,1,model
26,"First , our model uses deep networks to learn better representations for candidate answer chunks , instead of using fixed feature representations as in .",Introduction,Introduction,natural_language_inference,67,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",18,0.14285714285714285,25,0.12254901960784313,18,0.5625,1,1,model
27,"Second , it represents answer candidates as chunks , as in ( Rajpurkar et al. ) , instead of word - level representations , to make the model aware of the subtle differences among candidates ( importantly , overlapping candidates ) .",Introduction,Introduction,natural_language_inference,67,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.15079365079365079,26,0.12745098039215685,19,0.59375,1,1,model
136,We pre-processed the SQuAD dataset using Stanford CoreNLP tool 5 with its default setting to tokenize the text and obtain the POS and NE annotations .,Implementation Details,Implementation Details,natural_language_inference,67,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.047619047619047616,135,0.6617647058823529,33,0.6226415094339622,1,1,experimental-setup
137,"To train our model , we used stochastic gradient descent with the ADAM optimizer , with an initial learning rate of 0.001 .",Implementation Details,Implementation Details,natural_language_inference,67,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",2,0.09523809523809523,136,0.6666666666666666,34,0.6415094339622641,1,1,experimental-setup
138,"All GRU weights were initialized from a uniform distribution between ( - 0.01 , 0.01 ) .",Implementation Details,Implementation Details,natural_language_inference,67,"['B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.14285714285714285,137,0.6715686274509803,35,0.660377358490566,1,1,experimental-setup
139,"The hidden state size , d , was set to 300 for all GRUs .",Implementation Details,Implementation Details,natural_language_inference,67,"['O', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",4,0.19047619047619047,138,0.6764705882352942,36,0.6792452830188679,1,1,experimental-setup
142,"We also applied dropout of rate 0.2 to the embedding layer of input bi - GRU encoder , and gradient clipping when the norm of gradients exceeded 10 .",Implementation Details,Implementation Details,natural_language_inference,67,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'O']",,,7,0.3333333333333333,141,0.6911764705882353,39,0.7358490566037735,1,1,experimental-setup
143,We trained in mini-batch style ( mini - batch size is 180 ) and applied zero - padding to the passage and question inputs in each batch .,Implementation Details,Implementation Details,natural_language_inference,67,"['O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.38095238095238093,142,0.696078431372549,40,0.7547169811320755,1,1,experimental-setup
144,"We also set the maximum passage length to be 300 tokens , and pruned all the tokens after the 300 - th token in the training set to save memory and speedup the training process .",Implementation Details,Implementation Details,natural_language_inference,67,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.42857142857142855,143,0.7009803921568627,41,0.7735849056603774,1,1,experimental-setup
147,"We trained the model for at most 30 epochs , and in case the accuracy did not improve for 10 epochs , we stopped training .",Implementation Details,Implementation Details,natural_language_inference,67,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.5714285714285714,146,0.7156862745098039,44,0.8301886792452831,1,1,experimental-setup
148,"For the feature ranking - based system , we used jforest ranker ( Ganjis affar , Caruana , and Lopes 2011 ) with Lambda MART - Regression Tree algorithm and the ranking metric was NDCG @ 10 .",Implementation Details,Implementation Details,natural_language_inference,67,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.6190476190476191,147,0.7205882352941176,45,0.8490566037735849,1,1,experimental-setup
150,Results shows our main results on the SQuAD dataset .,Implementation Details,Implementation Details,natural_language_inference,67,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O']",15,0.7142857142857143,149,0.7303921568627451,47,0.8867924528301887,1,1,results
151,"Compared to the scores reported in , our exact match ( EM ) and F1 on the development set and EM score on the test set are better , and F1 on the test set is comparable .",Implementation Details,Implementation Details,natural_language_inference,67,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'O']",,,16,0.7619047619047619,150,0.7352941176470589,48,0.9056603773584906,1,1,results
154,"As the first row of shows , our baseline system improves 10 % ( EM ) over , row 1 ) , the feature - based ranking system .",Implementation Details,Implementation Details,natural_language_inference,67,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-b', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.9047619047619048,153,0.75,51,0.9622641509433962,1,1,results
155,"However when compared to our DCR model , row 2 ) , the baseline ( row 1 ) is more than 12 % ( EM ) behind even though it is based on the state - of - the - art model for cloze - style RC tasks .",Implementation Details,Implementation Details,natural_language_inference,67,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.9523809523809523,154,0.7549019607843137,52,0.9811320754716981,1,1,results
159,"First , replacing the word - by - word attention with Attentive Reader style attention decreases the EM score by about 4.5 % , showing the strength of our proposed attention mechanism .",Experiments,Experiments,natural_language_inference,67,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-n', 'I-n', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-b', 'I-b', 'B-b', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.08333333333333333,158,0.7745098039215687,2,0.08333333333333333,1,1,ablation-analysis
161,The result shows that POS feature ( 1 ) and question - word feature ( 3 ) are the two most important features .,Experiments,Experiments,natural_language_inference,67,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.16666666666666666,160,0.7843137254901961,4,0.16666666666666666,1,1,ablation-analysis
162,"Finally , combining the DCR model with the proposed POS - trie constraints yields a score similar to the one obtained using the DCR model with all possible n-gram chunks .",Experiments,Experiments,natural_language_inference,67,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']",,,5,0.20833333333333334,161,0.7892156862745098,5,0.20833333333333334,1,1,ablation-analysis
2,MACHINE COMPREHENSION USING MATCH - LSTM AND ANSWER POINTER,,,natural_language_inference,68,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.2,1,0.004016064257028112,1,0.0,1,1,research-problem
4,Machine comprehension of text is an important problem in natural language processing .,,MACHINE COMPREHENSION USING MATCH - LSTM AND ANSWER POINTER,natural_language_inference,68,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.4,3,0.012048192771084338,1,0.14285714285714285,1,1,research-problem
39,"Specifically , observing that in the SQuAD dataset many questions are paraphrases of sentences from the original text , we adopt a match - LSTM model that we developed earlier for textual entailment .",INTRODUCTION,INTRODUCTION,natural_language_inference,68,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",28,0.717948717948718,38,0.15261044176706828,28,0.717948717948718,1,1,model
40,"We further adopt the Pointer Net ( Ptr - Net ) model developed by , which enables the predictions of tokens from the input sequence only rather than from a larger fixed vocabulary and thus allows us to generate answers that consist of multiple tokens from the original text .",INTRODUCTION,INTRODUCTION,natural_language_inference,68,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",29,0.7435897435897436,39,0.1566265060240964,29,0.7435897435897436,1,1,model
41,We propose two ways to apply the Ptr - Net model for our task : a sequence model and a boundary model .,INTRODUCTION,INTRODUCTION,natural_language_inference,68,"['O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O']",30,0.7692307692307693,40,0.1606425702811245,30,0.7692307692307693,1,1,model
42,We also further extend the boundary model with a search mechanism .,INTRODUCTION,INTRODUCTION,natural_language_inference,68,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",31,0.7948717948717948,41,0.1646586345381526,31,0.7948717948717948,1,1,model
174,"We first tokenize all the passages , questions and answers .",EXPERIMENT SETTINGS,EXPERIMENT SETTINGS,natural_language_inference,68,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.08333333333333333,173,0.6947791164658634,1,0.08333333333333333,1,1,experimental-setup
176,We use word embeddings from GloVe to initialize the model .,EXPERIMENT SETTINGS,EXPERIMENT SETTINGS,natural_language_inference,68,"['O', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'I-p', 'O', 'B-ob', 'O']",3,0.25,175,0.7028112449799196,3,0.25,1,1,experimental-setup
177,Words not found in Glo Ve are initialized as zero vectors .,EXPERIMENT SETTINGS,EXPERIMENT SETTINGS,natural_language_inference,68,"['B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",4,0.3333333333333333,176,0.7068273092369478,4,0.3333333333333333,1,1,experimental-setup
179,The dimensionality l of the hidden layers is set to be 150 or 300 .,EXPERIMENT SETTINGS,EXPERIMENT SETTINGS,natural_language_inference,68,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.5,178,0.714859437751004,6,0.5,1,1,experimental-setup
180,We use ADAMAX with the coefficients ? 1 = 0.9 and ? 2 = 0.999 to optimize the model .,EXPERIMENT SETTINGS,EXPERIMENT SETTINGS,natural_language_inference,68,"['O', 'O', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'O']",7,0.5833333333333334,179,0.7188755020080321,7,0.5833333333333334,1,1,experimental-setup
192,"Furthermore , our boundary model has outperformed the sequence model , achieving an exact match score of 61.1 % and an F1 score of 71.2 % .",RESULTS,RESULTS,natural_language_inference,68,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O']",,,6,0.15384615384615385,191,0.7670682730923695,6,0.375,1,1,results
193,"In particular , in terms of the exact match score , the boundary model has a clear advantage over the sequence model .",RESULTS,RESULTS,natural_language_inference,68,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",7,0.1794871794871795,192,0.7710843373493976,7,0.4375,1,1,results
200,"While by adding Bi - Ans - Ptr with bi-directional pre-processing LSTM , we can get 1.2 % improvement in F1 .",RESULTS,RESULTS,natural_language_inference,68,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",14,0.358974358974359,199,0.7991967871485943,14,0.875,1,1,results
2,Constructing Datasets for Multi-hop Reading Comprehension Across Documents,title,,natural_language_inference,69,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",1,0.0,1,0.002898550724637681,1,0.0,1,1,research-problem
4,"Most Reading Comprehension methods limit themselves to queries which can be answered using a single sentence , paragraph , or document .",abstract,abstract,natural_language_inference,69,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.1111111111111111,3,0.008695652173913044,1,0.1111111111111111,1,1,research-problem
17,Contemporary end - to - end Reading Comprehension ( RC ) methods can learn to extract the correct answer span within a given text and approach human - level performance .,Introduction,Introduction,natural_language_inference,69,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.020618556701030927,16,0.0463768115942029,4,0.14814814814814814,1,1,research-problem
29,"The first , WIKIHOP , uses sets of WIKIPEDIA articles where answers to queries about specific properties of an entity can not be located in the entity 's article .",Introduction,Introduction,natural_language_inference,69,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O']",,,16,0.08247422680412371,28,0.08115942028985507,16,0.5925925925925926,1,1,dataset
30,"In the second dataset , MEDHOP , the goal is to establish drug - drug interactions based on scientific findings about drugs and proteins and their interactions , found across multiple MEDLINE abstracts .",Introduction,Introduction,natural_language_inference,69,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.08762886597938144,29,0.08405797101449275,17,0.6296296296296297,1,1,dataset
31,"For both datasets we draw upon existing Knowledge Bases ( KBs ) , WIKIDATA and DRUG - BANK , as ground truth , utilizing distant supervision ) to induce the data - similar to and .",Introduction,Introduction,natural_language_inference,69,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.09278350515463918,30,0.08695652173913043,18,0.6666666666666666,1,1,dataset
213,Random Selects a random candidate ; note that the number of candidates differs between samples .,Models,Models,natural_language_inference,69,"['B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.027777777777777776,212,0.6144927536231884,1,0.027777777777777776,1,1,baselines
214,Max- mention,Models,,natural_language_inference,69,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",2,0.05555555555555555,213,0.6173913043478261,2,0.05555555555555555,1,1,baselines
215,Predicts the most frequently mentioned candidate in the support documents,Models,Max- mention,natural_language_inference,69,"['B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob']",3,0.08333333333333333,214,0.6202898550724638,3,0.08333333333333333,1,1,baselines
217,Majority - candidate - per-query - type,Models,Max- mention,natural_language_inference,69,"['B', 'I', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",5,0.1388888888888889,216,0.6260869565217392,5,0.1388888888888889,1,1,baselines
218,Predicts the candidate c ?,Models,Max- mention,natural_language_inference,69,"['B', 'O', 'B', 'O', 'O']","['B-p', 'O', 'B-n', 'O', 'O']","['B-p', 'O', 'B-b', 'O', 'O']",6,0.16666666666666666,217,0.6289855072463768,6,0.16666666666666666,1,1,baselines
219,"C q that was most frequently observed as the true answer in the training set , given the query type of q .",Models,Max- mention,natural_language_inference,69,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.19444444444444445,218,0.6318840579710145,7,0.19444444444444445,1,1,baselines
221,TF - IDF,Models,Max- mention,natural_language_inference,69,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",9,0.25,220,0.6376811594202898,9,0.25,1,1,baselines
222,Retrieval - based models are known to be strong QA baselines if candidate answers are provided .,Models,Max- mention,natural_language_inference,69,"['B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-ob', 'O']",10,0.2777777777777778,221,0.6405797101449275,10,0.2777777777777778,1,1,baselines
229,"( 1 ) Document - cue During dataset construction we observed that certain document - answer pairs appear more frequently than others , to the effect that the correct candidate is often indicated solely by the presence of certain documents in Sq .",Models,Max- mention,natural_language_inference,69,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",17,0.4722222222222222,228,0.6608695652173913,17,0.4722222222222222,1,1,baselines
261,"The Document - cue baseline can predict more than a third of the samples correctly , for both datasets , even after sub - sampling frequent document - answer pairs for WIKIHOP .",Results and Discussion,Results and Discussion,natural_language_inference,69,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-ob', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'O']",1,0.037037037037037035,260,0.7536231884057971,1,0.08333333333333333,1,1,results
265,"In the masked setup all baseline models reliant on lexical cues fail in the face of the randomized answer expressions , since the same answer option has different placeholders in different samples .",Results and Discussion,Results and Discussion,natural_language_inference,69,"['B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.18518518518518517,264,0.7652173913043478,5,0.4166666666666667,1,1,results
267,Both neural RC models are able to largely retain or even improve their strong performance when answers are masked : they are able to leverage the textual context of the candidate expressions .,Results and Discussion,Results and Discussion,natural_language_inference,69,"['B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.25925925925925924,266,0.7710144927536232,7,0.5833333333333334,1,1,results
269,"In contrast , for the open - domain setting of WIKIHOP , a reduction of the answer vocabulary to 100 random single - token mask expressions clearly helps the model in selecting a candidate span , compared to the multi-token candidate expressions in the unmasked setting .",Results and Discussion,Results and Discussion,natural_language_inference,69,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,9,0.3333333333333333,268,0.7768115942028986,9,0.75,1,1,results
2,LEARNING RECURRENT SPAN REPRESENTATIONS FOR EXTRACTIVE QUESTION ANSWERING,,,natural_language_inference,7,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",2,0.13333333333333333,1,0.0056179775280898875,1,0.0,1,1,research-problem
7,"In this paper , we focus on this answer extraction task , presenting a novel model architecture that efficiently builds fixed length representations of all spans in the evidence document with a recurrent network .",,LEARNING RECURRENT SPAN REPRESENTATIONS FOR EXTRACTIVE QUESTION ANSWERING,natural_language_inference,7,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.4666666666666667,6,0.033707865168539325,4,0.3333333333333333,1,1,research-problem
24,"To overcome this , we present a novel neural architecture called RASOR that builds fixed - length span representations , reusing recurrent computations for shared substructures .",INTRODUCTION,INTRODUCTION,natural_language_inference,7,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.5,23,0.12921348314606743,8,0.7272727272727273,1,1,model
25,"We demonstrate that directly classifying each of the competing spans , and training with global normalization over all possible spans , leads to a significant increase in performance .",INTRODUCTION,INTRODUCTION,natural_language_inference,7,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",9,0.5625,24,0.1348314606741573,9,0.8181818181818182,1,1,model
106,We represent each of the words in the question and document using 300 dimensional GloVe embeddings trained on a corpus of 840 bn words .,EXPERIMENTAL SETUP,EXPERIMENTAL SETUP,natural_language_inference,7,"['O', 'B', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'O']",,,1,0.125,105,0.5898876404494382,1,0.125,1,1,experimental-setup
107,These embeddings cover 200 k words and all out of vocabulary ( OOV ) words are projected onto one of 1 m randomly initialized 300d embeddings .,EXPERIMENTAL SETUP,EXPERIMENTAL SETUP,natural_language_inference,7,"['O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.25,106,0.5955056179775281,2,0.25,1,1,experimental-setup
108,"We couple the input and forget gates in our LSTMs , as described in , and we use a single dropout mask to apply dropout across all LSTM time - steps as proposed by .",EXPERIMENTAL SETUP,EXPERIMENTAL SETUP,natural_language_inference,7,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",3,0.375,107,0.601123595505618,3,0.375,1,1,experimental-setup
109,Hidden layers in the feed forward neural networks use rectified linear units .,EXPERIMENTAL SETUP,EXPERIMENTAL SETUP,natural_language_inference,7,"['B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.5,108,0.6067415730337079,4,0.5,1,1,experimental-setup
110,Answer candidates are limited to spans with at most 30 words .,EXPERIMENTAL SETUP,EXPERIMENTAL SETUP,natural_language_inference,7,"['B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.625,109,0.6123595505617978,5,0.625,1,1,experimental-setup
111,"To choose the final model configuration , we ran grid searches over : the dimensionality of the LSTM hidden states ; the width and depth of the feed forward neural networks ; dropout for the LSTMs ; the number of stacked LSTM layers ; and the decay multiplier [ 0.9 , 0.95 , 1.0 ] with which we multiply the learning rate every 10 k steps .",EXPERIMENTAL SETUP,EXPERIMENTAL SETUP,natural_language_inference,7,"['B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']",,,6,0.75,110,0.6179775280898876,6,0.75,1,1,experimental-setup
112,The best model uses 50d LSTM states ; two - layer BiLSTMs for the span encoder and the passage - independent question representation ; dropout of 0.1 throughout ; and a learning rate decay of 5 % every 10 k steps .,EXPERIMENTAL SETUP,EXPERIMENTAL SETUP,natural_language_inference,7,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']",,,7,0.875,111,0.6235955056179775,7,0.875,1,1,experimental-setup
113,All models are implemented using TensorFlow 3 and trained on the SQUAD training set using the ADAM optimizer with a mini-batch size of 4 and trained using 10 asynchronous training threads on a single machine .,EXPERIMENTAL SETUP,EXPERIMENTAL SETUP,natural_language_inference,7,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",8,1.0,112,0.6292134831460674,8,1.0,1,1,experimental-setup
121,"Despite not having access to any external representation of linguistic structure , RASOR achieves an error reduction of more than 50 % over this baseline , both in terms of exact match and F1 , relative to the human performance upper bound .",RESULTS,COMPARISONS TO OTHER WORK,natural_language_inference,7,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.6363636363636364,120,0.6741573033707865,4,0.5,1,1,results
125,"In contrast , RASOR can efficiently and explicitly model the quadratic number of possible answers , which leads to a 14 % error reduction over the best performing Match - LSTM model .",RESULTS,COMPARISONS TO OTHER WORK,natural_language_inference,7,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,1.0,124,0.6966292134831461,8,1.0,1,1,results
131,"The passage - aligned question representation is crucial , since lexically similar regions of the passage provide strong signal for relevant answer spans .",MODEL VARIATIONS,MODEL VARIATIONS,natural_language_inference,7,"['O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.10869565217391304,130,0.7303370786516854,5,0.625,1,1,ablation-analysis
157,"First , we observe general improvements when using labels that closely align with the task .",MODEL VARIATIONS,MODEL VARIATIONS,natural_language_inference,7,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",31,0.6739130434782609,156,0.8764044943820225,19,0.5757575757575758,1,1,ablation-analysis
162,"Second , we observe the importance of allowing interactions between the endpoints using the spanlevel FFNN .",MODEL VARIATIONS,MODEL VARIATIONS,natural_language_inference,7,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",36,0.782608695652174,161,0.9044943820224719,24,0.7272727272727273,1,1,ablation-analysis
163,"RASOR outperforms the endpoint prediction model by 1.1 in exact match , The interaction between endpoints enables RASOR to enforce consistency across its two substructures .",MODEL VARIATIONS,MODEL VARIATIONS,natural_language_inference,7,"['B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",37,0.8043478260869565,162,0.9101123595505618,25,0.7575757575757576,1,1,ablation-analysis
4,This paper describes the KeLP system participating in the SemEval - 2016 Community Question Answering ( c QA ) task .,abstract,abstract,natural_language_inference,70,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",1,0.125,3,0.017142857142857144,1,0.125,1,1,research-problem
14,"In this task , participants are asked to automatically provide good answers in a c QA setting .",Introduction,Introduction,natural_language_inference,70,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O']",2,0.03773584905660377,13,0.07428571428571429,2,0.08333333333333333,1,1,research-problem
20,All the above subtasks have been modeled as binary classification problems : kernel - based classifiers are trained and the classification score is used to sort the instances and produce the final ranking .,Introduction,Introduction,natural_language_inference,70,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",8,0.1509433962264151,19,0.10857142857142857,8,0.3333333333333333,1,1,model
21,"All classifiers and kernels have been implemented within the Kernel - based Learning Platform 2 ( KeLP ) , thus determining the team 's name .",Introduction,Introduction,natural_language_inference,70,"['O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.16981132075471697,20,0.11428571428571428,9,0.375,1,1,model
22,"The proposed solution provides three main contributions : ( i ) we employ the approach proposed in , which applies tree kernels directly to question and answer texts modeled as pairs of linked syntactic trees .",Introduction,Introduction,natural_language_inference,70,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.18867924528301888,21,0.12,10,0.4166666666666667,1,1,model
25,( iii ) we propose a stacking schema so that classifiers for Subtask B and C exploit the inferences obtained in the previous subtasks .,Introduction,Introduction,natural_language_inference,70,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",13,0.24528301886792453,24,0.13714285714285715,13,0.5416666666666666,1,1,model
133,Subtask A,Submission and Results,,natural_language_inference,70,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",10,0.19230769230769232,132,0.7542857142857143,0,0.0,1,1,experiments
139,Results : reports the outcome on Subtask A .,Submission and Results,,natural_language_inference,70,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.3076923076923077,138,0.7885714285714286,6,0.6666666666666666,1,1,experiments
140,"The good results on the 10 fold cross validations are confirmed on the official test set : the model is very accurate and achieved the first position among 12 systems , with the best MAP .",Submission and Results,Results : reports the outcome on Subtask A .,natural_language_inference,70,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",17,0.3269230769230769,139,0.7942857142857143,7,0.7777777777777778,1,1,experiments
143,Subtask B,Submission and Results,,natural_language_inference,70,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",20,0.38461538461538464,142,0.8114285714285714,0,0.0,1,1,experiments
155,"On the official test set , our primary submission achieved the third position w.r.t. MAP among 11 systems .",Submission and Results,Results : shows the results on Subtask B .,natural_language_inference,70,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'O']",32,0.6153846153846154,154,0.88,12,0.375,1,1,experiments
157,The primary system achieves the highest F 1 and accuracy on both tuning and test stages .,Submission and Results,Results : shows the results on Subtask B .,natural_language_inference,70,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",34,0.6538461538461539,156,0.8914285714285715,14,0.4375,1,1,experiments
159,Subtask C Model :,Submission and Results,Results : shows the results on Subtask B .,natural_language_inference,70,"['B', 'I', 'O', 'O']","['B-n', 'I-n', 'O', 'O']","['B-b', 'I-b', 'O', 'O']",36,0.6923076923076923,158,0.9028571428571428,16,0.5,1,1,experiments
171,"Our primary submission achieved the second highest MAP , while our Contrastive 2 is the best result .",Submission and Results,Results : shows the results for Subtask C .,natural_language_inference,70,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",48,0.9230769230769231,170,0.9714285714285714,28,0.875,1,1,experiments
172,It should be also noted that the F 1 our system is the best among 10 primary submissions .,Submission and Results,Results : shows the results for Subtask C .,natural_language_inference,70,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",49,0.9423076923076923,171,0.9771428571428571,29,0.90625,1,1,experiments
4,We present a novel recurrent neural network ( RNN ) based model that combines the remembering ability of unitary RNNs with the ability of gated RNNs to effectively forget redundant / irrelevant information in its memory .,abstract,abstract,natural_language_inference,71,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.16666666666666666,3,0.013953488372093023,1,0.16666666666666666,1,1,research-problem
11,Recurrent Neural Networks with gating units - such as Long Short Term Memory ( LSTMs ) and Gated Recurrent Units ( GRUs ) ),Introduction,Introduction,natural_language_inference,71,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.04,10,0.046511627906976744,1,0.04,1,1,research-problem
13,These works have proven the importance of gating units for Recurrent Neural Networks .,Introduction,Introduction,natural_language_inference,71,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.12,12,0.05581395348837209,3,0.12,1,1,research-problem
14,The main advantage of using these gated units in RNNs is primarily due to the ease of optimization of the models using them and to reduce the learning degeneracies such as vanishing gradients that can cripple conventional RNNs .,Introduction,Introduction,natural_language_inference,71,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.16,13,0.06046511627906977,4,0.16,1,1,research-problem
29,"We propose a new architecture , the Gated Orthogonal Recurrent Unit ( GORU ) , which combines the advantages of the above two frameworks , namely ( i ) the ability to capture long term dependencies by using orthogonal matrices and ( ii ) the ability to "" forget "" by using a GRU structure .",Introduction,Introduction,natural_language_inference,71,"['O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O']",,,19,0.76,28,0.13023255813953488,19,0.76,1,1,model
30,"We demonstrate that GORU is able to learn long term dependencies effectively , even in complicated datasets which require a forgetting ability .",Introduction,Introduction,natural_language_inference,71,"['O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.8,29,0.13488372093023257,20,0.8,1,1,model
31,"In this work , we focus on implementation of orthogonal transition matrices which is just a subset of the unitary matrices .",Introduction,Introduction,natural_language_inference,71,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'O']",,,21,0.84,30,0.13953488372093023,21,0.84,1,1,model
103,"GORU is implemented in Tensorflow , available from https://github.com/jingli9111/GORU-tensorflow",Experiments,Experiments,natural_language_inference,71,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob']",3,0.05084745762711865,102,0.4744186046511628,3,1.0,1,1,code
105,The first task we consider is the well known Copying Memory Task .,Experiments,Copying Memory Task,natural_language_inference,71,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']",,,5,0.0847457627118644,104,0.48372093023255813,1,0.0625,1,1,
112,"In this experiment , we use RMSProp optimization with a learning rate of 0.001 and a decay rate of 0.9 for all models .",Experiments,Copying Memory Task,natural_language_inference,71,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O']",,,12,0.2033898305084746,111,0.5162790697674419,8,0.5,1,1,
113,The batch size is set to 128 .,Experiments,Copying Memory Task,natural_language_inference,71,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']",,,13,0.22033898305084745,112,0.5209302325581395,9,0.5625,1,1,
115,"Hidden state sizes are set to 128 , 100 , 90 , 512 , respectively to match total number of hidden to hidden parameters .",Experiments,Copying Memory Task,natural_language_inference,71,"['B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']",,,15,0.2542372881355932,114,0.5302325581395348,11,0.6875,1,1,
120,The GORU is the only gated - system to successfully solve this task while the GRU and LSTM get stuck at the baseline as shown in .,Experiments,Copying Memory Task,natural_language_inference,71,"['O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,20,0.3389830508474576,119,0.5534883720930233,16,1.0,1,1,
121,Denoise Task,Experiments,,natural_language_inference,71,"['B', 'I']",,,21,0.3559322033898305,120,0.5581395348837209,0,0.0,1,1,
128,"Just as in the previous experiment , we use RM - SProp optimization algorithm with a learning rate of 0.01 and a decay rate of 0.9 for all models .",Experiments,Denoise Task,natural_language_inference,71,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O']",,,28,0.4745762711864407,127,0.5906976744186047,7,0.5,1,1,
129,The batch size is set to 128 .,Experiments,Denoise Task,natural_language_inference,71,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']",,,29,0.4915254237288136,128,0.5953488372093023,8,0.5714285714285714,1,1,
131,"Hidden state sizes are set to 128 , 100 , 90 , 512 , respectively to match total number of hidden to hidden parameters .",Experiments,Denoise Task,natural_language_inference,71,"['B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,31,0.5254237288135594,130,0.6046511627906976,10,0.7142857142857143,1,1,
132,"EURNN get stuck at the baseline because of lacking forgetting mechanism , while GORU and GRU successfully solve the task .",Experiments,Denoise Task,natural_language_inference,71,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'O']",,,32,0.5423728813559322,131,0.6093023255813953,11,0.7857142857142857,1,1,
136,Parenthesis Task,Experiments,,natural_language_inference,71,"['B', 'I']",,,36,0.6101694915254238,135,0.627906976744186,0,0.0,1,1,
142,"In our experiment , the total input length is set to 200 .",Experiments,Parenthesis Task,natural_language_inference,71,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O']",,,42,0.711864406779661,141,0.6558139534883721,6,0.4,1,1,
143,"We used batch size 128 and RMSProp Optimizer with a learning rate 0.001 , decay rate 0.9 on all models .",Experiments,Parenthesis Task,natural_language_inference,71,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O']",,,43,0.7288135593220338,142,0.6604651162790698,7,0.4666666666666667,1,1,
146,"The GORU is able to successfully outperform GRU , LSTM and EURNN in terms of both learning speed and final performances as shown in .",Experiments,Parenthesis Task,natural_language_inference,71,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O']",,,46,0.7796610169491526,145,0.6744186046511628,10,0.6666666666666666,1,1,
147,We also analyzed the activations of the update gates for GORU and GRU .,Experiments,Parenthesis Task,natural_language_inference,71,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']",,,47,0.7966101694915254,146,0.6790697674418604,11,0.7333333333333333,1,1,
152,Algorithmic Task,Experiments,,natural_language_inference,71,"['B', 'I']",,,52,0.8813559322033898,151,0.7023255813953488,0,0.0,1,1,
156,We used batch size 50 and hidden size 128 for all models .,Experiments,Algorithmic Task,natural_language_inference,71,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O']",,,56,0.9491525423728814,155,0.7209302325581395,4,0.5714285714285714,1,1,
157,The RNNs are trained with RMSProp optimizer with a learning rate of 0.001 and decay rate of 0.9 .,Experiments,Algorithmic Task,natural_language_inference,71,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,57,0.9661016949152542,156,0.7255813953488373,5,0.7142857142857143,1,1,
159,We found that the GORU performs averagely better than GRU / LSTM and EURNN .,Experiments,Algorithmic Task,natural_language_inference,71,"['O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']",,,59,1.0,158,0.7348837209302326,7,1.0,1,1,
2,CliCR : A Dataset of Clinical Case Reports for Machine Reading Comprehension *,title,title,natural_language_inference,72,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.0,1,0.003205128205128205,1,0.0,1,1,research-problem
4,We present a new dataset for machine comprehension in the medical domain .,abstract,abstract,natural_language_inference,72,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.009615384615384616,1,0.2,1,1,research-problem
33,"For our dataset , we construct queries , answers and supporting passages from BMJ Case Reports , the largest online repository of such documents .",Introduction,The passage has been shortened for clarity .,natural_language_inference,72,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",24,0.5106382978723404,32,0.10256410256410256,24,0.5106382978723404,1,1,dataset
34,"A case report is a detailed description of a clinical case that focuses on rare diseases , unusual presentation of common conditions and novel treatment methods .",Introduction,The passage has been shortened for clarity .,natural_language_inference,72,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",25,0.5319148936170213,33,0.10576923076923077,25,0.5319148936170213,1,1,dataset
35,"Each report contains a Learning points section , summarizing the key pieces of information from that report .",Introduction,The passage has been shortened for clarity .,natural_language_inference,72,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O']",26,0.5531914893617021,34,0.10897435897435898,26,0.5531914893617021,1,1,dataset
37,We use these learning points to create queries by blanking out a medical entity .,Introduction,The passage has been shortened for clarity .,natural_language_inference,72,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",28,0.5957446808510638,36,0.11538461538461539,28,0.5957446808510638,1,1,dataset
39,"Our dataset contains around 100,000 queries on 12,000 case reports , has long support passages ( around 1,500 tokens on average ) and includes answers which are single - or multiword medical entities .",Introduction,The passage has been shortened for clarity .,natural_language_inference,72,"['O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",30,0.6382978723404256,38,0.12179487179487179,30,0.6382978723404256,1,1,dataset
149,We also include a distance - based method that uses word embeddings ( sim-entity ) .,Baselines,Baselines,natural_language_inference,72,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",2,0.06451612903225806,148,0.47435897435897434,2,0.2,1,1,baselines
157,We trained a 4 - gram Kneser - Ney model on CliCR training data ( with multi-word entities represented as a single token ) using SRILM .,Baselines,E .,natural_language_inference,72,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'O']",10,0.3225806451612903,156,0.5,10,1.0,1,1,baselines
208,"We see that answer prediction based on contextual representation of queries and passages ( sim -entity ) achieves a strong base performance that is only outperformed by GA 7 In precision , the number of correct words is divided by the number of all predicted words .",Results and analysis,We show the results in .,natural_language_inference,72,"['O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.041666666666666664,207,0.6634615384615384,2,0.09090909090909091,1,1,results
211,"The language model performs poorly on EM and F1 , but the embedding - metric score is higher , likely reflecting the fact that the predicted answers - though mostly incorrect - are related to the ground - truth answers .",Results and analysis,We show the results in .,natural_language_inference,72,"['O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.10416666666666667,210,0.6730769230769231,5,0.22727272727272727,1,1,results
213,"The GA reader performs well across all entity set - ups , even when the entities are not marked in the passage .",Results and analysis,We show the results in .,natural_language_inference,72,"['O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.14583333333333334,212,0.6794871794871795,7,0.3181818181818182,1,1,results
215,"Upon inspecting the predicted answers more closely , we have observed that GA - NoEnt tends to predict longer answers than GA - Ent / Anonym .",Results and analysis,We show the results in .,natural_language_inference,72,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.1875,214,0.6858974358974359,9,0.4090909090909091,1,1,results
223,The results for SA reader are far below the per-formance of GA reader .,Results and analysis,We show the results in .,natural_language_inference,72,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'O']",17,0.3541666666666667,222,0.7115384615384616,17,0.7727272727272727,1,1,results
224,We also see that it performs much better on anonymized entities than on non-anonymized ones .,Results and analysis,We show the results in .,natural_language_inference,72,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",18,0.375,223,0.7147435897435898,18,0.8181818181818182,1,1,results
14,Equipping deep neural networks ( DNN ) with attention mechanisms provides an effective and parallelizable approach for context fusion and sequence compression .,Introduction,Introduction,natural_language_inference,73,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.030303030303030304,13,0.04961832061068702,1,0.030303030303030304,1,1,research-problem
36,"In this paper , we first propose a novel hard attention mechanism called "" reinforced sequence sampling ( RSS ) "" , which selects tokens from an input sequence in parallel , and differs from existing ones in that it is highly parallelizable without any recurrent structure .",Introduction,Introduction,natural_language_inference,73,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",23,0.696969696969697,35,0.13358778625954199,23,0.696969696969697,1,1,model
37,"We then develop a model , "" reinforced self - attention ( ReSA ) "" , which naturally combines the RSS with a soft self - attention .",Introduction,Introduction,natural_language_inference,73,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",24,0.7272727272727273,36,0.13740458015267176,24,0.7272727272727273,1,1,model
38,"In ReSA , two parameter - untied RSS are respectively applied to two copies of the input sequence , where the tokens from one and another are called dependent and head tokens , respectively .",Introduction,Introduction,natural_language_inference,73,"['B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",25,0.7575757575757576,37,0.14122137404580154,25,0.7575757575757576,1,1,model
39,Re SA only models the sparse dependencies between the head and dependent tokens selected by the two RSS modules .,Introduction,Introduction,natural_language_inference,73,"['B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",26,0.7878787878787878,38,0.1450381679389313,26,0.7878787878787878,1,1,model
40,"Finally , we build an sentence - encoding model , "" reinforced self - attention network ( ReSAN ) "" , based on ReSA without any CNN / RNN structure .",Introduction,Introduction,natural_language_inference,73,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,0.8181818181818182,39,0.14885496183206107,27,0.8181818181818182,1,1,model
44,All the experiments codes are released at https://github.com/ taoshen58/DiSAN /tree/master/ReSAN .,Introduction,Introduction,natural_language_inference,73,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",31,0.9393939393939394,43,0.16412213740458015,31,0.9393939393939394,1,1,code
177,All experiments are conducted in Python with Tensorflow and run on a Nvidia GTX 1080 Ti .,Model Training,Model Training,natural_language_inference,73,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",34,0.918918918918919,176,0.6717557251908397,34,0.918918918918919,1,1,experimental-setup
178,"We use Adadelta as optimizer , which performs more stable than Adam on ReSAN .",Model Training,Model Training,natural_language_inference,73,"['O', 'B', 'B', 'B', 'B', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'O']",35,0.9459459459459459,177,0.6755725190839694,35,0.9459459459459459,1,1,experimental-setup
180,We use 300D Glo Ve 6B pre-trained vectors,Model Training,Model Training,natural_language_inference,73,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",37,1.0,179,0.683206106870229,37,1.0,1,1,experimental-setup
185,Natural Language Inference,Experiments,,natural_language_inference,73,"['B', 'I', 'I']",,,4,0.16666666666666666,184,0.7022900763358778,0,0.0,1,1,
193,"Compared to the methods from official leaderboard , ReSAN outperforms all the sentence encoding based methods and achieves the best test accuracy .",Experiments,Natural Language Inference,natural_language_inference,73,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O']",,,12,0.5,192,0.732824427480916,8,0.4,1,1,
194,"Specifically , compared to the last best models , i.e. , 600D Gumbel TreeLSTM encoders and 600D Residual stacked encoders , ReSAN uses far fewer parameters with better performance .",Experiments,Natural Language Inference,natural_language_inference,73,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",13,0.5416666666666666,193,0.7366412213740458,9,0.45,1,1,experiments
196,"Furthermore , ReSAN even outperforms the 300D SPINN - PI encoders by 3.1 %. , which is a recursive model and uses the result of an external semantic parsing tree as an extra input .",Experiments,Natural Language Inference,natural_language_inference,73,"['O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'O', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.625,195,0.7442748091603053,11,0.55,1,1,experiments
198,"Compared to the recurrent models ( e.g. , Bi - LSTM and Bi - GRU ) , ReSAN shows better prediction quality and more compelling efficiency due to parallelizable computations .",Experiments,Natural Language Inference,natural_language_inference,73,"['B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'O']",17,0.7083333333333334,197,0.7519083969465649,13,0.65,1,1,experiments
199,"Compared to the convolutional models ( i.e. , Multiwindow CNN and Hierarchical CNN ) , ReSAN significantly outperforms them by 3.1 % and 2.4 % respectively due to the weakness of CNNs in modeling long - range dependencies .",Experiments,Natural Language Inference,natural_language_inference,73,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.75,198,0.7557251908396947,14,0.7,1,1,experiments
200,"Compared to the attention - based models , multi-head attention and DiSAN , ReSAN uses a similar number of parameters with better test performance and less time cost .",Experiments,Natural Language Inference,natural_language_inference,73,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",19,0.7916666666666666,199,0.7595419847328244,15,0.75,1,1,experiments
204,"In terms of prediction quality , the results show that 1 ) the unselected head tokens do contribute to the prediction , bringing 0.2 % improvement ; 2 ) using separate RSS modules to select the head and dependent tokens improves accuracy by 0.5 % ; and 3 ) hard attention and soft self - attention modules improve the accuracy by 0.3 % and 2.9 % respectively .",Experiments,Natural Language Inference,natural_language_inference,73,"['B', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O']",,,23,0.9583333333333334,203,0.7748091603053435,19,0.95,1,1,ablation-analysis
2,Discourse Marker Augmented Network with Reinforcement Learning for Natural Language Inference,title,title,natural_language_inference,74,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004464285714285714,1,0.0,1,1,research-problem
4,"Natural Language Inference ( NLI ) , also known as Recognizing Textual Entailment ( RTE ) , is one of the most important problems in natural language processing .",abstract,abstract,natural_language_inference,74,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.1111111111111111,3,0.013392857142857142,1,0.1111111111111111,1,1,research-problem
6,"While current approaches mostly focus on the interaction architectures of the sentences , in this paper , we propose to transfer knowledge from some important discourse markers to augment the quality of the NLI model .",abstract,abstract,natural_language_inference,74,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O']",3,0.3333333333333333,5,0.022321428571428572,3,0.3333333333333333,1,1,research-problem
34,"In this paper , we propose a Discourse Marker Augmented Network for natural language inference , where we transfer the knowledge from the existing supervised task : Discourse Marker Prediction ( DMP ) , to an integrated NLI model .",Introduction,Introduction,natural_language_inference,74,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",21,0.5675675675675675,33,0.14732142857142858,21,0.42857142857142855,1,1,model
35,We first propose a sentence encoder model that learns the representations of the sentences from the DMP task and then inject the encoder to the NLI network .,Introduction,Introduction,natural_language_inference,74,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",22,0.5945945945945946,34,0.15178571428571427,22,0.4489795918367347,1,1,model
37,"In consideration of that different confidence level of the final labels should be discriminated , we employ reinforcement learning with a reward defined by the uniformity extent of the original labels to train the model .",Introduction,Introduction,natural_language_inference,74,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'O']",24,0.6486486486486487,36,0.16071428571428573,24,0.4897959183673469,1,1,model
153,We use the Stanford CoreNLP toolkit to tokenize the words and generate POS and NER tags .,Implementation Details,Implementation Details,natural_language_inference,74,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.08333333333333333,152,0.6785714285714286,1,0.08333333333333333,1,1,experimental-setup
154,"The word embeddings are initialized by 300d Glove , the dimensions of POS and NER embeddings are 30 and 10 .",Implementation Details,Implementation Details,natural_language_inference,74,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.16666666666666666,153,0.6830357142857143,2,0.16666666666666666,1,1,experimental-setup
156,We apply Tensorflow r 1.3 as our neural network framework .,Implementation Details,Implementation Details,natural_language_inference,74,"['O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.3333333333333333,155,0.6919642857142857,4,0.3333333333333333,1,1,experimental-setup
157,"We set the hidden size as 300 for all the LSTM layers and apply dropout between layers with an initial ratio of 0.9 , the decay rate as 0.97 for every 5000 step .",Implementation Details,Implementation Details,natural_language_inference,74,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O']",,,5,0.4166666666666667,156,0.6964285714285714,5,0.4166666666666667,1,1,experimental-setup
158,We use the AdaDelta for optimization as described in with ? as 0.95 and as 1 e - 8 .,Implementation Details,Implementation Details,natural_language_inference,74,"['O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.5,157,0.7008928571428571,6,0.5,1,1,experimental-setup
159,We set our batch size as 36 and the initial learning rate as 0.6 .,Implementation Details,Implementation Details,natural_language_inference,74,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O']",,,7,0.5833333333333334,158,0.7053571428571429,7,0.5833333333333334,1,1,experimental-setup
162,"For DMP task , we use stochastic gradient descent with initial learning rate as 0.1 , and we anneal by half each time the validation accuracy is lower than the previous epoch .",Implementation Details,Implementation Details,natural_language_inference,74,"['B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O']",,,10,0.8333333333333334,161,0.71875,10,0.8333333333333334,1,1,experimental-setup
163,"The number of epochs is set to be 10 , and the feedforward dropout rate is 0.2 .",Implementation Details,Implementation Details,natural_language_inference,74,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'O']",11,0.9166666666666666,162,0.7232142857142857,11,0.9166666666666666,1,1,experimental-setup
169,"Obviously , the performance of most of the integrated methods are better than the sentence encoding based models above .",Results,Results,natural_language_inference,74,"['O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",4,0.5714285714285714,168,0.75,4,0.5714285714285714,1,1,results
172,"The performance of our model achieves 89.6 % on SNLI , 80.3 % on matched MultiNLI and 79.4 % on mismatched MultiNLI , which are all state - of - the - art results .",Results,Results,natural_language_inference,74,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,7,1.0,171,0.7633928571428571,7,1.0,1,1,results
174,"As shown in , we conduct an ablation experiment on SNLI development dataset to evaluate the individual contribution of each component of our model .",Ablation Analysis,Ablation Analysis,natural_language_inference,74,"['O', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.04,173,0.7723214285714286,1,0.08333333333333333,1,1,ablation-analysis
176,"The result is obviously not satisfactory , which indicates that only using sentence embedding from discourse markers to predict the answer is not ideal in large - scale datasets .",Ablation Analysis,Ablation Analysis,natural_language_inference,74,"['O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']",,,3,0.12,175,0.78125,3,0.25,1,1,ablation-analysis
177,"We then remove the sentence encoder model , which means we do n't use the knowledge transferred from the DMP task and thus the representations r p and r hare set to be zero vectors in the equation ( 6 ) and the equation .",Ablation Analysis,Ablation Analysis,natural_language_inference,74,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.16,176,0.7857142857142857,4,0.3333333333333333,1,1,ablation-analysis
178,"We observe that the performance drops significantly to 87 . 24 % , which is nearly 1.5 % to our DMAN model , which indicates that the discourse markers have deep connections with the logical relations between two sentences they links .",Ablation Analysis,Ablation Analysis,natural_language_inference,74,"['O', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.2,177,0.7901785714285714,5,0.4166666666666667,1,1,ablation-analysis
181,"we remove the character - level embedding and the POS and NER features , the performance drops a lot .",Ablation Analysis,Ablation Analysis,natural_language_inference,74,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'B-b', 'I-b', 'I-b', 'O']",8,0.32,180,0.8035714285714286,8,0.6666666666666666,1,1,ablation-analysis
183,The exact match feature also demonstrates its effectiveness in the ablation result .,Ablation Analysis,Ablation Analysis,natural_language_inference,74,"['O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",10,0.4,182,0.8125,10,0.8333333333333334,1,1,ablation-analysis
184,"Finally , we ablate the reinforcement learning part , in other words , we only use the original loss function to optimize the model ( set ? = 1 ) .",Ablation Analysis,Ablation Analysis,natural_language_inference,74,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.44,183,0.8169642857142857,11,0.9166666666666666,1,1,ablation-analysis
185,"The result drops about 0.5 % , which proves that it is helpful to utilize all the information from the annotators .",Ablation Analysis,Ablation Analysis,natural_language_inference,74,"['O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.48,184,0.8214285714285714,12,1.0,1,1,ablation-analysis
4,Directly reading documents and being able to answer questions from them is an unsolved challenge .,abstract,abstract,natural_language_inference,75,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.014778325123152709,1,0.14285714285714285,1,1,research-problem
5,"To avoid its inherent difficulty , question answering ( QA ) has been directed towards using Knowledge Bases ( KBs ) instead , which has proven effective .",abstract,abstract,natural_language_inference,75,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.2857142857142857,4,0.019704433497536946,2,0.2857142857142857,1,1,research-problem
8,"To compare using KBs , information extraction or Wikipedia documents directly in a single framework we construct an analysis tool , WIKIMOVIES , a QA dataset that contains raw text alongside a preprocessed KB , in the domain of movies .",abstract,abstract,natural_language_inference,75,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.7142857142857143,7,0.034482758620689655,5,0.7142857142857143,1,1,research-problem
25,"In this work we propose the Key - Value Memory Network ( KV - MemNN ) , a new neural network architecture that generalizes the original Memory Network and can work with either knowledge source .",Introduction,Introduction,natural_language_inference,75,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.7368421052631579,24,0.11822660098522167,14,0.7368421052631579,1,1,model
26,The KV - MemNN performs QA by first storing facts in a key - value structured memory before reasoning on them in order to predict an answer .,Introduction,Introduction,natural_language_inference,75,"['O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.7894736842105263,25,0.12315270935960591,15,0.7894736842105263,1,1,model
27,"The memory is designed so that the model learns to use keys to address relevant memories with respect to the question , whose corresponding values are subsequently returned .",Introduction,Introduction,natural_language_inference,75,"['O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-p', 'B-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.8421052631578947,26,0.12807881773399016,16,0.8421052631578947,1,1,model
28,"This structure allows the model to encode prior knowledge for the considered task and to leverage possibly complex transforms between keys and values , while still being trained using standard backpropagation via stochastic gradient descent .",Introduction,Introduction,natural_language_inference,75,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.8947368421052632,27,0.1330049261083744,17,0.8947368421052632,1,1,model
161,WikiMovies,Window + Title,,natural_language_inference,75,['B'],['B-n'],['B-b'],50,0.5434782608695652,160,0.7881773399014779,0,0.0,1,1,results
170,"However , Key - Value Memory Networks outperform all other methods on all three data source types .",Window + Title,WikiMovies,natural_language_inference,75,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",59,0.6413043478260869,169,0.8325123152709359,9,0.36,1,1,results
171,"Reading from Wikipedia documents directly ( Doc ) outperforms an IE - based KB ( IE ) , which is an encouraging result towards automated machine reading though a gap to a humanannotated KB still remains ( 93.9 vs. 76.2 ) .",Window + Title,WikiMovies,natural_language_inference,75,"['B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",60,0.6521739130434783,170,0.8374384236453202,10,0.4,1,1,results
187,WikiQA,Window + Title,,natural_language_inference,75,['B'],['B-n'],['B-b'],76,0.8260869565217391,186,0.916256157635468,0,0.0,1,1,results
202,"Key - Value Memory Networks outperform a large set of other methods , although the results of the L.D.C. method of are very similar .",Window + Title,WikiQA,natural_language_inference,75,"['B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-s', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",91,0.9891304347826086,201,0.9901477832512315,15,0.9375,1,1,results
16,"Recognizing textual entailment ( RTE ) is the task of determining whether two natural language sentences are ( i ) contradicting each other , ( ii ) not related , or whether ( iii ) the first sentence ( called premise ) entails the second sentence ( called hypothesis ) .",INTRODUCTION,INTRODUCTION,natural_language_inference,76,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.14285714285714285,15,0.10273972602739725,2,0.14285714285714285,1,1,research-problem
17,"This task is important since many natural language processing ( NLP ) problems , such as information extraction , relation extraction , text summarization or machine translation , rely on it explicitly or implicitly and could benefit from more accurate RTE systems .",INTRODUCTION,INTRODUCTION,natural_language_inference,76,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O']",3,0.21428571428571427,16,0.1095890410958904,3,0.21428571428571427,1,1,research-problem
25,"In contrast , we are proposing an attentive neural network that is capable of reasoning over entailments of pairs of words and phrases by processing the hypothesis conditioned on the premise .",INTRODUCTION,INTRODUCTION,natural_language_inference,76,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'O']",,,11,0.7857142857142857,24,0.1643835616438356,11,0.7857142857142857,1,1,model
26,"Our contributions are threefold : ( i ) We present a neural model based on LSTMs that reads two sentences in one go to determine entailment , as opposed to mapping each sentence independently into a semantic space ( 2.2 ) , ( ii ) We extend this model with a neural word - by - word attention mechanism to encourage reasoning over entailments of pairs of words and phrases ( 2.4 ) , and ( iii ) We provide a detailed qualitative analysis of neural attention for RTE ( 4.1 ) .",INTRODUCTION,INTRODUCTION,natural_language_inference,76,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,12,0.8571428571428571,25,0.17123287671232876,12,0.8571428571428571,1,1,model
99,We found that processing the hypothesis conditioned on the premise instead of encoding each sentence independently gives an improvement of 3.3 percentage points in accuracy over Bowman et al. 's LSTM .,EXPERIMENTS,Conditional Encoding,natural_language_inference,76,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.25,98,0.6712328767123288,13,0.38235294117647056,1,1,results
105,Our LSTM outperforms a simple lexicalized classifier by 2.7 percentage points .,EXPERIMENTS,Conditional Encoding,natural_language_inference,76,"['B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",19,0.36538461538461536,104,0.7123287671232876,19,0.5588235294117647,1,1,results
108,"By incorporating an attention mechanism we found a 0.9 percentage point improvement over a single LSTM with a hidden size of 159 , and a 1.4 percentage point increase over a benchmark model that uses two LSTMs for conditional encoding ( one for the premise and one for the hypothesis conditioned on the representation of the premise ) .",EXPERIMENTS,Attention,natural_language_inference,76,"['O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,22,0.4230769230769231,107,0.7328767123287672,22,0.6470588235294118,1,1,results
114,Enabling the model to attend over output vectors of the premise for every word in the hypothesis yields another 1.2 percentage point improvement compared to attending based only on the last output vector of the premise .,EXPERIMENTS,Attention,natural_language_inference,76,"['B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O']",,,28,0.5384615384615384,113,0.773972602739726,28,0.8235294117647058,1,1,results
117,Allowing the model to also attend over the hypothesis based on the premise does not seem to improve performance for RTE .,EXPERIMENTS,Two-way Attention,natural_language_inference,76,"['B', 'O', 'B', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'B', 'B', 'B', 'O']","['B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'O', 'O', 'B-n', 'B-n', 'B-p', 'B-n', 'O']","['B-p', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'O', 'B-b', 'B-b', 'B-p', 'B-ob', 'O']",31,0.5961538461538461,116,0.7945205479452054,31,0.9117647058823529,1,1,results
2,Making Neural QA as Simple as Possible but not Simpler,title,title,natural_language_inference,77,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.003663003663003663,1,0.0,1,1,research-problem
4,Recent development of large - scale question answering ( QA ) datasets triggered a substantial amount of research into end - toend neural architectures for QA .,abstract,abstract,natural_language_inference,77,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O']",1,0.16666666666666666,3,0.01098901098901099,1,0.16666666666666666,1,1,research-problem
11,Question answering is an important end - user task at the intersection of natural language processing ( NLP ) and information retrieval ( IR ) .,Introduction,Introduction,natural_language_inference,77,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.010526315789473684,10,0.03663003663003663,1,0.038461538461538464,1,1,research-problem
28,"In particular , we develop a simple neural , bag - of - words ( BoW ) - and a recurrent neural network ( RNN ) baseline , namely FastQA .",Introduction,Introduction,natural_language_inference,77,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'O']",18,0.18947368421052632,27,0.0989010989010989,18,0.6923076923076923,1,1,model
29,"Crucially , both models do not make use of a complex interaction layer but model interaction between question and context only through computable features on the word level .",Introduction,Introduction,natural_language_inference,77,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",19,0.2,28,0.10256410256410256,19,0.7307692307692307,1,1,model
141,BoW Model,,,natural_language_inference,77,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",0,0.0,140,0.5128205128205128,1,0.125,1,1,experimental-setup
142,The BoW model is trained on spans up to length 10 to keep the computation tractable .,BoW Model,BoW Model,natural_language_inference,77,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.015873015873015872,141,0.5164835164835165,2,0.25,1,1,experimental-setup
144,As pre-processing steps we lowercase all inputs and tokenize it using spacy 4 .,BoW Model,BoW Model,natural_language_inference,77,"['B', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'O']","['B-p', 'B-n', 'I-n', 'O', 'B-n', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-p', 'B-n', 'O', 'O']","['B-p', 'B-b', 'I-b', 'O', 'B-b', 'B-ob', 'I-ob', 'O', 'B-b', 'O', 'B-p', 'B-ob', 'O', 'O']",3,0.047619047619047616,143,0.5238095238095238,4,0.5,1,1,experimental-setup
145,The binary word in question feature is computed on lemmas provided by spacy and restricted to alphanumeric words that are not stopwords .,BoW Model,BoW Model,natural_language_inference,77,"['O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",4,0.06349206349206349,144,0.5274725274725275,5,0.625,1,1,experimental-setup
146,"Throughout all experiments we use a hidden dimensionality of n = 150 , dropout at the input embeddings with the same mask for all words and a rate of 0.2 and 300 - dimensional fixed word - embeddings from Glove .",BoW Model,BoW Model,natural_language_inference,77,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'O']",,,5,0.07936507936507936,145,0.5311355311355311,6,0.75,1,1,experimental-setup
147,We employed ADAM for optimization with an initial learning - rate of 10 ?3 which was halved whenever the F 1 measure on the development set dropped between epochs .,BoW Model,BoW Model,natural_language_inference,77,"['O', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.09523809523809523,146,0.5347985347985348,7,0.875,1,1,experimental-setup
148,We used mini-batches of size 32 .,BoW Model,BoW Model,natural_language_inference,77,"['O', 'B', 'B', 'B', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'B-p', 'B-n', 'B-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'B-b', 'B-ob', 'O']",7,0.1111111111111111,147,0.5384615384615384,8,1.0,1,1,experimental-setup
149,FastQA,BoW Model,,natural_language_inference,77,['B'],['B-n'],['B-b'],8,0.12698412698412698,148,0.5421245421245421,0,0.0,1,1,experimental-setup
151,We tokenize the input on whitespaces ( exclusive ) and non-alphanumeric characters ( inclusive ) .,BoW Model,FastQA,natural_language_inference,77,"['O', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",10,0.15873015873015872,150,0.5494505494505495,2,0.046511627906976744,1,1,experimental-setup
152,The binary word in question feature is computed on the words as they appear in context .,BoW Model,FastQA,natural_language_inference,77,"['O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'O']",,,11,0.1746031746031746,151,0.5531135531135531,3,0.06976744186046512,1,1,experimental-setup
153,"Throughout all experiments we use a hidden dimensionality of n = 300 , variational dropout at the input embeddings with the same mask for all words and a rate of 0.5 and 300 dimensional fixed word - embeddings from Glove .",BoW Model,FastQA,natural_language_inference,77,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'O']",,,12,0.19047619047619047,152,0.5567765567765568,4,0.09302325581395349,1,1,experimental-setup
154,We employed ADAM for optimization with an initial learning - rate of 10 ?3 which was halved whenever the F 1 measure on the development set dropped between checkpoints .,BoW Model,FastQA,natural_language_inference,77,"['O', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,13,0.20634920634920634,153,0.5604395604395604,5,0.11627906976744186,1,1,experimental-setup
175,Our neural BoW baseline achieves good results on both datasets ( Tables 3 and 1 ) 5 .,BoW Model,Cutting Context Length Because News,natural_language_inference,77,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",34,0.5396825396825397,174,0.6373626373626373,26,0.6046511627906976,1,1,results
176,"For instance , it outperforms a feature rich logistic - regression baseline on the SQuAD development set and nearly reaches the BiLSTM baseline system ( i.e. , FastQA without character embeddings and features ) .",BoW Model,Cutting Context Length Because News,natural_language_inference,77,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",35,0.5555555555555556,175,0.6410256410256411,27,0.627906976744186,1,1,results
179,It is very competitive to previously established stateof - the - art results on the two datasets and even improves those for News QA .,BoW Model,Cutting Context Length Because News,natural_language_inference,77,"['O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",38,0.6031746031746031,178,0.652014652014652,30,0.6976744186046512,1,1,results
2,"Compare , Compress and Propagate : Enhancing Neural Architectures with Alignment Factorization for Natural Language Inference",title,title,natural_language_inference,78,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0036231884057971015,1,0.0,1,1,research-problem
4,This paper presents a new deep learning architecture for Natural Language Inference ( NLI ) .,abstract,abstract,natural_language_inference,78,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.125,3,0.010869565217391304,1,0.125,1,1,research-problem
14,"More concretely , given a premise and hypothesis , NLI aims to detect whether the latter entails or contradicts the former .",Introduction,Introduction,natural_language_inference,78,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.05263157894736842,13,0.04710144927536232,2,0.05263157894736842,1,1,research-problem
26,There are several new novel components in our work .,Introduction,Introduction,natural_language_inference,78,"['O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",14,0.3684210526315789,25,0.09057971014492754,14,0.3684210526315789,1,1,model
27,"Firstly , we propose a compare , compress and propagate ( Com Prop ) architecture where compressed alignment features are propagated to upper layers ( such as a RNN - based encoder ) for enhancing representation learning .",Introduction,Introduction,natural_language_inference,78,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",15,0.39473684210526316,26,0.09420289855072464,15,0.39473684210526316,1,1,model
28,"Secondly , in order to achieve an efficient propagation of alignment features , we propose alignment factorization layers to reduce each alignment vector to a single scalar valued feature .",Introduction,Introduction,natural_language_inference,78,"['O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.42105263157894735,27,0.09782608695652174,16,0.42105263157894735,1,1,model
29,"Each scalar valued feature is used to augment the base word representation , allowing the subsequent RNN encoder layers to benefit from not only global but also cross sentence information .",Introduction,Introduction,natural_language_inference,78,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.4473684210526316,28,0.10144927536231885,17,0.4473684210526316,1,1,model
192,We implement our model in TensorFlow and train them on Nvidia P100 GPUs .,Implementation Details,Implementation Details,natural_language_inference,78,"['O', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.09090909090909091,191,0.6920289855072463,1,0.09090909090909091,1,1,experimental-setup
193,"We use the Adam optimizer ( Kingma and Ba , 2014 ) with an initial learning rate of 0.0003 .",Implementation Details,Implementation Details,natural_language_inference,78,"['O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",2,0.18181818181818182,192,0.6956521739130435,2,0.18181818181818182,1,1,experimental-setup
194,L2 regularization is set to 10 ?6 .,Implementation Details,Implementation Details,natural_language_inference,78,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",3,0.2727272727272727,193,0.6992753623188406,3,0.2727272727272727,1,1,experimental-setup
195,"Dropout with a keep probability of 0.8 is applied after each fullyconnected , recurrent or highway layer .",Implementation Details,Implementation Details,natural_language_inference,78,"['B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.36363636363636365,194,0.7028985507246377,4,0.36363636363636365,1,1,experimental-setup
196,"The batch size is tuned amongst { 128 , 256 , 512 } .",Implementation Details,Implementation Details,natural_language_inference,78,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.45454545454545453,195,0.7065217391304348,5,0.45454545454545453,1,1,experimental-setup
197,"The number of latent factors k for the factorization layer is tuned amongst { 5 , 10 , 50 , 100 , 150 } .",Implementation Details,Implementation Details,natural_language_inference,78,"['O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.5454545454545454,196,0.7101449275362319,6,0.5454545454545454,1,1,experimental-setup
198,The size of the hidden layers of the highway network layers are set to 300 .,Implementation Details,Implementation Details,natural_language_inference,78,"['O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O']",,,7,0.6363636363636364,197,0.7137681159420289,7,0.6363636363636364,1,1,experimental-setup
199,All parameters are initialized with xavier initialization .,Implementation Details,Implementation Details,natural_language_inference,78,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",8,0.7272727272727273,198,0.717391304347826,8,0.7272727272727273,1,1,experimental-setup
200,Word embeddings are preloaded with 300d Glo Ve embeddings and fixed during training .,Implementation Details,Implementation Details,natural_language_inference,78,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'O']",9,0.8181818181818182,199,0.7210144927536232,9,0.8181818181818182,1,1,experimental-setup
201,Sequence lengths are padded to batch - wise maximum .,Implementation Details,Implementation Details,natural_language_inference,78,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.9090909090909091,200,0.7246376811594203,10,0.9090909090909091,1,1,experimental-setup
202,The batch order is ( randomly ) sorted within buckets following .,Implementation Details,Implementation Details,natural_language_inference,78,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'O', 'O']",11,1.0,201,0.7282608695652174,11,1.0,1,1,experimental-setup
204,Table 1 reports our results on the SNLI benchmark .,Experimental Results,Experimental Results,natural_language_inference,78,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O']",1,0.02631578947368421,203,0.7355072463768116,1,0.02631578947368421,1,1,results
205,"On the cross sentence ( single model setting ) , the performance of our proposed CAFE model is extremely competitive .",Experimental Results,Experimental Results,natural_language_inference,78,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",2,0.05263157894736842,204,0.7391304347826086,2,0.05263157894736842,1,1,results
207,CAFE obtains,Experimental Results,Experimental Results,natural_language_inference,78,"['B', 'B']","['B-n', 'B-p']","['B-b', 'B-p']",4,0.10526315789473684,206,0.7463768115942029,4,0.10526315789473684,1,1,results
208,"88.5 % accuracy on the SNLI test set , an extremely competitive score on the extremely popular benchmark .",Experimental Results,Experimental Results,natural_language_inference,78,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.13157894736842105,207,0.75,5,0.13157894736842105,1,1,results
210,"For example , CAFE also achieves 88.3 % and 88.1 % test accuracy with only 3.5 M and 1.5 M parameters",Experimental Results,Experimental Results,natural_language_inference,78,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",7,0.18421052631578946,209,0.7572463768115942,7,0.18421052631578946,1,1,results
214,"Due to resource constraints , we did not train CAFE + ELMo ensembles but a single run ( and single model ) of CAFE + ELMo already achieves 89.0 score on SNLI .",Experimental Results,Experimental Results,natural_language_inference,78,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",11,0.2894736842105263,213,0.7717391304347826,11,0.2894736842105263,1,1,results
216,This outperforms the state - of - theart ESIM and DIIN models with only a fraction of the parameter cost .,Experimental Results,Experimental Results,natural_language_inference,78,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",13,0.34210526315789475,215,0.7789855072463768,13,0.34210526315789475,1,1,results
218,"Moreover , our lightweight adaptation achieves 87.7 % with only 750K parameters , which makes it extremely performant amongst models having the same amount of parameters such as the decomposable attention model ( 86.8 % ) .",Experimental Results,Experimental Results,natural_language_inference,78,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.39473684210526316,217,0.7862318840579711,15,0.39473684210526316,1,1,results
219,"Finally , an ensemble of 5 CAFE models achieves 89.3 % test accuracy , the best test scores on the SNLI benchmark to date 3 .",Experimental Results,Experimental Results,natural_language_inference,78,"['O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.42105263157894735,218,0.7898550724637681,16,0.42105263157894735,1,1,results
228,"On MultiNLI , CAFE significantly outperforms ESIM , a strong state - of - the - art model on both settings .",Experimental Results,Experimental Results,natural_language_inference,78,"['O', 'B', 'O', 'B', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'O', 'B-n', 'B-n', 'I-n', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'O', 'B-b', 'B-b', 'I-b', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",25,0.6578947368421053,227,0.822463768115942,25,0.6578947368421053,1,1,results
229,We also outperform the ESIM + Read model .,Experimental Results,Experimental Results,natural_language_inference,78,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",26,0.6842105263157895,228,0.8260869565217391,26,0.6842105263157895,1,1,results
230,An ensemble of CAFE models achieve competitive re-sult on the MultiNLI dataset .,Experimental Results,Experimental Results,natural_language_inference,78,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",27,0.7105263157894737,229,0.8297101449275363,27,0.7105263157894737,1,1,results
231,"On SciTail , our proposed CAFE model achieves state - of - the - art performance .",Experimental Results,Experimental Results,natural_language_inference,78,"['B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",28,0.7368421052631579,230,0.8333333333333334,28,0.7368421052631579,1,1,results
232,The performance gain over strong baselines such as DecompAtt and ESIM are ?,Experimental Results,Experimental Results,natural_language_inference,78,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'B-p', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'B-ob', 'B-p', 'O']",29,0.7631578947368421,231,0.8369565217391305,29,0.7631578947368421,1,1,results
233,10 % ? 13 % in terms of accuracy .,Experimental Results,Experimental Results,natural_language_inference,78,"['B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'O']",30,0.7894736842105263,232,0.8405797101449275,30,0.7894736842105263,1,1,results
234,"CAFE also outperforms DGEM , which uses a graph - based attention for improved performance , by a significant margin of 5 % .",Experimental Results,Experimental Results,natural_language_inference,78,"['B', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'O', 'B-n', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'O', 'B-b', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",31,0.8157894736842105,233,0.8442028985507246,31,0.8157894736842105,1,1,results
239,The 1 - layer linear setting performs the best and is therefore reported in .,Experimental Results,Experimental Results,natural_language_inference,78,"['O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O']",36,0.9473684210526315,238,0.8623188405797102,36,0.9473684210526315,1,1,ablation-analysis
240,Using ReLU seems to be worse than nonlinear FC layers .,Experimental Results,Experimental Results,natural_language_inference,78,"['B', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'O']","['B-p', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",37,0.9736842105263158,239,0.8659420289855072,37,0.9736842105263158,1,1,ablation-analysis
243,"In , we explore the utility of using character and syntactic embeddings , which we found to have helped CAFE marginally .",Ablation Study,Ablation Study,natural_language_inference,78,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-n', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-ob', 'O', 'O']",1,0.034482758620689655,242,0.8768115942028986,1,0.125,1,1,ablation-analysis
244,"In ( 4 ) , we remove the inter-attention alignment features , which naturally impact the model performance significantly .",Ablation Study,Ablation Study,natural_language_inference,78,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'B-ob', 'O']",2,0.06896551724137931,243,0.8804347826086957,2,0.25,1,1,ablation-analysis
246,We observe that both highway layers have marginally helped the over all performance .,Ablation Study,Ablation Study,natural_language_inference,78,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.13793103448275862,245,0.8876811594202898,4,0.5,1,1,ablation-analysis
248,We observe that the Sub and Concat compositions were more important than the Mul composition .,Ablation Study,Ablation Study,natural_language_inference,78,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",6,0.20689655172413793,247,0.894927536231884,6,0.75,1,1,ablation-analysis
250,"Finally , in ( 10 ) , we replace the LSTM encoder with a BiLSTM , observing that adding bi-directionality did not improve performance for our model .",Ablation Study,Ablation Study,natural_language_inference,78,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-b', 'I-b', 'I-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.27586206896551724,249,0.9021739130434783,8,1.0,1,1,ablation-analysis
2,Distributed Representations of Sentences and Documents,title,title,natural_language_inference,79,"['B', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0037313432835820895,1,0.0,1,1,research-problem
23,"In this paper , we propose Paragraph Vector , an unsupervised framework that learns continuous distributed vector representations for pieces of texts .",Introduction,Introduction,natural_language_inference,79,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.14925373134328357,22,0.08208955223880597,10,0.30303030303030304,1,1,model
25,"The name Paragraph Vector is to emphasize the fact that the method can be applied to variable - length pieces of texts , anything from a phrase or sentence to a large document .",Introduction,Introduction,natural_language_inference,79,"['O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.1791044776119403,24,0.08955223880597014,12,0.36363636363636365,1,1,model
26,"In our model , the vector representation is trained to be useful for predicting words in a paragraph .",Introduction,Introduction,natural_language_inference,79,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'O']",13,0.19402985074626866,25,0.09328358208955224,13,0.3939393939393939,1,1,model
27,"More precisely , we concatenate the paragraph vector with several word vectors from a paragraph and predict the following word in the given context .",Introduction,Introduction,natural_language_inference,79,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",14,0.208955223880597,26,0.09701492537313433,14,0.42424242424242425,1,1,model
28,Both word vectors and paragraph vectors are trained by the stochastic gradient descent and backpropagation .,Introduction,Introduction,natural_language_inference,79,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O']",15,0.22388059701492538,27,0.10074626865671642,15,0.45454545454545453,1,1,model
29,"While paragraph vectors are unique among paragraphs , the word vectors are shared .",Introduction,Introduction,natural_language_inference,79,"['O', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O']",,,16,0.23880597014925373,28,0.1044776119402985,16,0.48484848484848486,1,1,model
30,"At prediction time , the paragraph vectors are inferred by fixing the word vectors and training the new paragraph vector until convergence .",Introduction,Introduction,natural_language_inference,79,"['B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",17,0.2537313432835821,29,0.10820895522388059,17,0.5151515151515151,1,1,model
163,"We learn the word vectors and paragraph vectors using 75,000 training documents ( 25,000 labeled and 50,000 unlabeled instances ) .",Experiments,The dataset can be downloaded at : http://nlp.Stanford.edu/sentiment/,natural_language_inference,79,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",27,0.5510204081632653,162,0.6044776119402985,20,0.47619047619047616,1,1,experimental-setup
164,"The paragraph vectors for the 25,000 labeled instances are then fed through a neural network with one hidden layer with 50 units and a logistic classifier to learn to predict the sentiment .",Experiments,The dataset can be downloaded at : http://nlp.Stanford.edu/sentiment/,natural_language_inference,79,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O']",,,28,0.5714285714285714,163,0.6082089552238806,21,0.5,1,1,experimental-setup
169,"In particular , we cross validate the window size , and the optimal window size is 10 words .",Experiments,The dataset can be downloaded at : http://nlp.Stanford.edu/sentiment/,natural_language_inference,79,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",33,0.673469387755102,168,0.6268656716417911,26,0.6190476190476191,1,1,experimental-setup
170,"The vector presented to the classifier is a concatenation of two vectors , one from PV - DBOW and one from PV - DM .",Experiments,The dataset can be downloaded at : http://nlp.Stanford.edu/sentiment/,natural_language_inference,79,"['O', 'B', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O']",34,0.6938775510204082,169,0.6305970149253731,27,0.6428571428571429,1,1,experimental-setup
171,"In PV - DBOW , the learned vector representations have 400 dimensions .",Experiments,The dataset can be downloaded at : http://nlp.Stanford.edu/sentiment/,natural_language_inference,79,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",35,0.7142857142857143,170,0.6343283582089553,28,0.6666666666666666,1,1,experimental-setup
172,"In PV - DM , the learned vector representations have 400 dimensions for both words and documents .",Experiments,The dataset can be downloaded at : http://nlp.Stanford.edu/sentiment/,natural_language_inference,79,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']",,,36,0.7346938775510204,171,0.6380597014925373,29,0.6904761904761905,1,1,experimental-setup
173,"To predict the 10 - th word , we concatenate the paragraph vectors and word vectors .",Experiments,The dataset can be downloaded at : http://nlp.Stanford.edu/sentiment/,natural_language_inference,79,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",37,0.7551020408163265,172,0.6417910447761194,30,0.7142857142857143,1,1,experimental-setup
174,"Special characters such as , .!?",Experiments,The dataset can be downloaded at : http://nlp.Stanford.edu/sentiment/,natural_language_inference,79,"['B', 'I', 'B', 'I', 'B', 'I']","['B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n']","['B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b']",38,0.7755102040816326,173,0.6455223880597015,31,0.7380952380952381,1,1,experimental-setup
175,are treated as a normal word .,Experiments,The dataset can be downloaded at : http://nlp.Stanford.edu/sentiment/,natural_language_inference,79,"['O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",39,0.7959183673469388,174,0.6492537313432836,32,0.7619047619047619,1,1,experimental-setup
179,"As can be seen from the for long documents , bag - of - words models perform quite well and it is difficult to improve upon them using word vectors .",Experiments,The dataset can be downloaded at : http://nlp.Stanford.edu/sentiment/,natural_language_inference,79,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",43,0.8775510204081632,178,0.664179104477612,36,0.8571428571428571,1,1,results
181,The combination of two models yields an improvement approximately 1.5 % in terms of error rates .,Experiments,The dataset can be downloaded at : http://nlp.Stanford.edu/sentiment/,natural_language_inference,79,"['O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",45,0.9183673469387755,180,0.6716417910447762,38,0.9047619047619048,1,1,results
184,The method described in this paper is the only approach that goes significantly beyond the barrier of 10 % error rate .,Experiments,Another significant improvement comes from the work of .,natural_language_inference,79,"['O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",48,0.9795918367346939,183,0.6828358208955224,41,0.9761904761904762,1,1,results
185,It achieves 7.42 % which is another 1.3 % absolute improvement ( or 15 % relative improvement ) over the best previous result of ..,Experiments,Another significant improvement comes from the work of .,natural_language_inference,79,"['O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",49,1.0,184,0.6865671641791045,42,1.0,1,1,results
2,Deep Learning for Answer Sentence Selection,title,,natural_language_inference,8,"['O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004739336492890996,1,0.0,1,1,research-problem
36,"In this paper , we show that a neural network - based sentence model can be applied to the task of answer sentence selection .",Introduction,Introduction,natural_language_inference,8,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",26,0.7647058823529411,35,0.16587677725118483,26,0.7647058823529411,1,1,model
37,"We construct two distributional sentence models ; first a bag - of - words model , and second , a bigram model based on a convolutional neural network .",Introduction,Introduction,natural_language_inference,8,"['O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",27,0.7941176470588235,36,0.17061611374407584,27,0.7941176470588235,1,1,model
38,"Assuming a set of pre-trained semantic word embeddings , we train a supervised model to learn a semantic matching between question and answer pairs .",Introduction,Introduction,natural_language_inference,8,"['B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",28,0.8235294117647058,37,0.17535545023696683,28,0.8235294117647058,1,1,model
40,"We also present an enhanced version of this model , which combines the signal of the distributed matching algorithm with two simple word matching features .",Introduction,Introduction,natural_language_inference,8,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",30,0.8823529411764706,39,0.1848341232227488,30,0.8823529411764706,1,1,model
150,We used word embeddings ( d = 50 ) that were computed using Collobert and Weston 's neural language model and provided by Turian et al ..,Experimental setup,Experimental setup,natural_language_inference,8,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.05,149,0.7061611374407583,1,0.05,1,1,experimental-setup
152,"The other model weights were randomly intitialised using a Gaussian distribution ( = 0 , ? = 0.01 ) .",Experimental setup,Experimental setup,natural_language_inference,8,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.15,151,0.7156398104265402,3,0.15,1,1,experimental-setup
153,All hyperparameters were optimised via grid search on the MAP score on the development data .,Experimental setup,Experimental setup,natural_language_inference,8,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.2,152,0.7203791469194313,4,0.2,1,1,experimental-setup
154,We use the AdaGrad algorithm for training .,Experimental setup,Experimental setup,natural_language_inference,8,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",5,0.25,153,0.7251184834123223,5,0.25,1,1,experimental-setup
159,"L - BFGS was used to train the logistic regression classifier , with L2 regulariser of 0.01 .",Experimental setup,Experimental setup,natural_language_inference,8,"['B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",10,0.5,158,0.7488151658767772,10,0.5,1,1,experimental-setup
161,"As can be seen , the bigram model performs better than the unigram model and the addition of the IDF - weighted word count features significantly improve performance for both models by 10 % - 15 % .",Experimental setup,Experimental setup,natural_language_inference,8,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'I-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.6,160,0.7582938388625592,12,0.6,1,1,results
169,"As can be seen in , our best models ( bigram + count ) outperform all baselines and prior work on MAP and are very close to the best model proposed by Yih et al. on MRR .",Experimental setup,Experimental setup,natural_language_inference,8,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,1.0,168,0.7962085308056872,20,1.0,1,1,results
2,DR- BiLSTM : Dependent Reading Bidirectional LSTM for Natural Language Inference,title,title,natural_language_inference,80,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0034482758620689655,1,0.0,1,1,research-problem
4,We present a novel deep learning architecture to address the natural language inference ( NLI ) task .,abstract,abstract,natural_language_inference,80,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",1,0.16666666666666666,3,0.010344827586206896,1,0.16666666666666666,1,1,research-problem
12,"The goal of NLI is to identify the logical relationship ( entailment , neutral , or contradiction ) between a premise and a corresponding hypothesis .",Introduction,Introduction,natural_language_inference,80,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.07142857142857142,11,0.03793103448275862,2,0.5,1,1,research-problem
30,We propose a dependent reading bidirectional LSTM ( DR - BiLSTM ) model to address these limitations .,Introduction,H b,natural_language_inference,80,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",20,0.7142857142857143,29,0.1,13,0.6190476190476191,1,1,model
31,"Given a premise u and a hypothesis v , our model first encodes them considering dependency on each other .",Introduction,H b,natural_language_inference,80,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",21,0.75,30,0.10344827586206896,14,0.6666666666666666,1,1,model
32,"Next , the model employs a soft attention mechanism to extract relevant information from these encodings .",Introduction,H b,natural_language_inference,80,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",22,0.7857142857142857,31,0.10689655172413794,15,0.7142857142857143,1,1,model
33,"The augmented sentence representations are then passed to the inference stage , which uses a similar dependent reading strategy in both directions , i.e. u ? v and v ? u .",Introduction,H b,natural_language_inference,80,"['O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",23,0.8214285714285714,32,0.1103448275862069,16,0.7619047619047619,1,1,model
34,"Finally , a decision is made through a multi - layer perceptron ( MLP ) based on the aggregated information .",Introduction,H b,natural_language_inference,80,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",24,0.8571428571428571,33,0.11379310344827587,17,0.8095238095238095,1,1,model
128,We use pre-trained 300 - D Glove 840B vectors to initialize our word embedding vectors .,Experimental Setup,Experimental Setup,natural_language_inference,80,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.023809523809523808,127,0.4379310344827586,1,0.1,1,1,hyperparameters
129,All hidden states of BiLSTMs during input encoding and inference have 450 dimensions ( r = 300 and d = 450 ) .,Experimental Setup,Experimental Setup,natural_language_inference,80,"['B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.047619047619047616,128,0.4413793103448276,2,0.2,1,1,hyperparameters
130,"The weights are learned by minimizing the log - loss on the training data via the Adam optimizer ( Kingma and Ba , 2014 ) .",Experimental Setup,Experimental Setup,natural_language_inference,80,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.07142857142857142,129,0.44482758620689655,3,0.3,1,1,hyperparameters
131,The initial learning rate is 0.0004 .,Experimental Setup,Experimental Setup,natural_language_inference,80,"['O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",4,0.09523809523809523,130,0.4482758620689655,4,0.4,1,1,hyperparameters
132,"To avoid overfitting , we use dropout with the rate of 0.4 for regularization , which is applied to all feedforward connections .",Experimental Setup,Experimental Setup,natural_language_inference,80,"['B', 'I', 'B', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",5,0.11904761904761904,131,0.4517241379310345,5,0.5,1,1,hyperparameters
133,"During training , the word embeddings are updated to learn effective representations for the NLI task .",Experimental Setup,Experimental Setup,natural_language_inference,80,"['B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",6,0.14285714285714285,132,0.45517241379310347,6,0.6,1,1,hyperparameters
134,We use a fairly small batch size of 32 to provide more exploration power to the model .,Experimental Setup,Experimental Setup,natural_language_inference,80,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.16666666666666666,133,0.4586206896551724,7,0.7,1,1,hyperparameters
174,DR - BiLSTM ( Single ) achieves 88.5 % accuracy on the test set which is noticeably the best reported result among the existing single models for this task .,Results,Results,natural_language_inference,80,"['B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",4,0.21052631578947367,173,0.596551724137931,3,0.16666666666666666,1,1,results
177,"DR - BiLSTM ( Ensemble ) achieves the accuracy of 89.3 % , the best result observed on SNLI , while DR - BiLSTM ( Single ) obtains the accuracy of 88.5 % , which considerably outperforms the previous non-ensemble models .",Results,Results,natural_language_inference,80,"['B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']",,,7,0.3684210526315789,176,0.6068965517241379,6,0.3333333333333333,1,1,results
178,"Also , utilizing a trivial preprocessing step yields to further improvements of 0.4 % and 0.3 % for single and ensemble DR - BiLSTM models respectively .",Results,Results,natural_language_inference,80,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']",,,8,0.42105263157894735,177,0.6103448275862069,7,0.3888888888888889,1,1,results
183,Our ensemble model considerably outperforms the current state - of - the - art by obtaining 89.3 % accuracy .,Results,Results,natural_language_inference,80,"['O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",13,0.6842105263157895,182,0.6275862068965518,12,0.6666666666666666,1,1,results
186,We can see that our preprocessing mechanism leads to further improvements of 0.4 % and 0.3 % on the SNLI test set for our single and ensemble models respectively .,Results,Results,natural_language_inference,80,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",16,0.8421052631578947,185,0.6379310344827587,15,0.8333333333333334,1,1,results
187,"In fact , our single model ( "" DR - BiLSTM ( Single ) + Process "" ) obtains the state - of - the - art performance over both reported single and ensemble models by performing a simple preprocessing step .",Results,Results,natural_language_inference,80,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.8947368421052632,186,0.6413793103448275,16,0.8888888888888888,1,1,results
188,"Furthermore , "" DR - BiLSTM ( Ensem . ) + Process "" outperforms the existing state - of - the - art remarkably ( 0.7 % improvement ) .",Results,Results,natural_language_inference,80,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",18,0.9473684210526315,187,0.6448275862068965,17,0.9444444444444444,1,1,results
195,We can see that all modifications lead to a new model and their differences are statistically significant with a p-value of < 0.001 over Chi square test .,Ablation and Configuration Study,Ablation and Configuration Study,natural_language_inference,80,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.11363636363636363,194,0.6689655172413793,5,0.3125,1,1,ablation-analysis
197,"Among all components , three of them have noticeable influences : max pooling , difference in the attention stage , and dependent reading .",Ablation and Configuration Study,Ablation and Configuration Study,natural_language_inference,80,"['B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O']",7,0.1590909090909091,196,0.6758620689655173,7,0.4375,1,1,ablation-analysis
199,"They illustrate the importance of our proposed dependent reading strategy which leads to significant improvement , specifically in the encoding stage .",Ablation and Configuration Study,Ablation and Configuration Study,natural_language_inference,80,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",9,0.20454545454545456,198,0.6827586206896552,9,0.5625,1,1,ablation-analysis
203,demonstrates that we achieve the best performance with 450 - dimensional BiLSTMs .,Ablation and Configuration Study,Ablation and Configuration Study,natural_language_inference,80,"['B', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.29545454545454547,202,0.696551724137931,13,0.8125,1,1,ablation-analysis
2,COARSE - GRAIN FINE - GRAIN COATTENTION NET - WORK FOR MULTI - EVIDENCE QUESTION ANSWERING,,,natural_language_inference,81,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",2,0.05,1,0.0023752969121140144,1,0.0,1,1,research-problem
4,"End - to - end neural models have made significant progress in question answering , however recent studies show that these models implicitly assume that the answer and evidence appear close together in a single document .",,,natural_language_inference,81,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.1,3,0.007125890736342043,1,0.02702702702702703,1,1,research-problem
42,A requirement of scalable and practical question answering ( QA ) systems is the ability to reason over multiple documents and combine their information to answer questions .,INTRODUCTION,INTRODUCTION,natural_language_inference,81,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.015873015873015872,41,0.09738717339667459,1,0.017241379310344827,1,1,research-problem
43,"Although existing datasets enabled the development of effective end - to - end neural question answering systems , they tend to focus on reasoning over localized sections of a single document .",INTRODUCTION,INTRODUCTION,natural_language_inference,81,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.031746031746031744,42,0.0997624703087886,2,0.034482758620689655,1,1,research-problem
46,"Our multi-evidence QA model , the Coarse - grain Fine - grain Coattention Network ( CFC ) , selects among a set of candidate answers given a set of support documents and a query .",INTRODUCTION,INTRODUCTION,natural_language_inference,81,"['B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'O']",,,5,0.07936507936507936,45,0.10688836104513064,5,0.08620689655172414,1,1,model
47,The CFC is inspired by coarse - grain reasoning and fine - grain reasoning .,INTRODUCTION,INTRODUCTION,natural_language_inference,81,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.09523809523809523,46,0.10926365795724466,6,0.10344827586206896,1,1,model
48,"In coarse - grain reasoning , the model builds a coarse summary of support documents conditioned on the query without knowing what candidates are available , then scores each candidate .",INTRODUCTION,INTRODUCTION,natural_language_inference,81,"['B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.1111111111111111,47,0.11163895486935867,7,0.1206896551724138,1,1,model
49,"In fine - grain reasoning , the model matches specific finegrain contexts in which the candidate is mentioned with the query in order to gauge the relevance of the candidate .",INTRODUCTION,INTRODUCTION,natural_language_inference,81,"['O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'O', 'O']",8,0.12698412698412698,48,0.11401425178147269,8,0.13793103448275862,1,1,model
51,Each module employs a novel hierarchical attention - a hierarchy of coattention and self - attention - to combine information from the support documents conditioned on the query and candidates .,INTRODUCTION,INTRODUCTION,natural_language_inference,81,"['B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-n', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'B-ob', 'O']",10,0.15873015873015872,50,0.1187648456057007,10,0.1724137931034483,1,1,model
111,MULTI - EVIDENCE QUESTION ANSWERING ON WIKIHOP,EXPERIMENTS,,natural_language_inference,81,"['B', 'I', 'I', 'I', 'I', 'B', 'B']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob']",6,0.1276595744680851,110,0.26128266033254155,6,0.21428571428571427,1,1,experiments
121,We tokenize the data using Stanford CoreNLP .,EXPERIMENTS,MULTI - EVIDENCE QUESTION ANSWERING ON WIKIHOP,natural_language_inference,81,"['O', 'B', 'O', 'O', 'B', 'B', 'I', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",16,0.3404255319148936,120,0.2850356294536817,16,0.5714285714285714,1,1,experiments
122,We use fixed Glo Ve embeddings as well as character ngram embeddings .,EXPERIMENTS,MULTI - EVIDENCE QUESTION ANSWERING ON WIKIHOP,natural_language_inference,81,"['O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.3617021276595745,121,0.28741092636579574,17,0.6071428571428571,1,1,experiments
123,We split symbolic query relations into words .,EXPERIMENTS,MULTI - EVIDENCE QUESTION ANSWERING ON WIKIHOP,natural_language_inference,81,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",18,0.3829787234042553,122,0.28978622327790976,18,0.6428571428571429,1,1,experiments
124,All models are trained using ADAM .,EXPERIMENTS,MULTI - EVIDENCE QUESTION ANSWERING ON WIKIHOP,natural_language_inference,81,"['O', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",19,0.40425531914893614,123,0.2921615201900237,19,0.6785714285714286,1,1,experiments
127,The CFC achieves state - of - the - art results on both the masked and unmasked versions of WikiHop .,EXPERIMENTS,MULTI - EVIDENCE QUESTION ANSWERING ON WIKIHOP,natural_language_inference,81,"['O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",22,0.46808510638297873,126,0.2992874109263658,22,0.7857142857142857,1,1,experiments
128,"In particular , on the blind , held - out WikiHop test set , the CFC achieves a new best accuracy of 70.6 % .",EXPERIMENTS,MULTI - EVIDENCE QUESTION ANSWERING ON WIKIHOP,natural_language_inference,81,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",23,0.48936170212765956,127,0.3016627078384798,23,0.8214285714285714,1,1,experiments
134,RERANKING EXTRACTIVE QUESTION ANSWERING ON TRIVIAQA,EXPERIMENTS,,natural_language_inference,81,"['B', 'I', 'I', 'I', 'B', 'B']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob']",29,0.6170212765957447,133,0.3159144893111639,0,0.0,1,1,experiments
141,Our experimental results in show that reranking using the CFC provides consistent performance gains over only using the span extraction question answering model .,EXPERIMENTS,RERANKING EXTRACTIVE QUESTION ANSWERING ON TRIVIAQA,natural_language_inference,81,"['B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",36,0.7659574468085106,140,0.332541567695962,7,0.3888888888888889,1,1,experiments
142,"In particular , reranking using the CFC improves performance regardless of whether the candidate answer set obtained from the span extraction model contains correct answers .",EXPERIMENTS,RERANKING EXTRACTIVE QUESTION ANSWERING ON TRIVIAQA,natural_language_inference,81,"['O', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,37,0.7872340425531915,141,0.334916864608076,8,0.4444444444444444,1,1,experiments
143,"On the whole Trivia QA dev set , reranking using the CFC results in again of 3.1 % EM and 3.0 % F1 , which suggests that the CFC can be used to further refine the outputs produced by span extraction question answering models .",EXPERIMENTS,RERANKING EXTRACTIVE QUESTION ANSWERING ON TRIVIAQA,natural_language_inference,81,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,38,0.8085106382978723,142,0.33729216152019004,9,0.5,1,1,experiments
145,Both the coarse - grain module and the fine - grain module significantly contribute to model performance .,EXPERIMENTS,RERANKING EXTRACTIVE QUESTION ANSWERING ON TRIVIAQA,natural_language_inference,81,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",40,0.851063829787234,144,0.342042755344418,11,0.6111111111111112,1,1,ablation-analysis
146,Replacing selfattention layers with mean - pooling and the bidirectional GRUs with unidirectional GRUs result in less performance degradation .,EXPERIMENTS,RERANKING EXTRACTIVE QUESTION ANSWERING ON TRIVIAQA,natural_language_inference,81,"['B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']",,,41,0.8723404255319149,145,0.34441805225653205,12,0.6666666666666666,1,1,ablation-analysis
147,"Replacing the encoder with a projection over word embeddings result in significant performance drop , which suggests that contextual encodings that capture positional information is crucial to this task .",EXPERIMENTS,RERANKING EXTRACTIVE QUESTION ANSWERING ON TRIVIAQA,natural_language_inference,81,"['B', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",42,0.8936170212765957,146,0.34679334916864607,13,0.7222222222222222,1,1,ablation-analysis
149,The fine - grain - only model under-performs the coarse - grain - only model consistently across almost all length measures .,EXPERIMENTS,RERANKING EXTRACTIVE QUESTION ANSWERING ON TRIVIAQA,natural_language_inference,81,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",44,0.9361702127659575,148,0.3515439429928741,15,0.8333333333333334,1,1,ablation-analysis
151,"However , the fine - grain - only model matches or outperforms the coarse - grain - only model on examples with a large number of support documents or with long support documents .",EXPERIMENTS,RERANKING EXTRACTIVE QUESTION ANSWERING ON TRIVIAQA,natural_language_inference,81,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",46,0.9787234042553191,150,0.35629453681710216,17,0.9444444444444444,1,1,ablation-analysis
2,Dynamic Entity Representation with Max - pooling Improves Machine Reading,title,title,natural_language_inference,82,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.008771929824561403,1,0.0,1,1,research-problem
7,Our code for the model is available at https://github.com/soskek/der-network,abstract,abstract,natural_language_inference,82,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob']",4,1.0,6,0.05263157894736842,4,1.0,1,1,code
23,"We , however , take it as a strong motivation to implement a reader that dynamically builds meaning representations for each entity , by gathering and accumulating information on that entity as it reads a document ( Section 2 ) .",Introduction,Introduction,natural_language_inference,82,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O']",15,0.8333333333333334,22,0.19298245614035087,15,0.8333333333333334,1,1,model
76,"For preprocessing , we segment sentences at punctuation marks "" . "" , "" ! "" , and "" ? "" .",Evaluation,Evaluation,natural_language_inference,82,"['B', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'B-ob', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O']",8,0.8,75,0.6578947368421053,8,0.8,1,1,hyperparameters
78,"We train our model 8 with hyper - parameters lightly tuned on the validation set 9 , and we conduct ablation test on several techniques that improve our basic model .",Evaluation,Evaluation,natural_language_inference,82,"['O', 'B', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,1.0,77,0.6754385964912281,10,1.0,1,1,hyperparameters
80,"As shown in , Max - pooling described in Section 2.2 drastically improves performance , showing the effect of accumulating information on entities .",Results,Results,natural_language_inference,82,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.1,79,0.6929824561403509,1,0.1,1,1,results
100,"Further , we note that initializing our model with pre-trained word vectors 10 is helpful , though world knowledge of entities has been prevented by the anonymization process .",Models,Models,natural_language_inference,82,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.4166666666666667,99,0.868421052631579,10,0.5263157894736842,1,1,results
102,"Finally , we note that our model , full DER Network , shows the best results compared to several previous reader models , endorsing our approach as promising .",Models,Models,natural_language_inference,82,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.5,101,0.8859649122807017,12,0.631578947368421,1,1,results
103,"The 99 % confidence intervals of the results of full DER Network and the one initialized by word2vec on the test set were [ 0.700 , 0.740 ] and [ 0.708 , 0.749 ] , respectively ( measured by bootstrap tests ) .",Models,Models,natural_language_inference,82,"['O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,13,0.5416666666666666,102,0.8947368421052632,13,0.6842105263157895,1,1,results
2,Story Comprehension for Predicting What Happens Next,title,,natural_language_inference,83,"['B', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.0032679738562091504,1,0.0,1,1,research-problem
4,"Automatic story comprehension is a fundamental challenge in Natural Language Understanding , and can enable computers to learn about social norms , human behavior and commonsense .",abstract,abstract,natural_language_inference,83,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.00980392156862745,1,0.14285714285714285,1,1,research-problem
14,"For these reasons , automatically understanding stories is an interesting but challenging task for Computational Linguists .",Introduction,Introduction,natural_language_inference,83,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.030303030303030304,13,0.042483660130718956,3,0.06818181818181818,1,1,research-problem
29,"Recently , introduced the story - cloze task for testing this ability , albeit without the aspect of language generation .",Introduction,Introduction,natural_language_inference,83,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.18181818181818182,28,0.0915032679738562,18,0.4090909090909091,1,1,research-problem
35,"In this paper we explore three semantic aspects of story understanding : ( i ) the sequence of events described in the story , ( ii ) the evolution of sentiment and emotional trajectories , and ( iii ) topical consistency .",Introduction,Introduction,natural_language_inference,83,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']",,,24,0.24242424242424243,34,0.1111111111111111,24,0.5454545454545454,1,1,model
36,"The first aspect is motivated from approaches in semantic script induction , and evaluates if events described in an ending - alternative are likely to occur within the sequence of events described in the preceding context .",Introduction,Introduction,natural_language_inference,83,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']",,,25,0.25252525252525254,35,0.11437908496732026,25,0.5681818181818182,1,1,model
42,Our model captures this by evaluating if the sentiment described in an ending option makes sense considering the context of the story .,Introduction,Introduction,natural_language_inference,83,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O']",31,0.31313131313131315,41,0.13398692810457516,31,0.7045454545454546,1,1,model
45,Our model accounts for that by analyzing if the topic of an ending option is consistent with the preceding context .,Introduction,Introduction,natural_language_inference,83,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",34,0.3434343434343434,44,0.1437908496732026,34,0.7727272727272727,1,1,model
46,We present a log - linear model that is used to weigh the various aspects of the story using a hidden variable .,Introduction,Introduction,natural_language_inference,83,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",35,0.35353535353535354,45,0.14705882352941177,35,0.7954545454545454,1,1,model
173,DSSM : It trains two deep neural networks to project the context and the ending - options into the same vector space .,Baselines,Baselines,natural_language_inference,83,"['B', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.09090909090909091,172,0.5620915032679739,2,0.09090909090909091,1,1,baselines
175,Msap :,Baselines,Baselines,natural_language_inference,83,"['B', 'O']","['B-n', 'O']","['B-b', 'O']",4,0.18181818181818182,174,0.5686274509803921,4,0.18181818181818182,1,1,baselines
177,It trains a logistic regression based on stylistic and languagemodel based features .,Baselines,Baselines,natural_language_inference,83,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.2727272727272727,176,0.5751633986928104,6,0.2727272727272727,1,1,baselines
178,LR : Our next baseline is a simple logistic regression model which is agnostic to the fact that there are multiple types of aspects .,Baselines,Baselines,natural_language_inference,83,"['B', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['B-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.3181818181818182,177,0.5784313725490197,7,0.3181818181818182,1,1,baselines
180,Majority Vote :,Baselines,Baselines,natural_language_inference,83,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-b', 'I-b', 'O']",9,0.4090909090909091,179,0.5849673202614379,9,0.4090909090909091,1,1,baselines
181,"This ensemble method uses the features extracted for each of the K = 3 aspects , to train K separate logistic regression models .",Baselines,Baselines,natural_language_inference,83,"['O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.45454545454545453,180,0.5882352941176471,10,0.45454545454545453,1,1,baselines
183,Soft Voting :,Baselines,Baselines,natural_language_inference,83,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-b', 'I-b', 'O']",12,0.5454545454545454,182,0.5947712418300654,12,0.5454545454545454,1,1,baselines
184,This baseline also learns K different aspect - specific classifiers .,Baselines,Baselines,natural_language_inference,83,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.5909090909090909,183,0.5980392156862745,13,0.5909090909090909,1,1,baselines
189,Aspect - aware Ensemble :,Baselines,Baselines,natural_language_inference,83,"['B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O']",18,0.8181818181818182,188,0.6143790849673203,18,0.8181818181818182,1,1,baselines
190,"Like the voting methods , this baseline also trains K different aspectspecific classifiers .",Baselines,Baselines,natural_language_inference,83,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.8636363636363636,189,0.6176470588235294,19,0.8636363636363636,1,1,baselines
197,shows the performance of a logistic regression model trained using all the features ( All ) and then using individual feature - groups .,Ablation Study,Ablation Study,natural_language_inference,83,"['B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.1,196,0.6405228758169934,2,0.1,1,1,ablation-analysis
198,"We can see that the features extracted from the aspect analyzing the event - sequence have the strongest predictive power , followed by those characterizing Sentiment - trajectory .",Ablation Study,Ablation Study,natural_language_inference,83,"['O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.15,197,0.6437908496732027,3,0.15,1,1,ablation-analysis
199,The features measuring top - ical consistency result in lowest accuracy but they still perform better than random on the task .,Ablation Study,Ablation Study,natural_language_inference,83,"['O', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O']",4,0.2,198,0.6470588235294118,4,0.2,1,1,ablation-analysis
2,LEARNING TO COMPUTE WORD EMBEDDINGS ON THE FLY,title,title,natural_language_inference,84,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004347826086956522,1,0.0,1,1,research-problem
12,"Learning representations for rare words is a well - known challenge of natural language understanding , since the standard end - to - end supervised learning methods require many occurrences of each word to generalize well .",INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.009389671361502348,11,0.04782608695652174,2,0.07407407407407407,1,1,research-problem
20,"In this paper we propose a new method for computing embeddings "" on the fly "" , which jointly addresses the large vocabulary problem and the paucity of data for learning representations in the long tail of the Zipfian distribution .",INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.046948356807511735,19,0.08260869565217391,10,0.37037037037037035,1,1,model
21,"This method , which we illustrate in , can be summarized as follows : instead of directly learning separate representations for all words in a potentially unbounded vocabulary , we train a network to predict the representations of words based on auxiliary data .",INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-n', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-b', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",11,0.051643192488262914,20,0.08695652173913043,11,0.4074074074074074,1,1,model
25,Several sources of auxiliary data can be used simultaneously as input to a neural network that will compute a combined representation .,INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O']",15,0.07042253521126761,24,0.10434782608695652,15,0.5555555555555556,1,1,model
26,"These representations can then be used for out - of - vocabulary words , or combined with withinvocabulary word embeddings directly trained on the task of interest or pretrained from an external data source .",INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",16,0.07511737089201878,25,0.10869565217391304,16,0.5925925925925926,1,1,model
27,"Importantly , the auxiliary data encoders are trained jointly with the objective , ensuring the preservation of semantic alignment with representations of within - vocabulary words .",INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O']",,,17,0.07981220657276995,26,0.11304347826086956,17,0.6296296296296297,1,1,model
99,QUESTION ANSWERING,INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",89,0.41784037558685444,98,0.4260869565217391,0,0.0,1,1,experiments
129,Looking at the results one can see that adding any external information results in a significant improvement over the baseline model ( B ) ( 3.7 - 10.5 points ) .,INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",119,0.5586854460093896,128,0.5565217391304348,30,0.5454545454545454,1,1,experiments
130,"When the dictionary alone is used , mean pooling ( D3 ) performs similarly to LSTM ( D4 ) .",INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O']",120,0.5633802816901409,129,0.5608695652173913,31,0.5636363636363636,1,1,experiments
133,"We found that adding the spelling ( S ) helps more than adding a dictionary ( D ) ( 3 points difference ) , possibly due to relatively lower coverage of our dictionary .",INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['O', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,123,0.5774647887323944,132,0.5739130434782609,34,0.6181818181818182,1,1,experiments
134,"However , the model that uses both ( SD ) has a 1.1 point advantage over the model that uses just the spelling ( S ) , demonstrating that combining several forms of auxiliary data allows the model to exploit the complementary information they provide .",INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['O', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,124,0.5821596244131455,133,0.5782608695652174,35,0.6363636363636364,1,1,experiments
135,"The model with GLoVe embeddings ( G ) is still ahead with a 1.1 point margin , but the gap has been shrunk .",INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",125,0.5868544600938967,134,0.5826086956521739,36,0.6545454545454545,1,1,experiments
155,ENTAILMENT PREDICTION,INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",145,0.6807511737089202,154,0.6695652173913044,0,0.0,1,1,experiments
172,"Compared to the SQuAD results , an important difference is that spelling was not as useful on SNLI and MultiNLI .",INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",162,0.7605633802816901,171,0.7434782608695653,17,0.7391304347826086,1,1,experiments
173,"We also note that we tried using fixed random embeddings for OOV words as proposed by , and that this method did not bring a significant advantage over the baseline .",INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",163,0.7652582159624414,172,0.7478260869565218,18,0.782608695652174,1,1,experiments
178,"shows that , as expected , dictionary - enabled models significantly outperform baseline models for sentences containing rare words .",INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-b', 'I-b', 'B-ob', 'I-ob', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",168,0.7887323943661971,177,0.7695652173913043,23,1.0,1,1,experiments
179,LANGUAGE MODELLING,INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",169,0.7934272300469484,178,0.7739130434782608,0,0.0,1,1,experiments
199,"Similarly to our other experiments , using external information to compute embeddings of unknown words helps in all cases .",INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",189,0.8873239436619719,198,0.8608695652173913,20,0.6451612903225806,1,1,experiments
201,"We note that lemma + lowercase performs worse than any model with the dictionary , which suggests that dictionary definitions are used in a non-trivial way .",INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",191,0.8967136150234741,200,0.8695652173913043,22,0.7096774193548387,1,1,experiments
202,Adding spelling consistently helps more than adding dictionary definitions .,INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['B', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-ob', 'I-ob', 'O']",192,0.9014084507042254,201,0.8739130434782608,23,0.7419354838709677,1,1,experiments
204,"Using both dictionary and spelling is consistently slightly better than using just spelling , and the improvement is more pronounced in the restricted setting .",INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",194,0.9107981220657277,203,0.8826086956521739,25,0.8064516129032258,1,1,experiments
205,Using Glo Ve embeddings results in the best perplexity .,INTRODUCTION,INTRODUCTION,natural_language_inference,84,"['O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",195,0.9154929577464789,204,0.8869565217391304,26,0.8387096774193549,1,1,experiments
2,Enhanced LSTM for Natural Language Inference,title,,natural_language_inference,85,"['O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.00425531914893617,1,0.0,1,1,research-problem
4,Reasoning and inference are central to human and artificial intelligence .,abstract,abstract,natural_language_inference,85,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.01276595744680851,1,0.14285714285714285,1,1,research-problem
15,"Specifically , natural language inference ( NLI ) is concerned with determining whether a naturallanguage hypothesis h can be inferred from a premise p , as depicted in the following example from MacCartney ( 2009 ) , where the hypothesis is regarded to be entailed from the premise .",Introduction,Introduction,natural_language_inference,85,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.21052631578947367,14,0.059574468085106386,4,0.21052631578947367,1,1,research-problem
24,"While some previous top - performing models use rather complicated network architectures to achieve the state - of - the - art results , we demonstrate in this paper that enhancing sequential inference models based on chain models can outperform all previous results , suggesting that the potentials of such sequential inference approaches have not been fully exploited yet .",Introduction,Introduction,natural_language_inference,85,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.6842105263157895,23,0.09787234042553192,13,0.6842105263157895,1,1,model
26,Exploring syntax for NLI is very attractive to us .,Introduction,Introduction,natural_language_inference,85,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.7894736842105263,25,0.10638297872340426,15,0.7894736842105263,1,1,research-problem
30,"We show that by explicitly encoding parsing information with recursive networks in both local inference modeling and inference composition and by incorporating it into our framework , we achieve additional improvement , increasing the performance to a new state of the art with an 88.6 % accuracy .",Introduction,Introduction,natural_language_inference,85,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,1.0,29,0.12340425531914893,19,1.0,1,1,model
167,"We use the Adam method ( Kingma and Ba , 2014 ) for optimization .",Training,Training,natural_language_inference,85,"['O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'O']",4,0.36363636363636365,166,0.7063829787234043,11,0.6111111111111112,1,1,hyperparameters
168,The first momentum is set to be 0.9 and the second 0.999 .,Training,Training,natural_language_inference,85,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'B-n', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'O', 'O', 'B-b', 'B-ob', 'O']",5,0.45454545454545453,167,0.7106382978723405,12,0.6666666666666666,1,1,hyperparameters
169,The initial learning rate is 0.0004 and the batch size is 32 .,Training,Training,natural_language_inference,85,"['O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O']",,,6,0.5454545454545454,168,0.7148936170212766,13,0.7222222222222222,1,1,hyperparameters
170,"All hidden states of LSTMs , tree - LSTMs , and word embeddings have 300 dimensions .",Training,Training,natural_language_inference,85,"['O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.6363636363636364,169,0.7191489361702128,14,0.7777777777777778,1,1,hyperparameters
171,"We use dropout with a rate of 0.5 , which is applied to all feedforward connections .",Training,Training,natural_language_inference,85,"['O', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.7272727272727273,170,0.723404255319149,15,0.8333333333333334,1,1,hyperparameters
172,We use pre-trained 300 - D Glove 840B vectors to initialize our word embeddings .,Training,Training,natural_language_inference,85,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.8181818181818182,171,0.7276595744680852,16,0.8888888888888888,1,1,hyperparameters
173,Out - of - vocabulary ( OOV ) words are initialized randomly with Gaussian samples .,Training,Training,natural_language_inference,85,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",10,0.9090909090909091,172,0.7319148936170212,17,0.9444444444444444,1,1,hyperparameters
185,"Our final model achieves the accuracy of 88.6 % , the best result observed on SNLI , while our enhanced sequential encoding model attains an accuracy of 88.0 % , which also outperform the previous models .",Results,Results,natural_language_inference,85,"['B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O']",,,10,0.45454545454545453,184,0.7829787234042553,10,0.45454545454545453,1,1,results
191,"In general , adding intra-sentence attention yields further improvement , which is not very surprising as it could help align the relevant text spans between premise and hypothesis .",Results,Results,natural_language_inference,85,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.7272727272727273,190,0.8085106382978723,16,0.7272727272727273,1,1,results
195,"The table shows that our ESIM model achieves an accuracy of 88.0 % , which has already outperformed all the previous models , including those using much more complicated network architectures .",Results,Results,natural_language_inference,85,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']",,,20,0.9090909090909091,194,0.825531914893617,20,0.9090909090909091,1,1,results
196,"We ensemble our ESIM model with syntactic tree - LSTMs based on syntactic parse trees and achieve significant improvement over our best sequential encoding model ESIM , attaining an accuracy of 88.6 % .",Results,Results,natural_language_inference,85,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O']",,,21,0.9545454545454546,195,0.8297872340425532,21,0.9545454545454546,1,1,results
204,Each tree node is implemented with a tree - LSTM block same as in model .,Ablation analysis,Ablation analysis,natural_language_inference,85,"['B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O']",4,0.14285714285714285,203,0.8638297872340426,4,0.14285714285714285,1,1,ablation-analysis
205,"shows that with this replacement , the performance drops to 88.2 % .",Ablation analysis,Ablation analysis,natural_language_inference,85,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",5,0.17857142857142858,204,0.8680851063829788,5,0.17857142857142858,1,1,ablation-analysis
207,"If we remove the pooling layer in inference composition and replace it with summation as in , the accuracy drops to 87.1 % .",Ablation analysis,Ablation analysis,natural_language_inference,85,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'O', 'O', 'O', 'O', 'B-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.25,206,0.8765957446808511,7,0.25,1,1,ablation-analysis
208,"If we remove the difference and elementwise product from the local inference enhancement layer , the accuracy drops to 87.0 % .",Ablation analysis,Ablation analysis,natural_language_inference,85,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'B-s', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.2857142857142857,207,0.8808510638297873,8,0.2857142857142857,1,1,ablation-analysis
209,"To provide some detailed comparison with , replacing bidirectional LSTMs in inference composition and also input encoding with feedforward neural network reduces the accuracy to 87.3 % and 86.3 % respectively .",Ablation analysis,Ablation analysis,natural_language_inference,85,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-b', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",9,0.32142857142857145,208,0.8851063829787233,9,0.32142857142857145,1,1,ablation-analysis
213,"If we remove the premise - based attention from ESIM ( model 23 ) , the accuracy drops to 87.2 % on the test set .",Ablation analysis,Ablation analysis,natural_language_inference,85,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'B-s', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",13,0.4642857142857143,212,0.902127659574468,13,0.4642857142857143,1,1,ablation-analysis
215,"Removing the hypothesis - based attention ( model 24 ) decrease the accuracy to 86.5 % , where hypothesis - based attention is the attention performed on the other direction for the sentence pairs .",Ablation analysis,Ablation analysis,natural_language_inference,85,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.5357142857142857,214,0.9106382978723404,15,0.5357142857142857,1,1,ablation-analysis
2,Multi - Perspective Context Matching for Machine Comprehension,title,,natural_language_inference,86,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.005847953216374269,1,0.0,1,1,research-problem
4,"Previous machine comprehension ( MC ) datasets are either too small to train endto - end deep learning models , or not difficult enough to evaluate the ability of current MC techniques .",abstract,abstract,natural_language_inference,86,"['O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O']",1,0.1,3,0.017543859649122806,1,0.1,1,1,research-problem
27,"In this work , we focus on the SQuAD dataset and propose an end - to - end deep neural network model for machine comprehension .",Introduction,Introduction,natural_language_inference,86,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",13,0.1566265060240964,26,0.15204678362573099,13,0.65,1,1,model
29,"Based on this assumption , we design a Multi - Perspective Context Matching ( MPCM ) model to identify the answer span by matching the context of each point in the passage with the question from multiple perspectives .",Introduction,Introduction,natural_language_inference,86,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",15,0.18072289156626506,28,0.16374269005847952,15,0.75,1,1,model
30,"Instead of enumerating all the possible spans explicitly and ranking them , our model identifies the answer span by predicting the beginning and ending points individually with globally normalized probability distributions across the whole passage .",Introduction,Introduction,natural_language_inference,86,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",16,0.1927710843373494,29,0.1695906432748538,16,0.8,1,1,model
102,We process the corpus with the tokenizer from Stanford CorNLP .,Experiment Settings,Experiment Settings,natural_language_inference,86,"['O', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",3,0.15,101,0.5906432748538012,3,0.2727272727272727,1,1,experimental-setup
104,"To initialize the word embeddings in the word representation layer , we use the 300 - dimensional GloVe word vectors pre-trained from the 840B Common Crawl corpus .",Experiment Settings,Experiment Settings,natural_language_inference,86,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.25,103,0.6023391812865497,5,0.45454545454545453,1,1,experimental-setup
105,"For the out - of - vocabulary ( OOV ) words , we initialize the word embeddings randomly .",Experiment Settings,Experiment Settings,natural_language_inference,86,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-ob', 'O']",6,0.3,104,0.6081871345029239,6,0.5454545454545454,1,1,experimental-setup
106,"We set the hidden size as 100 for all the LSTM layers , and set the number of perspectives l of our multiperspective matching function ( Equation ( 5 ) ) as 50 .",Experiment Settings,Experiment Settings,natural_language_inference,86,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O']",,,7,0.35,105,0.6140350877192983,7,0.6363636363636364,1,1,experimental-setup
107,"We apply dropout to every layers in , and set the dropout ratio as 0.2 .",Experiment Settings,Experiment Settings,natural_language_inference,86,"['O', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",8,0.4,106,0.6198830409356725,8,0.7272727272727273,1,1,experimental-setup
108,"To train the model , we minimize the cross entropy of the be - ginning and end points , and use the ADAM optimizer to update parameters .",Experiment Settings,Experiment Settings,natural_language_inference,86,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",9,0.45,107,0.6257309941520468,9,0.8181818181818182,1,1,experimental-setup
109,We set the learning rate as 0.0001 .,Experiment Settings,Experiment Settings,natural_language_inference,86,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",10,0.5,108,0.631578947368421,10,0.9090909090909091,1,1,experimental-setup
126,We can see that removing any components from the MPCM model decreases the performance significantly .,Layer Ablation,Layer Ablation,natural_language_inference,86,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'O', 'B-n', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-b', 'O', 'B-b', 'B-ob', 'O']",6,0.6666666666666666,125,0.7309941520467836,6,0.6666666666666666,1,1,ablation-analysis
127,"Among all the layers , the Aggregation Layer is the most crucial layer .",Layer Ablation,Layer Ablation,natural_language_inference,86,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",7,0.7777777777777778,126,0.7368421052631579,7,0.7777777777777778,1,1,ablation-analysis
128,"Among all the matching strategies , Maxpooling - Matching has the biggest effect .",Layer Ablation,Layer Ablation,natural_language_inference,86,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'O']",8,0.8888888888888888,127,0.7426900584795322,8,0.8888888888888888,1,1,ablation-analysis
2,SG - Net : Syntax - Guided Machine Reading Comprehension,title,title,natural_language_inference,87,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.005681818181818182,1,0.0,1,1,research-problem
13,"Understanding the meaning of a sentence is a prerequisite to solve many natural language understanding ( NLU ) problems , such as machine reading comprehension ( MRC ) based question answering .",Introduction,Introduction,natural_language_inference,87,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",2,0.09523809523809523,12,0.06818181818181818,2,0.09523809523809523,1,1,research-problem
17,We observe that the accuracy of MRC models decreases when answering long questions ( shown in Section 5.1 ) .,Introduction,Introduction,natural_language_inference,87,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.2857142857142857,16,0.09090909090909091,6,0.2857142857142857,1,1,research-problem
27,"In this paper , we extend the self - attention mechanism with syntax - guided constraint , to capture syntax related parts with each concerned word .",Introduction,Introduction,natural_language_inference,87,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']",,,16,0.7619047619047619,26,0.14772727272727273,16,0.7619047619047619,1,1,model
28,"Specifically , we adopt pre-trained dependency syntactic parse tree structure to produce the related nodes for each word in a sentence , namely syntactic dependency of interest ( SDOI ) , by regarding each word as a child node and the SDOI consists all its ancestor nodes and itself in the dependency parsing tree .",Introduction,Introduction,natural_language_inference,87,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,17,0.8095238095238095,27,0.1534090909090909,17,0.8095238095238095,1,1,model
30,"To effectively accommodate such SDOI information , we propose a novel syntax - guided network ( SG - Net ) , which fuses the original SAN and SDOI - SAN , to provide more linguistically inspired representation for challenging reading comprehension tasks 1 .",Introduction,Introduction,natural_language_inference,87,"['O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",19,0.9047619047619048,29,0.16477272727272727,19,0.9047619047619048,1,1,model
129,We adopt the Whole Word Masking BERT as the baseline 6 .,Implementation,Implementation,natural_language_inference,87,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",4,0.36363636363636365,128,0.7272727272727273,4,0.36363636363636365,1,1,hyperparameters
130,"The initial learning rate is set in { 8e -6 , 1 e - 5 , 2 e - 5 , 3 e - 5 } with warm - up rate of 0.1 and L2 weight decay of 0.01 .",Implementation,Implementation,natural_language_inference,87,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']",,,5,0.45454545454545453,129,0.7329545454545454,5,0.45454545454545453,1,1,hyperparameters
131,"The batch size is selected in { 16 , 20 , 32 } .",Implementation,Implementation,natural_language_inference,87,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.5454545454545454,130,0.7386363636363636,6,0.5454545454545454,1,1,hyperparameters
132,The maximum number of epochs is set to 3 or 10 depending on tasks .,Implementation,Implementation,natural_language_inference,87,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",7,0.6363636363636364,131,0.7443181818181818,7,0.6363636363636364,1,1,hyperparameters
133,The weight ?,Implementation,Implementation,natural_language_inference,87,"['O', 'B', 'O']","['O', 'B-n', 'O']","['O', 'B-b', 'O']",8,0.7272727272727273,132,0.75,8,0.7272727272727273,1,1,hyperparameters
134,in the dual context aggregation is 0.5 .,Implementation,Implementation,natural_language_inference,87,"['B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'O']",9,0.8181818181818182,133,0.7556818181818182,9,0.8181818181818182,1,1,hyperparameters
135,"All the texts are tokenized using wordpieces , and the maximum input length is set to 384 for both of SQuAD and RACE .",Implementation,Implementation,natural_language_inference,87,"['O', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.9090909090909091,134,0.7613636363636364,10,0.9090909090909091,1,1,hyperparameters
143,It also outperforms all the published works and achieves the 2nd place on the leaderboard when submitting SG - NET .,Main Results,Main Results,natural_language_inference,87,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.2857142857142857,142,0.8068181818181818,6,0.75,1,1,results
144,"We also find that adding an extra answer verifier module could yield better result , which is pre-trained only to determine whether question is answerable or not with the same training data as SG - Net .",Main Results,Main Results,natural_language_inference,87,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.3333333333333333,143,0.8125,7,0.875,1,1,results
2,Long Short - Term Memory - Networks for Machine Reading,title,title,natural_language_inference,88,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.004048582995951417,1,0.0,1,1,research-problem
42,The idea is to use multiple memory slots outside the recurrence to piece - wise store representations of the input ; read and write operations for each slot can be modeled as an attention mechanism with a recurrent controller .,Introduction,Introduction,natural_language_inference,88,"['O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",22,0.6875,41,0.1659919028340081,22,0.6875,1,1,model
43,We also leverage memory and attention to empower a recurrent network with stronger memorization capability and more importantly the ability to discover relations among tokens .,Introduction,Introduction,natural_language_inference,88,"['O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O']",23,0.71875,42,0.1700404858299595,23,0.71875,1,1,model
44,This is realized by inserting a memory network module in the update of a recurrent network together with attention for memory addressing .,Introduction,Introduction,natural_language_inference,88,"['O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",24,0.75,43,0.17408906882591094,24,0.75,1,1,model
47,"The resulting model , which we term Long Short - Term Memory - Network ( LSTMN ) , is a reading simulator that can be used for sequence processing tasks .",Introduction,Introduction,natural_language_inference,88,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",27,0.84375,46,0.1862348178137652,27,0.84375,1,1,model
49,The model processes text incrementally while learning which past tokens in the memory and to what extent they relate to the current token being processed .,Introduction,Introduction,natural_language_inference,88,"['O', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'B-p', 'B-n', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'B-b', 'B-ob', 'B-p', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",29,0.90625,48,0.19433198380566802,29,0.90625,1,1,model
50,"As a result , the model induces undirected relations among tokens as an intermediate step of learning representations .",Introduction,Introduction,natural_language_inference,88,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",30,0.9375,49,0.19838056680161945,30,0.9375,1,1,model
144,Our code is available at https://github.com/cheng6076/,Experiments,Experiments,natural_language_inference,88,"['O', 'O', 'O', 'O', 'O', 'B']","['O', 'O', 'O', 'O', 'O', 'B-n']","['O', 'O', 'O', 'O', 'O', 'B-ob']",5,0.8333333333333334,143,0.5789473684210527,5,0.8333333333333334,1,1,code
146,Language Modeling,,,natural_language_inference,88,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",0,0.0,145,0.5870445344129555,0,0.0,1,1,experiments
152,"We used stochastic gradient descent for optimization with an initial learning rate of 0.65 , which decays by a factor of 0.85 per epoch if no significant improvement has been observed on the validation set .",Language Modeling,Language Modeling,natural_language_inference,88,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,6,0.15384615384615385,151,0.611336032388664,6,0.1875,1,1,experiments
153,We renormalize the gradient if its norm is greater than 5 .,Language Modeling,Language Modeling,natural_language_inference,88,"['O', 'B', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'O', 'B-b', 'B-p', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",7,0.1794871794871795,152,0.6153846153846154,7,0.21875,1,1,experiments
154,The mini - batch size was set to 40 .,Language Modeling,Language Modeling,natural_language_inference,88,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",8,0.20512820512820512,153,0.6194331983805668,8,0.25,1,1,experiments
155,The dimensions of the word embeddings were set to 150 for all models .,Language Modeling,Language Modeling,natural_language_inference,88,"['O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O']","['O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",9,0.23076923076923078,154,0.6234817813765182,9,0.28125,1,1,experiments
157,The first one is a Kneser - Ney 5 - gram language model ( KN5 ) which generally serves as a non-neural baseline for the language modeling task .,Language Modeling,Language Modeling,natural_language_inference,88,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",11,0.28205128205128205,156,0.631578947368421,11,0.34375,1,1,experiments
160,The gated - feedback LSTM has feedback gates connecting the hidden states across multiple time steps as an adaptive control of the information flow .,Language Modeling,Language Modeling,natural_language_inference,88,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",14,0.358974358974359,159,0.6437246963562753,14,0.4375,1,1,experiments
161,The depth - gated LSTM uses a depth gate to connect memory cells of vertically adjacent layers .,Language Modeling,Language Modeling,natural_language_inference,88,"['O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",15,0.38461538461538464,160,0.6477732793522267,15,0.46875,1,1,experiments
172,"Amongst all deep architectures , the three - layer LSTMN also performs best .",Language Modeling,Language Modeling,natural_language_inference,88,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'O']",26,0.6666666666666666,171,0.6923076923076923,26,0.8125,1,1,experiments
179,Sentiment Analysis,Language Modeling,,natural_language_inference,88,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",33,0.8461538461538461,178,0.7206477732793523,0,0.0,1,1,experiments
193,We used pretrained 300 - D Glove 840B vectors to initialize the word embeddings .,Models,Models,natural_language_inference,88,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",7,0.1346153846153846,192,0.7773279352226721,7,0.3333333333333333,1,1,experiments
194,"The gradient for words with Glove embeddings , was scaled by 0.35 in the first epoch after which all word embeddings were updated normally .",Models,Models,natural_language_inference,88,"['O', 'B', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'O']","['O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'O']",8,0.15384615384615385,193,0.7813765182186235,8,0.38095238095238093,1,1,experiments
195,"We used Adam ( Kingma and Ba , 2015 ) for optimization with the two momentum parameters set to 0.9 and 0.999 respectively .",Models,Models,natural_language_inference,88,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",9,0.17307692307692307,194,0.7854251012145749,9,0.42857142857142855,1,1,experiments
196,The initial learning rate was set to 2E - 3 .,Models,Models,natural_language_inference,88,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.19230769230769232,195,0.7894736842105263,10,0.47619047619047616,1,1,experiments
197,The regularization constant was 1E - 4 and the mini-batch size was 5 .,Models,Models,natural_language_inference,88,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'O']",,,11,0.21153846153846154,196,0.7935222672064778,11,0.5238095238095238,1,1,experiments
198,A dropout rate of 0.5 was applied to the neural network classifier .,Models,Models,natural_language_inference,88,"['O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.23076923076923078,197,0.7975708502024291,12,0.5714285714285714,1,1,experiments
200,"Most of these models ( including ours ) are LSTM variants ( third block in , recursive neural networks ( first block ) , or convolutional neural networks ( CNNs ; second block ) .",Models,Models,natural_language_inference,88,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.2692307692307692,199,0.805668016194332,14,0.6666666666666666,1,1,experiments
203,"For comparison , we also report the performance of the paragraph vector model ( PV ; ; see , second block ) which neither operates on trees nor sequences but learns distributed document representations parameterized directly .",Models,Models,natural_language_inference,88,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.3269230769230769,202,0.8178137651821862,17,0.8095238095238095,1,1,experiments
204,The results in show that both 1 - and 2 - layer LSTMNs outperform the LSTM baselines while achieving numbers comparable to state of the art .,Models,Models,natural_language_inference,88,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.34615384615384615,203,0.8218623481781376,18,0.8571428571428571,1,1,experiments
206,On the fine - grained and binary classification tasks our 2 - layer LSTMN performs close to the best system T -. shows examples of intra-attention for sentiment words .,Models,Models,natural_language_inference,88,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.38461538461538464,205,0.8299595141700404,20,0.9523809523809523,1,1,experiments
208,Natural Language Inference,Models,,natural_language_inference,88,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",22,0.4230769230769231,207,0.8380566801619433,0,0.0,1,1,experiments
220,We used pre-trained 300 - D Glove 840B vectors to initialize the word embeddings .,Models,Natural Language Inference,natural_language_inference,88,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",34,0.6538461538461539,219,0.8866396761133604,12,0.4,1,1,experiments
221,"Out - of - vocabulary ( OOV ) words were initialized randomly with Gaussian samples ( = 0 , ?= 1 ) .",Models,Natural Language Inference,natural_language_inference,88,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",35,0.6730769230769231,220,0.8906882591093117,13,0.43333333333333335,1,1,experiments
222,"We only updated OOV vectors in the first epoch , after which all word embeddings were updated normally .",Models,Natural Language Inference,natural_language_inference,88,"['O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'O']",,,36,0.6923076923076923,221,0.8947368421052632,14,0.4666666666666667,1,1,experiments
223,"The dropout rate was selected from [ 0.1 , 0.2 , 0.3 , 0.4 ] .",Models,Natural Language Inference,natural_language_inference,88,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",37,0.7115384615384616,222,0.8987854251012146,15,0.5,1,1,experiments
224,"We used Adam ( Kingma and Ba , 2015 ) for optimization with the two momentum parameters set to 0.9 and 0.999 respectively , and the initial learning rate set to 1E - 3 .",Models,Natural Language Inference,natural_language_inference,88,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O']",,,38,0.7307692307692307,223,0.902834008097166,16,0.5333333333333333,1,1,experiments
225,The mini- batch size was set to 16 or 32 .,Models,Natural Language Inference,natural_language_inference,88,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",39,0.75,224,0.9068825910931174,17,0.5666666666666667,1,1,experiments
228,"Specifically , these include a model which encodes the premise and hypothesis independently with two LSTMs , a shared LSTM ( Rocktschel et al. , 2016 ) , a word - by - word attention model , and a matching LSTM ( m LSTM ; ) .",Models,Natural Language Inference,natural_language_inference,88,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",42,0.8076923076923077,227,0.9190283400809717,20,0.6666666666666666,1,1,experiments
230,We also compared our models with a bag - of - words baseline which averages the pre-trained embeddings for the words in each sentence and concatenates them to create features for a logistic regression classifier ( first block in ) .,Models,Natural Language Inference,natural_language_inference,88,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",44,0.8461538461538461,229,0.9271255060728745,22,0.7333333333333333,1,1,experiments
231,LSTMNs achieve better performance compared Models,Models,Natural Language Inference,natural_language_inference,88,"['B', 'B', 'B', 'I', 'O', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'O', 'O']","['B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O']",45,0.8653846153846154,230,0.9311740890688259,23,0.7666666666666667,1,1,experiments
233,"We also observe that fusion is generally beneficial , and that deep fusion slightly improves over shallow fusion .",Models,Natural Language Inference,natural_language_inference,88,"['O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",47,0.9038461538461539,232,0.9392712550607287,25,0.8333333333333334,1,1,experiments
235,"With standard training , our deep fusion yields the state - of - the - art performance in this task .",Models,Natural Language Inference,natural_language_inference,88,"['B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",49,0.9423076923076923,234,0.9473684210526315,27,0.9,1,1,experiments
2,Read + Verify : Machine Reading Comprehension with Unanswerable Questions,title,title,natural_language_inference,89,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",1,0.0,1,0.0038461538461538464,1,0.0,1,1,research-problem
26,"To address the above issue , we propose a read - then - verify system that aims to be robust to unanswerable questions in this paper .",Introduction,Introduction,natural_language_inference,89,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",16,0.45714285714285713,25,0.09615384615384616,16,0.45714285714285713,1,1,model
27,"As shown in , our system consists of two components : ( 1 ) a no-answer reader for extracting candidate answers and detecting unanswerable questions , and ( 2 ) an answer verifier for deciding whether or not the extracted candidate is legitimate .",Introduction,Introduction,natural_language_inference,89,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",17,0.4857142857142857,26,0.1,17,0.4857142857142857,1,1,model
29,"First , we augment existing readers with two auxiliary losses , to better handle answer extraction and no - answer detection respectively .",Introduction,Introduction,natural_language_inference,89,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.5428571428571428,28,0.1076923076923077,19,0.5428571428571428,1,1,model
32,We solve this problem by introducing an independent span loss that aims to concentrate on the answer extraction task regardless of the answerability of the question .,Introduction,Introduction,natural_language_inference,89,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.6285714285714286,31,0.11923076923076924,22,0.6285714285714286,1,1,model
33,"In order to not conflict with no - answer detection , we leverage a multi-head pointer network to generate two pairs of span scores , where one pair is normalized with the no -answer score and the other is used for our auxiliary loss .",Introduction,Introduction,natural_language_inference,89,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",23,0.6571428571428571,32,0.12307692307692308,23,0.6571428571428571,1,1,model
34,"Besides , we present another independent noanswer loss to further alleviate the confliction , by focusing on the no-answer detection task without considering the shared normalization of answer extraction .",Introduction,Introduction,natural_language_inference,89,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",24,0.6857142857142857,33,0.12692307692307692,24,0.6857142857142857,1,1,model
35,"Second , in addition to the standard reading phase , we introduce an additional answer verifying phase , which aims at finding local entailment that supports the answer by comparing the answer sentence with the question .",Introduction,Introduction,natural_language_inference,89,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",25,0.7142857142857143,34,0.13076923076923078,25,0.7142857142857143,1,1,model
39,"Inspired by recent advances in natural language inference ( NLI ) , we investigate three different architectures for the answer verifying task .",Introduction,Introduction,natural_language_inference,89,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",29,0.8285714285714286,38,0.14615384615384616,29,0.8285714285714286,1,1,model
40,"The first one is a sequential model that takes two sentences as along sequence , while the second one attempts to capture interactions between two sentences .",Introduction,Introduction,natural_language_inference,89,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'O']",,,30,0.8571428571428571,39,0.15,30,0.8571428571428571,1,1,model
41,The last one is a hybrid model that combines the above two models to test if the performance can be further improved .,Introduction,Introduction,natural_language_inference,89,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",31,0.8857142857142857,40,0.15384615384615385,31,0.8857142857142857,1,1,model
177,"We run a grid search on ? and ? among [ 0.1 , 0.3 , 0.5 , 0.7 , 1 , 2 ] .",Implementation,Implementation,natural_language_inference,89,"['O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.4,176,0.676923076923077,4,0.4,1,1,experimental-setup
179,"As for answer verifiers , we use the original configuration from for Model - I. For Model - II , the Adam optimizer ( Kingma and Ba 2014 ) with a learning rate of 0.0008 is used , the hidden size is set as 300 , and a dropout ) of 0.3 is applied for preventing overfitting .",Implementation,Implementation,natural_language_inference,89,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'O']",,,6,0.6,178,0.6846153846153846,6,0.6,1,1,experimental-setup
180,"The batch size is 48 for the reader , 64 for Model - II , and 32 for Model - I as well as Model - III .",Implementation,Implementation,natural_language_inference,89,"['O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O']",,,7,0.7,179,0.6884615384615385,7,0.7,1,1,experimental-setup
181,"We use the Glo Ve 100D embeddings for the reader , and 300D embeddings for Model - II and Model - III .",Implementation,Implementation,natural_language_inference,89,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']",,,8,0.8,180,0.6923076923076923,8,0.8,1,1,experimental-setup
182,"We utilize the nltk tokenizer 3 to preprocess passages and questions , as well as split sentences .",Implementation,Implementation,natural_language_inference,89,"['O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'O']",9,0.9,181,0.6961538461538461,9,0.9,1,1,experimental-setup
187,"As we can see , our system obtains state - of the - art results by achieving an EM score of 71.7 and a F 1 score of 74.2 on the test set .",Evaluation Main Results,Evaluation Main Results,natural_language_inference,89,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O']",,,3,0.6,186,0.7153846153846154,3,0.6,1,1,results
188,Notice that SLQA + has reached a comparable result compared to our approach .,Evaluation Main Results,Evaluation Main Results,natural_language_inference,89,"['B', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",4,0.8,187,0.7192307692307692,4,0.8,1,1,results
193,"Removing the independent span loss ( indep - I ) results in a performance drop for all answerable questions ( HasAns ) , indicating that this loss helps the model in better identifying the answer boundary .",Ablation Study,Ablation Study,natural_language_inference,89,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.06976744186046512,192,0.7384615384615385,3,0.13636363636363635,1,1,ablation-analysis
194,"Ablating independent no - answer loss ( indep - II ) , on the other hand , causes little influence on HasAns , but leads to a severe decline on no - answer accuracy ( NoAns ACC ) .",Ablation Study,Ablation Study,natural_language_inference,89,"['B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,4,0.09302325581395349,193,0.7423076923076923,4,0.18181818181818182,1,1,ablation-analysis
196,"Finally , deleting both of two losses causes a degradation of more than 1.5 points on the over all performance in terms of F1 , with or without ELMo embeddings .",Ablation Study,Ablation Study,natural_language_inference,89,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",6,0.13953488372093023,195,0.75,6,0.2727272727272727,1,1,ablation-analysis
200,"Adding ELMo embeddings , however , does not boost the performance .",Ablation Study,Ablation Study,natural_language_inference,89,"['B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-ob', 'O']",10,0.23255813953488372,199,0.7653846153846153,10,0.45454545454545453,1,1,ablation-analysis
204,We find that the improvement on noanswer accuracy is significant .,Ablation Study,Ablation Study,natural_language_inference,89,"['O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'O']",14,0.32558139534883723,203,0.7807692307692308,14,0.6363636363636364,1,1,ablation-analysis
210,We observe that RMR + ELMo + Verifier achieves the best precision when the recall is less than 80 .,Ablation Study,Ablation Study,natural_language_inference,89,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",20,0.46511627906976744,209,0.8038461538461539,20,0.9090909090909091,1,1,ablation-analysis
212,"Ablating two auxiliary losses , however , leads to an over all degradation on the curve , but it still outperforms the baseline by a large margin .",Ablation Study,Ablation Study,natural_language_inference,89,"['O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",22,0.5116279069767442,211,0.8115384615384615,22,1.0,1,1,ablation-analysis
2,Published as a conference paper at ICLR 2017 QUERY - REDUCTION NETWORKS FOR QUESTION ANSWERING,title,title,natural_language_inference,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.0030303030303030303,1,0.0,1,1,research-problem
4,"In this paper , we study the problem of question answering when reasoning over multiple facts is required .",abstract,abstract,natural_language_inference,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",1,0.2,3,0.00909090909090909,1,0.2,1,1,research-problem
24,"Our proposed model , Query - Reduction Network 1 ( QRN ) , is a single recurrent unit that addresses the long - term dependency problem of most RNN - based models by simplifying the recurrent update , while taking the advantage of RNN 's capability to model sequential data ) .",INTRODUCTION,INTRODUCTION,natural_language_inference,9,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O']",,,15,0.4838709677419355,23,0.0696969696969697,15,0.4838709677419355,1,1,model
25,"QRN considers the context sentences as a sequence of state - changing triggers , and transforms ( reduces ) the original query to a more informed query as it observes each trigger through time .",INTRODUCTION,INTRODUCTION,natural_language_inference,9,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'O']",16,0.5161290322580645,24,0.07272727272727272,16,0.5161290322580645,1,1,model
33,"Compared to memory - based approaches , QRN can better encodes locality information because it does not use a global memory access controller ( circle nodes in ) , and the query updates are performed locally .",INTRODUCTION,INTRODUCTION,natural_language_inference,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'O']",24,0.7741935483870968,32,0.09696969696969697,24,0.7741935483870968,1,1,model
204,We withhold 10 % of the training for development .,Training .,Training .,natural_language_inference,9,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'B-ob', 'O']",1,0.09090909090909091,203,0.6151515151515151,23,0.2948717948717949,1,1,hyperparameters
205,We use the hidden state size of 50 by deafult .,Training .,Training .,natural_language_inference,9,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O']",2,0.18181818181818182,204,0.6181818181818182,24,0.3076923076923077,1,1,hyperparameters
206,"Batch sizes of 32 for bAbI story - based QA 1k , bAb I dialog and DSTC2 dialog , and 128 for bAbI QA 10 k are used .",Training .,Training .,natural_language_inference,9,"['B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O']",,,3,0.2727272727272727,205,0.6212121212121212,25,0.32051282051282054,1,1,hyperparameters
207,The weights in the input and output modules are initialized with zero mean and the standard deviation of 1 / ? d.,Training .,Training .,natural_language_inference,9,"['O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.36363636363636365,206,0.6242424242424243,26,0.3333333333333333,1,1,hyperparameters
209,Forget bias of 2.5 is used for update gates ( no bias for reset gates ) .,Training .,Training .,natural_language_inference,9,"['B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.5454545454545454,208,0.6303030303030303,28,0.358974358974359,1,1,hyperparameters
210,L2 weight decay of 0.001 ( 0.0005 for QA 10 k ) is used for all weights .,Training .,Training .,natural_language_inference,9,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",7,0.6363636363636364,209,0.6333333333333333,29,0.3717948717948718,1,1,hyperparameters
211,The loss function is the cross entropy between v and the one - hot vector of the true answer .,Training .,Training .,natural_language_inference,9,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",8,0.7272727272727273,210,0.6363636363636364,30,0.38461538461538464,1,1,hyperparameters
212,"The loss is minimized by stochastic gradient descent for maximally 500 epochs , but training is early stopped if the loss on the development data does not decrease for 50 epochs .",Training .,Training .,natural_language_inference,9,"['O', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']",,,9,0.8181818181818182,211,0.6393939393939394,31,0.3974358974358974,1,1,hyperparameters
213,The learning rate is controlled by AdaGrad with the initial learning rate of 0.5 ( 0.1 for QA 10 k ) .,Training .,Training .,natural_language_inference,9,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.9090909090909091,212,0.6424242424242425,32,0.41025641025641024,1,1,hyperparameters
214,"Since the model is sensitive to the weight initialization , we repeat each training procedure 10 times ( 50 times for 10 k ) with the new random initialization of the weights and report the result on the test data with the lowest loss on the development data .",Training .,Training .,natural_language_inference,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,1.0,213,0.6454545454545455,33,0.4230769230769231,1,1,hyperparameters
217,"These include LSTM , End - to - end Memory Networks ( N2N ) , Dynamic Memory Networks ( DMN + ) , Gated End - to - end Memory Networks ( GMe m N2N ) , and Differentiable Neural Computer ( DNC ) .",RESULTS .,RESULTS .,natural_language_inference,9,"['O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.2,216,0.6545454545454545,36,0.46153846153846156,1,1,baselines
220,"In 1 k data , QRN 's ' 2 r' ( 2 layers + reset gate + d = 50 ) outperforms all other models by a large margin ( 2.8 + % ) .",RESULTS .,Story - based QA .,natural_language_inference,9,"['B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.5,219,0.6636363636363637,39,0.5,1,1,results
221,"In 10 k dataset , the average accuracy of QRN 's ' 6r200 ' ( 6 layers + reset gate + d = 200 ) model outperforms all previous models by a large margin ( 2.5 + % ) , achieving a nearly perfect score of 99.7 % .",RESULTS .,Story - based QA .,natural_language_inference,9,"['O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']",,,6,0.6,220,0.6666666666666666,40,0.5128205128205128,1,1,results
225,QRN outperforms previous work by a large margin ( 2.0 + % ) in every comparison .,RESULTS .,Story - based QA .,natural_language_inference,9,"['B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",10,1.0,224,0.6787878787878788,44,0.5641025641025641,1,1,results
229,"According to the ablation results , we infer that : ( a ) When the number of layers is only one , the model lacks reasoning capability .",Ablations .,Ablations .,natural_language_inference,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",3,0.09090909090909091,228,0.6909090909090909,48,0.6153846153846154,1,1,ablation-analysis
230,"In the case of 1 k dataset , when there are too many layers ( 6 ) , it seems correctly training the model becomes increasingly difficult .",Ablations .,Ablations .,natural_language_inference,9,"['B', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'O']",4,0.12121212121212122,229,0.693939393939394,49,0.6282051282051282,1,1,ablation-analysis
231,"In the case of 10 k dataset , many layers ( 6 ) and hidden dimensions ( 200 ) helps reasoning , most notably in difficult task such as task 16 .",Ablations .,Ablations .,natural_language_inference,9,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.15151515151515152,230,0.696969696969697,50,0.6410256410256411,1,1,ablation-analysis
232,( b ) Adding the reset gate helps .,Ablations .,Ablations .,natural_language_inference,9,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-ob', 'O']",6,0.18181818181818182,231,0.7,51,0.6538461538461539,1,1,ablation-analysis
233,"( c ) Including vector gates hurts in 1 k datasets , as the model either overfits to the training data or converges to local minima .",Ablations .,Ablations .,natural_language_inference,9,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.21212121212121213,232,0.703030303030303,52,0.6666666666666666,1,1,ablation-analysis
234,"On the other hand , vector gates in bAbI story - based QA 10 k dataset sometimes help .",Ablations .,Ablations .,natural_language_inference,9,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",8,0.24242424242424243,233,0.706060606060606,53,0.6794871794871795,1,1,ablation-analysis
235,"( d ) Increasing the dimension of the hidden state to 100 in the dialog 's Task 6 ( DSTC2 ) helps , while there is not much improvement in the dialog 's Task 1 - 5 .",Ablations .,Ablations .,natural_language_inference,9,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.2727272727272727,234,0.7090909090909091,54,0.6923076923076923,1,1,ablation-analysis
236,It can be hypothesized that a larger hidden state is required for real data . Parallelization .,Ablations .,Ablations .,natural_language_inference,9,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O']",10,0.30303030303030304,235,0.7121212121212122,55,0.7051282051282052,1,1,ablation-analysis
2,A Decomposable Attention Model for Natural Language Inference,title,,natural_language_inference,90,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.006666666666666667,1,0.0,1,1,research-problem
9,Natural language inference ( NLI ) refers to the problem of determining entailment and contradiction relationships between a premise and a hypothesis .,Introduction,Introduction,natural_language_inference,90,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.043478260869565216,8,0.05333333333333334,1,0.043478260869565216,1,1,research-problem
10,NLI is a central problem in language understanding ) and recently the large SNLI corpus of 570K sentence pairs was created for this task .,Introduction,Introduction,natural_language_inference,90,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.08695652173913043,9,0.06,2,0.08695652173913043,1,1,research-problem
24,"In contrast to existing approaches , our approach only relies on alignment and is fully computationally decomposable with respect to the input text .",Introduction,Introduction,natural_language_inference,90,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",16,0.6956521739130435,23,0.15333333333333332,16,0.6956521739130435,1,1,model
26,"Given two sentences , where each word is repre-sented by an embedding vector , we first create a soft alignment matrix using neural attention .",Introduction,Introduction,natural_language_inference,90,"['B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']",,,18,0.782608695652174,25,0.16666666666666666,18,0.782608695652174,1,1,model
27,We then use the ( soft ) alignment to decompose the task into subproblems that are solved separately .,Introduction,Introduction,natural_language_inference,90,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O']",19,0.8260869565217391,26,0.17333333333333334,19,0.8260869565217391,1,1,model
28,"Finally , the results of these subproblems are merged to produce the final classification .",Introduction,Introduction,natural_language_inference,90,"['O', 'O', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",20,0.8695652173913043,27,0.18,20,0.8695652173913043,1,1,model
29,"In addition , we optionally apply intra-sentence attention to endow the model with a richer encoding of substructures prior to the alignment step .",Introduction,Introduction,natural_language_inference,90,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",21,0.9130434782608695,28,0.18666666666666668,21,0.9130434782608695,1,1,model
112,The method was implemented in TensorFlow .,Implementation Details,Implementation Details,natural_language_inference,90,"['O', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",1,0.0625,111,0.74,1,0.0625,1,1,experimental-setup
119,We use 300 dimensional GloVe embeddings to represent words .,Implementation Details,Implementation Details,natural_language_inference,90,"['O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",8,0.5,118,0.7866666666666666,8,0.5,1,1,experimental-setup
120,"Each embedding vector was normalized to have 2 norm of 1 and projected down to 200 dimensions , a number determined via hyperparameter tuning .",Implementation Details,Implementation Details,natural_language_inference,90,"['B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.5625,119,0.7933333333333333,9,0.5625,1,1,experimental-setup
121,Out - of - vocabulary ( OOV ) words are hashed to one of 100 random embeddings each initialized to mean 0 and standard deviation 1 .,Implementation Details,Implementation Details,natural_language_inference,90,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.625,120,0.8,10,0.625,1,1,experimental-setup
123,All other parameter weights ( hidden layers etc. ) were initialized from random Gaussians with mean 0 and standard deviation 0.01 .,Implementation Details,Implementation Details,natural_language_inference,90,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.75,122,0.8133333333333334,12,0.75,1,1,experimental-setup
124,"Each hyperparameter setting was run on a single machine with 10 asynchronous gradient - update threads , using Adagrad for optimization with the default initial accumulator value of 0.1 .",Implementation Details,Implementation Details,natural_language_inference,90,"['B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O']",,,13,0.8125,123,0.82,13,0.8125,1,1,experimental-setup
125,"Dropout regularization was used for all ReLU layers , but not for the final linear layer .",Implementation Details,Implementation Details,natural_language_inference,90,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",14,0.875,124,0.8266666666666667,14,0.875,1,1,experimental-setup
126,"We additionally tuned the following hyperparameters and present their chosen values in , 1 dropout ratio ( 0.2 ) and learning rate ( 0.05 - vanilla , 0.025 - intra-attention ) .",Implementation Details,Implementation Details,natural_language_inference,90,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'O', 'B-b', 'O', 'B-ob', 'O', 'B-b', 'O', 'O']",15,0.9375,125,0.8333333333333334,15,0.9375,1,1,experimental-setup
130,Our vanilla approach achieves state - of - theart results with almost an order of magnitude fewer parameters than the LSTMN of .,Results,Results,natural_language_inference,90,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O']",2,0.1111111111111111,129,0.86,2,0.1111111111111111,1,1,results
131,Adding intra-sentence attention gives a considerable improvement of 0.5 percentage points over the existing state of the art .,Results,Results,natural_language_inference,90,"['B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.16666666666666666,130,0.8666666666666667,3,0.16666666666666666,1,1,results
2,A Fast Unified Model for Parsing and Sentence Understanding,title,,natural_language_inference,91,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.004291845493562232,1,0.0,1,1,research-problem
21,"This paper introduces a new model to address both these issues : the Stack - augmented Parser - Interpreter Neural Network , or SPINN , shown in .",Introduction,Introduction,natural_language_inference,91,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O']",12,0.6,20,0.08583690987124463,12,0.6,1,1,model
22,"SPINN executes the computations of a tree - structured model in a linearized sequence , and can incorporate a neural network parser that produces the required parse structure on the fly .",Introduction,Introduction,natural_language_inference,91,"['B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",13,0.65,21,0.09012875536480687,13,0.65,1,1,model
23,This design improves upon the TreeRNN architecture in three ways :,Introduction,Introduction,natural_language_inference,91,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O']",14,0.7,22,0.0944206008583691,14,0.7,1,1,model
24,"At test time , it can simultaneously parse and interpret unparsed sentences , removing the dependence on an external parser at nearly no additional computational cost .",Introduction,Introduction,natural_language_inference,91,"['B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'B-b', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.75,23,0.09871244635193133,15,0.75,1,1,model
25,"Secondly , it supports batched computation for both parsed and unparsed sentences , yielding dramatic speedups over standard TreeRNNs .",Introduction,Introduction,natural_language_inference,91,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",16,0.8,24,0.10300429184549356,16,0.8,1,1,model
26,"Finally , it supports a novel tree - sequence hybrid architecture for handling local linear context in sentence interpretation .",Introduction,Introduction,natural_language_inference,91,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",17,0.85,25,0.1072961373390558,17,0.85,1,1,model
143,Our optimized C ++/ CUDA models and the Theano source code for the full SPINN are available at https://github.com / stanfordnlp/spinn. 30 tokens or fewer .,Implementation issues,Inference speed,natural_language_inference,91,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",48,0.8727272727272727,142,0.6094420600858369,7,0.5,1,1,experimental-setup
144,We fix the model dimension D and the word embedding dimension at 300 .,Implementation issues,Inference speed,natural_language_inference,91,"['O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'O']",49,0.8909090909090909,143,0.6137339055793991,8,0.5714285714285714,1,1,experimental-setup
145,We run the CPU performance test on a 2.20 GHz 16 core Intel Xeon E5-2660 processor with hyperthreading enabled .,Implementation issues,Inference speed,natural_language_inference,91,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O']",50,0.9090909090909091,144,0.6180257510729614,9,0.6428571428571429,1,1,experimental-setup
146,We test our thin - stack implementation and the RNN model on an NVIDIA Titan X GPU .,Implementation issues,Inference speed,natural_language_inference,91,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",51,0.9272727272727272,145,0.6223175965665236,10,0.7142857142857143,1,1,experimental-setup
189,"We find that the bare SPINN - PI - NT model performs little better than the RNN baseline , but that SPINN - PI with the added tracking LSTM performs well .",Results,Results,natural_language_inference,91,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']",,,1,0.022222222222222223,188,0.8068669527896996,1,0.1111111111111111,1,1,results
191,"The full SPINN model with its relatively weak internal parser performs slightly less well , but nonetheless robustly exceeds the performance of the RNN baseline .",Results,Results,natural_language_inference,91,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",3,0.06666666666666667,190,0.8154506437768241,3,0.3333333333333333,1,1,results
192,Both SPINN - PI and the full SPINN significantly outperform all previous sentence - encoding models .,Results,Results,natural_language_inference,91,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.08888888888888889,191,0.8197424892703863,4,0.4444444444444444,1,1,results
193,"Most notably , these models outperform the tree - based CNN of , which also uses tree - structured composition for local feature extraction , but uses simpler pooling techniques to build sentence features in the interest of efficiency .",Results,Results,natural_language_inference,91,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.1111111111111111,192,0.8240343347639485,5,0.5555555555555556,1,1,results
194,"Our results show that a model that uses tree - structured composition fully ( SPINN ) outper - forms one which uses it only partially ( tree - based CNN ) , which in turn outperforms one which does not use it at all ( RNN ) .",Results,Results,natural_language_inference,91,"['O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'B-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'I-b', 'I-b', 'B-b', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.13333333333333333,193,0.8283261802575107,6,0.6666666666666666,1,1,results
195,"The full SPINN performed moderately well at reproducing the Stanford Parser 's parses of the SNLI data at a transition - by - transition level , with 92.4 % accuracy at test time .",Results,Results,natural_language_inference,91,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']",,,7,0.15555555555555556,194,0.8326180257510729,7,0.7777777777777778,1,1,results
2,A Discrete Hard EM Approach for Weakly Supervised Question Answering,title,title,natural_language_inference,92,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.003472222222222222,1,0.0,1,1,research-problem
4,Many question answering ( QA ) tasks only provide weak supervision for how the answer should be computed .,abstract,abstract,natural_language_inference,92,"['O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.010416666666666666,1,0.14285714285714285,1,1,research-problem
8,"Despite its simplicity , we show that this approach significantly outperforms previous methods on six QA tasks , including absolute gains of 2 - 10 % , and achieves the stateof - the - art on five of them .",abstract,abstract,natural_language_inference,92,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.7142857142857143,7,0.024305555555555556,5,0.7142857142857143,1,1,research-problem
20,"In this paper , we show it is possible to formulate a wide range of weakly supervised QA tasks as discrete latent - variable learning problems .",Introduction,Introduction,natural_language_inference,92,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.391304347826087,19,0.06597222222222222,9,0.391304347826087,1,1,model
25,"We demonstrate that for many recently introduced tasks , which we group into three categories as given in , it is relatively easy to precompute a discrete , task - specific set of possible solutions that contains the correct solution along with a modest number of spurious options .",Introduction,Introduction,natural_language_inference,92,"['O', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']",,,14,0.6086956521739131,24,0.08333333333333333,14,0.6086956521739131,1,1,
26,"The learning challenge is then to determine which solution in the set is the correct one , while estimating a complete QA model .",Introduction,Introduction,natural_language_inference,92,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",15,0.6521739130434783,25,0.08680555555555555,15,0.6521739130434783,1,1,model
27,"We model the set of possible solutions as a discrete latent variable , and develop a learning strategy that uses hard - EM - style parameter updates .",Introduction,Introduction,natural_language_inference,92,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.6956521739130435,26,0.09027777777777778,16,0.6956521739130435,1,1,model
28,"This algorithm repeatedly ( i ) predicts the most likely solution according to the current model from the precomputed set , and ( ii ) updates the model parameters to further encourage its own prediction .",Introduction,Introduction,natural_language_inference,92,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",17,0.7391304347826086,27,0.09375,17,0.7391304347826086,1,1,model
29,"Intuitively , these hard updates more strongly enforce our prior beliefs that there is a single correct solution .",Introduction,Introduction,natural_language_inference,92,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",18,0.782608695652174,28,0.09722222222222222,18,0.782608695652174,1,1,model
155,Multi-mention Reading Comprehension,Experiments,Experiments,natural_language_inference,92,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",3,0.3,154,0.5347222222222222,0,0.0,1,1,experiments
164,We use uncased version of BERT base .,Training details .,,natural_language_inference,92,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",1,0.1,163,0.5659722222222222,9,0.375,1,1,experiments
166,We use batch size of 20 for two reading comprehension tasks and 192 for two open - domain QA tasks .,Training details .,We use uncased version of BERT base .,natural_language_inference,92,"['O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']",,,3,0.3,165,0.5729166666666666,11,0.4583333333333333,1,1,experiments
168,"For opendomain QA tasks , we retrieve 50 Wikipedia articles through TF - IDF ( Chen et al. , 2017 ) and further run to retrieve 20 ( for train ) or 80 ( for development and test ) paragraphs .",Training details .,We use uncased version of BERT base .,natural_language_inference,92,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.5,167,0.5798611111111112,13,0.5416666666666666,1,1,experiments
169,"We try 10 , 20 , 40 and 80 paragraphs on the development set to choose the number of paragraphs to use on the test set .",Training details .,We use uncased version of BERT base .,natural_language_inference,92,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",6,0.6,168,0.5833333333333334,14,0.5833333333333334,1,1,experiments
170,"To avoid local optima , we perform annealing : at training step t , the model optimizes on MML objective with a probability of min ( t / ? , 1 ) and otherwise use our objective , where ?",Training details .,We use uncased version of BERT base .,natural_language_inference,92,"['B', 'I', 'B', 'I', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.7,169,0.5868055555555556,15,0.625,1,1,experiments
176,"6 First of all , we observe that First - Only is a strong baseline across all the datasets .",Results .,Results .,natural_language_inference,92,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",2,0.05,175,0.6076388888888888,21,0.875,1,1,experiments
178,"Second , while MML achieves comparable result to the First - Only baseline , our learning method outperforms others by 2 + F1 / ROUGE - L / EM consistently on all datasets .",Results .,Results .,natural_language_inference,92,"['O', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'B-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",4,0.1,177,0.6145833333333334,23,0.9583333333333334,1,1,experiments
179,"Lastly , our method achieves the new state - of the - art on NARRATIVEQA , TRIVIAQA - OPEN and NATURALQUESTIONS - OPEN , and is comparable to the state - of - the - art on TRIVIAQA , despite our aggressive truncation of documents .",Results .,Results .,natural_language_inference,92,"['O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,5,0.125,178,0.6180555555555556,24,1.0,1,1,experiments
2,Gated Self - Matching Networks for Reading Comprehension and Question Answering,title,title,natural_language_inference,93,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004830917874396135,1,0.0,1,1,research-problem
4,"In this paper , we present the gated selfmatching networks for reading comprehension style question answering , which aims to answer questions from a given passage .",abstract,abstract,natural_language_inference,93,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.014492753623188406,1,0.14285714285714285,1,1,research-problem
22,"Inspired by , we introduce a gated self - matching network , illustrated in , an end - to - end neural network model for reading comprehension and question answering .",Introduction,Introduction,natural_language_inference,93,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.12222222222222222,21,0.10144927536231885,11,0.4074074074074074,1,1,model
23,Our model consists of four parts :,Introduction,Introduction,natural_language_inference,93,"['O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O']",12,0.13333333333333333,22,0.10628019323671498,12,0.4444444444444444,1,1,model
24,"1 ) the recurrent network encoder to build representation for questions and passages separately , 2 ) the gated matching layer to match the question and passage , 3 ) the self - matching layer to aggregate information from the whole passage , and 4 ) the pointernetwork based answer boundary prediction layer .",Introduction,Introduction,natural_language_inference,93,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.14444444444444443,23,0.1111111111111111,13,0.48148148148148145,1,1,model
108,We use the tokenizer from Stanford CoreNLP to preprocess each passage and question .,Implementation Details,Implementation Details,natural_language_inference,93,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.3125,107,0.5169082125603864,5,0.38461538461538464,1,1,experimental-setup
109,The Gated Recurrent Unit variant of LSTM is used throughout our model .,Implementation Details,Implementation Details,natural_language_inference,93,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",6,0.375,108,0.5217391304347826,6,0.46153846153846156,1,1,experimental-setup
110,"For word embedding , we use pretrained case - sensitive GloVe embeddings 2 ( Pennington et al. , 2014 ) for both questions and passages , and it is fixed during training ; We use zero vectors to represent all out - of - vocab words .",Implementation Details,Implementation Details,natural_language_inference,93,"['B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.4375,109,0.5265700483091788,7,0.5384615384615384,1,1,experimental-setup
111,"We utilize 1 layer of bi-directional GRU to compute character - level embeddings and 3 layers of bi-directional GRU to encode questions and passages , the gated attention - based recurrent network for question and passage matching is also encoded bidirectionally in our experiment .",Implementation Details,Implementation Details,natural_language_inference,93,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'O']",8,0.5,110,0.5314009661835749,8,0.6153846153846154,1,1,experimental-setup
112,The hidden vector length is set to 75 for all layers .,Implementation Details,Implementation Details,natural_language_inference,93,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",9,0.5625,111,0.5362318840579711,9,0.6923076923076923,1,1,experimental-setup
113,The hidden size used to compute attention scores is also 75 .,Implementation Details,Implementation Details,natural_language_inference,93,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",10,0.625,112,0.5410628019323671,10,0.7692307692307693,1,1,experimental-setup
114,We also apply dropout between layers with a dropout rate of 0.2 .,Implementation Details,Implementation Details,natural_language_inference,93,"['O', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",11,0.6875,113,0.5458937198067633,11,0.8461538461538461,1,1,experimental-setup
115,"The model is optimized with AdaDelta ( Zeiler , 2012 ) with an initial learning rate of 1 .",Implementation Details,Implementation Details,natural_language_inference,93,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",12,0.75,114,0.5507246376811594,12,0.9230769230769231,1,1,experimental-setup
116,The ? and used in AdaDelta are 0.95 and 1e ? 6 respectively .,Implementation Details,Implementation Details,natural_language_inference,93,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",13,0.8125,115,0.5555555555555556,13,1.0,1,1,experimental-setup
132,attention - based recurrent network ( GARNN ) and self - matching attention mechanism positively contribute to the final results of gated self - matching networks .,Ablation Study,Ablation Study,natural_language_inference,93,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.2857142857142857,131,0.6328502415458938,6,0.5,1,1,ablation-analysis
133,"Removing self - matching results in 3.5 point EM drop , which reveals that information in the passage plays an important role .",Ablation Study,Ablation Study,natural_language_inference,93,"['B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.3333333333333333,132,0.6376811594202898,7,0.5833333333333334,1,1,ablation-analysis
134,Characterlevel embeddings contribute towards the model 's performance since it can better handle out - ofvocab or rare words .,Ablation Study,Ablation Study,natural_language_inference,93,"['B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.38095238095238093,133,0.642512077294686,8,0.6666666666666666,1,1,ablation-analysis
137,Character - level embeddings are not utilized .,Ablation Study,Ablation Study,natural_language_inference,93,"['B', 'I', 'I', 'I', 'O', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'O']",11,0.5238095238095238,136,0.6570048309178744,11,0.9166666666666666,1,1,ablation-analysis
138,"As shown in , the gate introduced in question and passage matching layer is helpful for both GRU and LSTM on the SQuAD dataset .",Ablation Study,Ablation Study,natural_language_inference,93,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",12,0.5714285714285714,137,0.6618357487922706,12,1.0,1,1,ablation-analysis
2,Commonsense for Generative Multi - Hop Question Answering Tasks,title,,natural_language_inference,94,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.0,1,0.0026109660574412533,1,0.0,1,1,research-problem
4,"Reading comprehension QA tasks have seen a recent surge in popularity , yet most works have focused on fact - finding extractive QA .",abstract,abstract,natural_language_inference,94,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.05263157894736842,3,0.007832898172323759,1,0.05263157894736842,1,1,research-problem
14,"Reading comprehension QA tasks have seen a recent surge in popularity , yet most works have focused on fact - finding extractive QA .",abstract,abstract,natural_language_inference,94,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,11,0.5789473684210527,13,0.033942558746736295,11,0.5789473684210527,1,1,research-problem
24,"In this paper , we explore the task of machine reading comprehension ( MRC ) based QA .",Introduction,Introduction,natural_language_inference,94,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.05,23,0.06005221932114883,1,0.05,1,1,research-problem
27,https://github.com/yicheng-w/CommonSenseMultiHopQA task tests a model 's natural language understanding capabilities by asking it to answer a question based on a passage of relevant content .,Introduction,Introduction,natural_language_inference,94,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.2,26,0.06788511749347259,4,0.2,1,1,code
28,"Much progress has been made in reasoning - based MRC - QA on the bAbI dataset , which contains questions that require the combination of multiple disjoint pieces of evidence in the context .",Introduction,Introduction,natural_language_inference,94,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.25,27,0.07049608355091384,5,0.25,1,1,research-problem
37,"In this paper , we first propose the Multi - Hop Pointer - Generator Model ( MHPGM ) , a strong baseline model that uses multiple hops of bidirectional attention , self - attention , and a pointer - generator decoder to effectively read and reason within along passage and synthesize a coherent response .",Introduction,Introduction,natural_language_inference,94,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'O']",14,0.7,36,0.09399477806788512,14,0.7,1,1,model
39,"Next , to address the issue that understanding human - generated text and performing longdistance reasoning on it often involves intermittent access to missing hops of external commonsense ( background ) knowledge , we present an algorithm for selecting useful , grounded multi-hop relational knowledge paths from ConceptNet ) via a pointwise mutual information ( PMI ) and term - frequency - based scoring function .",Introduction,Introduction,natural_language_inference,94,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.8,38,0.09921671018276762,16,0.8,1,1,model
40,"We then present a novel method of inserting these selected commonsense paths between the hops of document - context reasoning within our model , via the Necessary and Optional Information Cell ( NOIC ) , which employs a selectivelygated attention mechanism that utilizes commonsense information to effectively fill in gaps of inference .",Introduction,Introduction,natural_language_inference,94,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O']",,,17,0.85,39,0.10182767624020887,17,0.85,1,1,model
214,"We see empirically that our model outperforms all generative models on NarrativeQA , and is competitive with the top span prediction models .",Main Experiment,Main Experiment,natural_language_inference,94,"['O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-n', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-b', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.3333333333333333,213,0.556135770234987,2,0.3333333333333333,1,1,results
215,"Furthermore , with the NOIC commonsense integration , we were able to further improve performance ( p < 0.001 on all metrics 5 ) , establishing a new state - of - the - art for the task .",Main Experiment,Main Experiment,natural_language_inference,94,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",3,0.5,214,0.5587467362924282,3,0.5,1,1,results
216,"We also see that our model performs reasonably well on WikiHop , and further achieves promising initial improvements via the addition of commonsense , hinting at the generalizability of our approaches .",Main Experiment,Main Experiment,natural_language_inference,94,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']",,,4,0.6666666666666666,215,0.5613577023498695,4,0.6666666666666666,1,1,results
217,"We speculate that the improvement is smaller on Wikihop because only approximately 11 % of WikiHop data points require commonsense and because WikiHop data requires more fact - based commonsense ( e.g. , from Freebase ) as opposed to semantics - based commonsense ( e.g. , from Con-ceptNet ( Speer and Havasi , 2012 ) ) .",Main Experiment,Main Experiment,natural_language_inference,94,"['O', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.8333333333333334,216,0.5639686684073107,5,0.8333333333333334,1,1,results
224,Experiment 1 and 5 are our models presented in were also important for the model 's performance and that self - attention is able to contribute significantly to performance on top of other components of the model .,Model Ablations,Model Ablations,natural_language_inference,94,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.8333333333333334,223,0.5822454308093995,5,0.8333333333333334,1,1,ablation-analysis
225,"Finally , we see that effectively introducing external knowledge via our commonsense selection algorithm and NOIC can improve performance even further on top of our strong baseline .",Model Ablations,Model Ablations,natural_language_inference,94,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'B-b', 'B-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,1.0,224,0.5848563968668408,6,1.0,1,1,ablation-analysis
232,"The results of these are shown in , where we see that neither NumberBatch nor random - relationships nor single - hop common - sense offer statistically significant improvements 7 , whereas our commonsense selection and incorporation mechanism improves performance significantly across all metrics .",Commonsense Ablations,Commonsense Ablations,natural_language_inference,94,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",6,0.8571428571428571,231,0.6031331592689295,6,0.8571428571428571,1,1,ablation-analysis
2,Multi - Passage Machine Reading Comprehension with Cross - Passage Answer Verification,title,title,natural_language_inference,95,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.004273504273504274,1,0.0,1,1,research-problem
4,Machine reading comprehension ( MRC ) on real web data usually requires the machine to answer a question by analyzing multiple passages retrieved by search engine .,abstract,abstract,natural_language_inference,95,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.01282051282051282,1,0.2,1,1,research-problem
5,"Compared with MRC on a single passage , multi-passage MRC is more challenging , since we are likely to get multiple confusing answer candidates from different passages .",abstract,abstract,natural_language_inference,95,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.4,4,0.017094017094017096,2,0.4,1,1,research-problem
51,"The over all framework of our model is demonstrated in , which consists of three modules .",Introduction,Introduction,natural_language_inference,95,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O']",42,0.7368421052631579,50,0.21367521367521367,42,0.7368421052631579,1,1,model
52,"First , we follow the boundary - based MRC models to find an answer candidate for each passage by identifying the start and end position of the answer ( .",Introduction,Introduction,natural_language_inference,95,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'O', 'O']",43,0.7543859649122807,51,0.21794871794871795,43,0.7543859649122807,1,1,model
53,"Second , we model the meanings of the answer candidates extracted from those passages and use the content scores to measure the quality of the candidates from a second perspective .",Introduction,Introduction,natural_language_inference,95,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O']",,,44,0.7719298245614035,52,0.2222222222222222,44,0.7719298245614035,1,1,model
54,"Third , we conduct the answer verification by enabling each answer candidate to attend to the other candidates based on their representations .",Introduction,Introduction,natural_language_inference,95,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",45,0.7894736842105263,53,0.2264957264957265,45,0.7894736842105263,1,1,model
56,"Therefore , the final answer is determined by three factors : the boundary , the content and the crosspassage answer verification .",Introduction,Introduction,natural_language_inference,95,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'O', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-ob', 'O', 'O', 'B-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",47,0.8245614035087719,55,0.23504273504273504,47,0.8245614035087719,1,1,model
57,"The three steps are modeled using different modules , which can be jointly trained in our end - to - end framework .",Introduction,Introduction,natural_language_inference,95,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",48,0.8421052631578947,56,0.23931623931623933,48,0.8421052631578947,1,1,model
145,"For MS - MARCO , we preprocess the corpus with the reversible tokenizer from Stanford CoreNLP and we choose the span that achieves the highest ROUGE - L score with the reference answers as the gold span for training .",Implementation Details,Implementation Details,natural_language_inference,95,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0625,144,0.6153846153846154,1,0.0625,1,1,experimental-setup
146,We employ the 300 - D pre-trained Glove embeddings and keep it fixed during training .,Implementation Details,Implementation Details,natural_language_inference,95,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'O']",2,0.125,145,0.6196581196581197,2,0.125,1,1,experimental-setup
147,The character embeddings are randomly initialized with its dimension as 30 .,Implementation Details,Implementation Details,natural_language_inference,95,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O']",3,0.1875,146,0.6239316239316239,3,0.1875,1,1,experimental-setup
161,Results on DuReader,,,natural_language_inference,95,"['O', 'B', 'B']","['O', 'B-p', 'B-n']","['O', 'B-p', 'B-b']",0,0.0,160,0.6837606837606838,0,0.0,1,1,results
165,We can see that this paragraph ranking can boost the BiDAF baseline significantly .,Results on DuReader,Results on DuReader,natural_language_inference,95,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'B-ob', 'O']",4,0.25,164,0.7008547008547008,4,0.26666666666666666,1,1,results
166,"Finally , we implement our system based on this new strategy , and our system ( single model ) achieves further improvement by a large margin .",Results on DuReader,Results on DuReader,natural_language_inference,95,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.3125,165,0.7051282051282052,5,0.3333333333333333,1,1,results
186,"From , we can see that the answer verification makes a great contribution to the over all improvement , which confirms our hypothesis that cross - passage answer verification is useful for the multi-passage MRC .",Ablation Study,Ablation Study,natural_language_inference,95,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",8,0.25806451612903225,185,0.7905982905982906,8,0.6666666666666666,1,1,ablation-analysis
187,"For the ablation of the content model , we analyze that it will not only affect the content score itself , but also violate the verification model since the content probabilities are necessary for the answer representation , which will be further analyzed in Section 4.3 .",Ablation Study,Ablation Study,natural_language_inference,95,"['B', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.2903225806451613,186,0.7948717948717948,9,0.75,1,1,ablation-analysis
188,"Another discovery is that jointly training the three models can provide great benefits , which shows that the three tasks are actually closely related and can boost each other with shared representations at bottom layers .",Ablation Study,Ablation Study,natural_language_inference,95,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",10,0.3225806451612903,187,0.7991452991452992,10,0.8333333333333334,1,1,ablation-analysis
189,"At last , comparing our method with the baseline , we achieve an improvement of nearly 3 points without the yes / no classification .",Ablation Study,Ablation Study,natural_language_inference,95,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.3548387096774194,188,0.8034188034188035,11,0.9166666666666666,1,1,ablation-analysis
2,Swag : A Large - Scale Adversarial Dataset for Grounded Commonsense Inference,title,title,natural_language_inference,96,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.002564102564102564,1,0.0,1,1,research-problem
36,We use this method to construct Swag : an adversarial dataset with 113 k multiple - choice questions .,Introduction,Introduction,natural_language_inference,96,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",25,0.1497005988023952,35,0.08974358974358974,25,0.5102040816326531,1,1,dataset
37,"We start with pairs of temporally adjacent video captions , each with a context and a follow - up event that we know is physically possible .",Introduction,Introduction,natural_language_inference,96,"['O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",26,0.15568862275449102,36,0.09230769230769231,26,0.5306122448979592,1,1,dataset
38,We then use a state - of - theart language model fine - tuned on this data to massively oversample a diverse set of possible negative sentence endings ( or counterfactuals ) .,Introduction,Introduction,natural_language_inference,96,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",27,0.16167664670658682,37,0.09487179487179487,27,0.5510204081632653,1,1,dataset
39,"Next , we filter these candidate endings aggressively and adversarially using a committee of trained models to obtain a population of de-biased endings with similar stylistic features to the real ones .",Introduction,Introduction,natural_language_inference,96,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",28,0.16766467065868262,38,0.09743589743589744,28,0.5714285714285714,1,1,dataset
40,"Finally , these filtered counterfactuals are validated by crowd workers to further ensure data quality .",Introduction,Introduction,natural_language_inference,96,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",29,0.17365269461077845,39,0.1,29,0.5918367346938775,1,1,dataset
236,"The best model that only uses the ending is the LSTM sequence model with ELMo embeddings , which obtains 43.6 % .",Results,Results,natural_language_inference,96,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",2,0.03125,235,0.6025641025641025,2,0.2222222222222222,1,1,results
237,"This model , as with most models studied , greatly improves with more context : by 3.1 % when given the initial noun phrase , and by an ad-ditional 4 % when also given the first sentence .",Results,Results,natural_language_inference,96,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O']",,,3,0.046875,236,0.6051282051282051,3,0.3333333333333333,1,1,results
238,Further improvement is gained from models that compute pairwise representations of the inputs .,Results,Results,natural_language_inference,96,"['B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",4,0.0625,237,0.6076923076923076,4,0.4444444444444444,1,1,results
239,"While the simplest such model , Dual - BoW , obtains only 35.1 % accuracy , combining In - fer Sent sentence representations gives 40.5 % accuracy ( InferSent - Bilinear ) .",Results,Results,natural_language_inference,96,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",5,0.078125,238,0.6102564102564103,5,0.5555555555555556,1,1,results
240,"The best results come from pairwise NLI models : when fully trained on Swag , ESIM + ELMo obtains 59.2 % accuracy .",Results,Results,natural_language_inference,96,"['O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.09375,239,0.6128205128205129,6,0.6666666666666666,1,1,results
2,A Parallel - Hierarchical Model for Machine Comprehension on Sparse Data,title,title,natural_language_inference,97,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O']",1,0.0,1,0.003424657534246575,1,0.0,1,1,research-problem
4,Understanding unstructured text is a major goal within natural language processing .,abstract,abstract,natural_language_inference,97,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.125,3,0.010273972602739725,1,0.125,1,1,research-problem
16,Machine comprehension ( MC ) is evaluated by posing a set of questions based on a text passage ( akin to the reading tests we all took in school ) .,Introduction,Introduction,natural_language_inference,97,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.08695652173913043,15,0.05136986301369863,4,0.1111111111111111,1,1,research-problem
21,We present a parallel - hierarchical approach to machine comprehension designed to work well in a data - limited setting .,Introduction,Introduction,natural_language_inference,97,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.1956521739130435,20,0.0684931506849315,9,0.25,1,1,model
26,Our model learns to comprehend at a high level even when data is sparse .,Introduction,Introduction,natural_language_inference,97,"['O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O']",14,0.30434782608695654,25,0.08561643835616438,14,0.3888888888888889,1,1,model
27,The key to our model is that it compares the question and answer candidates to the text using several distinct perspectives .,Introduction,Introduction,natural_language_inference,97,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",15,0.32608695652173914,26,0.08904109589041095,15,0.4166666666666667,1,1,model
29,"The semantic perspective compares the hypothesis to sentences in the text viewed as single , self - contained thoughts ; these are represented using a sum and transformation of word embedding vectors , similarly to in .",Introduction,Introduction,natural_language_inference,97,"['O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",17,0.3695652173913043,28,0.0958904109589041,17,0.4722222222222222,1,1,model
30,"The word - by - word perspective focuses on similarity matches between individual words from hypothesis and text , at various scales .",Introduction,Introduction,natural_language_inference,97,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",18,0.391304347826087,29,0.09931506849315068,18,0.5,1,1,model
31,"As in the semantic perspective , we consider matches over complete sentences .",Introduction,Introduction,natural_language_inference,97,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",19,0.41304347826086957,30,0.10273972602739725,19,0.5277777777777778,1,1,model
32,"We also use a sliding window acting on a subsentential scale ( inspired by the work of ) , which implicitly considers the linear distance between matched words .",Introduction,Introduction,natural_language_inference,97,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.43478260869565216,31,0.10616438356164383,20,0.5555555555555556,1,1,model
218,"For word vectors we use Google 's publicly available embeddings , trained with word2vec on the 100 - billion - word News corpus .",Training and Model Details,Training and Model Details,natural_language_inference,97,"['B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.12,217,0.7431506849315068,3,0.12,1,1,experimental-setup
219,"These vectors are kept fixed throughout training , since we found that training them was not helpful ( likely because of MCTest 's size ) .",Training and Model Details,Training and Model Details,natural_language_inference,97,"['O', 'O', 'O', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.16,218,0.7465753424657534,4,0.16,1,1,experimental-setup
220,The vectors are 300 - dimensional ( d = 300 ) .,Training and Model Details,Training and Model Details,natural_language_inference,97,"['O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.2,219,0.75,5,0.2,1,1,experimental-setup
231,"We found dropout to be particularly effective at improving generalization from the training to the test set , and used 0.5 as the dropout probability .",Training and Model Details,Training and Model Details,natural_language_inference,97,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",16,0.64,230,0.7876712328767124,16,0.64,1,1,experimental-setup
232,"Dropout occurs after all neural - network transformations , if those transformations are allowed to change with training .",Training and Model Details,Training and Model Details,natural_language_inference,97,"['B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'O']","['B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O']","['B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O']",17,0.68,231,0.791095890410959,17,0.68,1,1,experimental-setup
235,"We used the Adam optimizer with the standard settings ( Kingma and Ba , 2014 ) and a learning rate of 0.003 .",Training and Model Details,Training and Model Details,natural_language_inference,97,"['O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",20,0.8,234,0.8013698630136986,20,0.8,1,1,experimental-setup
247,"On MCTest - 500 , the Parallel Hierarchical model significantly outperforms these methods on single questions ( > 2 % ) and slightly outperforms the latter two on multi questions ( ? 0.3 % ) and over all ( ?",Results,Results,natural_language_inference,97,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']",,,6,0.13953488372093023,246,0.8424657534246576,6,0.4,1,1,results
249,The method of achieves the best over all result on MCTest - 160 .,Results,Results,natural_language_inference,97,"['O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.18604651162790697,248,0.8493150684931506,8,0.5333333333333333,1,1,results
253,Here we see our model outperforming the alternatives by a large margin across the board ( > 15 % ) .,Results,Results,natural_language_inference,97,"['O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-b', 'O', 'B-ob', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.27906976744186046,252,0.863013698630137,12,0.8,1,1,results
260,"Not surprisingly , the n-gram functionality is important , contributing almost 5 % accuracy improvement .",Results,Analysis and Discussion,natural_language_inference,97,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.4418604651162791,259,0.886986301369863,3,0.1111111111111111,1,1,ablation-analysis
263,"The top N function contributes very little to the over all performance , suggesting that most multi questions have their evidence distributed across contiguous sentences .",Results,Analysis and Discussion,natural_language_inference,97,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.5116279069767442,262,0.8972602739726028,6,0.2222222222222222,1,1,ablation-analysis
264,"Ablating the sentential component made the most significant difference , reducing performance by more than 5 % .",Results,Analysis and Discussion,natural_language_inference,97,"['B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",23,0.5348837209302325,263,0.9006849315068494,7,0.25925925925925924,1,1,ablation-analysis
265,Simple word - by - word matching is obviously useful on MCTest .,Results,Analysis and Discussion,natural_language_inference,97,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'O']",24,0.5581395348837209,264,0.9041095890410958,8,0.2962962962962963,1,1,ablation-analysis
266,"The sequential sliding window makes a 3 % contribution , highlighting the importance of word - distance measures .",Results,Analysis and Discussion,natural_language_inference,97,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",25,0.5813953488372093,265,0.9075342465753424,9,0.3333333333333333,1,1,ablation-analysis
267,"On the other hand , the dependency - based sliding window makes only a minor contribution .",Results,Analysis and Discussion,natural_language_inference,97,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'O']",26,0.6046511627906976,266,0.910958904109589,10,0.37037037037037035,1,1,ablation-analysis
270,"Finally , the exogenous word weights make a significant contribution of almost 5 % .",Results,Analysis and Discussion,natural_language_inference,97,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",29,0.6744186046511628,269,0.9212328767123288,13,0.48148148148148145,1,1,ablation-analysis
2,Recurrent Neural Network - Based Sentence Encoder with Gated Attention for Natural Language Inference,title,title,natural_language_inference,98,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.00847457627118644,1,0.0,1,1,research-problem
14,"Task aims to evaluate language understanding models for sentence representation with natural language inference ( NLI ) tasks , where a sentence is represented as a fixedlength vector .",Introduction,Shared,natural_language_inference,98,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.42857142857142855,13,0.11016949152542373,3,0.42857142857142855,1,1,research-problem
16,"Specifically , NLI is concerned with determining whether a hypothesis sentence h can be inferred from a premise sentence p.",Introduction,Shared,natural_language_inference,98,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.7142857142857143,15,0.1271186440677966,5,0.7142857142857143,1,1,research-problem
29,"We present here the proposed natural language inference networks which are composed of the following major components : word embedding , sequence encoder , composition layer , and the toplayer classifier .",Methods,Methods,natural_language_inference,98,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",1,0.022222222222222223,28,0.23728813559322035,1,0.5,1,1,model
31,Word Embedding,Methods,,natural_language_inference,98,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",3,0.06666666666666667,30,0.2542372881355932,0,0.0,1,1,model
33,We concatenate embeddings learned at two different levels to represent each word in the sentence : the character composition and holistic word - level embedding .,Methods,Word Embedding,natural_language_inference,98,"['O', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.1111111111111111,32,0.2711864406779661,2,0.25,1,1,model
40,Sequence Encoder,Methods,,natural_language_inference,98,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",12,0.26666666666666666,39,0.3305084745762712,0,0.0,1,1,model
41,"To represent words and their context in a premise and hypothesis , sentence pairs are fed into sentence encoders to obtain hidden vectors ( h p and h h ) .",Methods,Sequence Encoder,natural_language_inference,98,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.28888888888888886,40,0.3389830508474576,1,0.08333333333333333,1,1,model
42,We use stacked bidirectional LSTMs ( BiL - STM ) as the encoders .,Methods,Sequence Encoder,natural_language_inference,98,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",14,0.3111111111111111,41,0.3474576271186441,2,0.16666666666666666,1,1,model
53,Composition Layer,Methods,,natural_language_inference,98,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",25,0.5555555555555556,52,0.4406779661016949,0,0.0,1,1,model
54,"To transform sentences into fixed - length vector representations and reason using those representations , we need to compose the hidden vectors obtained by the sequence encoder layer ( h p and h h ) .",Methods,Composition Layer,natural_language_inference,98,"['B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",26,0.5777777777777777,53,0.4491525423728814,1,0.05,1,1,model
55,We propose intra-sentence gated - attention to obtain a fixed - length vector .,Methods,Composition Layer,natural_language_inference,98,"['O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,0.6,54,0.4576271186440678,2,0.1,1,1,model
67,Top - layer Classifier,Methods,Composition Layer,natural_language_inference,98,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",39,0.8666666666666667,66,0.559322033898305,14,0.7,1,1,model
68,Our inference model feeds the resulting vectors obtained above to the final classifier to determine the over all inference relationship .,Methods,Composition Layer,natural_language_inference,98,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",40,0.8888888888888888,67,0.5677966101694916,15,0.75,1,1,model
82,"To help replicate our results , we publish our code at https : //github.com/lukecq1231/enc_nli",Training,Training,natural_language_inference,98,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",2,0.15384615384615385,81,0.6864406779661016,8,0.42105263157894735,1,1,code
84,"We use the Adam ( Kingma and Ba , 2014 ) for optimization .",Training,Training,natural_language_inference,98,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",4,0.3076923076923077,83,0.7033898305084746,10,0.5263157894736842,1,1,experimental-setup
85,"Stacked BiLSTM has 3 layers , and all hidden states of BiLSTMs and MLP have 600 dimensions .",Training,Training,natural_language_inference,98,"['B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",5,0.38461538461538464,84,0.711864406779661,11,0.5789473684210527,1,1,experimental-setup
86,"The character embedding has 15 dimensions , and CNN filters length is [ 1 , 3 , 5 ] , each of those is 100 dimensions .",Training,Training,natural_language_inference,98,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O']",6,0.46153846153846156,85,0.7203389830508474,12,0.631578947368421,1,1,experimental-setup
87,We use pretrained GloVe - 840B - 300D vectors as our word - level embeddings and fix these embeddings during the training process .,Training,Training,natural_language_inference,98,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",7,0.5384615384615384,86,0.7288135593220338,13,0.6842105263157895,1,1,experimental-setup
88,Out - of - vocabulary ( OOV ) words are initialized randomly with Gaussian samples .,Training,Training,natural_language_inference,98,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.6153846153846154,87,0.7372881355932204,14,0.7368421052631579,1,1,experimental-setup
95,"In addition , we also use our implementation of ESIM , which achieves an accuracy of 76.8 % in the in - domain test set , and 75.8 % in the cross - domain test set , which presents the state - of - the - art results .",Results,Results,natural_language_inference,98,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,1,0.09090909090909091,94,0.7966101694915254,1,0.09090909090909091,1,1,results
96,"After removing the cross - sentence attention and adding our gated - attention model , we achieve accuracies of 73.5 % and 73.6 % , which ranks first in the cross - domain test set and ranks second in the in - domain test set among the single models .",Results,Results,natural_language_inference,98,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,2,0.18181818181818182,95,0.8050847457627118,2,0.18181818181818182,1,1,results
97,"When ensembling our models , we obtain accuracies 74.9 % and 74.9 % , which ranks first in both test sets .",Results,Results,natural_language_inference,98,"['B', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'O']","['B-p', 'B-n', 'B-p', 'I-p', 'O', 'O', 'B-n', 'B-p', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'B-p', 'I-p', 'O', 'O', 'B-b', 'B-p', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.2727272727272727,96,0.8135593220338984,3,0.2727272727272727,1,1,results
102,"If we remove the gated - attention , the accuracies drop to 72.8 % and 73.6 % .",Results,Results,natural_language_inference,98,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.7272727272727273,101,0.8559322033898306,8,0.7272727272727273,1,1,ablation-analysis
103,"If we remove charactercomposition vector , the accuracies drop to 72.9 % and 73.5 % .",Results,Results,natural_language_inference,98,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-ob', 'B-s', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.8181818181818182,102,0.864406779661017,9,0.8181818181818182,1,1,ablation-analysis
104,"If we remove word - level embedding , the accuracies drop to 65.6 % and 66.0 % .",Results,Results,natural_language_inference,98,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'B-s', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.9090909090909091,103,0.8728813559322034,10,0.9090909090909091,1,1,ablation-analysis
4,"Machine Comprehension ( MC ) is a challenging task in Natural Language Processing field , which aims to guide the machine to comprehend a passage and answer the given question .",abstract,abstract,natural_language_inference,99,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.011904761904761904,1,0.14285714285714285,1,1,research-problem
5,"Many existing approaches on MC task are suffering the inefficiency in some bottlenecks , such as insufficient lexical understanding , complex question - passage interaction , incorrect answer extraction and soon .",abstract,abstract,natural_language_inference,99,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.2857142857142857,4,0.015873015873015872,2,0.2857142857142857,1,1,research-problem
13,Recently machine comprehension task accumulates much concern among NLP researchers .,Introduction,Introduction,natural_language_inference,99,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.030303030303030304,12,0.047619047619047616,2,0.06451612903225806,1,1,research-problem
28,"In this paper , we propose the novel framework named Smarnet with the hope that it can become as smart as humans .",Introduction,Introduction,natural_language_inference,99,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.25757575757575757,27,0.10714285714285714,17,0.5483870967741935,1,1,model
30,"Specifically , we first introduce the Smarnet framework that exploits fine - grained word understanding with various attribution discriminations , like humans recite words with corresponding properties .",Introduction,Introduction,natural_language_inference,99,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.2878787878787879,29,0.11507936507936507,19,0.6129032258064516,1,1,model
31,We then develop the interactive attention with memory network to mimic human reading procedure .,Introduction,Introduction,natural_language_inference,99,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",20,0.30303030303030304,30,0.11904761904761904,20,0.6451612903225806,1,1,model
32,We also add a checking layer on the answer refining in order to ensure the accuracy .,Introduction,Introduction,natural_language_inference,99,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",21,0.3181818181818182,31,0.12301587301587301,21,0.6774193548387096,1,1,model
190,"We preprocess each passage and question using the library of nltk and exploit the popular pretrained word embedding GloVe with 100 - dimensional vectors ( Pennington , Socher , and Manning 2014 ) for both questions and passages .",Experiments Datasets,Implemental Details,natural_language_inference,99,"['O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.5333333333333333,189,0.75,1,0.125,1,1,experimental-setup
191,The size of char - level embedding is also set as 100 - dimensional and is obtained by CNN filters under the instruction of ( Kim 2014 ) .,Experiments Datasets,Implemental Details,natural_language_inference,99,"['O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.6,190,0.753968253968254,2,0.25,1,1,experimental-setup
193,We adopt the AdaDelta ( Zeiler 2012 ) optimizer for training with an initial learning rate of 0.0005 .,Experiments Datasets,Implemental Details,natural_language_inference,99,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",11,0.7333333333333333,192,0.7619047619047619,4,0.5,1,1,experimental-setup
194,The batch size is set to be 48 for both the SQuAD and TriviaQA datasets .,Experiments Datasets,Implemental Details,natural_language_inference,99,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.8,193,0.7658730158730159,5,0.625,1,1,experimental-setup
195,We also apply dropout ( Srivastava et al. 2014 ) between layers with a dropout rate of 0.2 .,Experiments Datasets,Implemental Details,natural_language_inference,99,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",13,0.8666666666666667,194,0.7698412698412699,6,0.75,1,1,experimental-setup
196,"For the multi-hop reasoning , we set the number of hops as 2 which is imitating human reading procedure on skimming and scanning .",Experiments Datasets,Implemental Details,natural_language_inference,99,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'O', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",14,0.9333333333333333,195,0.7738095238095238,7,0.875,1,1,experimental-setup
197,"During training , we set the moving averages of all weights as the exponential decay rate of 0.999 .",Experiments Datasets,Implemental Details,natural_language_inference,99,"['B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']",,,15,1.0,196,0.7777777777777778,8,1.0,1,1,experimental-setup
209,"From the tables 1 and 2 we can see our single model achieves an EM score of 71.415 % and a F1 score of 80.160 % and the ensemble model improves to EM 75.989 % and F1 83. 475 % , which are both only after the r-net method at the time of submission .",Overall Results,Overall Results,natural_language_inference,99,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,7,0.7,208,0.8253968253968254,7,0.7,1,1,results
211,We also compare our models on the recently proposed dataset Trivia QA. shows the performance comparison on the test set of Trivia QA .,Overall Results,Overall Results,natural_language_inference,99,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O']",9,0.9,210,0.8333333333333334,9,0.9,1,1,results
212,We can see our Smarnet model outperforms the other baselines on both wikipedia domain and web domain .,Overall Results,Overall Results,natural_language_inference,99,"['O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",10,1.0,211,0.8373015873015873,10,1.0,1,1,results
216,"We see the full features integration obtain the best performance , which demonstrates the necessity of combining all the features into consideration .",Ablation Results,Ablation Results,natural_language_inference,99,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.12,215,0.8531746031746031,3,0.2,1,1,ablation-analysis
217,"Among all the feature ablations , the Part - Of - Speech , Exact Match , Qtype features drop much more than the other features , which shows the importance of these three features .",Ablation Results,Ablation Results,natural_language_inference,99,"['B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.16,216,0.8571428571428571,4,0.26666666666666666,1,1,ablation-analysis
219,"As for the final ablation of POS and NER , we can see the performance decays over 3 % point , which clearly proves the usefulness of the comprehensive lexical information .",Ablation Results,Ablation Results,natural_language_inference,99,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.24,218,0.8650793650793651,6,0.4,1,1,ablation-analysis
221,"We first replace our input gate mechanism into simplified feature concatenation strategy , the performance drops nearly 2.3 % on the EM score , which proves the effectiveness of our proposed dynamic input gating mechanism .",Ablation Results,Ablation Results,natural_language_inference,99,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-n', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'B-b', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.32,220,0.873015873015873,8,0.5333333333333333,1,1,ablation-analysis
223,The result proves that our modification of employing question influence on the passage encoding can boost the result up to 1.3 % on the EM score .,Ablation Results,Ablation Results,natural_language_inference,99,"['O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,10,0.4,222,0.8809523809523809,10,0.6666666666666666,1,1,ablation-analysis
2,NegBERT : A Transfer Learning Approach for Negation Detection and Scope Resolution,title,title,negation_scope_resolution,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004347826086956522,1,0.0,1,1,research-problem
34,"Motivated by the success of transfer learning , we apply BERT to negation detection and scope resolution .",Introduction,Introduction,negation_scope_resolution,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",22,0.6470588235294118,33,0.14347826086956522,22,0.7586206896551724,1,1,approach
35,"We explore the set of design choices involved , and experiment on all 3 public datasets available : the BioScope Corpus ( Abstracts and Full Papers ) , the Sherlock Dataset and the SFU Review Corpus .",Introduction,Introduction,negation_scope_resolution,0,"['O', 'B', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",23,0.6764705882352942,34,0.14782608695652175,23,0.7931034482758621,1,1,approach
189,We use Google 's BERT as the base model to generate contextual embeddings for the sentence .,Experimentation,Experimentation,negation_scope_resolution,0,"['O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",1,0.1,188,0.8173913043478261,1,0.1,1,1,experimental-setup
190,The input to the BERT model is a sequence of tokenized and encoded tokens of a sentence .,Experimentation,Experimentation,negation_scope_resolution,0,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",2,0.2,189,0.8217391304347826,2,0.2,1,1,experimental-setup
191,"We then use a vector of dimension R H x N_C to compute scores per token , for the classification task at hand .",Experimentation,Experimentation,negation_scope_resolution,0,"['O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.3,190,0.8260869565217391,3,0.3,1,1,experimental-setup
192,"BERT outputs a vector of size R H per token of the input , which we feed to a common classification layer of dimen-sion R Hx5 for cue detection and R Hx2 for scope resolution .",Experimentation,Experimentation,negation_scope_resolution,0,"['B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']",,,4,0.4,191,0.8304347826086956,4,0.4,1,1,experimental-setup
193,"We use early stopping on dev data for 6 epochs as tolerance and F 1 score as the early stopping metric , use the Adam optimizer with an initial learning rate of 3 e - 5 , and the Categorical Cross Entropy Loss with class weights as described above to avoid training on the padded label outputs .",Experimentation,Experimentation,negation_scope_resolution,0,"['O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O']",,,5,0.5,192,0.8347826086956521,5,0.5,1,1,experimental-setup
194,"We perform cue detection and scope resolution for all 3 datasets , and train on 1 and test on all datasets .",Experimentation,Experimentation,negation_scope_resolution,0,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",6,0.6,193,0.8391304347826087,6,0.6,1,1,experimental-setup
197,"For all other corpuses , we use a default 70 - 15 - 15 split for the train - dev - test data .",Experimentation,Experimentation,negation_scope_resolution,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.9,196,0.8521739130434782,9,0.9,1,1,experimental-setup
198,"We trained the models on free GPUs available via Google Colaboratory , the training scripts are publicly available .",Experimentation,Experimentation,negation_scope_resolution,0,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,1.0,197,0.8565217391304348,10,1.0,1,1,experimental-setup
201,"For cue detection , on the Sherlock dataset test data , we see that we outperform the best system [ FBK Chowdhury ] by 0.6 F1 measure .",Results,Results,negation_scope_resolution,0,"['B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.09523809523809523,200,0.8695652173913043,2,0.09523809523809523,1,1,results
202,"On the BioScope Abstracts , we perform reasonably well .",Results,Results,negation_scope_resolution,0,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",3,0.14285714285714285,201,0.8739130434782608,3,0.14285714285714285,1,1,results
204,"On the BioScope Full papers , we are able to achieve 90.43 F1 when training on the same data , but we do note that the amount of training data available is significantly lower than for the other datasets , and while general Deep Learning based approaches can not perform well in such situations , we still manage to perform well .",Results,Results,negation_scope_resolution,0,"['O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.23809523809523808,203,0.8826086956521739,5,0.23809523809523808,1,1,results
205,"On the SFU Review Corpus , we achieve an F1 of 87.08 .",Results,Results,negation_scope_resolution,0,"['O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O']",6,0.2857142857142857,204,0.8869565217391304,6,0.2857142857142857,1,1,results
208,For scope resolution :,Results,Results,negation_scope_resolution,0,"['O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O']",9,0.42857142857142855,207,0.9,9,0.42857142857142855,1,1,results
209,"On the Sherlock dataset , we achieve an F1 of 92.36 , outperforming the previous State of the Art by a significant margin ( almost 3.0 F1 ) .",Results,Results,negation_scope_resolution,0,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.47619047619047616,208,0.9043478260869565,10,0.47619047619047616,1,1,results
210,"On the BioScope Abstracts , we achieve an F1 of 95.68 , outperforming the best architecture by 3.57 F1 .",Results,Results,negation_scope_resolution,0,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.5238095238095238,209,0.908695652173913,11,0.5238095238095238,1,1,results
211,"On the Bioscope Full Papers , we outperform the best architecture by 2.64 F1 when training on the same dataset",Results,Results,negation_scope_resolution,0,"['O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob']",12,0.5714285714285714,210,0.9130434782608695,12,0.5714285714285714,1,1,results
212,"On the SFU Review Corpus , we outperform the best system to date by 1.02 F1 .",Results,Results,negation_scope_resolution,0,"['O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",13,0.6190476190476191,211,0.9173913043478261,13,0.6190476190476191,1,1,results
213,"For negation cue detection , we observe a significant gap between our model , NegBERT , and the current state - of the - art systems , while we outperform the baseline systems .",Results,Results,negation_scope_resolution,0,"['O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",14,0.6666666666666666,212,0.9217391304347826,14,0.6666666666666666,1,1,results
217,"When we trained on BioScope Abstracts and tested on the BioScope Full Papers , we surprisingly observed a stateof - the - art result of 91.24 ( a gain of 3.89 F1 points over training on BioScope Full Papers ) , which is far beyond the achievable results on training and evaluating on the Bio-Medical sub corpora .",Results,Results,negation_scope_resolution,0,"['O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.8571428571428571,216,0.9391304347826087,18,0.8571428571428571,1,1,results
2,Learning Semantic Sentence Embeddings using Pair- wise Discriminator,title,,paraphrase_generation,0,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.004219409282700422,1,0.0,1,1,research-problem
4,"In this paper , we propose a method for obtaining sentence - level embeddings .",abstract,abstract,paraphrase_generation,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.09090909090909091,3,0.012658227848101266,1,0.09090909090909091,1,1,research-problem
22,Our model consists of a sequential encoder - decoder that is further trained using a pairwise discriminator .,Introduction,Introduction,paraphrase_generation,0,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",7,0.25,21,0.08860759493670886,7,0.25,1,1,model
23,The encoder - decoder architecture has been widely used for machine translation and machine comprehension tasks .,Introduction,Introduction,paraphrase_generation,0,"['O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O']",8,0.2857142857142857,22,0.09282700421940929,8,0.2857142857142857,1,1,model
24,"In general , the model ensures a ' local ' loss that is incurred for each recurrent unit cell .",Introduction,Introduction,paraphrase_generation,0,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.32142857142857145,23,0.0970464135021097,9,0.32142857142857145,1,1,model
27,"To ensure that the whole sentence is correctly encoded , we make further use of a pair - wise discriminator that encodes the whole sentence and obtains an embedding for it .",Introduction,Introduction,paraphrase_generation,0,"['B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'O', 'O']",,,12,0.42857142857142855,26,0.10970464135021098,12,0.42857142857142855,1,1,model
28,We further ensure that this is close to the desired ground - truth embeddings while being far from other ( sentences in the corpus ) embeddings .,Introduction,Introduction,paraphrase_generation,0,"['O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.4642857142857143,27,0.11392405063291139,13,0.4642857142857143,1,1,model
29,This model thus provides a ' global ' loss that ensures the sentence embedding as a whole is close to other semantically related sentence embeddings .,Introduction,Introduction,paraphrase_generation,0,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.5,28,0.11814345991561181,14,0.5,1,1,model
148,We start with baseline model which we take as a simple encoder and decoder network with only the local loss ( ED - Local ) .,Ablation Analysis,Ablation Analysis,paraphrase_generation,0,"['O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.09090909090909091,147,0.620253164556962,2,0.13333333333333333,1,1,baselines
149,Further we have experimented with encoder - decoder and a discriminator network with only global loss ( EDD - Global ) to distinguish the ground truth paraphrase with the predicted one .,Ablation Analysis,Ablation Analysis,paraphrase_generation,0,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,3,0.13636363636363635,148,0.6244725738396625,3,0.2,1,1,baselines
150,Another variation of our model is used both the global and local loss ( EDD - LG ) .,Ablation Analysis,Ablation Analysis,paraphrase_generation,0,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.18181818181818182,149,0.6286919831223629,4,0.26666666666666666,1,1,baselines
152,"Finally , we make the discriminator share weights with the encoder and train this network with both the losses ( EDD - LG ( shared ) ) .",Ablation Analysis,Ablation Analysis,paraphrase_generation,0,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,6,0.2727272727272727,151,0.6371308016877637,6,0.4,1,1,baselines
155,"Among the ablations , the proposed EDD - LG ( shared ) method works way better than the other variants in terms of BLEU and METEOR metrics by achieving an improvement of 8 % and 6 % in the scores respectively over the baseline method for 50 K dataset and an improvement of 10 % and 7 % in the scores respectively for 100 K dataset .",Ablation Analysis,Ablation Analysis,paraphrase_generation,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'O']",,,9,0.4090909090909091,154,0.6497890295358649,9,0.6,1,1,ablation-analysis
2,A Deep Generative Framework for Paraphrase Generation,title,,paraphrase_generation,1,"['O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.004524886877828055,1,0.0,1,1,research-problem
5,"In this paper , we address the problem of generating paraphrases automatically .",abstract,abstract,paraphrase_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.25,4,0.01809954751131222,2,0.25,1,1,research-problem
25,"In this paper , we present a deep generative framework for automatically generating paraphrases , given a sentence .",Introduction,Introduction,paraphrase_generation,1,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'O', 'B-p', 'O', 'B-ob', 'O']",13,0.4482758620689655,24,0.1085972850678733,13,0.4482758620689655,1,1,model
26,"Our framework combines the power of sequenceto - sequence models , specifically the long short - term memory ( LSTM ) , and deep generative models , specifically the variational autoencoder ( VAE ) , to develop a novel , end - to - end deep learning architecture for the task of paraphrase generation .",Introduction,Introduction,paraphrase_generation,1,"['O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O']",,,14,0.4827586206896552,25,0.11312217194570136,14,0.4827586206896552,1,1,model
30,"To address this limitation , we present a mechanism to condition our VAE model on the original sentence for which we wish to generate the paraphrases .",Introduction,Introduction,paraphrase_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",18,0.6206896551724138,29,0.13122171945701358,18,0.6206896551724138,1,1,model
32,"Unlike these methods where number of classes are finite , and do not require any intermediate representation , our method conditions both the sides ( i.e. encoder and decoder ) of VAE on the intermediate representation of the input question obtained through LSTM .",Introduction,Introduction,paraphrase_generation,1,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O']",,,20,0.6896551724137931,31,0.14027149321266968,20,0.6896551724137931,1,1,model
35,"In contrast , our deep generative model enjoys a simple , modular architecture , and can generate not just a single but multiple , semantically sensible , paraphrases for any given sentence .",Introduction,Introduction,paraphrase_generation,1,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",23,0.7931034482758621,34,0.15384615384615385,23,0.7931034482758621,1,1,model
38,"This is in contrast to the proposed method where all variations will be of relatively better quality since they are the top beam - search result , generated based on different z sampled from a latent space .",Introduction,Introduction,paraphrase_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",26,0.896551724137931,37,0.167420814479638,26,0.896551724137931,1,1,model
122,Residual LSTM is also the current state - of - the - art on the MSCOCO dataset .,Baselines,Baselines,paraphrase_generation,1,"['B', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",4,0.5,121,0.5475113122171946,4,0.5,1,1,baselines
123,"For the Quora dataset , there were no known baseline results , so we compare our model with ( 1 ) standard VAE model i.e. , the unsupervised version , and ( 2 ) a "" supervised "" variant VAE - S of the unsupervised model .",Baselines,Baselines,paraphrase_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.625,122,0.5520361990950227,5,0.625,1,1,baselines
131,"The dimension of the embedding vector is set to 300 , the dimension of both encoder and decoder is 600 , and the latent space dimension is 1100 .",Experimental Setup,Experimental Setup,paraphrase_generation,1,"['O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'O']",,,4,0.3333333333333333,130,0.5882352941176471,4,0.3333333333333333,1,1,hyperparameters
132,The number of layers in the encoder is 1 and in decoder,Experimental Setup,Experimental Setup,paraphrase_generation,1,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'B']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'B-n']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'B-b']",5,0.4166666666666667,131,0.5927601809954751,5,0.4166666666666667,1,1,hyperparameters
133,2 . Models are trained with stochastic gradient descent with learning rate fixed at a value of 5 10 ? 5 with dropout rate of 30 % .,Experimental Setup,Experimental Setup,paraphrase_generation,1,"['B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",6,0.5,132,0.5972850678733032,6,0.5,1,1,hyperparameters
134,Batch size is kept at 32 .,Experimental Setup,Experimental Setup,paraphrase_generation,1,"['B', 'I', 'O', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",7,0.5833333333333334,133,0.6018099547511312,7,0.5833333333333334,1,1,hyperparameters
135,"Models are trained for a predefined number of iterations , rather than a fixed number of epochs .",Experimental Setup,Experimental Setup,paraphrase_generation,1,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.6666666666666666,134,0.6063348416289592,8,0.6666666666666666,1,1,hyperparameters
139,Number of units in LSTM are set to be the maximum length of the sequence in the training data .,Experimental Setup,Experimental Setup,paraphrase_generation,1,"['B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O']",,,12,1.0,138,0.6244343891402715,12,1.0,1,1,hyperparameters
172,"Furthermore , the paraphrases generated by our system are well - formed , semantically sensible , and grammatically correct for the most part .",Results,Results,paraphrase_generation,1,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",5,0.10416666666666667,171,0.7737556561085973,5,0.10416666666666667,1,1,results
187,"Those numbers are reported in the Measure column with row best - BLEU / best - METEOR . , we report the results for MSCOCO dataset .",Results,Results,paraphrase_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O']",20,0.4166666666666667,186,0.8416289592760181,20,0.4166666666666667,1,1,results
189,"As we can see , we have a significant improvement w.r.t. the baselines .",Results,Results,paraphrase_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",22,0.4583333333333333,188,0.8506787330316742,22,0.4583333333333333,1,1,results
190,"Both variations of our supervised model i.e. , VAE - SVG and VAE - SVG - eq perform better than the state - of - the - art with VAE - SVG performing slightly better than VAE - SVG - eq .",Results,Results,paraphrase_generation,1,"['B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']",,,23,0.4791666666666667,189,0.8552036199095022,23,0.4791666666666667,1,1,results
196,"When comparing our results with the state - of - the - art baseline , the average metric of the VAE - SVG model is able to give a 10 % absolute point performance improvement for the TER metric , a significant number with respect to the difference between the best and second best baseline which only stands at 2 % absolute point .",Results,Results,paraphrase_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",29,0.6041666666666666,195,0.8823529411764706,29,0.6041666666666666,1,1,results
197,"For the BLEU and METEOR , our best results are 4.7 % and 4 % absolute point improvement over the state - of - the - art .",Results,Results,paraphrase_generation,1,"['B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",30,0.625,196,0.8868778280542986,30,0.625,1,1,results
198,"In , we report results for the Quora dataset .",Results,Results,paraphrase_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O']",31,0.6458333333333334,197,0.8914027149321267,31,0.6458333333333334,1,1,results
199,"As we can see , both variations of our model perform significantly better than unsupervised VAE and VAE - S , which is not surprising .",Results,Results,paraphrase_generation,1,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",32,0.6666666666666666,198,0.8959276018099548,32,0.6666666666666666,1,1,results
200,"We also report the results on different training sizes , and as expected , as we increase the training data size , results improve .",Results,Results,paraphrase_generation,1,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'O']",33,0.6875,199,0.9004524886877828,33,0.6875,1,1,results
201,"Comparing the results across different variants of supervised model , VAE - SVG - eq performs the best .",Results,Results,paraphrase_generation,1,"['B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O']","['B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",34,0.7083333333333334,200,0.9049773755656109,34,0.7083333333333334,1,1,results
203,"We also experimented with generating paraphrases through beam - search , and , unlike MSCOCO , it turns out that beam search improves the results significantly .",Results,Results,paraphrase_generation,1,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'B', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-ob', 'O']",36,0.75,202,0.9140271493212669,36,0.75,1,1,results
205,"When comparing the best variant of our model with unsupervised model ( VAE ) , we are able to get more than 27 % absolute point ( more than 3 times ) boost in BLEU score , and more than 19 % absolute point ( more than 2 times ) boost in METEOR ; and when comparing with VAE - S , we are able to get a boost of almost 19 % absolute points in BLEU ( 2 times ) and more than 10 % absolute points in METEOR ( 1.5 times ) .",Results,Results,paraphrase_generation,1,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']",,,38,0.7916666666666666,204,0.9230769230769231,38,0.7916666666666666,1,1,results
2,Robust Multilingual Part - of - Speech Tagging via Adversarial Training,title,title,part-of-speech_tagging,0,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",1,0.0,1,0.0040650406504065045,1,0.0,1,1,research-problem
6,"In this paper , we propose and analyze a neural POS tagging model that exploits AT .",abstract,abstract,part-of-speech_tagging,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",3,0.42857142857142855,5,0.02032520325203252,3,0.42857142857142855,1,1,research-problem
32,"In this paper , spotlighting a well - studied core problem of NLP , we propose and carefully analyze a neural part - of - speech ( POS ) tagging model that exploits adversarial training .",Introduction,Previous work,part-of-speech_tagging,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",21,0.45652173913043476,31,0.12601626016260162,21,0.45652173913043476,1,1,model
33,"With a BiLSTM - CRF model as our baseline POS tagger , we apply adversarial training by considering perturbations to input word / character embeddings .",Introduction,Previous work,part-of-speech_tagging,0,"['B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",22,0.4782608695652174,32,0.13008130081300814,22,0.4782608695652174,1,1,model
132,"We train the model parameters and word / character embeddings by the mini-batch stochastic gradient descent ( SGD ) with batch size 10 , momentum 0.9 , initial learning rate 0.01 and decay rate 0.05 .",Model,Optimization .,part-of-speech_tagging,0,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-n', 'O', 'B-n', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'O', 'B-n', 'I-n', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-ob', 'O', 'B-b', 'B-ob', 'O', 'B-b', 'I-b', 'I-b', 'B-ob', 'O', 'B-b', 'I-b', 'B-ob', 'O']",4,0.6666666666666666,131,0.532520325203252,4,0.4444444444444444,1,1,hyperparameters
133,We also use a gradient clipping of 5.0 .,Model,,part-of-speech_tagging,0,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",5,0.8333333333333334,132,0.5365853658536586,5,0.5555555555555556,1,1,hyperparameters
134,The models are trained with early stopping ) based on the development performance .,Model,We also use a gradient clipping of 5.0 .,part-of-speech_tagging,0,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",6,1.0,133,0.540650406504065,6,0.6666666666666666,1,1,hyperparameters
139,PTB - WSJ dataset .,Results,,part-of-speech_tagging,0,"['B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O']",1,0.009900990099009901,138,0.5609756097560976,1,0.07692307692307693,1,1,results
141,"As expected , our baseline ( BiLSTM - CRF ) model ( accuracy 97.54 % ) performs on par with other state - of - the - art systems .",Results,PTB - WSJ dataset .,part-of-speech_tagging,0,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.0297029702970297,140,0.5691056910569106,3,0.23076923076923078,1,1,results
142,"Built upon this baseline , our adversarial training ( AT ) model reaches accuracy 97.58 % thanks to its regularization power , outperforming recent POS taggers except .",Results,PTB - WSJ dataset .,part-of-speech_tagging,0,"['B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O']","['B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O']","['B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",4,0.039603960396039604,141,0.573170731707317,4,0.3076923076923077,1,1,results
2,Learning Better Internal Structure of Words for Sequence Labeling,title,title,part-of-speech_tagging,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.004,1,0.0,1,1,research-problem
43,"Furthermore , we propose IntNet , a funnel - shaped wide convolutional neural network for learning the internal structure of words by composing their characters .",Introduction,Introduction,part-of-speech_tagging,1,"['O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",30,0.7142857142857143,42,0.168,30,0.7142857142857143,1,1,model
44,"Unlike previous CNN - based approaches , our funnel - shaped Int - Net explores deeper and wider architecture with no down - sampling for learning character - to - word representations from limited supervised training corpora .",Introduction,Introduction,part-of-speech_tagging,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",31,0.7380952380952381,43,0.172,31,0.7380952380952381,1,1,model
45,"Lastly , we combine our IntNet model with LSTM - CRF , which captures both word shape and context information , and jointly decode tags for sequence labeling .",Introduction,Introduction,part-of-speech_tagging,1,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",32,0.7619047619047619,44,0.176,32,0.7619047619047619,1,1,model
177,The size of the dimensions of character embeddings is 32 which are randomly initialized using a uniform distribution .,Training Settings,Initialization .,part-of-speech_tagging,1,"['O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,2,0.125,176,0.704,2,0.125,1,1,hyperparameters
178,We adopt the same initialization method for randomly initialized word embeddings that are updated during training .,Training Settings,Initialization .,part-of-speech_tagging,1,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",3,0.1875,177,0.708,3,0.1875,1,1,hyperparameters
179,"For IntNet , the filter size of the initial convolution is 32 and that of other convolutions is 16 .",Training Settings,Initialization .,part-of-speech_tagging,1,"['B', 'B', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O']",,,4,0.25,178,0.712,4,0.25,1,1,hyperparameters
181,"The number of convolutional layers are 5 and 9 for IntNet - 5 and IntNet - 9 , respectively , and we have adopted the same weight initialization as that of ResNet .",Training Settings,Initialization .,part-of-speech_tagging,1,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-ob', 'O']",6,0.375,180,0.72,6,0.375,1,1,hyperparameters
182,"We use pre-trained word embeddings for initialization , GloVe 100 - dimension word embeddings for English , and fastText 300 dimension word embeddings for Spanish , Dutch , and German .",Training Settings,Initialization .,part-of-speech_tagging,1,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']",,,7,0.4375,181,0.724,7,0.4375,1,1,hyperparameters
183,The state size of the bi-directional LSTMs is set to 256 .,Training Settings,Initialization .,part-of-speech_tagging,1,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",8,0.5,182,0.728,8,0.5,1,1,hyperparameters
184,We adopt standard BIOES tagging scheme for NER and Chunking .,Training Settings,Initialization .,part-of-speech_tagging,1,"['O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.5625,183,0.732,9,0.5625,1,1,hyperparameters
186,We employ mini-batch stochastic gradient descent with momentum .,Training Settings,,part-of-speech_tagging,1,"['O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",11,0.6875,185,0.74,11,0.6875,1,1,hyperparameters
190,"0.05 is the decay ratio , the value of gradient clipping is 5 .",Training Settings,We employ mini-batch stochastic gradient descent with momentum .,part-of-speech_tagging,1,"['B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O']",,,15,0.9375,189,0.756,15,0.9375,1,1,hyperparameters
191,"Dropout is applied on the input of IntNet , LSTMs , and CRF , and its ratio 0.5 is fixed , but with no dropout inside of IntNet .",Training Settings,We employ mini-batch stochastic gradient descent with momentum .,part-of-speech_tagging,1,"['B', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,1.0,190,0.76,16,1.0,1,1,hyperparameters
194,"Firstly , we use LSTM - CRF with randomly initialized word embeddings as our initial baseline .",Compared Methods,Compared Methods,part-of-speech_tagging,1,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",2,0.04,193,0.772,2,0.06060606060606061,1,1,baselines
195,"We adopt two state - of - the - art methods in sequence labeling , denoted as char - LSTM and char - CNN .",Compared Methods,Compared Methods,part-of-speech_tagging,1,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.06,194,0.776,3,0.09090909090909091,1,1,baselines
196,"We add more layers to the char - CNN model and refer to that as char - CNN - 5 and char - CNN - 9 , respectively for 5 and 9 convolutional layers .",Compared Methods,Compared Methods,part-of-speech_tagging,1,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.08,195,0.78,4,0.12121212121212122,1,1,baselines
197,"Furthermore , we add residual connections to the char - CNN - 9 and refer it as char - ResNet .",Compared Methods,Compared Methods,part-of-speech_tagging,1,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",5,0.1,196,0.784,5,0.15151515151515152,1,1,baselines
198,"Also , we apply 3 dense blocks based on char - ResNet which we refer to as char - DenseNet , to compare the difference between residual connection and dense connection .",Compared Methods,Compared Methods,part-of-speech_tagging,1,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.12,197,0.788,6,0.18181818181818182,1,1,baselines
200,5 Results and Analysis 5.1 Character - to - word Models presents the performance of different character - to - word models on six benchmark datasets .,Compared Methods,Compared Methods,part-of-speech_tagging,1,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.16,199,0.796,8,0.24242424242424243,1,1,results
204,"The result shows that for most of the datasets , the F1 score does not improve much when we directly add more layers .",Compared Methods,Compared Methods,part-of-speech_tagging,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-ob', 'I-ob', 'O']",12,0.24,203,0.812,12,0.36363636363636365,1,1,results
205,We also observe some accuracy drop when we continuously increase the depth .,Compared Methods,Compared Methods,part-of-speech_tagging,1,"['O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'O']",13,0.26,204,0.816,13,0.3939393939393939,1,1,results
207,"Furthermore , we add residual connections to char - CNN - 9 as char - ResNet - 9 , which confirms that residual connections can help train deep layers .",Compared Methods,Compared Methods,part-of-speech_tagging,1,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O']",,,15,0.3,206,0.824,15,0.45454545454545453,1,1,results
208,"We further improve char - ResNet - 9 by changing residual connections into dense connection blocks as char - DenseNet - 9 , which shows that the dense connections are better than residual connections for learning word shape information .",Compared Methods,Compared Methods,part-of-speech_tagging,1,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']",,,16,0.32,207,0.828,16,0.48484848484848486,1,1,results
209,"Our proposed character - to - word model , char - IntNet - 5 and char - IntNet - 9 generally improves the results across all datasets .",Compared Methods,Compared Methods,part-of-speech_tagging,1,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",17,0.34,208,0.832,17,0.5151515151515151,1,1,results
210,"Our IntNet significantly outperforms other character embedding models , for example , the improvement is more than 2 % in terms of F 1 score for German and Dutch .",Compared Methods,Compared Methods,part-of-speech_tagging,1,"['O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.36,209,0.836,18,0.5454545454545454,1,1,results
211,"Also , we observe that char - IntNet - 5 is more effective for learning character - to - word representations than char - IntNet - 9 in most of the cases .",Compared Methods,Compared Methods,part-of-speech_tagging,1,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.38,210,0.84,19,0.5757575757575758,1,1,results
214,Table 2 presents our proposed model in comparison with state - of - the - art results .,Compared Methods,State - of - the - art Results,part-of-speech_tagging,1,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",22,0.44,213,0.852,22,0.6666666666666666,1,1,results
220,These experiments show that our char - IntNet generally improves results across different models and datasets .,Compared Methods,State - of - the - art Results,part-of-speech_tagging,1,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",28,0.56,219,0.876,28,0.8484848484848485,1,1,results
221,"The improvement is more pronounced for non-English datasets , for example , IntNet improves the F - 1 score over the stateof - the - art results by more than 2 % for Dutch and Spanish .",Compared Methods,State - of - the - art Results,part-of-speech_tagging,1,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",29,0.58,220,0.88,29,0.8787878787878788,1,1,results
222,"It also shows that the results of LSTM - CRF are significantly improved after adding character - to - word models , which confirms that word shape information is very important for sequence labeling .",Compared Methods,State - of - the - art Results,part-of-speech_tagging,1,"['O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",30,0.6,221,0.884,30,0.9090909090909091,1,1,results
2,TRANSFER LEARNING FOR SEQUENCE TAGGING WITH HIERARCHICAL RECURRENT NETWORKS,,,part-of-speech_tagging,2,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",2,0.18181818181818182,1,0.0056179775280898875,1,0.0,1,1,research-problem
11,1 Code is available at https://github.com/kimiyoung/transfer 1 ar Xiv:1703.06345v1 [ cs.CL ],,TRANSFER LEARNING FOR SEQUENCE TAGGING WITH HIERARCHICAL RECURRENT NETWORKS,part-of-speech_tagging,2,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O']",11,1.0,10,0.056179775280898875,8,1.0,1,1,code
25,"We present a transfer learning approach based on a deep hierarchical recurrent neural network , which shares the hidden feature repre-sentation and part of the model parameters between the source task and the target task .",INTRODUCTION,INTRODUCTION,part-of-speech_tagging,2,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",13,0.65,24,0.1348314606741573,13,0.65,1,1,approach
26,Our approach combines the objectives of the two tasks and uses gradient - based methods for efficient training .,INTRODUCTION,INTRODUCTION,part-of-speech_tagging,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",14,0.7,25,0.1404494382022472,14,0.7,1,1,approach
132,TRANSFER LEARNING PERFORMANCE,MODEL IMPLEMENTATION,,part-of-speech_tagging,2,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",25,0.38461538461538464,131,0.7359550561797753,0,0.0,1,1,experiments
134,"We fix the hyperparameters for all the results reported in this section : we set the character embedding dimension at 25 , the word embedding dimension at 50 for English and 64 for Spanish , the dimension of hidden states of the character - level GRUs at 80 , the dimension of hidden states of the word - level GRUs at 300 , and the initial learning rate at 0.01 .",MODEL IMPLEMENTATION,TRANSFER LEARNING PERFORMANCE,part-of-speech_tagging,2,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O']",,,27,0.4153846153846154,133,0.7471910112359551,2,0.05,1,1,experiments
142,We can see that our transfer learning approach consistently improved over the non-transfer results .,MODEL IMPLEMENTATION,TRANSFER LEARNING PERFORMANCE,part-of-speech_tagging,2,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",35,0.5384615384615384,141,0.7921348314606742,10,0.25,1,1,experiments
143,We also observe that the improvement by transfer learning is more substantial when the labeling rate is lower .,MODEL IMPLEMENTATION,TRANSFER LEARNING PERFORMANCE,part-of-speech_tagging,2,"['O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,36,0.5538461538461539,142,0.797752808988764,11,0.275,1,1,experiments
146,"As shown in and 2 ( e ) , our transfer learning approach can improve the performance on Twitter POS tagging and NER for all labeling rates , and the improvements with 0.1 labels are more than 8 % for both datasets .",MODEL IMPLEMENTATION,TRANSFER LEARNING PERFORMANCE,part-of-speech_tagging,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']",,,39,0.6,145,0.8146067415730337,14,0.35,1,1,experiments
147,Cross - application transfer also leads to substantial improvement under low - resource conditions .,MODEL IMPLEMENTATION,TRANSFER LEARNING PERFORMANCE,part-of-speech_tagging,2,"['B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",40,0.6153846153846154,146,0.8202247191011236,15,0.375,1,1,experiments
157,COMPARISON WITH STATE - OF - THE - ART RESULTS,MODEL IMPLEMENTATION,TRANSFER LEARNING PERFORMANCE,part-of-speech_tagging,2,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",50,0.7692307692307693,156,0.8764044943820225,25,0.625,1,1,experiments
160,We use publicly available pretrained word embeddings as initialization .,MODEL IMPLEMENTATION,TRANSFER LEARNING PERFORMANCE,part-of-speech_tagging,2,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",53,0.8153846153846154,159,0.8932584269662921,28,0.7,1,1,experiments
161,"On the English datasets , following previous works that are based on neural networks , we experiment with both the 50 - dimensional SENNA embeddings and the 100 - dimensional GloVe embeddings and use the development set to choose the embeddings for different tasks and settings .",MODEL IMPLEMENTATION,TRANSFER LEARNING PERFORMANCE,part-of-speech_tagging,2,"['B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",54,0.8307692307692308,160,0.898876404494382,29,0.725,1,1,experiments
162,"For Spanish and Dutch , we use the 64 - dimensional Polyglot embeddings .",MODEL IMPLEMENTATION,TRANSFER LEARNING PERFORMANCE,part-of-speech_tagging,2,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",55,0.8461538461538461,161,0.9044943820224719,30,0.75,1,1,experiments
163,We set the hidden state dimensions to be 300 for the word - level GRU .,MODEL IMPLEMENTATION,TRANSFER LEARNING PERFORMANCE,part-of-speech_tagging,2,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",56,0.8615384615384616,162,0.9101123595505618,31,0.775,1,1,experiments
164,The initial learning rate for AdaGrad is fixed at 0.01 .,MODEL IMPLEMENTATION,TRANSFER LEARNING PERFORMANCE,part-of-speech_tagging,2,"['O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",57,0.8769230769230769,163,0.9157303370786517,32,0.8,1,1,experiments
171,"First , our transfer learning approach achieves new state - of - the - art results on all the considered benchmark datasets except PTB POS tagging , which indicates that transfer learning can still improve the performance even on datasets with relatively abundant labels .",MODEL IMPLEMENTATION,TRANSFER LEARNING PERFORMANCE,part-of-speech_tagging,2,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",64,0.9846153846153847,170,0.9550561797752809,39,0.975,1,1,experiments
172,"Second , our base model ( w/o transfer ) performs competitively compared to the state - of - the - art systems , which means that the improvements shown in Section 4.2 are obtained over a strong baseline .",MODEL IMPLEMENTATION,TRANSFER LEARNING PERFORMANCE,part-of-speech_tagging,2,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",65,1.0,171,0.9606741573033708,40,1.0,1,1,experiments
2,End - to - end Sequence Labeling via Bi-directional LSTM-CNNs-CRF,title,title,part-of-speech_tagging,3,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",1,0.0,1,0.0049261083743842365,1,0.0,1,1,research-problem
4,State - of - the - art sequence labeling systems traditionally require large amounts of taskspecific knowledge in the form of handcrafted features and data pre-processing .,abstract,abstract,part-of-speech_tagging,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.014778325123152709,1,0.2,1,1,research-problem
10,"Linguistic sequence labeling , such as part - ofspeech ( POS ) tagging and named entity recognition ( NER ) , is one of the first stages in deep language understanding and its importance has been well recognized in the natural language processing community .",Introduction,Introduction,part-of-speech_tagging,3,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.045454545454545456,9,0.04433497536945813,1,0.045454545454545456,1,1,research-problem
21,"In this paper , we propose a neural network architecture for sequence labeling .",Introduction,Introduction,part-of-speech_tagging,3,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",12,0.5454545454545454,20,0.09852216748768473,12,0.5454545454545454,1,1,model
22,"It is a truly endto - end model requiring no task - specific resources , feature engineering , or data pre-processing beyond pre-trained word embeddings on unlabeled corpora .",Introduction,Introduction,part-of-speech_tagging,3,"['O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",13,0.5909090909090909,21,0.10344827586206896,13,0.5909090909090909,1,1,model
23,"Thus , our model can be easily applied to a wide range of sequence labeling tasks on different languages and domains .",Introduction,Introduction,part-of-speech_tagging,3,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.6363636363636364,22,0.10837438423645321,14,0.6363636363636364,1,1,model
24,We first use convolutional neural networks ( CNNs ) to encode character - level information of a word into its character - level representation .,Introduction,Introduction,part-of-speech_tagging,3,"['O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.6818181818181818,23,0.11330049261083744,15,0.6818181818181818,1,1,model
25,Then we combine character - and word - level representations and feed them into bi-directional LSTM ( BLSTM ) to model context information of each word .,Introduction,Introduction,part-of-speech_tagging,3,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",16,0.7272727272727273,24,0.11822660098522167,16,0.7272727272727273,1,1,model
26,"On top of BLSTM , we use a sequential CRF to jointly decode labels for the whole sentence .",Introduction,Introduction,part-of-speech_tagging,3,"['B', 'I', 'I', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'O']","['B-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",17,0.7727272727272727,25,0.12315270935960591,17,0.7727272727272727,1,1,model
97,Parameter optimization is performed with minibatch stochastic gradient descent ( SGD ) with batch size 10 and momentum 0.9 .,Network Training,Optimization Algorithm,part-of-speech_tagging,3,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-n', 'O', 'B-n', 'B-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-ob', 'O', 'B-b', 'B-ob', 'O']",16,0.6153846153846154,96,0.4729064039408867,1,0.05263157894736842,1,1,hyperparameters
98,"We choose an initial learning rate of ? 0 ( ? 0 = 0.01 for POS tagging , and 0.015 for NER , see Section 3.3 . ) , and the learning rate is updated on each epoch of training as ? t = ? 0 / ( 1 + ?t ) , with decay rate ? =",Network Training,Optimization Algorithm,part-of-speech_tagging,3,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,17,0.6538461538461539,97,0.47783251231527096,2,0.10526315789473684,1,1,hyperparameters
100,"To reduce the effects of "" gradient exploding "" , we use a gradient clipping of 5.0 .",Network Training,Optimization Algorithm,part-of-speech_tagging,3,"['O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,19,0.7307692307692307,99,0.4876847290640394,4,0.21052631578947367,1,1,hyperparameters
103,We use early stopping based on performance on validation sets .,Network Training,Early Stopping .,part-of-speech_tagging,3,"['O', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",22,0.8461538461538461,102,0.5024630541871922,7,0.3684210526315789,1,1,hyperparameters
104,"The "" best "" parameters appear at around 50 epochs , according to our experiments .",Network Training,Early Stopping .,part-of-speech_tagging,3,"['O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",23,0.8846153846153846,103,0.5073891625615764,8,0.42105263157894735,1,1,hyperparameters
106,"For each of the embeddings , we fine - tune initial embeddings , modifying them during gradient updates of the neural network model by back - propagating gradients .",Network Training,Fine Tuning .,part-of-speech_tagging,3,"['B', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",25,0.9615384615384616,105,0.5172413793103449,10,0.5263157894736842,1,1,hyperparameters
109,"To mitigate overfitting , we apply the dropout method ( Srivastava et al. , 2014 ) to regularize our model .",Dropout Training .,Dropout Training .,part-of-speech_tagging,3,"['B', 'I', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O']","['B-p', 'I-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['B-p', 'I-p', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",1,0.14285714285714285,108,0.5320197044334976,13,0.6842105263157895,1,1,hyperparameters
110,"As shown in and 3 , we apply dropout on character embeddings before inputting to CNN , and on both the input and output vectors of BLSTM .",Dropout Training .,Dropout Training .,part-of-speech_tagging,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",2,0.2857142857142857,109,0.5369458128078818,14,0.7368421052631579,1,1,hyperparameters
111,We fix dropout rate at 0.5 for all dropout layers through all the experiments .,Dropout Training .,Dropout Training .,part-of-speech_tagging,3,"['O', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",3,0.42857142857142855,110,0.541871921182266,15,0.7894736842105263,1,1,hyperparameters
118,"We compare the performance with three baseline systems - BRNN , the bi-direction RNN ; BLSTM , the bidirection LSTM , and BLSTM - CNNs , the combination of BLSTM with CNN to model characterlevel information .",Main Results,Main Results,part-of-speech_tagging,3,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",2,0.6666666666666666,117,0.5763546798029556,2,0.6666666666666666,1,1,baselines
123,"Finally , by adding CRF layer for joint decoding we achieve significant improvements over BLSTM - CNN models for both POS tagging and NER on all metrics .",Model,Model,part-of-speech_tagging,3,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']",,,3,0.05263157894736842,122,0.6009852216748769,3,0.21428571428571427,1,1,results
127,"Comparing with traditional statistical models , our system achieves state - of - the - art accuracy , obtaining 0.05 % improvement over the previously best reported results by .",Model,Model,part-of-speech_tagging,3,"['B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",7,0.12280701754385964,126,0.6206896551724138,7,0.5,1,1,results
133,"Similar to the observations of POS tagging , our model achieves significant improvements over Senna and the other three neural models , namely the LSTM - CRF proposed by , LSTM - CNNs pro- :",Model,Model,part-of-speech_tagging,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.22807017543859648,132,0.6502463054187192,13,0.9285714285714286,1,1,results
2,Hierarchically - Refined Label Attention Network for Sequence Labeling,title,,part-of-speech_tagging,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.004291845493562232,1,0.0,1,1,research-problem
4,CRF has been used as a powerful model for statistical sequence labeling .,abstract,abstract,part-of-speech_tagging,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.2,3,0.012875536480686695,1,0.2,1,1,research-problem
19,"To this question , we investigate a neural network model for output label sequences .",Introduction,Introduction,part-of-speech_tagging,4,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.30303030303030304,18,0.07725321888412018,10,0.4166666666666667,1,1,model
20,"In particular , we represent each possible label using an embedding vector , and aim to encode sequences of label distributions using a recurrent neural network .",Introduction,Introduction,part-of-speech_tagging,4,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']",,,11,0.3333333333333333,19,0.0815450643776824,11,0.4583333333333333,1,1,model
22,This makes our task essentially to represent a full - exponential search space without making Markov assumptions .,Introduction,Introduction,part-of-speech_tagging,4,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",13,0.3939393939393939,21,0.09012875536480687,13,0.5416666666666666,1,1,model
179,WSJ . shows the final POS tagging results on WSJ .,Final Results,Final Results,part-of-speech_tagging,4,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.021739130434782608,178,0.7639484978540773,1,0.05,1,1,results
181,"BiLSTM - LAN gives significant accuracy improvements over both BiLSTM - CRF and BiLSTM- softmax ( p < 0.01 ) , which is consistent with observations on development experiments .",Final Results,Final Results,part-of-speech_tagging,4,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.06521739130434782,180,0.7725321888412017,3,0.15,1,1,results
186,"Universal Dependencies ( UD ) v 2.2 . We design a multilingual experiment to compare BiLSTMsoftmax , BiLSTM - CRF ( strictly following 1 , which is the state - of - theart on multi-lingual POS tagging ) and BiLSTM - LAN .",Final Results,Final Results,part-of-speech_tagging,4,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.17391304347826086,185,0.7939914163090128,8,0.4,1,1,results
188,Our model outperforms all the baselines on all the languages .,Final Results,Final Results,part-of-speech_tagging,4,"['B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.21739130434782608,187,0.8025751072961373,10,0.5,1,1,results
189,"The improvements are statistically significant for all the languages ( p < 0.01 ) , suggesting that BiLSTM - LAN is generally effective across languages .",Final Results,Final Results,part-of-speech_tagging,4,"['O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",11,0.2391304347826087,188,0.8068669527896996,11,0.55,1,1,results
190,"OntoNotes 5.0 . In NER , BiLSTM - CRF is widely used , because local dependencies between neighboring labels relatively more important that POS tagging and CCG supertagging .",Final Results,Final Results,part-of-speech_tagging,4,"['B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.2608695652173913,189,0.8111587982832618,12,0.6,1,1,results
191,BiLSTM - LAN also significantly outperforms BiLSTM - CRF by 1.17 F1-score ( p < 0.01 ) . CCGBank .,Final Results,Final Results,part-of-speech_tagging,4,"['B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.2826086956521739,190,0.8154506437768241,13,0.65,1,1,results
193,"As shown in , BiLSTM - LAN significantly outperforms both BiLSTMsoftmax and BiLSTM - CRF ( p < 0.01 ) , showing the advantage of LAN . and explore BiRNN - softmax and BiLSTM - softmax , respectively .",Final Results,Final Results,part-of-speech_tagging,4,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.32608695652173914,192,0.8240343347639485,15,0.75,1,1,results
198,"Compared with these methods , BiLSTM - LAN obtains new state - of - theart results on CCGBank , matching the tri-training performance of , without training on external data .",Final Results,Final Results,part-of-speech_tagging,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.43478260869565216,197,0.8454935622317596,20,1.0,1,1,results
2,Morphosyntactic Tagging with a Meta-BiLSTM Model over Context Sensitive Token Encodings,title,title,part-of-speech_tagging,5,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.0049504950495049506,1,0.0,1,1,research-problem
24,We propose a novel model where we learn context sensitive initial character and word representations through two separate sentence - level recurrent models .,Introduction,Introduction,part-of-speech_tagging,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.6842105263157895,23,0.11386138613861387,13,0.6842105263157895,1,1,model
25,These are then combined via a meta-BiLSTM model that builds a unified representation of each word that is then used for syntactic tagging .,Introduction,Introduction,part-of-speech_tagging,5,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",14,0.7368421052631579,24,0.1188118811881188,14,0.7368421052631579,1,1,model
119,The word embeddings are initialized with zero values and the pre-trained embeddings are not updated during training .,Experimental Setup,Experimental Setup,part-of-speech_tagging,5,"['O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'O']",5,0.1724137931034483,118,0.5841584158415841,5,0.7142857142857143,1,1,hyperparameters
120,The dropout used on the embeddings is achieved by a RRIE is the relative reduction in error .,Experimental Setup,Experimental Setup,part-of-speech_tagging,5,"['O', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-p', 'I-p', 'O', 'B-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.20689655172413793,119,0.5891089108910891,6,0.8571428571428571,1,1,hyperparameters
135,Part - of - Speech Tagging Results,Experimental Setup,,part-of-speech_tagging,5,"['B', 'I', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",21,0.7241379310344828,134,0.6633663366336634,13,0.6190476190476191,1,1,results
141,Our model outperforms in 32 of the 54 treebanks with 13 ties .,Experimental Setup,Part - of - Speech Tagging Results,part-of-speech_tagging,5,"['B', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'B-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",27,0.9310344827586207,140,0.693069306930693,19,0.9047619047619048,1,1,results
143,"Our model tends to produce better results , especially for morphologically rich languages ( e.g. Slavic",Experimental Setup,Part - of - Speech Tagging Results,part-of-speech_tagging,5,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",29,1.0,142,0.7029702970297029,21,1.0,1,1,results
150,Morphological Tagging Results,,,part-of-speech_tagging,5,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",0,0.0,149,0.7376237623762376,0,0.0,1,1,results
155,"Our models tend to produce significantly better results than the winners of the CoNLL 2017 Shared Task ( i.e. , 1.8 % absolute improvement on average , corresponding to a RRIE of 21.20 % ) .",Morphological Tagging Results,Morphological Tagging Results,part-of-speech_tagging,5,"['B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.625,154,0.7623762376237624,5,0.625,1,1,results
167,shows that separately optimized models are significantly more accurate on average than jointly optimized models .,Ablation Study,Impact of the Training Schema,part-of-speech_tagging,5,"['B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.1951219512195122,166,0.8217821782178217,2,0.05714285714285714,1,1,ablation-analysis
168,Separate optimization leads to better accuracy for 34 out of 40 treebanks for the morphological features task and for 30 out of 39 treebanks for xpos tagging .,Ablation Study,Impact of the Training Schema,part-of-speech_tagging,5,"['B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']",,,9,0.21951219512195122,167,0.8267326732673267,3,0.08571428571428572,1,1,ablation-analysis
169,"Separate optimization outperformed joint optimization by up to 2.1 percent absolute , while joint never out - performed separate by more than 0.5 % absolute .",Ablation Study,Impact of the Training Schema,part-of-speech_tagging,5,"['O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']",,,10,0.24390243902439024,168,0.8316831683168316,4,0.11428571428571428,1,1,ablation-analysis
179,The examples show that the combined model has significantly higher accuracy compared with either the character and word models individually .,Ablation Study,Impact of the Sentence - based Character Model,part-of-speech_tagging,5,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",20,0.4878048780487805,178,0.8811881188118812,14,0.4,1,1,ablation-analysis
194,"For all of the network sizes in the grid search , we still observed during training that the accuracy reach a high value and degrades with more iterations for the character and word model .",Ablation Study,Search,part-of-speech_tagging,5,"['B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",35,0.8536585365853658,193,0.9554455445544554,29,0.8285714285714286,1,1,ablation-analysis
2,A Novel Neural Network Model for Joint POS Tagging and Graph - based Dependency Parsing,title,title,part-of-speech_tagging,6,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.006711409395973154,1,0.0,1,1,research-problem
7,Our code is open - source and available together with pre-trained models at : https://github.com/ datquocnguyen/jPTDP .,abstract,abstract,part-of-speech_tagging,6,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",4,1.0,6,0.040268456375838924,4,1.0,1,1,code
19,"In this paper , we propose a novel neural architecture for joint POS tagging and graph - based dependency parsing .",Introduction,Introduction,part-of-speech_tagging,6,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.8461538461538461,18,0.12080536912751678,11,0.8461538461538461,1,1,model
20,Our model learns latent feature representations shared for both POS tagging and dependency parsing tasks by using BiLSTMthe bidirectional LSTM .,Introduction,Introduction,part-of-speech_tagging,6,"['O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.9230769230769231,19,0.12751677852348994,12,0.9230769230769231,1,1,model
75,Our jPTDP is implemented using DYNET v 2.0 .,Implementation details,,part-of-speech_tagging,6,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.07142857142857142,74,0.4966442953020134,1,0.07142857142857142,1,1,experimental-setup
76,"We optimize the objective function using Adam ( Kingma and Ba , 2014 ) with default DYNET parameter settings and no mini-batches .",Implementation details,Our jPTDP is implemented using DYNET v 2.0 .,part-of-speech_tagging,6,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",2,0.14285714285714285,75,0.5033557046979866,2,0.14285714285714285,1,1,experimental-setup
78,"Following Kiperwasser and Goldberg ( 2016 b ) and , we apply a word dropout rate of 0.25 and Gaussian noise with ? = 0.2 .",Implementation details,Our jPTDP is implemented using DYNET v 2.0 .,part-of-speech_tagging,6,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.2857142857142857,77,0.5167785234899329,4,0.2857142857142857,1,1,experimental-setup
79,"For training , we run for 30 epochs , and evaluate the mixed accuracy of correctly assigning POS tag together with dependency arc and relation type on the development set after each training epoch .",Implementation details,Our jPTDP is implemented using DYNET v 2.0 .,part-of-speech_tagging,6,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.35714285714285715,78,0.5234899328859061,5,0.35714285714285715,1,1,experimental-setup
80,We perform a minimal grid search of hyper - parameters on English .,Implementation details,Our jPTDP is implemented using DYNET v 2.0 .,part-of-speech_tagging,6,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",6,0.42857142857142855,79,0.5302013422818792,6,0.42857142857142855,1,1,experimental-setup
84,"compares the POS tagging and dependency parsing results of our model jPTDP with results reported in prior work , using the same experimental setup .",Implementation details,Our jPTDP is implemented using DYNET v 2.0 .,part-of-speech_tagging,6,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.7142857142857143,83,0.5570469798657718,10,0.7142857142857143,1,1,experimental-setup
90,"In terms of dependency parsing , in most cases , our model jPTDP outperforms Stack - propagation .",Main results,Main results,part-of-speech_tagging,6,"['B', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.022727272727272728,89,0.5973154362416108,1,0.1111111111111111,1,1,results
91,It is somewhat unexpected that our model produces about 7 % absolute lower LAS score than Stack - propagation on Dutch ( nl ) .,Main results,Main results,part-of-speech_tagging,6,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.045454545454545456,90,0.6040268456375839,2,0.2222222222222222,1,1,results
94,"Without taking "" nl "" into account , our averaged LAS score over all remaining languages is 1.1 % absolute higher than Stack - propagation 's .",Main results,Main results,part-of-speech_tagging,6,"['B', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'O', 'B-p', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.11363636363636363,93,0.6241610738255033,5,0.5555555555555556,1,1,results
96,"The last row in shows an absolute LAS improvement of 4.4 % on average when comparing our jPTDP with its simplified version of not using characterbased representations : specifically , morphologically rich languages get an averaged improvement of 9.3 % , vice versa 2.6 % for others .",Main results,Main results,part-of-speech_tagging,6,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,7,0.1590909090909091,95,0.6375838926174496,7,0.7777777777777778,1,1,results
98,"So , our jPDTP is particularly good for morphologically rich languages , with 1.7 % higher averaged LAS than Stack - propagation over these languages .",Main results,Main results,part-of-speech_tagging,6,"['O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",9,0.20454545454545456,97,0.6510067114093959,9,1.0,1,1,results
2,Multilingual Part - of - Speech Tagging with Bidirectional Long Short - Term Memory Models and Auxiliary Loss,title,title,part-of-speech_tagging,7,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.008,1,0.0,1,1,research-problem
5,"We address these issues and evaluate bi - LSTMs with word , character , and unicode byte embeddings for POS tagging .",abstract,abstract,part-of-speech_tagging,7,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",2,0.3333333333333333,4,0.032,2,0.3333333333333333,1,1,research-problem
22,"Finally , we introduce a novel model , a bi - LSTM trained with auxiliary loss .",Introduction,Introduction,part-of-speech_tagging,7,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.2,21,0.168,12,0.22641509433962265,1,1,model
23,The model jointly predicts the POS and the log frequency of the word .,Introduction,Introduction,part-of-speech_tagging,7,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.21666666666666667,22,0.176,13,0.24528301886792453,1,1,model
52,"epochs , default learning rate ( 0.1 ) , 128 dimensions for word embeddings , 100 for character and byte embeddings , 100 hidden states and Gaussian noise with ?= 0.2 .",Introduction,Contributions,part-of-speech_tagging,7,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O']",,,42,0.7,51,0.408,42,0.7924528301886793,1,1,hyperparameters
53,"As training is stochastic in nature , we use a fixed seed throughout .",Introduction,Contributions,part-of-speech_tagging,7,"['O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O']","['O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O']","['O', 'B-b', 'B-p', 'B-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O']",43,0.7166666666666667,52,0.416,43,0.8113207547169812,1,1,hyperparameters
55,In that case we use offthe - shelf polyglot embeddings .,Introduction,Contributions,part-of-speech_tagging,7,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",45,0.75,54,0.432,45,0.8490566037735849,1,1,hyperparameters
58,The code is released at : https : //github.com/bplank/bilstm-aux,Introduction,Contributions,part-of-speech_tagging,7,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",48,0.8,57,0.456,48,0.9056603773584906,1,1,code
79,"In an initial investigation , we compared Tnt , HunPos and TreeTagger and found Tnt to be consistently better than Treetagger , Hunpos followed closely but crashed on some languages ( e.g. , Arabic ) .",Results,Results,part-of-speech_tagging,7,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.20512820512820512,78,0.624,8,0.20512820512820512,1,1,results
80,"The combined word + character representation model is the best representation , outperforming the baseline on all except one language ( Indonesian ) , providing strong results already without pre-trained embeddings .",Results,Results,part-of-speech_tagging,7,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-b', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.23076923076923078,79,0.632,9,0.23076923076923078,1,1,results
81,This model ( w + c ) reaches the biggest improvement ( more than + 2 % accuracy ) on Hebrew and Slovene .,Results,Results,part-of-speech_tagging,7,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.2564102564102564,80,0.64,10,0.2564102564102564,1,1,results
82,Initializing the word embeddings ( + POLYGLOT ) with off - the - shelf languagespecific embeddings further improves accuracy .,Results,Results,part-of-speech_tagging,7,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'O']",11,0.28205128205128205,81,0.648,11,0.28205128205128205,1,1,results
85,The over all best system is the multi-task bi - LSTM FREQBIN ( it uses w + c and POLYGLOT initialization for w ) .,Results,Results,part-of-speech_tagging,7,"['O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.358974358974359,84,0.672,14,0.358974358974359,1,1,results
2,Document Expansion by Query Prediction,title,title,passage_re-ranking,0,"['B', 'I', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O']",1,0.0,1,0.00819672131147541,1,0.0,1,1,research-problem
24,"In this paper , we explore an alternative approach based on enriching the document representation ( prior to indexing ) .",Introduction,Input : Document,passage_re-ranking,0,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.5652173913043478,23,0.1885245901639344,13,0.5652173913043478,1,1,approach
25,"Focusing on question answering , we train a sequence - to - sequence model , that given a document , generates possible questions that the document might answer .",Introduction,Input : Document,passage_re-ranking,0,"['B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'O']",,,14,0.6086956521739131,24,0.19672131147540983,14,0.6086956521739131,1,1,approach
68,BM25 : We use the Anserini open - source IR toolkit 3 to index the original ( non -expanded ) documents and BM25 to rank the passages .,Experimental Setup,Experimental Setup,passage_re-ranking,0,"['B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O']","['B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",7,0.3333333333333333,67,0.5491803278688525,7,0.3333333333333333,1,1,baselines
70,BM25 + Doc2query :,Experimental Setup,Experimental Setup,passage_re-ranking,0,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",9,0.42857142857142855,69,0.5655737704918032,9,0.42857142857142855,1,1,baselines
71,We first expand the documents using the proposed Doc2query method .,Experimental Setup,Experimental Setup,passage_re-ranking,0,"['O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.47619047619047616,70,0.5737704918032787,10,0.47619047619047616,1,1,baselines
72,We then index and rank the expanded documents exactly as in the BM25 method above .,Experimental Setup,Experimental Setup,passage_re-ranking,0,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O']",11,0.5238095238095238,71,0.5819672131147541,11,0.5238095238095238,1,1,baselines
76,RM3 :,Experimental Setup,Experimental Setup,passage_re-ranking,0,"['B', 'O']","['B-n', 'O']","['B-b', 'O']",15,0.7142857142857143,75,0.6147540983606558,15,0.7142857142857143,1,1,baselines
77,"To compare document expansion with query expansion , we applied the RM3 query expansion technique .",Experimental Setup,Experimental Setup,passage_re-ranking,0,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.7619047619047619,76,0.6229508196721312,16,0.7619047619047619,1,1,baselines
79,BM25 + BERT : We index and retrieve documents as in the BM25 condition and further re-rank the documents with BERT as described in .,Experimental Setup,Experimental Setup,passage_re-ranking,0,"['B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O']",,,18,0.8571428571428571,78,0.639344262295082,18,0.8571428571428571,1,1,baselines
80,"BM25 + Doc2query + BERT : We expand , index , and retrieve documents as in the BM25 + Doc2query condition and further re-rank the documents with BERT .",Experimental Setup,Experimental Setup,passage_re-ranking,0,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'O']",,,19,0.9047619047619048,79,0.6475409836065574,19,0.9047619047619048,1,1,baselines
86,Document expansion with our method ( BM25 + Doc2query ) improves retrieval effectiveness by ? 15 % for both datasets .,Results,BM25 is the baseline .,passage_re-ranking,0,"['B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",3,0.0967741935483871,85,0.6967213114754098,3,0.0967741935483871,1,1,results
87,"When we combine document expansion with a state - of - the - art re-ranker ( BM25 + Doc2query + BERT ) , we achieve the best - known results to date on TREC CAR ; for MS MARCO , we are near the state of the art .",Results,BM25 is the baseline .,passage_re-ranking,0,"['O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.12903225806451613,86,0.7049180327868853,4,0.12903225806451613,1,1,results
89,"Our full re-ranking condition ( BM25 + Doc2query + BERT ) beats BM25 + BERT alone , which verifies that the contribution Input Document : July is the hottest month in Washington DC with an average temperature of 27C ( 80F ) and the coldest is January at 4C ( 38F ) with the most daily sunshine hours at 9 in July .",Results,BM25 is the baseline .,passage_re-ranking,0,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.1935483870967742,88,0.7213114754098361,6,0.1935483870967742,1,1,results
99,"We notice that the model tends to copy some words from the input document ( e.g. , Washington DC , River , chromosome ) , meaning that it can effectively perform term re-weighting ( i.e. , increasing the importance of key terms ) .",Results,BM25 is the baseline .,passage_re-ranking,0,"['O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.5161290322580645,98,0.8032786885245902,16,0.5161290322580645,1,1,results
100,"Nevertheless , the model also produces words not present in the input document ( e.g. , weather , relationship ) , which can be characterized as expansion by synonyms and other related terms .",Results,BM25 is the baseline .,passage_re-ranking,0,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.5483870967741935,99,0.8114754098360656,17,0.5483870967741935,1,1,results
103,"If we expand MS MARCO documents using only new words and retrieve the development set queries with BM25 , we obtain an MRR@10 of 18.8 ( as opposed to 18.4 when indexing with original documents ) .",Results,BM25 is the baseline .,passage_re-ranking,0,"['O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.6451612903225806,102,0.8360655737704918,20,0.6451612903225806,1,1,results
104,Expanding with copied words gives an MRR@10 of 19.7 .,Results,BM25 is the baseline .,passage_re-ranking,0,"['B', 'I', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O']",21,0.6774193548387096,103,0.8442622950819673,21,0.6774193548387096,1,1,results
105,"We achieve a higher MRR@10 of 21.5 when documents are expanded with both types of words , showing that they are complementary .",Results,BM25 is the baseline .,passage_re-ranking,0,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.7096774193548387,104,0.8524590163934426,22,0.7096774193548387,1,1,results
107,We find that the Recall@1000 of the MS MARCO development set increased from 85.3 ( BM25 ) to 89.3 ( BM25 + Doc2query ) .,Results,BM25 is the baseline .,passage_re-ranking,0,"['O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",24,0.7741935483870968,106,0.8688524590163934,24,0.7741935483870968,1,1,results
109,"As a contrastive condition , we find that query expansion with RM3 hurts in both datasets , whether applied to the unexpanded corpus ( BM25 + RM3 ) or the expanded version ( BM25 + Doc2query + RM3 ) .",Results,BM25 is the baseline .,passage_re-ranking,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",26,0.8387096774193549,108,0.8852459016393442,26,0.8387096774193549,1,1,results
111,"This result shows that document expansion can be more effective than query expansion , most likely because there are more signals to exploit as documents are much longer .",Results,BM25 is the baseline .,passage_re-ranking,0,"['O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",28,0.9032258064516129,110,0.9016393442622951,28,0.9032258064516129,1,1,results
113,"Our method without a re-ranker ( BM25 + Doc2query ) adds a small latency increase over baseline BM25 ( 50 ms vs. 90 ms ) but is approximately seven times faster than a neural re-ranker that has a three points higher MRR@10 ( Single Duet v2 , which is presented as a baseline in MS MARCO by the organizers ) .",Results,BM25 is the baseline .,passage_re-ranking,0,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",30,0.967741935483871,112,0.9180327868852459,30,0.967741935483871,1,1,results
2,PASSAGE RE - RANKING WITH BERT,title,title,passage_re-ranking,1,"['B', 'I', 'I', 'I', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",1,0.0,1,0.0136986301369863,1,0.0,1,1,research-problem
5,"In this paper , we describe a simple re-implementation of BERT for query - based passage re-ranking .",abstract,abstract,passage_re-ranking,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.4,4,0.0547945205479452,2,0.4,1,1,research-problem
16,"In this paper , we describe in detail how we have re-purposed BERT as a passage re-ranker and achieved state - of - the - art results on the MS MARCO passage re-ranking task .",INTRODUCTION,INTRODUCTION,passage_re-ranking,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.5384615384615384,15,0.2054794520547945,7,0.5384615384615384,1,1,approach
17,PASSAGE RE - RANKING WITH BERT,INTRODUCTION,INTRODUCTION,passage_re-ranking,1,"['B', 'I', 'I', 'I', 'O', 'O']",,,8,0.6153846153846154,16,0.2191780821917808,8,0.6153846153846154,1,1,research-problem
35,MS MARCO,EXPERIMENTS,EXPERIMENTS,passage_re-ranking,1,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",2,0.25,34,0.4657534246575342,0,0.0,1,1,experiments
43,"We fine - tune the model using TPUs 1 with a batch size of 32 ( 32 sequences * 512 tokens = 16,384 tokens / batch ) for 400 k iterations , which takes approximately 70 hours .",Training,Training,passage_re-ranking,1,"['O', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.07142857142857142,42,0.5753424657534246,8,0.25,1,1,experiments
46,"We use ADAM ( Kingma & Ba , 2014 ) with the initial learning rate set to 3 10 ?6 , ? 1 = 0.9 , ? 2 = 0.999 , L2 weight decay of 0.01 , learning rate warmup over the first 10,000 steps , and linear decay of the learning rate .",Training,Training,passage_re-ranking,1,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,4,0.2857142857142857,45,0.6164383561643836,11,0.34375,1,1,experiments
47,We use a dropout probability of 0.1 on all layers .,Training,Training,passage_re-ranking,1,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",5,0.35714285714285715,46,0.6301369863013698,12,0.375,1,1,experiments
48,TREC - CAR,Training,Training,passage_re-ranking,1,"['B', 'I', 'I']",,,6,0.42857142857142855,47,0.6438356164383562,13,0.40625,1,1,
63,"For the fine - tuning data , we generate our query - passage pairs by retrieving the top ten passages from the entire TREC - CAR corpus using BM25 .",Training,Training,passage_re-ranking,1,"['B', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",6,0.6,62,0.8493150684931506,28,0.875,1,1,experiments
66,"We train it for 400 k iterations , or 12.8 M examples ( 400 k iterations * 32 pairs / batch ) , which corresponds to only 40 % of the training set .",Training,Training,passage_re-ranking,1,"['O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.9,65,0.8904109589041096,31,0.96875,1,1,experiments
70,"Despite training on a fraction of the data available , the proposed BERT - based models surpass the previous state - of - the - art models by a large margin on both of the tasks .",RESULTS,RESULTS,passage_re-ranking,1,"['B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.4,69,0.9452054794520548,2,0.4,1,1,results
2,Multi - level Multimodal Common Semantic Space for Image - Phrase Grounding,title,title,phrase_grounding,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0044444444444444444,1,0.0,1,1,research-problem
4,We address the problem of phrase grounding by learning a multi - level common semantic space shared by the textual and visual modalities .,abstract,abstract,phrase_grounding,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.013333333333333334,1,0.14285714285714285,1,1,research-problem
24,"In this work , we propose to explicitly learn a non-linear mapping of the visual and textual modalities into a common space , and do so at different granularity for each domain .",Introduction,Introduction,phrase_grounding,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",13,0.65,23,0.10222222222222223,13,0.65,1,1,model
26,"This common space mapping is trained with weak supervision and exploited at test - time with a multi - level multimodal attention mechanism , where a natural formalism for computing attention heatmaps at each level , attended features and pertinence scoring , enables us to solve the phrase grounding task elegantly and effectively .",Introduction,Introduction,phrase_grounding,0,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'O']",15,0.75,25,0.1111111111111111,15,0.75,1,1,model
168,"We use a batch size of B = 32 , where for a batch of image - caption pairs each image ( caption ) is only related to one caption ( image ) .",Experimental Setup,Experimental Setup,phrase_grounding,0,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.08333333333333333,167,0.7422222222222222,1,0.03571428571428571,1,1,hyperparameters
169,Image - caption pairs are sampled randomly with a uniform distribution .,Experimental Setup,Experimental Setup,phrase_grounding,0,"['B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",2,0.16666666666666666,168,0.7466666666666667,2,0.07142857142857142,1,1,hyperparameters
170,We train the network for 20 epochs with the Adam optimizer with lr = 0.001 where the learning rate is divided by 2 once at the 10 - th epoch and again at the 15 - th epoch .,Experimental Setup,Experimental Setup,phrase_grounding,0,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']",,,3,0.25,169,0.7511111111111111,3,0.10714285714285714,1,1,hyperparameters
171,We use D = 1024 for common space mapping dimension and ? = 0.25 for Leaky ReLU in the non-linear mappings .,Experimental Setup,Experimental Setup,phrase_grounding,0,"['O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,4,0.3333333333333333,170,0.7555555555555555,4,0.14285714285714285,1,1,hyperparameters
172,We regularize weights of the mappings with l 2 regularization with reg value = 0.0005 .,Experimental Setup,Experimental Setup,phrase_grounding,0,"['O', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']",,,5,0.4166666666666667,171,0.76,5,0.17857142857142858,1,1,hyperparameters
173,"For VGG , we take outputs from { conv 4 1 , conv 4 3 , conv5 1 , conv5 3 } and map to semantic feature maps with dimension 18181024 , and for PNAS - Net we take outputs from { Cell 5 , Cell 7 , Cell 9 , Cell 11 } pointing game accuracy attention correctness Ours Ours Ours Ours Class",Experimental Setup,Experimental Setup,phrase_grounding,0,"['B', 'B', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,6,0.5,172,0.7644444444444445,6,0.21428571428571427,1,1,hyperparameters
176,Both visual and textual networks weights are fixed during training and only common space mapping weights are trainable .,Experimental Setup,Experimental Setup,phrase_grounding,0,"['B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-p', 'I-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'O']",9,0.75,175,0.7777777777777778,9,0.32142857142857145,1,1,hyperparameters
187,The results show that our method significantly outperforms all state - of - the - art methods in all conditions and all datasets .,Evaluation,For Refer,phrase_grounding,0,"['O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.4666666666666667,186,0.8266666666666667,20,0.7142857142857143,1,1,results
188,"For fair comparison with To get a deeper understanding of our model , we first report in category - wise pointing game accuracy and attention correctness ( percentage of the heatmap falling into the ground truth bounding box ) and compare with the state - of - the - art method on Flickr30 k .",Evaluation,For Refer,phrase_grounding,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'O']",8,0.5333333333333333,187,0.8311111111111111,21,0.75,1,1,results
189,We observe that our method obtains a higher performance on almost all categories even when VGG16 is used as the visual backbone .,Evaluation,For Refer,phrase_grounding,0,"['O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.6,188,0.8355555555555556,22,0.7857142857142857,1,1,results
190,The model based on PNASNet consistently outperforms the state - of - the - art on all categories on both metrics .,Evaluation,For Refer,phrase_grounding,0,"['O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O']",,,10,0.6666666666666666,189,0.84,23,0.8214285714285714,1,1,results
192,It shows that the 3rd level dominates the selection while the 4th level is also important for several categories such as scene and animals .,Evaluation,For Refer,phrase_grounding,0,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.8,191,0.8488888888888889,25,0.8928571428571429,1,1,results
193,The 1st level is exploited mostly for the animals and people categories .,Evaluation,For Refer,phrase_grounding,0,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.8666666666666667,192,0.8533333333333334,26,0.9285714285714286,1,1,results
194,"The full sentence selection relies mostly on the 3rd level as well , while for some sentences the 4th model has been selected .",Evaluation,For Refer,phrase_grounding,0,"['O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'O']",14,0.9333333333333333,193,0.8577777777777778,27,0.9642857142857143,1,1,results
202,"The results in rows 1 , 2 show that using level - attention mechanism based on multi-level feature maps significantly improves the performance over single visual - textual feature comparison .",Ablation Study,Ablation Study,phrase_grounding,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.375,201,0.8933333333333333,6,0.375,1,1,ablation-analysis
204,"By comparing rows 2 , 4 , 5 , 7 , we see that non-linear mapping in our model is really important , and replacing any mapping with a linear one significantly degrades the performance .",Ablation Study,Ablation Study,phrase_grounding,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",8,0.5,203,0.9022222222222223,8,0.5,1,1,ablation-analysis
205,"We can also see that non-linear mapping seems more important on the visual side , but best results are obtained with both text and visual non-linear mappings .",Ablation Study,Ablation Study,phrase_grounding,0,"['O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.5625,204,0.9066666666666666,9,0.5625,1,1,ablation-analysis
208,"The results in rows 1 , 3 and 2 , 6 show the importance of using a strong contextualized text embedding as the performance drops significantly .",Ablation Study,Ablation Study,phrase_grounding,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-ob', 'I-ob', 'O']",12,0.75,207,0.92,12,0.75,1,1,ablation-analysis
209,"We also study the use of softmax on the heatmaps , comparing rows 2 , 8 , we see that applying softmax leads to a very negative effect on the performance .",Ablation Study,Ablation Study,phrase_grounding,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'O']",13,0.8125,208,0.9244444444444444,13,0.8125,1,1,ablation-analysis
2,Predicting Prosodic Prominence from Text with Pre-trained Contextualized Word Representations,title,title,prosody_prediction,0,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.005208333333333333,1,0.0,1,1,research-problem
4,In this paper we introduce a new natural language processing dataset and benchmark for predicting prosodic prominence from written text .,abstract,abstract,prosody_prediction,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.16666666666666666,3,0.015625,1,0.16666666666666666,1,1,research-problem
16,"In this paper we introduce a new NLP dataset and benchmark for predicting prosodic prominence from text which is based on the recently published Libri TTS corpus , containing automatically generated prosodic prominence labels for over 260 hours or 2.8 million words of English audio books , read by 1230 different speakers .",Introduction,Introduction,prosody_prediction,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.3157894736842105,15,0.078125,6,0.3157894736842105,1,1,dataset
17,To our knowledge this will be the largest publicly available dataset with prosodic annotations .,Introduction,Introduction,prosody_prediction,0,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.3684210526315789,16,0.08333333333333333,7,0.3684210526315789,1,1,dataset
20,Prosody prediction can be turned into a sequence labeling task by giving each word in a text a discrete prominence value based on the amount of emphasis the speaker gives to the word when reading the text .,Introduction,Introduction,prosody_prediction,0,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.5263157894736842,19,0.09895833333333333,10,0.5263157894736842,1,1,research-problem
84,We performed experiments with the following models :,Experimental Setup,Experimental Setup,prosody_prediction,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O']",1,0.047619047619047616,83,0.4322916666666667,1,0.047619047619047616,1,1,experimental-setup
85,"BERT - base uncased 3 - layer 600D Bidirectional Long Short - Term Memory ( BiLSTM ) ( Hochreiter and Schmidhuber , 1997 ) Minitagger ( SVM ) ) + GloVe MarMoT ( CRF ) Majority class per word",Experimental Setup,Experimental Setup,prosody_prediction,0,"['B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-ob', 'I-ob', 'I-ob', 'I-ob']",2,0.09523809523809523,84,0.4375,2,0.09523809523809523,1,1,experimental-setup
88,"We use the Huggingface PyTorch implementation of BERT available in the pytorch transformers library , 3 which we further fine - tune during training .",Experimental Setup,Experimental Setup,prosody_prediction,0,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",5,0.23809523809523808,87,0.453125,5,0.23809523809523808,1,1,experimental-setup
89,"We take the last hidden layer of BERT and train a single fully - connected classifier layer on top of it , mapping the representation of each word to the labels .",Experimental Setup,Experimental Setup,prosody_prediction,0,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O']",,,6,0.2857142857142857,88,0.4583333333333333,6,0.2857142857142857,1,1,experimental-setup
90,For our experiments we use the smaller BERT - base model using the uncased alternative .,Experimental Setup,Experimental Setup,prosody_prediction,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",7,0.3333333333333333,89,0.4635416666666667,7,0.3333333333333333,1,1,experimental-setup
91,We use a batch size of 32 and fine - tune the model for 2 epochs .,Experimental Setup,Experimental Setup,prosody_prediction,0,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.38095238095238093,90,0.46875,8,0.38095238095238093,1,1,experimental-setup
92,For BiLSTM we use pre-trained 300D Glo Ve 840B word embeddings .,Experimental Setup,Experimental Setup,prosody_prediction,0,"['B', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.42857142857142855,91,0.4739583333333333,9,0.42857142857142855,1,1,experimental-setup
94,"As with BERT , we add one fullyconnected classifier layer on top of the BiLSTM , mapping the representation of each word to the labels .",Experimental Setup,Experimental Setup,prosody_prediction,0,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'O']",,,11,0.5238095238095238,93,0.484375,11,0.5238095238095238,1,1,experimental-setup
95,We use a dropout of 0.2 between the layers of the BiLSTM .,Experimental Setup,Experimental Setup,prosody_prediction,0,"['O', 'O', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.5714285714285714,94,0.4895833333333333,12,0.5714285714285714,1,1,experimental-setup
97,"For the SVM we use Minitagger 4 implementation by using each dimension of the pre-trained 300D Glo Ve 840B word embeddings as features , with context - size 1 , i.e. including the previous and the next word in the context .",Experimental Setup,Experimental Setup,prosody_prediction,0,"['O', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.6666666666666666,96,0.5,14,0.6666666666666666,1,1,experimental-setup
98,For the conditional random field ( CRF ) model we use MarMot 5 by with the default configuration .,Experimental Setup,Experimental Setup,prosody_prediction,0,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",15,0.7142857142857143,97,0.5052083333333334,15,0.7142857142857143,1,1,experimental-setup
101,All systems except the Minitagger and CRF are our implementations using PyTorch and are made available on GitHub : https://github.com/Helsinki - NLP / prosody .,Experimental Setup,Experimental Setup,prosody_prediction,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.8571428571428571,100,0.5208333333333334,18,0.8571428571428571,1,1,code
106,All models reach over 80 % in the 2 - way classification task while 3 - way classification accuracy stays below 70 % for all of them .,Results,Results,prosody_prediction,0,"['B', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.013333333333333334,105,0.546875,1,0.03125,1,1,results
107,"The BERTbased model gets the highest accuracy of 83.2 % and 68.6 % in the 2 - way and 3 - way classification tasks , respectively , demonstrating the value of a pytorch - transformers 4 https://github.com/karlstratos/",Results,Results,prosody_prediction,0,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.02666666666666667,106,0.5520833333333334,2,0.0625,1,1,results
111,The 3layer BiLSTM achieves 82.1 % in the 2 - way classification and 66.4 % in the 3 - way classification task .,Results,Results,prosody_prediction,0,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']",,,6,0.08,110,0.5729166666666666,6,0.1875,1,1,results
112,"The traditional feature - based classifiers perform slightly below the neural network models , with the CRF obtaining 81.8 % and 66.4 % for the two classification tasks , respectively .",Results,Results,prosody_prediction,0,"['O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",7,0.09333333333333334,111,0.578125,7,0.21875,1,1,results
113,The Minitagger SVM model 's test accuracies are slightly lower than the CRF 's with 80.8 % and 65.4 % test accuracies .,Results,Results,prosody_prediction,0,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.10666666666666667,112,0.5833333333333334,8,0.25,1,1,results
114,Finally taking a simple majority class per word gives 80.2 % for the 2 - way classification task and 62.4 % for the 3 - way classification task .,Results,Results,prosody_prediction,0,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']",,,9,0.12,113,0.5885416666666666,9,0.28125,1,1,results
121,For most of the models the biggest improvement in performance is achieved when moving from 1 % of the training examples to 5 % .,Results,Results,prosody_prediction,0,"['B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",16,0.21333333333333335,120,0.625,16,0.5,1,1,results
122,All models have reached close to their full predictive capacity with only 10 % of the training examples .,Results,Results,prosody_prediction,0,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.22666666666666666,121,0.6302083333333334,17,0.53125,1,1,results
127,"As the proposed dataset has been automatically generated as described in Section 3 , we also tested the best two models , BERT and BiLSTM , with a manually annotated test set from The Boston University radio news corpus . :",Results,Results,prosody_prediction,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O']",22,0.29333333333333333,126,0.65625,22,0.6875,1,1,results
131,The good results 6 from this experiment provide further support for the quality of the new dataset .,Results,Results,prosody_prediction,0,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",26,0.3466666666666667,130,0.6770833333333334,26,0.8125,1,1,results
132,Notice also that the difference between BERT and BiLSTM is much bigger with this test set ( + 3.9 % compared to + 1.1 % ) .,Results,Results,prosody_prediction,0,"['O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",27,0.36,131,0.6822916666666666,27,0.84375,1,1,results
2,Identifying Well - formed Natural Language Questions,title,,query_wellformedness,0,"['B', 'I', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.010416666666666666,1,0.0,1,1,research-problem
19,"Thus , in this paper we present a model to predict whether a given query is a well - formed natural language question .",Introduction,Introduction,query_wellformedness,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.21951219512195122,18,0.1875,9,0.5625,1,1,model
20,"We construct and publicly release a dataset of 25,100 queries annotated with the probability of being a well - formed natural language question ( 2.1 ) .",Introduction,Introduction,query_wellformedness,0,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",10,0.24390243902439024,19,0.19791666666666666,10,0.625,1,1,dataset
21,We then train a feed - forward neural network classifier that uses the lexical and syntactic features extracted from the query on this data ( 2.2 ) .,Introduction,Introduction,query_wellformedness,0,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O']",11,0.2682926829268293,20,0.20833333333333334,11,0.6875,1,1,model
24,Our dataset ise available for download at http://goo.gl/language/ query-wellformedness .,Introduction,Introduction,query_wellformedness,0,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",14,0.34146341463414637,23,0.23958333333333334,14,0.875,1,1,dataset
58,"The best performance obtained is 70.7 % while using word - 1 , 2 - grams and POS - 1 , 2 , 3 - grams as features .",Results .,Results .,query_wellformedness,0,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",1,0.09090909090909091,57,0.59375,6,0.375,1,1,results
59,Using POS n-grams gave a strong boost of 5.2 points over word unigrams and bigrams .,Results .,Results .,query_wellformedness,0,"['B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.18181818181818182,58,0.6041666666666666,7,0.4375,1,1,results
60,"Although character - 3 , 4 grams gave improvement over word unigrams and bigrams , the performance did not sustain when combined with POS tags .",Results .,Results .,query_wellformedness,0,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'O', 'B-p', 'B-ob', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",3,0.2727272727272727,59,0.6145833333333334,8,0.5,1,1,results
71,The majority class baseline is 61.5 % which corresponds to all queries being classified non-wellformed .,Baselines .,Baselines .,query_wellformedness,0,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.058823529411764705,70,0.7291666666666666,2,0.5,1,1,baselines
72,The question word baseline that classifies any query starting with a question word word n-grams char n-grams POS n -grams pwf ( q ) :,Baselines .,Baselines .,query_wellformedness,0,"['O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.11764705882352941,71,0.7395833333333334,3,0.75,1,1,baselines
4,We present a memory augmented neural network for natural language understanding : Neural Semantic Encoders .,abstract,abstract,question-answering,7,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.03571428571428571,3,0.01090909090909091,1,0.014492753623188406,1,1,research-problem
18,In this paper we propose a novel class of memory augmented neural networks called Neural Semantic Encoders ( NSE ) for natural language understanding .,abstract,abstract,question-answering,7,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",15,0.5357142857142857,17,0.06181818181818182,15,0.21739130434782608,1,1,model
20,NSE has a variable sized encoding memory which allows the model to access entire input sequence during the reading process ; therefore efficiently delivering long - term dependencies overtime .,abstract,NSE offers several desirable properties .,question-answering,7,"['B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.6071428571428571,19,0.06909090909090909,17,0.2463768115942029,1,1,model
21,"The encoding memory evolves overtime and maintains the memory of the input sequence through read , compose and write operations .",abstract,NSE offers several desirable properties .,question-answering,7,"['O', 'B', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.6428571428571429,20,0.07272727272727272,18,0.2608695652173913,1,1,model
22,NSE sequentially processes the input and supports word compositionality inheriting both temporal and hierarchical nature of human language .,abstract,NSE offers several desirable properties .,question-answering,7,"['O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.6785714285714286,21,0.07636363636363637,19,0.2753623188405797,1,1,model
23,NSE can read from and write to a set of relevant encoding memories simultaneously or multiple NSEs can access a shared encoding memory effectively supporting knowledge and representation sharing .,abstract,NSE offers several desirable properties .,question-answering,7,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",20,0.7142857142857143,22,0.08,20,0.2898550724637681,1,1,model
24,"NSE is flexible , robust and suitable for practical NLU tasks and can be trained easily by any gradient descent optimizer .",abstract,NSE offers several desirable properties .,question-answering,7,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.75,23,0.08363636363636363,21,0.30434782608695654,1,1,research-problem
127,The models are trained using Adam with hyperparameters selected on development set .,Experiments,Experiments,question-answering,7,"['O', 'O', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.02857142857142857,126,0.4581818181818182,4,0.36363636363636365,1,1,experimental-setup
128,We chose two one - layer LSTM for read / write modules on the tasks other than QA on which we used two - layer LSTM .,Experiments,Experiments,question-answering,7,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.03571428571428571,127,0.4618181818181818,5,0.45454545454545453,1,1,experimental-setup
129,The pre-trained 300 - D Glove 840B vectors and 100 - D Glove 6B vectors were obtained for the word embeddings .,Experiments,Experiments,question-answering,7,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O']",6,0.04285714285714286,128,0.46545454545454545,6,0.5454545454545454,1,1,experimental-setup
132,We crop or pad the input sequence to a fixed length .,Experiments,The word embeddings are fixed during training .,question-answering,7,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",9,0.06428571428571428,131,0.4763636363636364,9,0.8181818181818182,1,1,experimental-setup
134,The models were regularized by using dropouts and an l 2 weight decay .,Experiments,A padding vector was inserted when padding .,question-answering,7,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.07857142857142857,133,0.48363636363636364,11,1.0,1,1,experimental-setup
135,Natural Language Inference,Experiments,A padding vector was inserted when padding .,question-answering,7,"['B', 'I', 'I']","['B-p', 'I-p', 'I-p']","['B-p', 'I-p', 'I-p']",12,0.08571428571428572,134,0.48727272727272725,0,0.0,1,1,tasks
142,"In addition , the MLP has a hidden layer with 1024 units with ReLU activation and a sof tmax layer .",Experiments,A padding vector was inserted when padding .,question-answering,7,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",19,0.1357142857142857,141,0.5127272727272727,7,0.2692307692307692,1,1,tasks
143,"We set the batch size to 128 , the initial learning rate to 3e - 4 and l 2 regularizer strength to 3 e - 5 , and train each model for 40 epochs .",Experiments,A padding vector was inserted when padding .,question-answering,7,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",20,0.14285714285714285,142,0.5163636363636364,8,0.3076923076923077,1,1,tasks
158,Our MMA - NSE attention model is similar to the LSTM attention model .,Experiments,A padding vector was inserted when padding .,question-answering,7,"['O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",35,0.25,157,0.5709090909090909,23,0.8846153846153846,1,1,tasks
160,This model obtained 85.4 % accuracy score .,Experiments,,question-answering,7,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",37,0.2642857142857143,159,0.5781818181818181,25,0.9615384615384616,1,1,tasks
162,Answer Sentence Selection,Experiments,This model obtained 85.4 % accuracy score .,question-answering,7,"['B', 'I', 'I']","['B-p', 'I-p', 'I-p']","['B-p', 'I-p', 'I-p']",39,0.2785714285714286,161,0.5854545454545454,0,0.0,1,1,tasks
173,"We set the batch size to 4 and the initial learning rate to 1 e - 5 , and train the model for 10 epochs .",Experiments,We experiment on WikiQA dataset constructed from Wikipedia .,question-answering,7,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",50,0.35714285714285715,172,0.6254545454545455,11,0.4782608695652174,1,1,tasks
174,We used 40 % dropouts afterword embeddings and no l 2 weight decay .,Experiments,We experiment on WikiQA dataset constructed from Wikipedia .,question-answering,7,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",51,0.36428571428571427,173,0.6290909090909091,12,0.5217391304347826,1,1,tasks
175,The word embeddings are pre-trained 300 - D Glove 840B vectors .,Experiments,We experiment on WikiQA dataset constructed from Wikipedia .,question-answering,7,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",52,0.37142857142857144,174,0.6327272727272727,13,0.5652173913043478,1,1,tasks
176,"For this task , a linear mapping layer transforms the 300 - D word embeddings to the 512- D LSTM inputs .",Experiments,We experiment on WikiQA dataset constructed from Wikipedia .,question-answering,7,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",53,0.37857142857142856,175,0.6363636363636364,14,0.6086956521739131,1,1,tasks
181,Our MMA - NSE attention model exceeds the NASM by approximately 1 % on MAP and 0.8 % on MRR for this task .,Experiments,We experiment on WikiQA dataset constructed from Wikipedia .,question-answering,7,"['O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O']",,,58,0.4142857142857143,180,0.6545454545454545,19,0.8260869565217391,1,1,tasks
186,Sentence Classification,Experiments,,question-answering,7,"['B', 'I']","['B-p', 'I-p']","['B-p', 'I-p']",63,0.45,185,0.6727272727272727,0,0.0,1,1,tasks
191,The first layer of the MLP has ReLU activation and 1024 or 300 units for binary or fine - grained setting .,Experiments,Sentence Classification,question-answering,7,"['O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",68,0.4857142857142857,190,0.6909090909090909,5,0.38461538461538464,1,1,tasks
192,The second layer is a sof tmax layer .,Experiments,,question-answering,7,"['O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",69,0.4928571428571429,191,0.6945454545454546,6,0.46153846153846156,1,1,tasks
193,The read / write modules are two one - layer LSTM with 300 hidden units and the word embeddings are the pre-trained 300 - D Glove 840B vectors .,Experiments,The second layer is a sof tmax layer .,question-answering,7,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",70,0.5,192,0.6981818181818182,7,0.5384615384615384,1,1,tasks
194,"We set the batch size to 64 , the initial learning rate to 3e - 4 and l 2 regularizer strength to 3 e - 5 , and train each model for 25 epochs .",Experiments,The second layer is a sof tmax layer .,question-answering,7,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'O']",,,71,0.5071428571428571,193,0.7018181818181818,8,0.6153846153846154,1,1,tasks
199,Our model outperformed the DMN and set the state - of - the - art results on both subtasks .,Experiments,The second layer is a sof tmax layer .,question-answering,7,"['B', 'I', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",76,0.5428571428571428,198,0.72,13,1.0,1,1,tasks
200,Document Sentiment Analysis,Experiments,The second layer is a sof tmax layer .,question-answering,7,"['B', 'I', 'I']","['B-p', 'I-p', 'I-p']","['B-p', 'I-p', 'I-p']",77,0.55,199,0.7236363636363636,0,0.0,1,1,tasks
204,We stack a NSE or LSTM on the top of another NSE for document modeling .,Experiments,"Particularly , we used the pre-split datasets of .",question-answering,7,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",81,0.5785714285714286,203,0.7381818181818182,4,0.2,1,1,tasks
207,The whole network is trained jointly by backpropagating the cross entropy loss .,Experiments,"Particularly , we used the pre-split datasets of .",question-answering,7,"['B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",84,0.6,206,0.7490909090909091,7,0.35,1,1,tasks
208,We used one - layer LSTM with 100 hidden units for the read / write modules and the pre-trained 100 - D Glove 6B vectors for this task .,Experiments,"Particularly , we used the pre-split datasets of .",question-answering,7,"['O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",85,0.6071428571428571,207,0.7527272727272727,8,0.4,1,1,tasks
209,"We set the batch size to 32 , the initial learning rate to 3e - 4 and l 2 regularizer strength to 1 e - 5 , and trained each model for 50 epochs .",Experiments,"Particularly , we used the pre-split datasets of .",question-answering,7,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'O']",,,86,0.6142857142857143,208,0.7563636363636363,9,0.45,1,1,tasks
221,Machine Translation,Experiments,,question-answering,7,"['B', 'I']","['B-p', 'I-p']","['B-p', 'I-p']",98,0.7,220,0.8,0,0.0,1,1,tasks
241,The models were trained to minimize word - level cross entropy loss and were regularized by 20 % input dropouts and the 30 % output dropouts .,Experiments,"For NTM , we implemented three different models .",question-answering,7,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",118,0.8428571428571429,240,0.8727272727272727,20,0.8695652173913043,1,1,tasks
242,"We set the batch size to 128 , the initial learning rate to 1e - 3 for LSTM - LSTM and 3e - 4 for the other models and l 2 regularizer strength to 3 e - 5 , and train each model for 40 epochs .",Experiments,"For NTM , we implemented three different models .",question-answering,7,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'O']",,,119,0.85,241,0.8763636363636363,21,0.9130434782608695,1,1,tasks
2,Modeling Semantics with Gated Graph Neural Networks for Knowledge Base Question Answering,title,title,question_answering,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.003389830508474576,1,0.0,1,1,research-problem
11,Knowledge base question answering ( QA ) is an important natural language processing problem .,Introduction,Introduction,question_answering,0,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.007751937984496124,10,0.03389830508474576,1,0.02564102564102564,1,1,research-problem
15,QA requires precise modeling of the question semantics through the entities and relations available in the KB in order to retrieve the correct answer .,Introduction,Introduction,question_answering,0,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.03875968992248062,14,0.04745762711864407,5,0.1282051282051282,1,1,research-problem
19,"In this paper , we describe a semantic parsing approach to the problem of KB QA .",Introduction,Introduction,question_answering,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",9,0.06976744186046512,18,0.061016949152542375,9,0.23076923076923078,1,1,research-problem
20,"That is , for each input question , we construct an explicit structural semantic parse ( semantic graph ) , as in .",Introduction,Introduction,question_answering,0,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",10,0.07751937984496124,19,0.06440677966101695,10,0.2564102564102564,1,1,approach
21,Semantic parses can be deterministically converted to a query to extract the answers from the KB .,Introduction,Introduction,question_answering,0,"['B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'O']","['B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O']","['B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O']",11,0.08527131782945736,20,0.06779661016949153,11,0.28205128205128205,1,1,approach
34,"In particular , we adapt Gated Graph Neural Networks ( GGNNs ) , described in , to process and score semantic parses .",Introduction,Introduction,question_answering,0,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",24,0.18604651162790697,33,0.11186440677966102,24,0.6153846153846154,1,1,approach
48,https://github.com/UKPLab/coling2018-graph-neural-networks-question-answering.,Introduction,Contributions,question_answering,0,['O'],['O'],['O'],38,0.29457364341085274,47,0.15932203389830507,38,0.9743589743589743,1,1,code
171,3 . Pooled Edges model - We use the DCNN to encode the question and the label of each edge in the semantic graph .,Models,Models,question_answering,0,"['O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",8,0.4,170,0.576271186440678,8,0.4,1,1,baselines
174,Graph Neural Network ( GNN ) -,Models,Models,question_answering,0,"['B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",11,0.55,173,0.5864406779661017,11,0.55,1,1,baselines
175,"To judge the effect of the gated graph neural architecture , we also include a model variant that does not use the gating mechanism and directly computes the hidden state as a combination of the activations ( Eq 1 ) and the previous state .",Models,Models,question_answering,0,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.6,174,0.5898305084745763,12,0.6,1,1,baselines
176,"Gated Graph Neural Network ( GGNN ) - We use the GGNN to process semantic parses , as described in Section 3.2 .",Models,Models,question_answering,0,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.65,175,0.5932203389830508,13,0.65,1,1,baselines
219,We compare the results on the WebQSP - WD data set in .,Results,WebQSP-WD,question_answering,0,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O']",7,0.1320754716981132,218,0.7389830508474576,1,0.038461538461538464,1,1,results
220,"As can be seen , the graph models outperform all other models across precision , recall and F-score , with GGNN showing the best over all result .",Results,WebQSP-WD,question_answering,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.1509433962264151,219,0.7423728813559322,2,0.07692307692307693,1,1,results
223,"The STAGG architecture delivers the worst results in our experiments , the main reason being supposedly that the model had to rely on manually defined features that are less flexible .",Results,WebQSP-WD,question_answering,0,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.20754716981132076,222,0.752542372881356,5,0.19230769230769232,1,1,results
224,The Single Edge model outperforms the more complex Pooled Edges model by a noticeable margin .,Results,WebQSP-WD,question_answering,0,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",12,0.22641509433962265,223,0.7559322033898305,6,0.23076923076923078,1,1,results
225,The Single Edge baseline prefers simple graphs that consist of a single edge which is a good strategy to achieve higher recall values .,Results,WebQSP-WD,question_answering,0,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",13,0.24528301886792453,224,0.7593220338983051,7,0.2692307692307692,1,1,results
228,"In , we see that for the STAGG and Single Edge baselines the performance on more complex questions drops compared to the results on simpler questions .",Results,WebQSP-WD,question_answering,0,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']",,,16,0.3018867924528302,227,0.7694915254237288,10,0.38461538461538464,1,1,results
229,"The Pooled Edges model maintains a better performance across questions of different complexity , which shows the benefits of encoding all graph edges .",Results,WebQSP-WD,question_answering,0,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.32075471698113206,228,0.7728813559322034,11,0.4230769230769231,1,1,results
233,"We see that the GGNN model offers the best results both on simple and complex questions , as it effectively encodes the structure of semantic graphs .",Results,WebQSP-WD,question_answering,0,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.39622641509433965,232,0.7864406779661017,15,0.5769230769230769,1,1,results
2,BI - DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION,title,title,question_answering,1,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.0031545741324921135,1,0.0,1,1,research-problem
4,"Machine comprehension ( MC ) , answering a query about a given context paragraph , requires modeling complex interactions between the context and the query .",abstract,abstract,question_answering,1,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.00946372239747634,1,0.2,1,1,research-problem
5,"Recently , attention mechanisms have been successfully extended to MC .",abstract,abstract,question_answering,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O']",2,0.4,4,0.012618296529968454,2,0.4,1,1,research-problem
10,The tasks of machine comprehension ( MC ) and question answering ( QA ) have gained significant popularity over the past few years within the natural language processing and computer vision communities .,INTRODUCTION,INTRODUCTION,question_answering,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.043478260869565216,9,0.028391167192429023,1,0.043478260869565216,1,1,research-problem
17,"In this paper , we introduce the Bi- Directional Attention Flow ( BIDAF ) network , a hierarchical multi-stage architecture for modeling the representations of the context paragraph at different levels of granularity ) .",INTRODUCTION,INTRODUCTION,question_answering,1,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",8,0.34782608695652173,16,0.050473186119873815,8,0.34782608695652173,1,1,model
18,"BIDAF includes character - level , word - level , and contextual embeddings , and uses bi-directional attention flow to obtain a query - aware context representation .",INTRODUCTION,INTRODUCTION,question_answering,1,"['B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.391304347826087,17,0.05362776025236593,9,0.391304347826087,1,1,model
21,"Instead , the attention is computed for every time step , and the attended vector at each time step , along with the representations from previous layers , is allowed to flow through to the subsequent modeling layer .",INTRODUCTION,INTRODUCTION,question_answering,1,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.5217391304347826,20,0.06309148264984227,12,0.5217391304347826,1,1,model
23,"Second , we use a memory - less attention mechanism .",INTRODUCTION,INTRODUCTION,question_answering,1,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",14,0.6086956521739131,22,0.0694006309148265,14,0.6086956521739131,1,1,model
26,"It forces the attention layer to focus on learning the attention between the query and the context , and enables the modeling layer to focus on learning the interaction within the query - aware context representation ( the output of the attention layer ) .",INTRODUCTION,INTRODUCTION,question_answering,1,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O']",,,17,0.7391304347826086,25,0.07886435331230283,17,0.7391304347826086,1,1,model
27,It also allows the attention at each time step to be unaffected from incorrect attendances at previous time steps .,INTRODUCTION,INTRODUCTION,question_answering,1,"['O', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']",,,18,0.782608695652174,26,0.08201892744479496,18,0.782608695652174,1,1,model
29,"Third , we use attention mechanisms in both directions , query - to - context and context - to - query , which provide complimentary information to each other .",INTRODUCTION,INTRODUCTION,question_answering,1,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",20,0.8695652173913043,28,0.08832807570977919,20,0.8695652173913043,1,1,model
174,Each paragraph and question are tokenized by a regular - expression - based word tokenizer ( PTB Tokenizer ) and fed into the model .,Training .,Dataset .,question_answering,1,"['B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",72,0.8780487804878049,173,0.5457413249211357,10,0.15384615384615385,1,1,experimental-setup
175,"We use 100 1D filters for CNN char embedding , each with a width of 5 .",Training .,Dataset .,question_answering,1,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",73,0.8902439024390244,174,0.5488958990536278,11,0.16923076923076924,1,1,experimental-setup
176,The hidden state size ( d ) of the model is 100 .,Training .,Dataset .,question_answering,1,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O']",74,0.9024390243902439,175,0.5520504731861199,12,0.18461538461538463,1,1,experimental-setup
177,The model has about 2.6 million parameters .,Training .,Dataset .,question_answering,1,"['B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",75,0.9146341463414634,176,0.555205047318612,13,0.2,1,1,experimental-setup
178,"We use the AdaDelta ( Zeiler , 2012 ) optimizer , with a minibatch size of 60 and an initial learning rate of 0.5 , for 12 epochs .",Training .,Dataset .,question_answering,1,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'O']",,,76,0.926829268292683,177,0.5583596214511041,14,0.2153846153846154,1,1,experimental-setup
179,"A dropout ) rate of 0.2 is used for the CNN , all LSTM layers , and the linear transformation before the softmax for the answers .",Training .,Dataset .,question_answering,1,"['O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O']",77,0.9390243902439024,178,0.5615141955835962,15,0.23076923076923078,1,1,experimental-setup
180,"During training , the moving averages of all weights of the model are maintained with the exponential decay rate of 0.999 .",Training .,Dataset .,question_answering,1,"['B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'O']",,,78,0.9512195121951219,179,0.5646687697160884,16,0.24615384615384617,1,1,experimental-setup
181,"At test time , the moving averages instead of the raw weights are used .",Training .,Dataset .,question_answering,1,"['B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O']",79,0.9634146341463414,180,0.5678233438485805,17,0.26153846153846155,1,1,experimental-setup
182,The training process takes roughly 20 hours on a single Titan X GPU .,Training .,Dataset .,question_answering,1,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",80,0.975609756097561,181,0.5709779179810726,18,0.27692307692307694,1,1,experimental-setup
187,"BIDAF ( ensemble ) achieves an EM score of 73.3 and an F 1 score of 81.1 , outperforming all previous approaches .",Results .,Results .,question_answering,1,"['B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O']",,,2,1.0,186,0.5867507886435331,23,0.35384615384615387,1,1,results
190,Both char - level and word - level embeddings contribute towards the model 's performance .,Ablations .,Ablations .,question_answering,1,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.04081632653061224,189,0.5962145110410094,26,0.4,1,1,ablation-analysis
195,C2Q attention proves to be critical with a drop of more than 10 points on both metrics .,Ablations .,Ablations .,question_answering,1,"['B', 'I', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",7,0.14285714285714285,194,0.61198738170347,31,0.47692307692307695,1,1,ablation-analysis
199,"Despite being a simpler attention mechanism , our proposed static attention outperforms the dynamically computed attention by more than 3 points .",Ablations .,Ablations .,question_answering,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.22448979591836735,198,0.6246056782334385,35,0.5384615384615384,1,1,ablation-analysis
207,"At the word embedding layer , query words such as When , Where and Who are not well aligned to possible answers in the context , but this dramatically changes in the contextual embedding layer which has access to context from surrounding words and is just 1 layer below the attention layer .",Ablations .,Ablations .,question_answering,1,"['B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.3877551020408163,206,0.6498422712933754,43,0.6615384615384615,1,1,ablation-analysis
2,Focal Visual - Text Attention for Visual Question Answering,title,,question_answering,2,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0036101083032490976,1,0.0,1,1,research-problem
13,"Visual question answering ( VQA ) is a successful direction utilizing both computer vision and natural language processing techniques to solve an interesting problem : given a pair of image and a question ( in natural language ) , the goal is to learn an inference model that can the answer questions according to cues discovered from the image .",Introduction,Introduction,question_answering,2,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.05405405405405406,12,0.04332129963898917,2,0.05405405405405406,1,1,research-problem
15,"Extending from VQA on a single image , this paper considers the following problem :",Introduction,Introduction,question_answering,2,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.10810810810810811,14,0.05054151624548736,4,0.10810810810810811,1,1,research-problem
32,"To address these two challenges , we propose a focal visual - text attention ( FVTA ) model for sequential data",Introduction,Introduction,question_answering,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob']",21,0.5675675675675675,31,0.11191335740072202,21,0.5675675675675675,1,1,model
37,"Inspired by this process , FVTA first learns to localize relevant information within a few , small , temporally consecutive regions over the input sequences , and learns to infer an answer based on the cross-modal statistics pooled from these regions .",Introduction,Introduction,question_answering,2,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",26,0.7027027027027027,36,0.1299638989169675,26,0.7027027027027027,1,1,model
38,FVTA proposes a novel kernel to compute the attention tensor that jointly models the latent information in three sources :,Introduction,Introduction,question_answering,2,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O']",27,0.7297297297297297,37,0.13357400722021662,27,0.7297297297297297,1,1,model
39,"1 ) answer - signaling words in the question , 2 ) temporal correlation within a sequence , and 3 ) cross-modal interaction between the text and image .",Introduction,Introduction,question_answering,2,"['O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",28,0.7567567567567568,38,0.1371841155234657,28,0.7567567567567568,1,1,model
40,"FVTA attention allows for collective reasoning by the attention kernel learned over a few , small , consecutive sub-sequences of text and image .",Introduction,Introduction,question_answering,2,"['B', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",29,0.7837837837837838,39,0.1407942238267148,29,0.7837837837837838,1,1,model
44,We propose a novel attention kernel for VQA on visual - text data .,Introduction,Introduction,question_answering,2,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",33,0.8918918918918919,43,0.1552346570397112,33,0.8918918918918919,1,1,model
183,Memex QA provides 4 answer choices and only one correct answer for each question .,Network Architecture,Cross Sequence Interaction,question_answering,2,"['B', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",103,0.9537037037037037,182,0.6570397111913358,33,0.32673267326732675,1,1,experiments
191,"We implement the following methods as baselines : Logistic Regression predicts the answer with concatenated image , question and metadata features as reported in .",Baseline Methods,Baseline Methods,question_answering,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",2,0.13333333333333333,190,0.6859205776173285,41,0.40594059405940597,1,1,experiments
192,"Embedding + LSTM utilizes word embeddings and character embeddings , along with the same visual embeddings used in FVTA .",Baseline Methods,Baseline Methods,question_answering,2,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",3,0.2,191,0.6895306859205776,42,0.4158415841584158,1,1,experiments
194,Embedding + LSTM + Concat concatenates the last LSTM output from different modalities to produce the final output .,Baseline Methods,Baseline Methods,question_answering,2,"['B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.3333333333333333,193,0.6967509025270758,44,0.43564356435643564,1,1,experiments
196,Classic Soft Attention uses classic one dimensional question - to - context attention to summarize context for question answering .,Baseline Methods,Baseline Methods,question_answering,2,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.4666666666666667,195,0.703971119133574,46,0.45544554455445546,1,1,experiments
198,"DMN + is the improved dynamic memory networks , which is one of the representative architectures that achieve good performance on the VQA Task .",Baseline Methods,Baseline Methods,question_answering,2,"['B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",9,0.6,197,0.7111913357400722,48,0.4752475247524752,1,1,experiments
201,TGIF Temporal Attention is a recently proposed spatial - temporal reasoning network on sequential animated image QA .,Baseline Methods,Baseline Methods,question_answering,2,"['B', 'I', 'I', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.8,200,0.7220216606498195,51,0.504950495049505,1,1,experiments
211,We encode GPS locations using words .,Implementation Details In Memex,Implementation Details In Memex,question_answering,2,"['O', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",6,0.13043478260869565,210,0.7581227436823105,61,0.6039603960396039,1,1,experiments
213,"All questions , textual context and answers are tokenized using the Stanford word tokenizer .",Implementation Details In Memex,Implementation Details In Memex,question_answering,2,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.17391304347826086,212,0.7653429602888087,63,0.6237623762376238,1,1,experiments
214,"We use pre-trained Glo Ve word embeddings , which is fixed during training .",Implementation Details In Memex,Implementation Details In Memex,question_answering,2,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",9,0.1956521739130435,213,0.7689530685920578,64,0.6336633663366337,1,1,experiments
215,"For image / video embedding , we extract fixed - size features using the pre-trained CNN model , Inception - ResNet , by concatenating the pool5 layer and classification layer 's output before softmax .",Implementation Details In Memex,Implementation Details In Memex,question_answering,2,"['B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",10,0.21739130434782608,214,0.7725631768953068,65,0.6435643564356436,1,1,experiments
216,We then use a linear transformation to compress the image feature into 100 dimensional .,Implementation Details In Memex,Implementation Details In Memex,question_answering,2,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.2391304347826087,215,0.776173285198556,66,0.6534653465346535,1,1,experiments
217,Then a bi-directional LSTM is used for each modality to obtain contextual representations .,Implementation Details In Memex,Implementation Details In Memex,question_answering,2,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",12,0.2608695652173913,216,0.779783393501805,67,0.6633663366336634,1,1,experiments
218,"Given a hidden state size of d , which is set to 50 , we concatenate the output of both directions of the LSTM and get a question matrix Q ?",Implementation Details In Memex,Implementation Details In Memex,question_answering,2,"['B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'O']",,,13,0.2826086956521739,217,0.7833935018050542,68,0.6732673267326733,1,1,experiments
219,R 2 d M and context tensor H ?,Implementation Details In Memex,Implementation Details In Memex,question_answering,2,"['B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'O']",14,0.30434782608695654,218,0.7870036101083032,69,0.6831683168316832,1,1,experiments
220,R 2dV KN 6 for all media documents .,Implementation Details In Memex,Implementation Details In Memex,question_answering,2,"['B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'O']",15,0.32608695652173914,219,0.7906137184115524,70,0.693069306930693,1,1,experiments
221,We reshape the context tensor into H ? R 2 d T 6 .,Implementation Details In Memex,Implementation Details In Memex,question_answering,2,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.34782608695652173,220,0.7942238267148014,71,0.7029702970297029,1,1,experiments
222,"To select the best hyperparmeters , we randomly select 20 % of the official training set as the validation set .",Implementation Details In Memex,Implementation Details In Memex,question_answering,2,"['B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",17,0.3695652173913043,221,0.7978339350180506,72,0.7128712871287128,1,1,experiments
223,We use the AdaDelta optimizer and an initial learning rate of 0.5 to train for 200 epochs with a dropout rate of 0.3 ..,Implementation Details In Memex,Implementation Details In Memex,question_answering,2,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,18,0.391304347826087,222,0.8014440433212996,73,0.7227722772277227,1,1,experiments
234,FVTA outperforms other attention models on finding the relevant photos for the question .,Implementation Details In Memex,The Memex,question_answering,2,"['B', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",29,0.6304347826086957,233,0.8411552346570397,84,0.8316831683168316,1,1,experiments
242,"To evaluate the FVTA attention mechanism , we first replace our kernel tensor with simple cosine similarity function .",Implementation Details In Memex,The Memex,question_answering,2,"['O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",37,0.8043478260869565,241,0.8700361010830325,92,0.9108910891089109,1,1,experiments
243,Results show that standard cosine similarity is inferior to our similarity function .,Implementation Details In Memex,The Memex,question_answering,2,"['O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",38,0.8260869565217391,242,0.8736462093862816,93,0.9207920792079208,1,1,experiments
244,"For ablating intra-sequence dependency , we use the representations from the last timestep of each context document .",Implementation Details In Memex,The Memex,question_answering,2,"['B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",39,0.8478260869565217,243,0.8772563176895307,94,0.9306930693069307,1,1,experiments
245,"For ablating cross sequence interaction , we average all attended context representation from different modalities to get the final context vector .",Implementation Details In Memex,The Memex,question_answering,2,"['O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",40,0.8695652173913043,244,0.8808664259927798,95,0.9405940594059405,1,1,experiments
246,"Both aspects of correlation of the FVTA attention tensor contribute towards the model 's performance , while intra-sequence dependency shows more importance in this experiment .",Implementation Details In Memex,The Memex,question_answering,2,"['B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",41,0.8913043478260869,245,0.8844765342960289,96,0.9504950495049505,1,1,experiments
247,We compare the effectiveness of context - aware question attention by removing the question attention and use the last timestep of the LSTM output from the question as the question representation .,Implementation Details In Memex,The Memex,question_answering,2,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O']",,,42,0.9130434782608695,246,0.8880866425992779,97,0.9603960396039604,1,1,experiments
248,It shows the question attention provides slight improvement .,Implementation Details In Memex,The Memex,question_answering,2,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-s', 'I-s', 'B-p', 'B-ob', 'I-ob', 'O']",43,0.9347826086956522,247,0.8916967509025271,98,0.9702970297029703,1,1,experiments
249,"Finally , we train FVTA without photos to see the contribution of visual information .",Implementation Details In Memex,The Memex,question_answering,2,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",44,0.9565217391304348,248,0.8953068592057761,99,0.9801980198019802,1,1,experiments
250,"The result is quite good but it is perhaps not surprising due to the language bias in the questions and answers of the dataset , which is not uncommon in VQA dataset and in Visual7W .",Implementation Details In Memex,The Memex,question_answering,2,"['O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",45,0.9782608695652174,249,0.8989169675090253,100,0.9900990099009901,1,1,experiments
257,"In the MovieQA dataset , each QA is given a set of N movie clips of the same movie , and each clip comes with subtitles .",Implementation Details,Implementation Details,question_answering,2,"['O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O']",1,0.047619047619047616,256,0.924187725631769,4,0.21052631578947367,1,1,experiments
258,We implement FVTA network for Movie QA task with modality number of 2 ( video & text ) .,Implementation Details,Implementation Details,question_answering,2,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.09523809523809523,257,0.927797833935018,5,0.2631578947368421,1,1,experiments
259,"We set the maximum number of movie clips per question to N = 20 , the maximum number of frames to consider to F = 10 , the maximum number of subtitle sentences in a clip to K = 100 and the maximum words to V = 10 .",Implementation Details,Implementation Details,question_answering,2,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']",,,3,0.14285714285714285,258,0.9314079422382672,6,0.3157894736842105,1,1,experiments
261,We use the AdaDelta optimizer with a minibatch of 16 and an initial learning rate of 0.5 to trained for 300 epochs .,Implementation Details,Implementation Details,question_answering,2,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'O']",,,5,0.23809523809523808,260,0.9386281588447654,8,0.42105263157894735,1,1,experiments
264,FVTA model outperforms all baseline methods and achieves comparable performance to the state - of - the - art result 2 on the MovieQA test server .,Implementation Details,Implementation Details,question_answering,2,"['B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.38095238095238093,263,0.9494584837545126,11,0.5789473684210527,1,1,experiments
266,Our accuracy is 0.410 ( vs 0.387 by RWMN ) on the validation set and 0.373 ( vs 0.363 ) on the test set .,Implementation Details,Implementation Details,question_answering,2,"['O', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'O']",,,10,0.47619047619047616,265,0.9566787003610109,13,0.6842105263157895,1,1,experiments
267,"Benefiting from such modeling ability , FVTA consistently outperforms the classical attention models including soft attention , MCB and TGIF .",Implementation Details,Implementation Details,question_answering,2,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-s', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'O', 'B-ob', 'O']",11,0.5238095238095238,266,0.9602888086642599,14,0.7368421052631579,1,1,experiments
2,Multi - Granular Sequence Encoding via Dilated Compositional Units for Reading Comprehension,title,title,question_answering,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.0035714285714285713,1,0.0,1,1,research-problem
5,This paper presents a new compositional encoder for reading comprehension ( RC ) .,abstract,abstract,question_answering,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.2857142857142857,4,0.014285714285714285,2,0.2857142857142857,1,1,research-problem
9,"We conduct experiments on three RC datasets , showing that our proposed encoder demonstrates very promising results both as a standalone encoder as well as a complementary building block .",abstract,abstract,question_answering,3,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.8571428571428571,8,0.02857142857142857,6,0.8571428571428571,1,1,research-problem
22,"To this end , we propose a new compositional encoder that can either be used in place of standard RNN encoders or serve as a new module that is complementary to existing neural architectures .",Introduction,Introduction,question_answering,3,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",11,0.12087912087912088,21,0.075,11,0.2894736842105263,1,1,model
23,Our proposed encoder leverages dilated compositions to model relationships across multiple granularities .,Introduction,Introduction,question_answering,3,"['B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",12,0.13186813186813187,22,0.07857142857142857,12,0.3157894736842105,1,1,model
24,"That is , for a given word in the target sequence , our encoder exploits both long - term ( far ) and short - term ( near ) information to decide how much information to retain for it .",Introduction,Introduction,question_answering,3,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O']",13,0.14285714285714285,23,0.08214285714285714,13,0.34210526315789475,1,1,model
26,"The output of the dilated composition mechanism acts as gating functions , which are then used to learn compositional representations of the input sequence .",Introduction,Introduction,question_answering,3,"['O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,15,0.16483516483516483,25,0.08928571428571429,15,0.39473684210526316,1,1,model
178,RACE,Competitor Methods,,question_answering,3,['B'],['B-n'],['B-b'],2,0.10526315789473684,177,0.6321428571428571,0,0.0,1,1,baselines
179,"The key competitors are the Stanford Attention Reader ( Stanford AR ) , Gated Attention Reader ( GA ) , and Dynamic Fusion Networks ( DFN ) .",Competitor Methods,RACE,question_answering,3,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.15789473684210525,178,0.6357142857142857,1,0.058823529411764705,1,1,baselines
185,SearchQA,Competitor Methods,,question_answering,3,['B'],['B-n'],['B-b'],9,0.47368421052631576,184,0.6571428571428571,7,0.4117647058823529,1,1,baselines
186,The main competitor baseline is the AMANDA model proposed by .,Competitor Methods,SearchQA,question_answering,3,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O']",10,0.5263157894736842,185,0.6607142857142857,8,0.47058823529411764,1,1,baselines
190,NarrativeQA,Competitor Methods,,question_answering,3,['B'],['B-n'],['B-b'],14,0.7368421052631579,189,0.675,12,0.7058823529411765,1,1,baselines
192,"We compete on the summaries setting , in which the baselines are a context - less sequence to sequence ( seq2seq ) model , ASR and BiDAF .",Competitor Methods,NarrativeQA,question_answering,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'B-ob', 'O']",16,0.8421052631578947,191,0.6821428571428572,14,0.8235294117647058,1,1,baselines
211,We implement all models in TensorFlow .,Implementation Details,Implementation Details,question_answering,3,"['O', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",1,0.05,210,0.75,1,0.05,1,1,experimental-setup
212,Word embeddings are initialized with 300d Glo Ve vectors and are not fine - tuned during training .,Implementation Details,Implementation Details,question_answering,3,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'O']",2,0.1,211,0.7535714285714286,2,0.1,1,1,experimental-setup
213,"Dropout rate is tuned amongst { 0.1 , 0.2 , 0.3 } on all layers including the embedding layer .",Implementation Details,Implementation Details,question_answering,3,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",3,0.15,212,0.7571428571428571,3,0.15,1,1,experimental-setup
216,"We adopt the Adam optimizer ( Kingma and Ba , 2014 ) with a learning rate of 0.0003/ 0.001/0.001 for RACE / SearchQA / Narrative QA respectively .",Implementation Details,Implementation Details,question_answering,3,"['O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",6,0.3,215,0.7678571428571429,6,0.3,1,1,experimental-setup
217,The batch size is set to 64/256/32 accordingly .,Implementation Details,Implementation Details,question_answering,3,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O']",7,0.35,216,0.7714285714285715,7,0.35,1,1,experimental-setup
218,The maximum sequence lengths are 500/200/1100 respectively .,Implementation Details,Implementation Details,question_answering,3,"['O', 'B', 'I', 'I', 'B', 'B', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O']",8,0.4,217,0.775,8,0.4,1,1,experimental-setup
219,"For Narrative QA , we use the Rouge - L score to find the best approximate answer relative to the human written answer for training the span model .",Implementation Details,Implementation Details,question_answering,3,"['B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",9,0.45,218,0.7785714285714286,9,0.45,1,1,experimental-setup
220,All models are trained and all runtime benchmarks are based on a TitanXP GPU .,Implementation Details,Implementation Details,question_answering,3,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",10,0.5,219,0.7821428571428571,10,0.5,1,1,experimental-setup
221,reports our results on the RACE benchmark dataset .,Implementation Details,Implementation Details,question_answering,3,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O']",11,0.55,220,0.7857142857142857,11,0.55,1,1,results
222,Our proposed DCU model achieves the best result for both single models and ensemble models .,Implementation Details,Implementation Details,question_answering,3,"['B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",12,0.6,221,0.7892857142857143,12,0.6,1,1,results
223,We outperform highly complex models such as DFN .,Implementation Details,Implementation Details,question_answering,3,"['O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",13,0.65,222,0.7928571428571428,13,0.65,1,1,results
224,We also pull ahead of other recent baselines such as ElimiNet and GA by at least 5 % .,Implementation Details,Implementation Details,question_answering,3,"['O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.7,223,0.7964285714285714,14,0.7,1,1,results
225,The best single model score from RACE - H and RACE - M alternates between Sim - DCU and DCU .,Implementation Details,Implementation Details,question_answering,3,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O']",15,0.75,224,0.8,15,0.75,1,1,results
243,Table 2 reports our results on the Search QA dataset .,Experimental Results on SearchQA,Experimental Results on SearchQA,question_answering,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O']",1,0.06666666666666667,242,0.8642857142857143,1,0.06666666666666667,1,1,results
245,We achieve the same accuracy as AMANDA without using any LSTM or GRU encoder .,Experimental Results on SearchQA,Experimental Results on SearchQA,question_answering,3,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.2,244,0.8714285714285714,3,0.2,1,1,results
248,"Finally , the hybrid combination , DCU - LSTM significantly outperforms AMANDA by 3 % .",Experimental Results on SearchQA,Experimental Results on SearchQA,question_answering,3,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",6,0.4,247,0.8821428571428571,6,0.4,1,1,results
249,"Contrary to MCQ - based datasets , we found that reports our results on the NarrativeQA benchmark .",Experimental Results on SearchQA,Experimental Results on SearchQA,question_answering,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O']",7,0.4666666666666667,248,0.8857142857142857,7,0.4666666666666667,1,1,results
250,"First , we observe that 300d DCU can achieve comparable performance with BiDAF .",Experimental Results on SearchQA,Experimental Results on SearchQA,question_answering,3,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",8,0.5333333333333333,249,0.8892857142857142,8,0.5333333333333333,1,1,results
256,"Finally , DCU - LSTM significantly outperforms all models in terms of ROUGE - L , including BiDAF on this dataset .",Experimental Results on SearchQA,Experimental Results on SearchQA,question_answering,3,"['O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'B', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'O']",14,0.9333333333333333,255,0.9107142857142857,14,0.9333333333333333,1,1,results
257,"Performance improvement over the vanilla BiLSTM model ranges from 1 % ? 3 % across all metrics , suggesting that DCU encoders are also effective as a complementary neural building block .",Experimental Results on SearchQA,Experimental Results on SearchQA,question_answering,3,"['B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,1.0,256,0.9142857142857143,15,1.0,1,1,results
2,Densely Connected Attention Propagation for Reading Comprehension,title,,question_answering,4,"['O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.0038910505836575876,1,0.0,1,1,research-problem
4,"We propose DECAPROP ( Densely Connected Attention Propagation ) , a new densely connected neural architecture for reading comprehension ( RC ) .",abstract,abstract,question_answering,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.125,3,0.011673151750972763,1,0.125,1,1,research-problem
9,We conduct extensive experiments on four challenging RC benchmarks .,abstract,abstract,question_answering,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O']",6,0.75,8,0.0311284046692607,6,0.75,1,1,research-problem
31,"Firstly , our network is densely connected , connecting every layer of P with every layer of Q .",Introduction,Introduction,question_answering,4,"['O', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.14074074074074075,30,0.11673151750972763,19,0.25,1,1,model
37,"To this end , we propose efficient Bidirectional Attention Connectors ( BAC ) as a base building block to connect two sequences at arbitrary layers .",Introduction,Introduction,question_answering,4,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",25,0.18518518518518517,36,0.14007782101167315,25,0.32894736842105265,1,1,model
38,"The key idea is to compress the attention outputs so that they can be small enough to propagate , yet enabling a connection between two sequences .",Introduction,Introduction,question_answering,4,"['O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,26,0.1925925925925926,37,0.14396887159533073,26,0.34210526315789475,1,1,model
39,"The propagated features are collectively passed into prediction layers , which effectively connect shallow layers to deeper layers .",Introduction,Introduction,question_answering,4,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",27,0.2,38,0.14785992217898833,27,0.35526315789473684,1,1,model
41,"Overall , we propose DECAPROP ( Densely Connected Attention Propagation ) , a novel architecture for reading comprehension .",Introduction,Introduction,question_answering,4,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",29,0.21481481481481482,40,0.1556420233463035,29,0.3815789473684211,1,1,model
152,NewsQA,Datasets and Competitor Baselines,,question_answering,4,['B'],['B-n'],['B-b'],2,0.07692307692307693,151,0.5875486381322957,2,0.07692307692307693,1,1,baselines
156,"On this dataset , the key competitors are BiDAF , Match - LSTM , FastQA / Fast QA - Ext , R2-BiLSTM , AMANDA .",Datasets and Competitor Baselines,NewsQA,question_answering,4,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'B-ob', 'O']",6,0.23076923076923078,155,0.603112840466926,6,0.23076923076923078,1,1,baselines
157,Quasar -T,Datasets and Competitor Baselines,,question_answering,4,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",7,0.2692307692307692,156,0.6070038910505836,7,0.2692307692307692,1,1,baselines
159,The key competitors on this dataset are BiDAF and the Reinforced Ranker - Reader ( R 3 ) .,Datasets and Competitor Baselines,Quasar -T,question_answering,4,"['O', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,9,0.34615384615384615,158,0.6147859922178989,9,0.34615384615384615,1,1,baselines
161,SearchQA,Datasets and Competitor Baselines,,question_answering,4,['B'],['B-n'],['B-b'],11,0.4230769230769231,160,0.622568093385214,11,0.4230769230769231,1,1,baselines
165,"The competitor baselines on this dataset are Attention Sum Reader ( ASR ) , Focused Hierarchical RNNs ( FH - RNN ) , AMANDA , BiDAF , AQA and the Reinforced Ranker - Reader ( R 3 ) .",Datasets and Competitor Baselines,SearchQA,question_answering,4,"['O', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.5769230769230769,164,0.6381322957198443,15,0.5769230769230769,1,1,baselines
166,Narrative QA ] is a recent QA dataset that involves comprehension over stories .,Datasets and Competitor Baselines,SearchQA,question_answering,4,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.6153846153846154,165,0.642023346303502,16,0.6153846153846154,1,1,baselines
168,"We compare with the baselines in the original paper , namely Seq2Seq , Attention Sum Reader and BiDAF .",Datasets and Competitor Baselines,SearchQA,question_answering,4,"['O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O']",18,0.6923076923076923,167,0.6498054474708171,18,0.6923076923076923,1,1,baselines
169,We also compare with the recent BiAttention + MRU model .,Datasets and Competitor Baselines,SearchQA,question_answering,4,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.7307692307692307,168,0.6536964980544747,19,0.7307692307692307,1,1,baselines
178,Our model is implemented in Tensorflow .,Experimental Setup,Experimental Setup,question_answering,4,"['O', 'B', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",1,0.07692307692307693,177,0.688715953307393,1,0.07692307692307693,1,1,experimental-setup
179,"The sequence lengths are capped at 800/700/1500/1100 for News QA , Search QA , Quasar - T and Narrative QA respectively .",Experimental Setup,Experimental Setup,question_answering,4,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",2,0.15384615384615385,178,0.6926070038910506,2,0.15384615384615385,1,1,experimental-setup
180,"We use Adadelta with ? = 0.5 for News QA , Adam with ? = 0.001 for Search QA , Quasar - T and Narrative QA .",Experimental Setup,Experimental Setup,question_answering,4,"['O', 'B', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O']",,,3,0.23076923076923078,179,0.6964980544747081,3,0.23076923076923078,1,1,experimental-setup
181,"The choice of the RNN encoder is tuned between GRU and LSTM cells and the hidden size is tuned amongst { 32 , 50 , 64 , 75 } .",Experimental Setup,Experimental Setup,question_answering,4,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.3076923076923077,180,0.7003891050583657,4,0.3076923076923077,1,1,experimental-setup
182,We use the CUDNN implementation of the RNN encoder .,Experimental Setup,Experimental Setup,question_answering,4,"['O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.38461538461538464,181,0.7042801556420234,5,0.38461538461538464,1,1,experimental-setup
183,"Batch size is tuned amongst { 16 , 32 , 64 } .",Experimental Setup,Experimental Setup,question_answering,4,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.46153846153846156,182,0.708171206225681,6,0.46153846153846156,1,1,experimental-setup
184,"Dropout rate is tuned amongst { 0.1 , 0.2 , 0.3 } and applied to all RNN and fully - connected layers .",Experimental Setup,Experimental Setup,question_answering,4,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.5384615384615384,183,0.7120622568093385,7,0.5384615384615384,1,1,experimental-setup
185,We apply variational dropout in - between RNN layers .,Experimental Setup,Experimental Setup,question_answering,4,"['O', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",8,0.6153846153846154,184,0.7159533073929961,8,0.6153846153846154,1,1,experimental-setup
186,We initialize the word embeddings with 300D Glo Ve embeddings and are fixed during training .,Experimental Setup,Experimental Setup,question_answering,4,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",9,0.6923076923076923,185,0.7198443579766537,9,0.6923076923076923,1,1,experimental-setup
187,The size of the character embeddings is set to 8 and the character RNN is set to the same as the word - level RNN encoders .,Experimental Setup,Experimental Setup,question_answering,4,"['O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']",,,10,0.7692307692307693,186,0.7237354085603113,10,0.7692307692307693,1,1,experimental-setup
188,The maximum characters per word is set to 16 .,Experimental Setup,Experimental Setup,question_answering,4,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",11,0.8461538461538461,187,0.7276264591439688,11,0.8461538461538461,1,1,experimental-setup
189,The number of layers in DECAENC is set to 3 and the number of factors in the factorization kernel is set to 64 .,Experimental Setup,Experimental Setup,question_answering,4,"['O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']",,,12,0.9230769230769231,188,0.7315175097276264,12,0.9230769230769231,1,1,experimental-setup
190,We use a learning rate decay factor of 2 and patience of 3 epochs whenever the EM ( or ROUGE - L ) score on the development set does not increase .,Experimental Setup,Experimental Setup,question_answering,4,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,13,1.0,189,0.7354085603112841,13,1.0,1,1,experimental-setup
192,"Overall , our results are optimistic and promising , with results indicating that DECAPROP achieves state - of - the - art performance 6 on all four datasets . 66.2 75.9 DCN + CoVE 71.3 79.9 R- NET 72.3 80.6 R - NET",Results,Results,question_answering,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.05,191,0.7431906614785992,1,0.05,1,1,results
194,"On this dataset , DECAPROP outperforms the existing state - of - the - art , i.e. , the recent AMANDA model by ( + 4.7 % EM / + 2.6 % F1 ) .",Results,Results,question_answering,4,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",3,0.15,193,0.7509727626459144,3,0.15,1,1,results
196,"Moreover , our proposed model also outperforms well - established baselines such as Match - LSTM ( + 18 % EM / + 16.3 % F1 ) and BiDAF ( + 16 % EM / + 14 % F1 ) .",Results,Results,question_answering,4,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.25,195,0.7587548638132295,5,0.25,1,1,results
197,reports the results on Quasar - T .,Results,Results,question_answering,4,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O']",6,0.3,196,0.7626459143968871,6,0.3,1,1,results
198,"Our model achieves state - of - the - art performance on this dataset , outperforming the state - of - the - art R 3 ( Reinforced Ranker Reader ) by a considerable margin of + 4.4 % EM / + 6 % F1 .",Results,Results,question_answering,4,"['B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.35,197,0.7665369649805448,7,0.35,1,1,results
202,"On the original setting , our model outperforms AMANDA by + 15.4 % EM and + 14.2 % in terms of F1 score .",Results,Quasar - T,question_answering,4,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.55,201,0.7821011673151751,11,0.55,1,1,results
203,"On the over all setting , our model outperforms both AQA ( + 18.1 % EM / + 18 % F1 ) and Reinforced Reader Ranker ( + 7.8 % EM / + 8.3 % F1 ) .",Results,Quasar - T,question_answering,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",12,0.6,202,0.7859922178988327,12,0.6,1,1,results
209,SQuAD reports dev scores 8 of our model against several representative models on the popular SQuAD benchmark .,Results,Quasar - T,question_answering,4,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O']",18,0.9,208,0.8093385214007782,18,0.9,1,1,results
210,"While our model does not achieve state - of - the - art performance , our model can outperform the base R - NET ( both our implementation as well as the published score ) .",Results,Quasar - T,question_answering,4,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.95,209,0.8132295719844358,19,0.95,1,1,results
213,We conduct an ablation study on the New s QA development set .,Ablation Study,Ablation Study,question_answering,4,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.06666666666666667,212,0.8249027237354085,1,0.06666666666666667,1,1,ablation-analysis
221,"Finally , in ( 8 - 9 ) , we varied the FM with linear and nonlinear feed - forward layers . From ( 1 ) , we observe a significant gap in performance between DECAPROP and R - NET .",Ablation Study,Ablation Study,question_answering,4,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.6,220,0.8560311284046692,9,0.6,1,1,ablation-analysis
223,"Overall , the key insight is that all model components are crucial to DECAPROP .",Ablation Study,Ablation Study,question_answering,4,"['O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'O']",11,0.7333333333333333,222,0.8638132295719845,11,0.7333333333333333,1,1,ablation-analysis
224,"Notably , the DECAENC seems to contribute the most to the over all performance .",Ablation Study,Ablation Study,question_answering,4,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.8,223,0.867704280155642,12,0.8,1,1,ablation-analysis
226,We observe that the superiority of DECAPROP over R - NET is consistent and relatively stable .,Ablation Study,Ablation Study,question_answering,4,"['O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.9333333333333333,225,0.8754863813229572,14,0.9333333333333333,1,1,ablation-analysis
2,EVIDENCE AGGREGATION FOR ANSWER RE - RANKING IN OPEN - DOMAIN QUESTION ANSWERING,,,question_answering,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",2,0.14285714285714285,1,0.0036231884057971015,1,0.0,1,1,research-problem
16,Open-domain question answering ( QA ) aims to answer questions from a broad range of domains by effectively marshalling evidence from large open - domain knowledge sources .,INTRODUCTION,INTRODUCTION,question_answering,5,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.027777777777777776,15,0.05434782608695652,1,0.027777777777777776,1,1,research-problem
18,Recent work on open - domain QA has focused on using unstructured text retrieved from the web to build machine comprehension models .,INTRODUCTION,INTRODUCTION,question_answering,5,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.08333333333333333,17,0.06159420289855073,3,0.08333333333333333,1,1,research-problem
23,"In this paper , we propose a method to improve open - domain QA by explicitly aggregating evidence from across multiple passages .",INTRODUCTION,INTRODUCTION,question_answering,5,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",8,0.2222222222222222,22,0.07971014492753623,8,0.2222222222222222,1,1,model
35,We formulate the above evidence aggregation as an answer re-ranking problem .,INTRODUCTION,INTRODUCTION,question_answering,5,"['O', 'B', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",20,0.5555555555555556,34,0.12318840579710146,20,0.5555555555555556,1,1,model
37,"Here we apply the idea of re-ranking ; for each answer candidate , we efficiently incorporate global information from multiple pieces of textual evidence without significantly increasing the complexity of the prediction of the RC model .",INTRODUCTION,INTRODUCTION,question_answering,5,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'O']",,,22,0.6111111111111112,36,0.13043478260869565,22,0.6111111111111112,1,1,model
39,The re-rankers are :,INTRODUCTION,INTRODUCTION,question_answering,5,"['O', 'B', 'B', 'O']","['O', 'B-n', 'B-p', 'O']","['O', 'B-b', 'B-p', 'O']",24,0.6666666666666666,38,0.13768115942028986,24,0.6666666666666666,1,1,model
40,"A strength - based re-ranker , which ranks the answer candidates according to how often their evidence occurs in different passages .",INTRODUCTION,INTRODUCTION,question_answering,5,"['O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",25,0.6944444444444444,39,0.14130434782608695,25,0.6944444444444444,1,1,model
43,"A coverage - based re-ranker , which aims to rank an answer candidate higher if the union of all its contexts in different passages could cover more aspects included in the question .",INTRODUCTION,INTRODUCTION,question_answering,5,"['O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",28,0.7777777777777778,42,0.15217391304347827,28,0.7777777777777778,1,1,model
160,"Our baseline models 9 include the following : GA , a reading comprehension model with gated - attention ; BiDAF ) , a RC model with bidirectional attention flow ; AQA ) , a reinforced system learning to aggregate the answers generated by the re-written questions ; R 3 ) , a reinforced model making use of a ranker for selecting passages to train the RC model .",BASELINES,BASELINES,question_answering,5,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O']",,,1,0.16666666666666666,159,0.5760869565217391,1,0.16666666666666666,1,1,baselines
167,"We first use a pre-trained R 3 model , which gets the state - of - the - art performance on the three public datasets we consider , to generate the top 50 candidate spans for the training , development and test datasets , and we use them for further ranking .",IMPLEMENTATION DETAILS,IMPLEMENTATION DETAILS,question_answering,5,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",1,0.14285714285714285,166,0.6014492753623188,1,0.14285714285714285,1,1,hyperparameters
169,"For the coverage - based re-ranker , we use Adam to optimize the model .",IMPLEMENTATION DETAILS,IMPLEMENTATION DETAILS,question_answering,5,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",3,0.42857142857142855,168,0.6086956521739131,3,0.42857142857142855,1,1,hyperparameters
171,We set all the words beyond Glove as zero vectors .,IMPLEMENTATION DETAILS,IMPLEMENTATION DETAILS,question_answering,5,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'O']",5,0.7142857142857143,170,0.6159420289855072,5,0.7142857142857143,1,1,hyperparameters
172,"We set l to 300 , batch size to 30 , learning rate to 0.002 .",IMPLEMENTATION DETAILS,IMPLEMENTATION DETAILS,question_answering,5,"['O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,6,0.8571428571428571,171,0.6195652173913043,6,0.8571428571428571,1,1,hyperparameters
173,"We tune the dropout probability from 0 to 0.5 and the number of candidate answers for re-ranking ( K ) in [ 3 , 5 , 10 ] 11 .",IMPLEMENTATION DETAILS,IMPLEMENTATION DETAILS,question_answering,5,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",7,1.0,172,0.6231884057971014,7,1.0,1,1,hyperparameters
181,"The results showed that R 3 achieved F1 56.0 , EM 50.9 on Wiki domain and F1 68.5 , EM 63.0 on Web domain , which is competitive to the state - of - the - arts .",RESULTS AND ANALYSIS,RESULTS AND ANALYSIS,question_answering,5,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,7,0.5833333333333334,180,0.6521739130434783,7,0.5833333333333334,1,1,results
184,Our code will be released under https://github.com/shuohangwang/mprc.,RESULTS AND ANALYSIS,RESULTS AND ANALYSIS,question_answering,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.8333333333333334,183,0.6630434782608695,10,0.8333333333333334,1,1,code
190,"From the results , we can clearly see that the full re-ranker , the combination of different re-rankers , significantly outperforms the previous best performance by a large margin , especially on Quasar - T and Search QA .",OVERALL RESULTS,OVERALL RESULTS,question_answering,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",3,0.05454545454545454,189,0.6847826086956522,3,0.6,1,1,results
191,"Moreover , our model is much better than the human performance on the Search QA dataset .",OVERALL RESULTS,OVERALL RESULTS,question_answering,5,"['O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.07272727272727272,190,0.6884057971014492,4,0.8,1,1,results
192,"In addition , we see that our coverage - based re-ranker achieves consistently good performance on the three datasets , even though its performance is marginally lower than the strength - based re-ranker on the Search QA dataset .",OVERALL RESULTS,OVERALL RESULTS,question_answering,5,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.09090909090909091,191,0.6920289855072463,5,1.0,1,1,results
2,Neural Question Generation from Text : A Preliminary Study,title,,question_generation,0,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.00546448087431694,1,0.0,1,1,research-problem
4,Automatic question generation aims to generate questions from a text passage where the generated questions can be answered by certain sub- spans of the given passage .,abstract,abstract,question_generation,0,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.01639344262295082,1,0.2,1,1,research-problem
10,"Automatic question generation from natural language text aims to generate questions taking text as input , which has the potential value of education purpose ) .",Introduction,Introduction,question_generation,0,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0625,9,0.04918032786885246,1,0.0625,1,1,research-problem
11,"As the reverse task of question answering , question generation also has the potential for providing a large scale corpus of question - answer pairs .",Introduction,Introduction,question_generation,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.125,10,0.0546448087431694,2,0.125,1,1,research-problem
16,"In this work we conduct a preliminary study on question generation from text with neural networks , which is denoted as the Neural Question Generation ( NQG ) framework , to generate natural language questions from text without pre-defined rules .",Introduction,Introduction,question_generation,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.4375,15,0.08196721311475409,7,0.4375,1,1,model
17,The Neural Question Generation framework extends the sequence - to - sequence models by enriching the encoder with answer and lexical features to generate answer focused questions .,Introduction,Introduction,question_generation,0,"['O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.5,16,0.08743169398907104,8,0.5,1,1,model
18,"Concretely , the encoder reads not only the input sentence , but also the answer position indicator and lexical features .",Introduction,Introduction,question_generation,0,"['O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",9,0.5625,17,0.09289617486338798,9,0.5625,1,1,model
19,"The answer position feature denotes the answer span in the input sentence , which is essential to generate answer relevant questions .",Introduction,Introduction,question_generation,0,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.625,18,0.09836065573770492,10,0.625,1,1,model
20,The lexical features include part - of - speech ( POS ) and named entity ( NER ) tags to help produce better sentence encoding .,Introduction,Introduction,question_generation,0,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O']",11,0.6875,19,0.10382513661202186,11,0.6875,1,1,model
21,"Lastly , the decoder with attention mechanism generates an answer specific question of the sentence .",Introduction,Introduction,question_generation,0,"['O', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",12,0.75,20,0.1092896174863388,12,0.75,1,1,model
71,PCFG - Trans,Experiments and Results,Experiments and Results,question_generation,0,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",8,0.4,70,0.3825136612021858,8,0.4,1,1,baselines
72,The rule - based system 1 modified on the code released by .,Experiments and Results,Experiments and Results,question_generation,0,"['O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.45,71,0.3879781420765027,9,0.45,1,1,baselines
74,s 2 s+ att,Experiments and Results,Experiments and Results,question_generation,0,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",11,0.55,73,0.3989071038251366,11,0.55,1,1,baselines
75,We implement a seq2seq with attention as the baseline method .,Experiments and Results,Experiments and Results,question_generation,0,"['O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",12,0.6,74,0.40437158469945356,12,0.6,1,1,baselines
76,NQG,Experiments and Results,,question_generation,0,['B'],['B-n'],['B-b'],13,0.65,75,0.4098360655737705,13,0.65,1,1,baselines
77,We extend the s 2s+ att with our feature - rich encoder to build the NQG system .,Experiments and Results,NQG,question_generation,0,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",14,0.7,76,0.41530054644808745,14,0.7,1,1,baselines
78,"NQG + Based on NQG , we incorporate copy mechanism to deal with rare words problem .",Experiments and Results,NQG,question_generation,0,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",15,0.75,77,0.4207650273224044,15,0.75,1,1,baselines
79,"NQG + Pretrain Based on NQG + , we initialize the word embedding matrix with pre-trained GloVe vectors .",Experiments and Results,NQG,question_generation,0,"['B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",16,0.8,78,0.4262295081967213,16,0.8,1,1,baselines
80,"NQG + STshare Based on NQG + , we make the encoder and decoder share the same embedding matrix .",Experiments and Results,NQG,question_generation,0,"['B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.85,79,0.43169398907103823,17,0.85,1,1,baselines
81,NQG ++,Experiments and Results,NQG,question_generation,0,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",18,0.9,80,0.4371584699453552,18,0.9,1,1,baselines
82,"Based on NQG + , we use both pre-train word embedding and STshare methods , to further improve the performance .",Experiments and Results,NQG,question_generation,0,"['B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'O']",19,0.95,81,0.4426229508196721,19,0.95,1,1,baselines
89,Our NQG framework outperforms the PCFG - Trans and s 2s + att baselines by a large margin .,Results and Analysis,Results and Analysis,question_generation,0,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.625,88,0.4808743169398907,5,0.625,1,1,results
91,"With the help of copy mechanism , NQG + has a 2.05 BLEU improvement since it solves the rare words problem .",Results and Analysis,Results and Analysis,question_generation,0,"['B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.875,90,0.4918032786885246,7,0.875,1,1,results
92,"The extended version , NQG ++ , has 1.11 BLEU score gain over NQG + , which shows that initializing with pre-trained word vectors and sharing them between encoder and decoder help learn better word representation .",Results and Analysis,Results and Analysis,question_generation,0,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,1.0,91,0.4972677595628415,8,1.0,1,1,results
104,"The answer position indicator , as expected , plays a crucial role in answer focused question generation as shown in the NQG ?",Ablation Test,Ablation Test,question_generation,0,"['O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.03125,103,0.5628415300546448,5,0.3333333333333333,1,1,ablation-analysis
109,"NER , show that word case , POS and NER tag features contributes to question generation .",Ablation Test,Ablation Test,question_generation,0,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",6,0.1875,108,0.5901639344262295,10,0.6666666666666666,1,1,ablation-analysis
2,Multimodal Differential Network for Visual Question Generation,title,,question_generation,1,"['O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.002551020408163265,1,0.0,1,1,research-problem
4,Generating natural questions from an image is a semantic task that requires using visual and language modality to learn multimodal representations .,abstract,abstract,question_generation,1,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.16666666666666666,3,0.007653061224489796,1,0.16666666666666666,1,1,research-problem
18,Here the au-thors have proposed the challenging task of generating natural questions for an image .,Introduction,Introduction,question_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.27586206896551724,17,0.04336734693877551,8,0.27586206896551724,1,1,research-problem
24,"To solve this problem , we use the context obtained by considering exemplars , specifically we use the difference between relevant and irrelevant exemplars .",Introduction,Introduction,question_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.4827586206896552,23,0.058673469387755105,14,0.4827586206896552,1,1,approach
25,"We consider different contexts in the form of Location , Caption , and Part of Speech tags .",Introduction,Introduction,question_generation,1,"['O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.5172413793103449,24,0.061224489795918366,15,0.5172413793103449,1,1,approach
26,Our method implicitly uses a differential context obtained through supporting and contrasting exemplars to obtain a differentiable embedding .,Introduction,Introduction,question_generation,1,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O']",16,0.5517241379310345,25,0.06377551020408163,16,0.5517241379310345,1,1,approach
27,This embedding is used by a question decoder to decode the appropriate question .,Introduction,Introduction,question_generation,1,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",17,0.5862068965517241,26,0.0663265306122449,17,0.5862068965517241,1,1,approach
36,"To summarize , we propose a multimodal differential network to solve the task of visual question generation .",Introduction,Figure,question_generation,1,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",26,0.896551724137931,35,0.08928571428571429,26,0.896551724137931,1,1,approach
2,Tha3aroon at NSURL - 2019 Task 8 : Semantic Question Similarity in Arabic,title,title,question_similarity,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.007246376811594203,1,0.0,1,1,research-problem
4,"In this paper , we describe our team 's effort on the semantic text question similarity task of NSURL 2019 .",abstract,abstract,question_similarity,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.021739130434782608,1,0.2,1,1,research-problem
10,Semantic Text Similarity ( STS ) problems are both real - life and challenging .,Introduction,Introduction,question_similarity,0,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.06666666666666667,9,0.06521739130434782,1,0.06666666666666667,1,1,research-problem
11,"For example , in the paraphrase identification task , STS is used to predict if one sentence is a paraphrase of the other or not .",Introduction,Introduction,question_similarity,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.13333333333333333,10,0.07246376811594203,2,0.13333333333333333,1,1,research-problem
14,A new task has been proposed by Mawdoo3 1 company with a new dataset provided by their data annotation team for Semantic Question Similarity ( SQS ) for the Arabic language .,Introduction,Introduction,question_similarity,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.3333333333333333,13,0.09420289855072464,5,0.3333333333333333,1,1,research-problem
15,"SQS is a variant of STS , which aims to compare a pair of questions and determine whether they have the same meaning or not .",Introduction,Introduction,question_similarity,0,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.4,14,0.10144927536231885,6,0.4,1,1,research-problem
19,We then build a neural network model with four components .,Introduction,Introduction,question_similarity,0,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",10,0.6666666666666666,18,0.13043478260869565,10,0.6666666666666666,1,1,model
20,The model uses ELMo ( which stands for Embeddings from Language Models ) pre-trained contextual embeddings as an input and builds sequence representation vectors that are used to predict the relation between the question pairs .,Introduction,Introduction,question_similarity,0,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.7333333333333333,19,0.13768115942028986,11,0.7333333333333333,1,1,model
85,All experiments discussed in this work have been done on the Google Colab 7 environment using Tesla T4 GPU accelerator with the following hyperparameters :,Experimental Setup,Experimental Setup,question_similarity,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.02040816326530612,84,0.6086956521739131,1,0.125,1,1,experimental-setup
100,"The tables show that while GRU cells are the most efficient , the ON - LSTM cells ( with chunk size 8 ) are the most effective ( in terms of all considered measures ) .",Experimental Setup,Effect of RNN Cell Type,question_similarity,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O']",,,16,0.32653061224489793,99,0.717391304347826,7,1.0,1,1,results
101,Effect of Data Augmentation,Experimental Setup,,question_similarity,0,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",17,0.3469387755102041,100,0.7246376811594203,0,0.0,1,1,results
106,The tables show that each augmentation step affects the model 's efficiency negatively .,Experimental Setup,Effect of Data Augmentation,question_similarity,0,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-ob', 'O']",22,0.4489795918367347,105,0.7608695652173914,5,0.5,1,1,results
108,"On the other hand , not each increment step has a positive effect on the model 's effectiveness .",Experimental Setup,Effect of Data Augmentation,question_similarity,0,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",24,0.4897959183673469,107,0.7753623188405797,7,0.7,1,1,results
114,"For example , using pre-trained FastText embeddings as an input to our model yields worse F1score on both public and private leaderboards with 94.254 and 93.118 , respectively , compared with the ELMo contextual embeddings model .",Experimental Setup,Other Attempts,question_similarity,0,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",30,0.6122448979591837,113,0.8188405797101449,2,0.3333333333333333,1,1,results
116,"However , the sequence weighted attention gives better results by about 1 point of the F1-score .",Experimental Setup,Other Attempts,question_similarity,0,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",32,0.6530612244897959,115,0.8333333333333334,4,0.6666666666666666,1,1,results
117,"Moreover , an attempt to overcome the weakness of the Arabic ELMo model is done by translating the data to English using Google Translate 8 and treating the problem as an English SQS problem instead , but the results are much worse with 88.868 and 87.504 F1 - scores on public and private leaderboards , respectively .",Experimental Setup,Other Attempts,question_similarity,0,"['O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",33,0.673469387755102,116,0.8405797101449275,5,0.8333333333333334,1,1,results
2,SCIBERT : A Pretrained Language Model for Scientific Text,title,,relation-classification,9,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",1,0.0,1,0.006802721088435374,1,0.0,1,1,research-problem
4,Obtaining large - scale annotated data for NLP tasks in the scientific domain is challenging and expensive .,abstract,abstract,relation-classification,9,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.16666666666666666,3,0.02040816326530612,1,0.16666666666666666,1,1,research-problem
5,"We release SCIBERT , a pretrained language model based on BERT ( Devlin et al. , 2019 ) to address the lack of high - quality , large - scale labeled scientific data .",abstract,abstract,relation-classification,9,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.3333333333333333,4,0.027210884353741496,2,0.3333333333333333,1,1,research-problem
9,The code and pretrained models are available at https://github.com/allenai/scibert/.,abstract,abstract,relation-classification,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,1.0,8,0.05442176870748299,6,1.0,1,1,code
13,"In general domains , large - scale training data is often possible to obtain through crowdsourcing , but in scientific domains , annotated data is difficult and expensive to collect due to the expertise required for quality annotation .",Introduction,Introduction,relation-classification,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.25,12,0.08163265306122448,3,0.25,1,1,research-problem
27,SCIB - ERT follows the same architecture as BERT but is instead pretrained on scientific text .,Background,Background,relation-classification,9,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",3,0.0375,26,0.17687074829931973,4,0.4,0,1,approach
31,"We construct SCIVOCAB , a new WordPiece vocabulary on our scientific corpus using the Sen - tencePiece 1 library .",Background,Background,relation-classification,9,"['O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.0875,30,0.20408163265306123,8,0.8,0,1,approach
34,Corpus,Background,,relation-classification,9,['B'],['B-n'],['B-b'],10,0.125,33,0.22448979591836735,0,0.0,0,1,approach
35,We train SCIBERT on a random sample of 1.14 M papers from Semantic Scholar .,Background,Corpus,relation-classification,9,"['O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.1375,34,0.23129251700680273,1,0.16666666666666666,0,1,approach
36,This corpus consists of 18 % papers from the computer science domain and 82 % from the broad biomedical domain .,Background,Corpus,relation-classification,9,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']",,,12,0.15,35,0.23809523809523808,2,0.3333333333333333,0,1,approach
44,Named Entity Recognition ( NER ),Background,Tasks,relation-classification,9,"['B', 'I', 'I', 'O', 'B', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-ob', 'O']",20,0.25,43,0.2925170068027211,3,0.3333333333333333,0,1,tasks
45,2 . PICO Extraction ( PICO ),Background,Tasks,relation-classification,9,"['O', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'O']",21,0.2625,44,0.29931972789115646,4,0.4444444444444444,0,1,tasks
46,3 . Text Classification ( CLS ),Background,Tasks,relation-classification,9,"['O', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'O']",22,0.275,45,0.30612244897959184,5,0.5555555555555556,0,1,tasks
47,4 . Relation Classification ( REL ),Background,Tasks,relation-classification,9,"['O', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'O']",23,0.2875,46,0.3129251700680272,6,0.6666666666666666,0,1,tasks
48,5 . Dependency Parsing ( DEP ) ,Background,Tasks,relation-classification,9,"['O', 'O', 'B', 'I', 'O', 'B', 'O', 'O']",,,24,0.3,47,0.3197278911564626,7,0.7777777777777778,0,1,
103,We observe that SCIBERT outperforms BERT - Base on scientific tasks ( + 2.11 F1 with finetuning and + 2.43 F1 without ),Background,Embeddings,relation-classification,9,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",79,0.9875,102,0.6938775510204082,22,0.9565217391304348,0,1,results
106,Biomedical Domain,Results,,relation-classification,9,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",1,0.03225806451612903,105,0.7142857142857143,0,0.0,1,1,results
107,We observe that SCIBERT outperforms BERT - Base on biomedical tasks ( + 1.92 F1 with finetuning and + 3.59 F1 without ) .,Results,Biomedical Domain,relation-classification,9,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'O']",,,2,0.06451612903225806,106,0.7210884353741497,1,0.09090909090909091,1,1,results
108,"In addition , SCIB - ERT achieves new SOTA results on BC5 CDR and ChemProt , and EBM - NLP .",Results,Biomedical Domain,relation-classification,9,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.0967741935483871,107,0.7278911564625851,2,0.18181818181818182,1,1,results
118,Computer Science Domain,Results,,relation-classification,9,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",13,0.41935483870967744,117,0.7959183673469388,0,0.0,1,1,results
119,We observe that SCIBERT outperforms BERT - Base on computer science tasks ( + 3.55 F1 with finetuning and + 1.13 F1 without ) .,Results,Computer Science Domain,relation-classification,9,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'O']",,,14,0.45161290322580644,118,0.8027210884353742,1,0.3333333333333333,1,1,results
120,"In addition , SCIBERT achieves new SOTA results on ACL - ARC , and the NER part of SciERC .",Results,Computer Science Domain,relation-classification,9,"['O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.4838709677419355,119,0.8095238095238095,2,0.6666666666666666,1,1,results
122,Multiple Domains,Results,,relation-classification,9,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",17,0.5483870967741935,121,0.8231292517006803,0,0.0,1,1,results
123,We observe that SCIBERT outperforms BERT - Base on the multidomain tasks ( + 0.49 F1 with finetuning and + 0.93 F1 without ) .,Results,Multiple Domains,relation-classification,9,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'O']",,,18,0.5806451612903226,122,0.8299319727891157,1,0.3333333333333333,1,1,results
124,"In addition , SCIBERT outperforms the SOTA on Sci - Cite .",Results,Multiple Domains,relation-classification,9,"['O', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",19,0.6129032258064516,123,0.8367346938775511,2,0.6666666666666666,1,1,results
2,Going out on a limb : Joint Extraction of Entity Mentions and Relations without Dependency Trees,title,title,relation_extraction,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",1,0.0,1,0.00390625,1,0.0,1,1,research-problem
10,Extraction of entities and their relations from text belongs to a very well - studied family of structured prediction tasks in NLP .,Introduction,Introduction,relation_extraction,0,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.04,9,0.03515625,1,0.04,1,1,research-problem
12,Several methods have been proposed for entity mention and relation extraction at the sentencelevel .,Introduction,Introduction,relation_extraction,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.12,11,0.04296875,3,0.12,1,1,research-problem
24,"In this paper , we propose a novel RNN - based model for the joint extraction of entity mentions and relations .",Introduction,Introduction,relation_extraction,0,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.6,23,0.08984375,15,0.6,1,1,model
25,"Unlike other models , our model does not depend on any dependency tree information .",Introduction,Introduction,relation_extraction,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.64,24,0.09375,16,0.64,1,1,model
26,Our RNN - based model is a multi - layer bidirectional LSTM over a sequence .,Introduction,Introduction,relation_extraction,0,"['B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",17,0.68,25,0.09765625,17,0.68,1,1,model
27,We encode the output sequence from left - to - right .,Introduction,Introduction,relation_extraction,0,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.72,26,0.1015625,18,0.72,1,1,model
28,"At each time step , we use an attention - like model on the previously decoded time steps , to identify the tokens in a specified relation with the current token .",Introduction,Introduction,relation_extraction,0,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",19,0.76,27,0.10546875,19,0.76,1,1,model
29,We also add an additional layer to our network to encode the output sequence from right - to - left and find significant improvement on the performance of relation identification using bi-directional encoding .,Introduction,Introduction,relation_extraction,0,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.8,28,0.109375,20,0.8,1,1,model
170,The model proposed by is a feature - based structured perceptron model with efficient beam - search .,Baselines and Previous Models,Baselines and Previous Models,relation_extraction,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.2,169,0.66015625,2,0.2,1,1,baselines
171,They employ a segment - based decoder instead of token - based decoding .,Baselines and Previous Models,Baselines and Previous Models,relation_extraction,0,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.3,170,0.6640625,3,0.3,1,1,baselines
173,"( SPTree ) recently proposed a LSTM - based model with a sequence layer for entity identification , and a tree - based dependency layer which identifies relations between pairs of candidate entities using the shortest dependency path between them .",Baselines and Previous Models,Baselines and Previous Models,relation_extraction,0,"['O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.5,172,0.671875,5,0.5,1,1,baselines
174,We also employed our previous approach for extraction of opinion entities and relations to this task .,Baselines and Previous Models,Baselines and Previous Models,relation_extraction,0,"['O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",6,0.6,173,0.67578125,6,0.6,1,1,baselines
180,We train our model using Adadelta with gradient clipping .,Hyperparameters and Training Details,Hyperparameters and Training Details,relation_extraction,0,"['O', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",1,0.06666666666666667,179,0.69921875,1,0.06666666666666667,1,1,hyperparameters
181,We regularize our network using dropout with the drop - out rate tuned using development set .,Hyperparameters and Training Details,Hyperparameters and Training Details,relation_extraction,0,"['O', 'B', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",2,0.13333333333333333,180,0.703125,2,0.13333333333333333,1,1,hyperparameters
186,We have 3 hidden layers in our network and the dimensionality of the hidden units is 100 .,Hyperparameters and Training Details,Hyperparameters and Training Details,relation_extraction,0,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",7,0.4666666666666667,185,0.72265625,7,0.4666666666666667,1,1,hyperparameters
187,All the weights in the network are initialized from small random uniform noise .,Hyperparameters and Training Details,Hyperparameters and Training Details,relation_extraction,0,"['O', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.5333333333333333,186,0.7265625,8,0.5333333333333333,1,1,hyperparameters
188,We tune our hyperparameters based on ACE05 development set and use them for training on ACE04 dataset .,Hyperparameters and Training Details,Hyperparameters and Training Details,relation_extraction,0,"['O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",9,0.6,187,0.73046875,9,0.6,1,1,hyperparameters
196,Multiple Relations,Results,,relation_extraction,0,"['O', 'O']","['O', 'O']","['O', 'O']",1,0.02127659574468085,195,0.76171875,1,0.07692307692307693,1,1,results
197,"We find that modifying our objective to include multiple relations improves the recall of our system on relations , leading to slight improvement on the over all performance on relations .",Results,Multiple Relations,relation_extraction,0,"['O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']",,,2,0.0425531914893617,196,0.765625,2,0.15384615384615385,1,1,results
201,"By adding bidirectional encoding to our system , we find that we can significantly improve the performance of our system compared to left - to - right encoding .",Results,Encoding,relation_extraction,0,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']",,,6,0.1276595744680851,200,0.78125,6,0.46153846153846156,1,1,results
202,It also improves precision compared to left - toright decoding combined with multiple relations objective .,Results,Encoding,relation_extraction,0,"['O', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",7,0.14893617021276595,201,0.78515625,7,0.5384615384615384,1,1,results
203,We find that for some relations it is easier to detect them with respect to one of the entities in the entity pair .,Results,Encoding,relation_extraction,0,"['O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",8,0.1702127659574468,202,0.7890625,8,0.6153846153846154,1,1,results
204,PHYS relation is easier identified with respect to GPE entity than PER entity .,Results,Encoding,relation_extraction,0,"['B', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",9,0.19148936170212766,203,0.79296875,9,0.6923076923076923,1,1,results
2,Simple BERT Models for Relation Extraction and Semantic Role Labeling,title,title,relation_extraction,1,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.011235955056179775,1,0.0,1,1,research-problem
10,Relation extraction and semantic role labeling ( SRL ) are two fundamental tasks in natural language understanding .,Introduction,Introduction,relation_extraction,1,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.058823529411764705,9,0.10112359550561797,1,0.0625,1,1,research-problem
14,"For SRL , the task is to extract the predicate - argument structure of a sentence , determining "" who did what to whom "" , "" when "" , "" where "" , etc .",Introduction,Introduction,relation_extraction,1,"['O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.29411764705882354,13,0.14606741573033707,5,0.3125,1,1,research-problem
24,We show that simple neural architectures built on top of BERT yields state - of - the - art performance on a variety of benchmark datasets for these two tasks .,Introduction,Introduction,relation_extraction,1,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",15,0.8823529411764706,23,0.25842696629213485,15,0.9375,1,1,model
64,We conduct experiments on two SRL tasks : and the predicate indicator embedding size is 10 .,Experimental Setup,Experimental Setup,relation_extraction,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",1,0.07692307692307693,63,0.7078651685393258,1,0.05555555555555555,1,1,hyperparameters
65,The learning rate is 5 10 ?5 . BERT base - cased and large - cased models are used in our experiments .,Experimental Setup,Experimental Setup,relation_extraction,1,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",2,0.15384615384615385,64,0.7191011235955056,2,0.1111111111111111,1,1,hyperparameters
66,The position embeddings are randomly initialized and fine - tuned during the training process .,Experimental Setup,Experimental Setup,relation_extraction,1,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",3,0.23076923076923078,65,0.7303370786516854,3,0.16666666666666666,1,1,hyperparameters
79,We see that the BERT - LSTM - large model achieves the state - of - the - art F 1 score among single models and outperforms the ensemble model on the CoNLL 2005 in - domain and out - of - domain tests .,Results,Results,relation_extraction,1,"['O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.5,78,0.8764044943820225,16,0.8888888888888888,1,1,results
80,"However , it falls short on the CoNLL 2012 benchmark because the model of obtains very high precision .",Results,Results,relation_extraction,1,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.75,79,0.8876404494382022,17,0.9444444444444444,1,1,results
2,Span - Level Model for Relation Extraction,title,,relation_extraction,10,"['O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.005208333333333333,1,0.0,1,1,research-problem
13,"This paper focuses on Relation Extraction ( RE ) , which is the task of entity mention detection and classifying the relations between each pair of those mentions .",Introduction,Introduction,relation_extraction,10,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.13333333333333333,12,0.0625,4,0.13333333333333333,1,1,research-problem
21,"Since , work on RE has revolved around end - to - end systems : single models which first perform entity mention detection and then relation extraction .",Introduction,Introduction,relation_extraction,10,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.4,20,0.10416666666666667,12,0.4,1,1,research-problem
36,We propose a simple bi - LSTM based model which generates span representations for each possible span .,Introduction,Introduction,relation_extraction,10,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",27,0.9,35,0.18229166666666666,27,0.9,1,1,model
37,The span representations are used to perform entity mention detection on all spans in parallel .,Introduction,Introduction,relation_extraction,10,"['O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",28,0.9333333333333333,36,0.1875,28,0.9333333333333333,1,1,model
38,The same span representations are then used to perform relation extraction on all pairs of detected entity mentions .,Introduction,Introduction,relation_extraction,10,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",29,0.9666666666666667,37,0.19270833333333334,29,0.9666666666666667,1,1,model
143,"The learned character embeddings are of size 8 . 1 - dimensional convolutions of window size 3 , 4,5 are applied per-token with 50 filters of each window size .",Experiments,Character Embeddings,relation_extraction,10,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.8571428571428571,142,0.7395833333333334,6,0.5,1,1,hyperparameters
146,Our stacked bi - LSTMs ( Section 3.1 ) has 3 layers with 200 - dimensional hidden states and highway connections .,Model Size,Model Size,relation_extraction,10,"['O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",1,0.07142857142857142,145,0.7552083333333334,9,0.75,1,1,hyperparameters
147,"All Multi Layer Perceptrons ( MLP ) has two hidden layers with 500 dimensions , each followed by ReLU activation .",Model Size,Model Size,relation_extraction,10,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",2,0.14285714285714285,146,0.7604166666666666,10,0.8333333333333334,1,1,hyperparameters
152,We only consider spans that are entirely within a sentence and limit spans to a max length of L = 10 .,Model Size,Span Pruning,relation_extraction,10,"['O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']",,,7,0.5,151,0.7864583333333334,2,0.2222222222222222,1,1,hyperparameters
155,"Regularization Dropout is applied with dropout rate 0.2 to all hidden layers of all MLPs and feature encodings , with dropout rate 0.5 to all word and character embeddings and with dropout rate 0.4 to all LSTM layer outputs .",Model Size,Span Pruning,relation_extraction,10,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']",,,10,0.7142857142857143,154,0.8020833333333334,5,0.5555555555555556,1,1,hyperparameters
156,"Learning Learning is done with Adam ( Kingma and Ba , 2015 ) with default parameters .",Model Size,Span Pruning,relation_extraction,10,"['B', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.7857142857142857,155,0.8072916666666666,6,0.6666666666666666,1,1,hyperparameters
157,The learning rate is annealed by 1 % every 100 iterations .,Model Size,Span Pruning,relation_extraction,10,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",12,0.8571428571428571,156,0.8125,7,0.7777777777777778,1,1,hyperparameters
158,Minibatch Size is 1 .,Model Size,Span Pruning,relation_extraction,10,"['B', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'B-p', 'B-ob', 'O']",13,0.9285714285714286,157,0.8177083333333334,8,0.8888888888888888,1,1,hyperparameters
159,Early Stopping of 20 evaluations on the dev set is used .,Model Size,Span Pruning,relation_extraction,10,"['B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O']",14,1.0,158,0.8229166666666666,9,1.0,1,1,hyperparameters
181,"Our proposed model achieves a new SOTA on RE with a F 1 of 62. 83 , more than 2.3 F 1 above the previous SOTA .",Model Complexity,Entity Mention Detection,relation_extraction,10,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.7777777777777778,180,0.9375,12,0.6666666666666666,1,1,results
182,Our proposed model also beats a multitask model which uses signals from additional tasks by more than 1.5 F 1 points .,Model Complexity,Entity Mention Detection,relation_extraction,10,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",22,0.8148148148148148,181,0.9427083333333334,13,0.7222222222222222,1,1,results
183,"For both tasks , our model 's Precision is close to and Recall is significantly higher than previous works .",Model Complexity,Entity Mention Detection,relation_extraction,10,"['B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'B-p', 'I-p', 'B-p', 'B-b', 'I-b', 'O']",23,0.8518518518518519,182,0.9479166666666666,14,0.7777777777777778,1,1,results
184,The Recall gains for RE ( 4.3 absolute points ) are much higher than for EMD ( 0.6 absolute points ) .,Model Complexity,Entity Mention Detection,relation_extraction,10,"['O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",24,0.8888888888888888,183,0.953125,15,0.8333333333333334,1,1,results
187,"Thus , our large gains in RE Recall ( and F 1 ) showcase the effectiveness of our simple modeling of ordered span pairs for relation extraction ( Section 3.3 ) .",Model Complexity,Entity Mention Detection,relation_extraction,10,"['O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",27,1.0,186,0.96875,18,1.0,1,1,results
2,RESIDE : Improving Distantly - Supervised Neural Relation Extraction using Side Information,title,title,relation_extraction,11,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",1,0.0,1,0.004032258064516129,1,0.0,1,1,research-problem
4,Distantly - supervised Relation Extraction ( RE ) methods train an extractor by automatically aligning relation instances in a Knowledge Base ( KB ) with unstructured text .,abstract,abstract,relation_extraction,11,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.125,3,0.012096774193548387,1,0.125,1,1,research-problem
6,RE models usually ignore such readily available side information .,abstract,abstract,relation_extraction,11,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.375,5,0.020161290322580645,3,0.375,1,1,research-problem
15,Relation Extraction ( RE ) attempts to fill this gap by extracting semantic relationships between entity pairs from plain text .,Introduction,Introduction,relation_extraction,11,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.09090909090909091,14,0.056451612903225805,3,0.09090909090909091,1,1,research-problem
39,"In this paper , we propose RESIDE , a novel distant supervised relation extraction method which utilizes additional supervision from KB through its neural network based architecture .",Introduction,Introduction,relation_extraction,11,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,0.8181818181818182,38,0.1532258064516129,27,0.8181818181818182,1,1,model
40,"RESIDE makes principled use of entity type and relation alias information from KBs , to impose soft constraints while predicting the relation .",Introduction,Introduction,relation_extraction,11,"['B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",28,0.8484848484848485,39,0.15725806451612903,28,0.8484848484848485,1,1,model
41,"It uses encoded syntactic information obtained from Graph Convolution Networks ( GCN ) , along with embedded side information , to improve neural relation extraction .",Introduction,Introduction,relation_extraction,11,"['O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",29,0.8787878787878788,40,0.16129032258064516,29,0.8787878787878788,1,1,model
45,RESIDE 's source code and datasets used in the paper are available at http://github.com / malllabiisc / RESIDE .,Introduction,Introduction,relation_extraction,11,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",33,1.0,44,0.1774193548387097,33,1.0,1,1,code
198,Mintz : Multi-class logistic regression model proposed by for distant supervision paradigm .,Baselines,Baselines,relation_extraction,11,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.25,197,0.7943548387096774,2,0.25,1,1,baselines
199,MultiR : Probabilistic graphical model for multi instance learning by MIMLRE :,Baselines,Baselines,relation_extraction,11,"['B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'O']","['B-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O']","['B-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'O']",3,0.375,198,0.7983870967741935,3,0.375,1,1,baselines
200,A graphical model which jointly models multiple instances and multiple labels .,Baselines,Baselines,relation_extraction,11,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.5,199,0.8024193548387096,4,0.5,1,1,baselines
201,More details in . PCNN : A CNN based relation extraction model by which uses piecewise max - pooling for sentence representation .,Baselines,Baselines,relation_extraction,11,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",5,0.625,200,0.8064516129032258,5,0.625,1,1,baselines
202,PCNN + ATT : A piecewise max - pooling over CNN based model which is used by to get sentence representation followed by attention over sentences .,Baselines,Baselines,relation_extraction,11,"['B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.75,201,0.8104838709677419,6,0.75,1,1,baselines
203,BGWA : Bi - GRU based relation extraction model with word and sentence level attention ) .,Baselines,Baselines,relation_extraction,11,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O']","['B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",7,0.875,202,0.8145161290322581,7,0.875,1,1,baselines
219,"Overall , we find that RESIDE achieves higher precision over the entire recall range on both the datasets .",Results,Performance Comparison,relation_extraction,11,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.6666666666666666,218,0.8790322580645161,4,0.4444444444444444,1,1,results
220,All the non-neural baselines could not perform well as the features used by them are mostly derived from NLP tools which can be erroneous .,Results,Performance Comparison,relation_extraction,11,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.7333333333333333,219,0.8830645161290323,5,0.5555555555555556,1,1,results
221,RESIDE outperforms PCNN + ATT and BGWA which indicates that incorporating side information helps in improving the performance of the model .,Results,Performance Comparison,relation_extraction,11,"['B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.8,220,0.8870967741935484,6,0.6666666666666666,1,1,results
222,The higher performance of BGWA and PCNN + ATT over PCNN shows that attention helps in distant supervised RE .,Results,Performance Comparison,relation_extraction,11,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",13,0.8666666666666667,221,0.8911290322580645,7,0.7777777777777778,1,1,results
230,The results validate that GCNs are effective at encoding syntactic information .,Ablation Results,Ablation Results,relation_extraction,11,"['O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",5,0.29411764705882354,229,0.9233870967741935,5,0.8333333333333334,1,1,ablation-analysis
231,"Further , the improvement from side information shows that it is complementary to the features extracted from text , thus validating the central thesis of this paper , that inducing side information leads to improved relation extraction .",Ablation Results,Ablation Results,relation_extraction,11,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.35294117647058826,230,0.9274193548387096,6,1.0,1,1,ablation-analysis
240,We find that the model performs best when aliases are provided by the KB itself .,Ablation Results,Effect of Relation Alias Side Information,relation_extraction,11,"['O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O']",15,0.8823529411764706,239,0.9637096774193549,8,0.8,1,1,ablation-analysis
241,"Overall , we find that RESIDE gives competitive performance even when very limited amount of relation alias information is available .",Ablation Results,Effect of Relation Alias Side Information,relation_extraction,11,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",16,0.9411764705882353,240,0.967741935483871,9,0.9,1,1,ablation-analysis
242,We observe that performance improves further with the availability of more alias information .,Ablation Results,Effect of Relation Alias Side Information,relation_extraction,11,"['O', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,1.0,241,0.9717741935483871,10,1.0,1,1,ablation-analysis
2,Attention Guided Graph Convolutional Networks for Relation Extraction,title,,relation_extraction,12,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.00303951367781155,1,0.0,1,1,research-problem
32,"In this paper , we propose the novel Attention Guided Graph Convolutional Networks ( AGGCNs ) , which operate directly on the full tree .",Introduction,Introduction,relation_extraction,12,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",16,0.0935672514619883,31,0.09422492401215805,16,0.41025641025641024,1,1,model
33,"Intuitively , we develop a "" soft pruning "" strategy that transforms the original dependency tree into a fully connected edgeweighted graph .",Introduction,Introduction,relation_extraction,12,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.09941520467836257,32,0.0972644376899696,17,0.4358974358974359,1,1,model
34,"These weights can be viewed as the strength of relatedness between nodes , which can be learned in an end - to - end fashion by using self - attention mechanism .",Introduction,Introduction,relation_extraction,12,"['O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.10526315789473684,33,0.10030395136778116,18,0.46153846153846156,1,1,model
41,we next introduce dense connections ) to the GCN model following .,Introduction,Introduction,relation_extraction,12,"['O', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O']",25,0.14619883040935672,40,0.12158054711246201,25,0.6410256410256411,1,1,model
42,"For GCNs , L layers will be needed in order to capture neighborhood information that is L hops away .",Introduction,Introduction,relation_extraction,12,"['B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['B-p', 'B-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",26,0.15204678362573099,41,0.12462006079027356,26,0.6666666666666666,1,1,model
45,"With the help of dense connections , we are able to train the AGGCN model with a large depth , allowing rich local and non-local dependency information to be captured .",Introduction,Introduction,relation_extraction,12,"['B', 'I', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",29,0.1695906432748538,44,0.1337386018237082,29,0.7435897435897436,1,1,model
49,Our code is available at https://github.com/Cartus / AGGCN_TACRED,Introduction,Introduction,relation_extraction,12,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",33,0.19298245614035087,48,0.1458966565349544,33,0.8461538461538461,1,1,code
174,"We choose the number of heads N for attention guided layer from { 1 , 2 , 3 , 4 } , the block number M from { 1 , 2 , 3 } , the number of sub - layers L in each densely connected layer from { 2 , 3 , 4 }.",Introduction,Setup,relation_extraction,12,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,158,0.9239766081871345,173,0.5258358662613982,3,0.1875,1,1,hyperparameters
176,Glo Ve vectors are used as the initialization for word embeddings .,Introduction,Setup,relation_extraction,12,"['B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",160,0.935672514619883,175,0.5319148936170213,5,0.3125,1,1,hyperparameters
182,"For cross - sentence n- ary relation extraction task , we consider three kinds of models as baselines :",Introduction,Setup,relation_extraction,12,"['B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",166,0.9707602339181286,181,0.5501519756838906,11,0.6875,1,1,baselines
183,"1 ) a feature - based classifier based on shortest dependency paths between all entity pairs , 2 ) Graph - structured LSTM methods , including Graph LSTM , bidirectional DAG LSTM ( Bidir DAG LSTM ) and Graph State LSTM ( GS GLSTM ) .",Introduction,Setup,relation_extraction,12,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",167,0.9766081871345029,182,0.5531914893617021,12,0.75,1,1,baselines
184,"These methods extend LSTM to encode graphs constructed from input sentences with dependency edges , 3 ) Graph convolutional networks ( GCN ) with pruned trees , 6 https://nlp.stanford.edu/projects/",Introduction,Setup,relation_extraction,12,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O']",168,0.9824561403508771,183,0.5562310030395137,13,0.8125,1,1,baselines
202,"For ternary relation extraction ( first two columns in ) , our AGGCN model achieves accuracies of 87.1 and 87.0 on instances within single sentence ( Single ) and on all instances ( Cross ) , respectively , which outperform all the baselines .",Model,Multi-class,relation_extraction,12,"['B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",14,0.45161290322580644,201,0.6109422492401215,11,0.39285714285714285,1,1,results
203,"More specifically , our AG - GCN model surpasses the state - of - the - art Graphstructured LSTM model ( GS GLSTM ) by 6.8 and 3.8 points for the Single and Cross settings , respectively .",Model,Multi-class,relation_extraction,12,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",15,0.4838709677419355,202,0.6139817629179332,12,0.42857142857142855,1,1,results
204,"Compared to GCN models , our model obtains 1.3 and 1.2 points higher than the best performing model with pruned tree ( K=1 ) .",Model,Multi-class,relation_extraction,12,"['B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.5161290322580645,203,0.6170212765957447,13,0.4642857142857143,1,1,results
205,"For binary relation extraction ( third and fourth columns in ) , AGGCN consistently outperforms GS GLSTM and GCN as well .",Model,Multi-class,relation_extraction,12,"['O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'O', 'O', 'O']",17,0.5483870967741935,204,0.6200607902735562,14,0.5,1,1,results
207,"AGGCN also performs better than GCNs , although its performance can be boosted via pruned trees .",Model,Multi-class,relation_extraction,12,"['B', 'O', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.6129032258064516,206,0.6261398176291794,16,0.5714285714285714,1,1,results
215,"However , our AGGCN model still obtains 8.0 and 5.7 points higher than the GS GLSTM model for ternary and binary relations , respectively .",Model,Multi-class,relation_extraction,12,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",27,0.8709677419354839,214,0.6504559270516718,24,0.8571428571428571,1,1,results
216,"We also notice that our AGGCN achieves a better test accuracy than all GCN models , which further demonstrates its ability to learn better representations from full trees .",Model,Multi-class,relation_extraction,12,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",28,0.9032258064516129,215,0.6534954407294833,25,0.8928571428571429,1,1,results
227,"Our C - AGGCN model achieves an F1 score of 68.2 , which outperforms the state - ofart C - GCN model by 1.8 points .",Model F1,C- AGGCN,relation_extraction,12,"['O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.5,226,0.6869300911854104,7,0.5384615384615384,1,1,results
228,"We also notice that AGGCN and C - AGGCN achieve better precision and recall scores than GCN and C - GCN , respectively .",Model F1,C- AGGCN,relation_extraction,12,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",8,0.5714285714285714,227,0.6899696048632219,8,0.6153846153846154,1,1,results
229,The performance gap between GCNs with pruned trees and AGGCNs with full trees empirically show that the AGGCN model is better at distinguishing relevant from irrelevant information for learning a better graph representation .,Model F1,C- AGGCN,relation_extraction,12,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.6428571428571429,228,0.6930091185410334,9,0.6923076923076923,1,1,results
230,We also evaluate our model on the SemEval dataset under the same settings as .,Model F1,C- AGGCN,relation_extraction,12,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.7142857142857143,229,0.6960486322188449,10,0.7692307692307693,1,1,results
233,"Our C - AGGCN model ( 85.7 ) consistently outperforms the C - GCN model ( 84.8 ) , showing the good generalizability .",Model F1,C- AGGCN,relation_extraction,12,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",13,0.9285714285714286,232,0.7051671732522796,13,1.0,1,1,results
238,We can observe that adding either attention guided layers or densely connected layers improves the performance of the model .,Ablation Study .,Ablation Study .,relation_extraction,12,"['O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O']",3,0.10344827586206896,237,0.7203647416413373,4,0.13333333333333333,1,1,ablation-analysis
240,We also notice that the feed - forward layer is effective in our model .,Ablation Study .,Ablation Study .,relation_extraction,12,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",5,0.1724137931034483,239,0.7264437689969605,6,0.2,1,1,ablation-analysis
241,"Without the feed - forward layer , the result drops to an F1 score of 67.8 .",Ablation Study .,Ablation Study .,relation_extraction,12,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.20689655172413793,240,0.729483282674772,7,0.23333333333333334,1,1,ablation-analysis
244,We can observe that all the C - AGGCN models with varied values of K are able to outperform the state - of - the - art C - GCN model ( reported in ) .,Ablation Study .,Performance with Pruned Trees .,relation_extraction,12,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",9,0.3103448275862069,243,0.7386018237082067,10,0.3333333333333333,1,1,ablation-analysis
247,"In addition , we notice that the performance of C - AGGCN with full trees outperforms all C - AGGCNs with pruned trees .",Ablation Study .,Performance with Pruned Trees .,relation_extraction,12,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.41379310344827586,246,0.7477203647416414,13,0.43333333333333335,1,1,ablation-analysis
252,"In general , C - AGGCN with full trees outperforms C - AGGCN with pruned trees and C - GCN against various sentence lengths .",Ablation Study .,Performance with Pruned Trees .,relation_extraction,12,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.5862068965517241,251,0.7629179331306991,18,0.6,1,1,ablation-analysis
254,"Moreover , the improvement achieved by C - AGGCN with pruned trees decays when the sentence length increases .",Ablation Study .,Performance with Pruned Trees .,relation_extraction,12,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-ob', 'O']",19,0.6551724137931034,253,0.7689969604863222,20,0.6666666666666666,1,1,ablation-analysis
257,This suggests that C - AGGCN can benefit more from larger graphs ( full tree ) .,Ablation Study .,Performance with Pruned Trees .,relation_extraction,12,"['O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",22,0.7586206896551724,256,0.7781155015197568,23,0.7666666666666667,1,1,ablation-analysis
261,C - AGGCN consistently outperforms C - GCN under the same amount of training data .,Ablation Study .,Performance against Training Data Size .,relation_extraction,12,"['B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",26,0.896551724137931,260,0.790273556231003,27,0.9,1,1,ablation-analysis
262,"When the size of training data increases , we can observe that the performance gap becomes more obvious .",Ablation Study .,Performance against Training Data Size .,relation_extraction,12,"['B', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",27,0.9310344827586207,261,0.7933130699088146,28,0.9333333333333333,1,1,ablation-analysis
263,"Particularly , using 80 % of the training data , the C - AGGCN model is able to achieve a F 1 score of 66.5 , higher than C - GCN trained on the whole dataset .",Ablation Study .,Performance against Training Data Size .,relation_extraction,12,"['O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']",,,28,0.9655172413793104,262,0.7963525835866262,29,0.9666666666666667,1,1,ablation-analysis
2,Matching the Blanks : Distributional Similarity for Relation Learning,title,,relation_extraction,13,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.004694835680751174,1,0.0,1,1,research-problem
11,Reading text to identify and extract relations between entities has been along standing goal in natural language processing .,Introduction,Introduction,relation_extraction,13,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.029411764705882353,10,0.046948356807511735,1,0.05,1,1,research-problem
12,Typically efforts in relation extraction fall into one of three groups .,Introduction,Introduction,relation_extraction,13,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.058823529411764705,11,0.051643192488262914,2,0.1,1,1,research-problem
19,"First , we study the ability of the Transformer neural network architecture to encode relations between entity pairs , and we identify a method of representation that outperforms previous work in supervised relation extraction .",Introduction,Introduction,relation_extraction,13,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.2647058823529412,18,0.08450704225352113,9,0.45,1,1,model
20,"Then , we present a method of training this relation representation without any supervision from a knowledge graph or human annotators by matching the blanks .",Introduction,Introduction,relation_extraction,13,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'O']",10,0.29411764705882354,19,0.0892018779342723,10,0.5,1,1,model
187,shows that the task agnostic BERT EM and BERT EM + MTB models outperform the previous published state of the art on FewRel task even when they have not seen any FewRel training data .,Experimental Evaluation,Experimental Evaluation,relation_extraction,13,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.32,186,0.8732394366197183,8,0.3333333333333333,1,1,results
188,"For BERT EM + MTB , the increase over 's supervised approach is very significant - 8.8 % on the 5 - way - 1 - shot task and 12.7 % on the 10 - way - 1 - shot task .",Experimental Evaluation,Experimental Evaluation,relation_extraction,13,"['B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,9,0.36,187,0.8779342723004695,9,0.375,1,1,results
189,"BERT EM + MTB also significantly outperforms BERT EM in this unsupervised setting , which is to be expected since there is no relation - specific loss during BERT EM 's training .",Experimental Evaluation,Experimental Evaluation,relation_extraction,13,"['B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.4,188,0.8826291079812206,10,0.4166666666666667,1,1,results
192,"When given access to all of the training data , BERT EM approaches BERT EM + MTB 's performance .",Experimental Evaluation,Experimental Evaluation,relation_extraction,13,"['O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.52,191,0.8967136150234741,13,0.5416666666666666,1,1,results
195,The results in show that MTB training could be used to significantly reduce effort in implementing an exemplar based relation extraction system .,Experimental Evaluation,Experimental Evaluation,relation_extraction,13,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.64,194,0.9107981220657277,16,0.6666666666666666,1,1,results
199,The additional MTB based training further increases F 1 scores for all tasks .,Experimental Evaluation,Experimental Evaluation,relation_extraction,13,"['O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",20,0.8,198,0.9295774647887324,20,0.8333333333333334,1,1,results
202,"For all tasks , we see that MTB based training is even more effective for low - resource cases , where there is a larger gap in performance between our BERT EM and BERT EM + MTB based classifiers .",Experimental Evaluation,Experimental Evaluation,relation_extraction,13,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",23,0.92,201,0.9436619718309859,23,0.9583333333333334,1,1,results
203,"This further supports our argument that training by matching the blanks can significantly reduce the amount of human input required to create relation extractors , and populate a knowledge base .",Experimental Evaluation,Experimental Evaluation,relation_extraction,13,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",24,0.96,202,0.9483568075117371,24,1.0,1,1,results
2,Enriching Pre-trained Language Model with Entity Information for Relation Classification,title,title,relation_extraction,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.007407407407407408,1,0.0,1,1,research-problem
25,"In this paper , we apply the pretrained BERT model for relation classification .",Introduction,Introduction,relation_extraction,2,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",14,0.6666666666666666,24,0.17777777777777778,14,0.6666666666666666,1,1,model
26,"We insert special tokens before and after the target entities before feeding the text to BERT for fine - tuning , in order to identify the locations of the two target entities and transfer the information into the BERT model .",Introduction,Introduction,relation_extraction,2,"['O', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",15,0.7142857142857143,25,0.18518518518518517,15,0.7142857142857143,1,1,model
27,We then locate the positions of the two target entities in the output embedding from BERT model .,Introduction,Introduction,relation_extraction,2,"['O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",16,0.7619047619047619,26,0.1925925925925926,16,0.7619047619047619,1,1,model
28,We use their embeddings as well as the sentence encoding ( embedding of the special first token in the setting of BERT ) as the input to a multi - layer neural network for classification .,Introduction,Introduction,relation_extraction,2,"['O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O']",17,0.8095238095238095,27,0.2,17,0.8095238095238095,1,1,model
95,We add dropout before each add - on layer .,Dataset and Evaluation Metric,Parameter Settings,relation_extraction,2,"['O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.7857142857142857,94,0.6962962962962963,2,0.18181818181818182,1,1,hyperparameters
96,"For the pre-trained BERT model , we use the uncased basic model .",Dataset and Evaluation Metric,Parameter Settings,relation_extraction,2,"['B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.8571428571428571,95,0.7037037037037037,3,0.2727272727272727,1,1,hyperparameters
100,"We compare our method , R - BERT , against results by multiple methods recently published for the SemEval - 2010 Task 8 dataset , including SVM , RNN , MVRNN , CNN + Softmax , FCM , CR - CNN , Attention - CNN , Entity Attention Bi-LSTM .",Methods,Methods,relation_extraction,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.2,99,0.7333333333333333,7,0.6363636363636364,1,1,baselines
103,We can see that R - BERT significantly beats all the baseline methods .,Methods,Methods,relation_extraction,2,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'B-ob', 'I-ob', 'O']",4,0.8,102,0.7555555555555555,10,0.9090909090909091,1,1,results
104,"The MACRO F1 value of R - BERT is 89. 25 , which is much better than the previous best solution on this dataset .",Methods,Methods,relation_extraction,2,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",5,1.0,103,0.762962962962963,11,1.0,1,1,results
124,We observe that the three methods all perform worse than R - BERT .,Effect of Model Components,Att-Pooling-CNN 88.0,relation_extraction,2,"['O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",18,0.75,123,0.9111111111111111,12,0.6666666666666666,1,1,ablation-analysis
125,"Of the methods , BERT - NO - SEP - NO - ENT performs worst , with its F1 8.16 absolute points worse than R - BERT .",Effect of Model Components,Att-Pooling-CNN 88.0,relation_extraction,2,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",19,0.7916666666666666,124,0.9185185185185185,13,0.7222222222222222,1,1,ablation-analysis
126,This ablation study demonstrates that both the special separate tokens and the hidden entity vectors make important contributions to our approach .,Effect of Model Components,Att-Pooling-CNN 88.0,relation_extraction,2,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",20,0.8333333333333334,125,0.9259259259259259,14,0.7777777777777778,1,1,ablation-analysis
128,BERT without special separate tokens can not locate the target entities and lose this key information .,Effect of Model Components,Att-Pooling-CNN 88.0,relation_extraction,2,"['B', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.9166666666666666,127,0.9407407407407408,16,0.8888888888888888,1,1,ablation-analysis
130,"On the other hand , incorporating the output of the target entity vectors further enriches the information and helps to make more accurate prediction .",Effect of Model Components,Att-Pooling-CNN 88.0,relation_extraction,2,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",24,1.0,129,0.9555555555555556,18,1.0,1,1,ablation-analysis
2,Extracting Multiple - Relations in One - Pass with Pre-Trained Transformers,title,title,relation_extraction,3,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.0072992700729927005,1,0.0,1,1,research-problem
4,The state - of - the - art solutions for extracting multiple entity - relations from an input paragraph always require a multiple - pass encoding on the input .,abstract,abstract,relation_extraction,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.021897810218978103,1,0.2,1,1,research-problem
5,"This paper proposes a new solution that can complete the multiple entityrelations extraction task with only one - pass encoding on the input corpus , and achieve a new state - of - the - art accuracy performance , as demonstrated in the ACE 2005 benchmark .",abstract,abstract,relation_extraction,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.4,4,0.029197080291970802,2,0.4,1,1,research-problem
10,Relation extraction ( RE ) aims to find the semantic relation between a pair of entity mentions from an input paragraph .,Introduction,Introduction,relation_extraction,3,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.09090909090909091,9,0.06569343065693431,1,0.09090909090909091,1,1,research-problem
12,One particular type of the RE task is multiplerelations extraction ( MRE ) that aims to recognize relations of multiple pairs of entity mentions from an input paragraph .,Introduction,Introduction,relation_extraction,3,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.2727272727272727,11,0.08029197080291971,3,0.2727272727272727,1,1,research-problem
13,"Because in real - world applications , whose input paragraphs dominantly contain multiple pairs of entities , an efficient and effective solution for MRE has more important and more practical implications .",Introduction,Introduction,relation_extraction,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.36363636363636365,12,0.08759124087591241,4,0.36363636363636365,1,1,research-problem
16,"This work presents a solution that can resolve the inefficient multiple - passes issue of existing solutions for MRE by encoding the input only once , which significantly increases the efficiency and scalability .",Introduction,Introduction,relation_extraction,3,"['O', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.6363636363636364,15,0.10948905109489052,7,0.6363636363636364,1,1,model
17,"Specifically , the proposed solution is built on top of the existing transformer - based , pretrained general - purposed language encoders .",Introduction,Introduction,relation_extraction,3,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.7272727272727273,16,0.11678832116788321,8,0.7272727272727273,1,1,model
18,"In this paper we use Bidirectional Encoder Representations from Transformers ( BERT ) as the transformer - based encoder , but this solution is not limited to using BERT alone .",Introduction,Introduction,relation_extraction,3,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.8181818181818182,17,0.12408759124087591,9,0.8181818181818182,1,1,model
19,The two novel modifications to the original BERT architecture are : ( 1 ) we introduce a structured prediction layer for predicting multiple relations for different entity pairs ; and ( 2 ) we make the selfattention layers aware of the positions of all en-tities in the input paragraph .,Introduction,Introduction,relation_extraction,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",10,0.9090909090909091,18,0.13138686131386862,10,0.9090909090909091,1,1,model
77,"BERT SP : BERT with structured prediction only , which includes proposed improvement in 3.1 .",Methods,Methods,relation_extraction,3,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.25,76,0.5547445255474452,2,0.25,1,1,baselines
78,"Entity - Aware BERT SP : our full model , which includes both improvements in 3.1 and 3.2 .",Methods,Methods,relation_extraction,3,"['B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.375,77,0.5620437956204379,3,0.375,1,1,baselines
79,BERT SP with position embedding on the final attention layer .,Methods,Methods,relation_extraction,3,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",4,0.5,78,0.5693430656934306,4,0.5,1,1,baselines
80,This is a more straightforward way to achieve MRE in one - pass derived from previous works using position embeddings .,Methods,Methods,relation_extraction,3,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O']",,,5,0.625,79,0.5766423357664233,5,0.625,1,1,baselines
83,"BERT SP with entity indicators on input layer : it replaces our structured attention layer , and adds indicators of entities ( transformed to embeddings )",Methods,Methods,relation_extraction,3,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",8,1.0,82,0.5985401459854015,8,1.0,1,1,baselines
86,The first observation is that our model architecture achieves much better results compared to the previous state - of - the - art methods .,Results on ACE 2005,Results on ACE 2005,relation_extraction,3,"['O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.10526315789473684,85,0.6204379562043796,2,0.08,1,1,results
87,"Note that our method was not designed for domain adaptation , it still outperforms those methods with domain adaptation .",Results on ACE 2005,Results on ACE 2005,relation_extraction,3,"['B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']",,,3,0.15789473684210525,86,0.6277372262773723,3,0.12,1,1,results
89,"Among all the BERT - based approaches , finetuning the off - the - shelf BERT does not give a satisfying result , because the sentence embeddings can not distinguish different entity pairs .",Results on ACE 2005,This result further demonstrates its effectiveness .,relation_extraction,3,"['B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.2631578947368421,88,0.6423357664233577,5,0.2,1,1,results
90,"The simpler version of our approach , BERT SP , can successfully adapt the pre-trained BERT to the MRE task , and achieves comparable performance at the 3 Note the usage of relative position embeddings does notwork for one - pass MRE , since each word corresponds to a varying number of position embedding vectors .",Results on ACE 2005,This result further demonstrates its effectiveness .,relation_extraction,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.3157894736842105,89,0.6496350364963503,6,0.24,1,1,results
92,"It works for the singlerelation per pass setting , but the performance lags behind using only indicators of the two target entities .",Results on ACE 2005,Summing up the vectors confuses this information .,relation_extraction,3,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.42105263157894735,91,0.6642335766423357,8,0.32,1,1,results
94,"Our full model , with the structured fine - tuning of attention layers , brings further improvement of about 5.5 % , in the MRE one - pass setting , and achieves a new state - of - the - art performance when compared to the methods with domain adaptation .",Results on ACE 2005,Summing up the vectors confuses this information .,relation_extraction,3,"['B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']",,,10,0.5263157894736842,93,0.6788321167883211,10,0.4,1,1,results
99,"For BERT SP with entity indicators on inputs , it is expected to perform slightly better in the single - relation setting , because of the mixture of information from multiple pairs .",Results on ACE 2005,Summing up the vectors confuses this information .,relation_extraction,3,"['B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.7894736842105263,98,0.7153284671532847,15,0.6,1,1,results
100,A 2 % gap is observed as expected .,Results on ACE 2005,,relation_extraction,3,"['O', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'O', 'O']",16,0.8421052631578947,99,0.7226277372262774,16,0.64,1,1,results
103,"For BERT SP with position embeddings on the final attention layer , we train the model in the single - relation setting and test with two different settings , so the results are the same .",Results on ACE 2005,A 2 % gap is observed as expected .,relation_extraction,3,"['O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O']",19,1.0,102,0.7445255474452555,19,0.76,1,1,results
117,"Our Entity - Aware BERT SP gives comparable results to the top - ranked system in the shared task , with slightly lower Macro - F1 , which is the official metric of the task , and slightly higher Micro - F1 .",Results on SemEval 2018,Task 7,relation_extraction,3,"['B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.42857142857142855,116,0.8467153284671532,7,0.5384615384615384,1,1,results
118,"When predicting multiple relations in one - pass , we have 0.9 % drop on Macro - F1 , but a further 0.8 % improvement on Micro - F1 .",Results on SemEval 2018,Task 7,relation_extraction,3,"['B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']",,,4,0.5714285714285714,117,0.8540145985401459,8,0.6153846153846154,1,1,results
120,"On the other hand , compared to the top singlemodel result , which makes use of additional word and entity embeddings pretrained on in - domain data , our methods demonstrate clear advantage as a single model .",Results on SemEval 2018,Task 7,relation_extraction,3,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",6,0.8571428571428571,119,0.8686131386861314,10,0.7692307692307693,1,1,results
5,"However , the ability to populate knowledge bases with facts automatically extracted from documents has improved frustratingly slowly .",abstract,abstract,relation_extraction,4,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.2857142857142857,4,0.01932367149758454,2,0.2857142857142857,1,1,research-problem
12,A basic but highly important challenge in natural language understanding is being able to populate a knowledge base with relational facts contained in a piece of text .,Introduction,Introduction,relation_extraction,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.012345679012345678,11,0.05314009661835749,1,0.08333333333333333,1,1,research-problem
21,"Existing work on relation extraction ( e.g. , has been unable to achieve sufficient recall or precision for the results to be usable versus hand - constructed knowledge bases .",Introduction,Introduction,relation_extraction,4,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.12345679012345678,20,0.0966183574879227,10,0.8333333333333334,1,1,research-problem
30,"We propose a new , effective neural network sequence model for relation classification .",Introduction,This work addresses both of these problems .,relation_extraction,4,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",19,0.2345679012345679,29,0.14009661835748793,6,0.13636363636363635,1,1,model
31,Its architecture is better customized for the slot filling task : the word representations are augmented by extra distributed representations of word position relative to the subject and object of the putative relation .,Introduction,This work addresses both of these problems .,relation_extraction,4,"['O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",20,0.24691358024691357,30,0.14492753623188406,7,0.1590909090909091,1,1,model
32,This means that the neural attention model can effectively exploit the combination of semantic similarity - based attention and positionbased attention .,Introduction,This work addresses both of these problems .,relation_extraction,4,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",21,0.25925925925925924,31,0.1497584541062802,8,0.18181818181818182,1,1,model
33,"Secondly , we markedly improve the availability of supervised training data by using Mechanical Turk crowd annotation to produce a large supervised training dataset , suitable for the common relations between people , organizations and locations which are used in the TAC KBP evaluations .",Introduction,This work addresses both of these problems .,relation_extraction,4,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",22,0.2716049382716049,32,0.15458937198067632,9,0.20454545454545456,1,1,dataset
34,"We name this dataset the TAC Relation Extraction Dataset ( TACRED ) , and will make it available through the Linguistic Data Consortium ( LDC ) in order to respect copyrights on the underlying text .",Introduction,This work addresses both of these problems .,relation_extraction,4,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",23,0.2839506172839506,33,0.15942028985507245,10,0.22727272727272727,1,1,dataset
120,We map words that occur less than 2 times in the training set to a special < UNK > token .,Implementation Details,Implementation Details,relation_extraction,4,"['O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.06666666666666667,119,0.5748792270531401,1,0.06666666666666667,1,1,hyperparameters
121,We use the pre-trained GloVe vectors to initialize word embeddings .,Implementation Details,Implementation Details,relation_extraction,4,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",2,0.13333333333333333,120,0.5797101449275363,2,0.13333333333333333,1,1,hyperparameters
122,"For all the LSTM layers , we find that 2 - layer stacked LSTMs generally work better than one - layer LSTMs .",Implementation Details,Implementation Details,relation_extraction,4,"['B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.2,121,0.5845410628019324,3,0.2,1,1,hyperparameters
123,We minimize cross - entropy loss over all 42 relations using AdaGrad .,Implementation Details,Implementation Details,relation_extraction,4,"['O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'O']",4,0.26666666666666666,122,0.5893719806763285,4,0.26666666666666666,1,1,hyperparameters
124,We apply Dropout with p = 0.5 to CNNs and LSTMs .,Implementation Details,Implementation Details,relation_extraction,4,"['O', 'B', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",5,0.3333333333333333,123,0.5942028985507246,5,0.3333333333333333,1,1,hyperparameters
125,During training we also find a word dropout strategy to be very effective : we randomly set a token to be < UNK > with a probability p.,Implementation Details,Implementation Details,relation_extraction,4,"['B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'O', 'O']",,,6,0.4,124,0.5990338164251208,6,0.4,1,1,hyperparameters
126,We set p to be 0.06 for the SDP - LSTM model and 0.04 for all other models .,Implementation Details,Implementation Details,relation_extraction,4,"['O', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'O']",,,7,0.4666666666666667,125,0.6038647342995169,7,0.4666666666666667,1,1,hyperparameters
141,"We observe that all neural models achieve higher F 1 scores than the logistic regression and patterns systems , which demonstrates the effectiveness of neural models for relation extraction .",Evaluation on TACRED,We first evaluate all models on TACRED .,relation_extraction,4,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",6,0.20689655172413793,140,0.6763285024154589,6,0.5,1,1,results
142,"Although positional embeddings help increase the F 1 by around 2 % over the plain CNN model , a simple ( 2 - layer ) LSTM model performs surprisingly better than CNN and dependency - based models .",Evaluation on TACRED,We first evaluate all models on TACRED .,relation_extraction,4,"['O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.2413793103448276,141,0.6811594202898551,7,0.5833333333333334,1,1,results
143,"Lastly , our proposed position - aware mechanism is very effective and achieves an F 1 score of 65.4 % , with an absolute increase of 3.9 % over the best baseline neural model ( LSTM ) and 7.9 % over the baseline logistic regression system .",Evaluation on TACRED,We first evaluate all models on TACRED .,relation_extraction,4,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']",,,8,0.27586206896551724,142,0.6859903381642513,8,0.6666666666666666,1,1,results
144,We also run an ensemble of our position - aware attention model which takes majority votes from 5 runs with random initializations and it further pushes the F 1 score up by 1.6 % .,Evaluation on TACRED,We first evaluate all models on TACRED .,relation_extraction,4,"['O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",9,0.3103448275862069,143,0.6908212560386473,9,0.75,1,1,results
146,CNN - based models tend to have higher precision ; RNN - based models have better recall .,Evaluation on TACRED,We first evaluate all models on TACRED .,relation_extraction,4,"['B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.3793103448275862,145,0.7004830917874396,11,0.9166666666666666,1,1,results
156,"Evaluating relation extraction systems on slot filling is particularly challenging in that : ( 1 ) Endto - end cold start slot filling scores conflate the performance of all modules in the system ( i.e. , entity recognizer , entity linker and relation extractor ) .",Evaluation on TACRED,We first evaluate all models on TACRED .,relation_extraction,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",21,0.7241379310344828,155,0.748792270531401,8,0.5333333333333333,1,1,results
157,( 2 ) Errors in hop - 0 predictions can easily propagate to hop - 1 predictions .,Evaluation on TACRED,We first evaluate all models on TACRED .,relation_extraction,4,"['O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",22,0.7586206896551724,156,0.7536231884057971,9,0.6,1,1,results
163,"We find that : ( 1 ) by only training our logistic regression model on TACRED ( in contrast to on the 2 million bootstrapped examples used in the 2015 Stanford system ) and combining it with patterns , we obtain a higher hop - 0 F 1 score than the 2015 Stanford sys -",Evaluation on TACRED,We first evaluate all models on TACRED .,relation_extraction,4,"['O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",28,0.9655172413793104,162,0.782608695652174,15,1.0,1,1,results
166,presents the results of an ablation test of our position - aware attention model on the development set of TACRED .,Model ablation .,Model ablation .,relation_extraction,4,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.05263157894736842,165,0.7971014492753623,2,0.1,1,1,ablation-analysis
167,"The entire attention mechanism contributes about 1.5 % F 1 , where the position - aware term in Eq.",Model ablation .,Model ablation .,relation_extraction,4,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O']",2,0.10526315789473684,166,0.8019323671497585,3,0.15,1,1,ablation-analysis
168,( 3 ) alone contributes about 1 % F 1 score .,Model ablation .,Model ablation .,relation_extraction,4,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']",,,3,0.15789473684210525,167,0.8067632850241546,4,0.2,1,1,ablation-analysis
170,"shows how the slot filling evaluation scores change as we change the amount of negative ( i.e. , no relation ) training data provided to our proposed model .",Model ablation .,Impact of negative examples .,relation_extraction,4,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-n', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-b', 'B-p', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",5,0.2631578947368421,169,0.8164251207729468,6,0.3,1,1,ablation-analysis
171,"We find that : ( 1 ) At hop - 0 level , precision increases as we provide more negative examples , while recall stays almost unchanged .",Model ablation .,Impact of negative examples .,relation_extraction,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",6,0.3157894736842105,170,0.821256038647343,7,0.35,1,1,ablation-analysis
172,F 1 score keeps increasing .,Model ablation .,,relation_extraction,4,"['B', 'I', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",7,0.3684210526315789,171,0.8260869565217391,8,0.4,1,1,ablation-analysis
173,"( 2 ) At hop - all level , F 1 score increases by Performance by sentence length .",Model ablation .,F 1 score keeps increasing .,relation_extraction,4,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.42105263157894735,172,0.8309178743961353,9,0.45,1,1,ablation-analysis
175,We find that : ( 1 ) Performance of all models degrades substantially as the sentences get longer .,Model ablation .,F 1 score keeps increasing .,relation_extraction,4,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'O']","['O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O']",10,0.5263157894736842,174,0.8405797101449275,11,0.55,1,1,ablation-analysis
178,"When compared with the CNN - PE model , our position - aware attention model achieves improved F 1 scores on 30 out of the 41 slot types , with the top 5 slot types being org : members , per: country of death , org : shareholders , per:children and per:religion .",Model ablation .,Improvement by slot types .,relation_extraction,4,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'B-ob', 'O']",13,0.6842105263157895,177,0.855072463768116,14,0.7,1,1,ablation-analysis
179,"When compared with SDP - LSTM model , our model achieves improved F 1 scores on 26 out of the 41 slot types , with the top 5 slot types being org : political / religious affiliation , per: country of death , org : alternate names , per:religion and per: alternate names .",Model ablation .,Improvement by slot types .,relation_extraction,4,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",14,0.7368421052631579,178,0.8599033816425121,15,0.75,1,1,ablation-analysis
180,We observe that slot types with relatively sparse training examples tend to be improved by using the position - aware attention model .,Model ablation .,Improvement by slot types .,relation_extraction,4,"['O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.7894736842105263,179,0.8647342995169082,16,0.8,1,1,ablation-analysis
183,"We find that the model learns to pay more attention to words that are informative for the relation ( e.g. , "" graduated from "" , "" niece "" and "" chairman "" ) , though it still makes mistakes ( e.g. , "" refused to name the three "" ) .",Model ablation .,Attention visualization .,relation_extraction,4,"['O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.9473684210526315,182,0.8792270531400966,19,0.95,1,1,ablation-analysis
184,"We also observe that the model tends to put a lot of weight onto object entities , as the object NER signatures are very informative to the classification of relations .",Model ablation .,Attention visualization .,relation_extraction,4,"['O', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,1.0,183,0.8840579710144928,20,1.0,1,1,ablation-analysis
2,Graph Convolution over Pruned Dependency Trees Improves Relation Extraction,title,,relation_extraction,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.0038022813688212928,1,0.0,1,1,research-problem
28,"In this work , we propose a novel extension of the graph convolutional network ) that is tailored for relation extraction .",Introduction,Introduction,relation_extraction,5,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",16,0.6956521739130435,27,0.10266159695817491,16,0.6956521739130435,1,1,model
29,"Our model encodes the dependency structure over the input sentence with efficient graph convolution operations , then extracts entity - centric representations to make robust relation predictions .",Introduction,Introduction,relation_extraction,5,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.7391304347826086,28,0.10646387832699619,17,0.7391304347826086,1,1,model
30,"We also apply a novel path - centric pruning technique to remove irrelevant information from the tree while maximally keeping relevant content , which further improves the performance of several dependencybased models including ours .",Introduction,Introduction,relation_extraction,5,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.782608695652174,29,0.11026615969581749,18,0.782608695652174,1,1,model
124,Dependency - based models .,Baseline Models,Baseline Models,relation_extraction,5,"['B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O']",2,0.15384615384615385,123,0.467680608365019,2,0.15384615384615385,1,1,baselines
126,( 1 ) A logistic regression ( LR ) classifier which combines dependencybased features with other lexical features .,Baseline Models,Baseline Models,relation_extraction,5,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.3076923076923077,125,0.4752851711026616,4,0.3076923076923077,1,1,baselines
127,"( 2 ) Shortest Dependency Path LSTM ( SDP - LSTM ) , which applies a neural sequence model on the shortest path between the subject and object entities in the dependency tree .",Baseline Models,Baseline Models,relation_extraction,5,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.38461538461538464,126,0.4790874524714829,5,0.38461538461538464,1,1,baselines
128,"Tree - LSTM , which is a recursive model that generalizes the LSTM to arbitrary tree structures .",Baseline Models,Baseline Models,relation_extraction,5,"['B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.46153846153846156,127,0.4828897338403042,6,0.46153846153846156,1,1,baselines
132,Neural sequence model .,Baseline Models,Baseline Models,relation_extraction,5,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",10,0.7692307692307693,131,0.49809885931558934,10,0.7692307692307693,1,1,baselines
133,"Our group presented a competitive sequence model that employs a position - aware attention mechanism over LSTM outputs ( PA - LSTM ) , and showed that it outperforms several CNN and dependency - based models by a substantial margin .",Baseline Models,Baseline Models,relation_extraction,5,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.8461538461538461,132,0.5019011406844106,11,0.8461538461538461,1,1,baselines
149,Results on the TACRED Dataset,Experimental Setup,,relation_extraction,5,"['O', 'B', 'O', 'B', 'I']","['O', 'B-p', 'O', 'B-n', 'I-n']","['O', 'B-p', 'O', 'B-b', 'I-b']",13,0.30952380952380953,148,0.5627376425855514,0,0.0,1,1,results
151,We observe that our GCN model Our Model ( C - GCN ) 84.8 * 76.5 * outperforms all dependency - based models by at least 1.6 F 1 .,Experimental Setup,Results on the TACRED Dataset,relation_extraction,5,"['O', 'B', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.35714285714285715,150,0.5703422053231939,2,0.15384615384615385,1,1,results
152,"By using contextualized word representations , the C - GCN model further outperforms the strong PA - LSTM model by 1.3 F 1 , and achieves a new state of the art .",Experimental Setup,Results on the TACRED Dataset,relation_extraction,5,"['O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.38095238095238093,151,0.5741444866920152,3,0.23076923076923078,1,1,results
153,"In addition , we find our model improves upon other dependencybased models in both precision and recall .",Experimental Setup,Results on the TACRED Dataset,relation_extraction,5,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.40476190476190477,152,0.5779467680608364,4,0.3076923076923077,1,1,results
154,"Comparing the C - GCN model with the GCN model , we find that the gain mainly comes from improved recall .",Experimental Setup,Results on the TACRED Dataset,relation_extraction,5,"['B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",18,0.42857142857142855,153,0.5817490494296578,5,0.38461538461538464,1,1,results
156,"As we will show in Section 6.2 , we find that our GCN models have complementary strengths when compared to the PA - LSTM .",Experimental Setup,Results on the TACRED Dataset,relation_extraction,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",20,0.47619047619047616,155,0.5893536121673004,7,0.5384615384615384,1,1,results
161,"This simple interpolation between a GCN and a PA - LSTM achieves an F 1 score of 67.1 , outperforming each model alone by at least 2.0 F 1 .",Experimental Setup,Results on the TACRED Dataset,relation_extraction,5,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",25,0.5952380952380952,160,0.6083650190114068,12,0.9230769230769231,1,1,results
162,An interpolation between a C - GCN and a PA - LSTM further improves the result to 68.2 .,Experimental Setup,Results on the TACRED Dataset,relation_extraction,5,"['O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'O']","['O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'O']",26,0.6190476190476191,161,0.6121673003802282,13,1.0,1,1,results
163,Results on the SemEval Dataset,Experimental Setup,,relation_extraction,5,"['O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'B-b', 'I-b']",27,0.6428571428571429,162,0.6159695817490495,0,0.0,1,1,results
165,"We find that under the conventional with- entity evaluation , our C - GCN model outperforms all existing dependency - based neural models on this sep - arate dataset .",Experimental Setup,Results on the SemEval Dataset,relation_extraction,5,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",29,0.6904761904761905,164,0.623574144486692,2,0.14285714285714285,1,1,results
166,"Notably , by properly incorporating off - path information , our model outperforms the previous shortest dependency path - based model ( SDP - LSTM ) .",Experimental Setup,Results on the SemEval Dataset,relation_extraction,5,"['O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",30,0.7142857142857143,165,0.6273764258555133,3,0.21428571428571427,1,1,results
167,"Under the mask - entity evaluation , our C - GCN model also outperforms PA - LSTM by a substantial margin , suggesting its generalizability even when entities are not seen .",Experimental Setup,Results on the SemEval Dataset,relation_extraction,5,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",31,0.7380952380952381,166,0.6311787072243346,4,0.2857142857142857,1,1,results
170,"To show the effectiveness of path - centric pruning , we compare the two GCN models and the Tree - LSTM when the pruning distance K is varied .",Experimental Setup,Pruning,relation_extraction,5,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",34,0.8095238095238095,169,0.6425855513307985,7,0.5,1,1,results
172,"As shown in , the performance of all three models peaks when K = 1 , outperforming their respective dependency path - based counterpart ( K = 0 ) .",Experimental Setup,Pruning,relation_extraction,5,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",36,0.8571428571428571,171,0.6501901140684411,9,0.6428571428571429,1,1,results
176,"We find that all three models are less effective when the entire dependency tree is present , indicating that including extra information hurts performance .",Experimental Setup,Pruning,relation_extraction,5,"['O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",40,0.9523809523809523,175,0.6653992395437263,13,0.9285714285714286,1,1,results
177,"Finally , we note that contextualizing the GCN makes it less sensitive to changes in the tree structures provided , presumably because the model can use word sequence information in the LSTM layer to recover any off - path information that it needs for correct relation extraction .",Experimental Setup,Pruning,relation_extraction,5,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",41,0.9761904761904762,176,0.6692015209125475,14,1.0,1,1,results
181,We find that : The entity representations and feedforward layers contribute 1.0 F 1 .,Ablation Study,Ablation Study,relation_extraction,5,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.10526315789473684,180,0.6844106463878327,2,0.10526315789473684,1,1,ablation-analysis
182,"( 2 ) When we remove the dependency structure ( i.e. , setting to I ) , the score drops by 3.2 F 1 .",Ablation Study,Ablation Study,relation_extraction,5,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.15789473684210525,181,0.688212927756654,3,0.15789473684210525,1,1,ablation-analysis
183,"( 3 ) F 1 drops by 10.3 when we remove the feedforward layers , the LSTM component and the dependency structure altogether .",Ablation Study,Ablation Study,relation_extraction,5,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O']",4,0.21052631578947367,182,0.6920152091254753,4,0.21052631578947367,1,1,ablation-analysis
184,"( 4 ) Removing the pruning ( i.e. , using full trees as input ) further hurts the result by another 9.7 F 1 .",Ablation Study,Ablation Study,relation_extraction,5,"['O', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",5,0.2631578947368421,183,0.6958174904942965,5,0.2631578947368421,1,1,ablation-analysis
2,Context - Aware Representations for Knowledge Base Relation Extraction,title,title,relation_extraction,6,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.007692307692307693,1,0.0,1,1,research-problem
4,We demonstrate that for sentence - level relation extraction it is beneficial to consider other relations in the sentential context while predicting the target relation .,abstract,abstract,relation_extraction,6,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.023076923076923078,1,0.14285714285714285,1,1,research-problem
12,The main goal of relation extraction is to determine a type of relation between two target entities that appear together in a text .,Introduction,Introduction,relation_extraction,6,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.06666666666666667,11,0.08461538461538462,1,0.06666666666666667,1,1,research-problem
13,"In this paper , we consider the sentential relation extraction task : to each occurrence of the target entity pair e 1 , e 2 in some sentence s one has to assign a relation type r from a given set R. A triple e 1 , r , e 2 is called a relation instance and we refer to the relation of the target entity pair as target relation .",Introduction,Introduction,relation_extraction,6,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.13333333333333333,12,0.09230769230769231,2,0.13333333333333333,1,1,research-problem
20,We present a novel architecture that considers other relations in the sentence as a context for predicting the label of the target relation .,Introduction,Introduction,relation_extraction,6,"['O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'O', 'B-ob', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",9,0.6,19,0.14615384615384616,9,0.6,1,1,model
22,Our architecture uses an LSTM - based encoder to jointly learn representations for all relations in a single sentence .,Introduction,Introduction,relation_extraction,6,"['O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",11,0.7333333333333333,21,0.16153846153846155,11,0.7333333333333333,1,1,model
23,The representation of the target relation and representations of the context relations are combined to make the final prediction .,Introduction,Introduction,relation_extraction,6,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",12,0.8,22,0.16923076923076924,12,0.8,1,1,model
99,All models were trained using the Adam optimizer with categorical crossentropy as the loss function .,Training the models,Training the models,relation_extraction,6,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",1,0.16666666666666666,98,0.7538461538461538,1,0.038461538461538464,1,1,hyperparameters
100,We use an early stopping criterion on the validation data to determine the number of training epochs .,Training the models,Training the models,relation_extraction,6,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.3333333333333333,99,0.7615384615384615,2,0.07692307692307693,1,1,hyperparameters
101,"The learning rate is fixed to 0.01 and the rest of the optimization parameters are set as recommended in : ? 1 = 0.9 , ? 2 = 0.999 , ? = 1e ? 08 . The training is performed in batches of 128 instances .",Training the models,Training the models,relation_extraction,6,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-ob', 'I-ob', 'O']",3,0.5,100,0.7692307692307693,3,0.11538461538461539,1,1,hyperparameters
102,We apply Dropout on the penultimate layer as well as on the embeddings layer with a probability of 0.5 .,Training the models,Training the models,relation_extraction,6,"['O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O']",4,0.6666666666666666,101,0.7769230769230769,4,0.15384615384615385,1,1,hyperparameters
103,We choose the size of the layers ( RNN layer size o = 256 ) and entity marker embeddings ( d = 3 ) with a random search on the validation set .,Training the models,Training the models,relation_extraction,6,"['O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.8333333333333334,102,0.7846153846153846,5,0.19230769230769232,1,1,hyperparameters
113,"The models that take the context into account perform similar to the baselines at the smallest recall numbers , but start to positively deviate from them at higher recall rates .",Held - out evaluation,Held - out evaluation,relation_extraction,6,"['O', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'O']",,,8,0.42105263157894735,112,0.8615384615384616,15,0.5769230769230769,1,1,results
114,"In particular , the ContextAtt model performs better than any other system in our study over the entire recall range .",Held - out evaluation,Held - out evaluation,relation_extraction,6,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.47368421052631576,113,0.8692307692307693,16,0.6153846153846154,1,1,results
115,"Compared to the competitive LSTM - baseline that uses the same relation encoder , the ContextAtt model achieves a 24 % reduction of the average error : from 0.2096 0.002 to 0.1590 0.002 .",Held - out evaluation,Held - out evaluation,relation_extraction,6,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.5263157894736842,114,0.8769230769230769,17,0.6538461538461539,1,1,results
118,shows that the ContextAtt model performs best over all relation types .,Held - out evaluation,Held - out evaluation,relation_extraction,6,"['B', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",13,0.6842105263157895,117,0.9,20,0.7692307692307693,1,1,results
119,One can also see that the ContextSum does n't universally outperforms the LSTM - baseline .,Held - out evaluation,Held - out evaluation,relation_extraction,6,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",14,0.7368421052631579,118,0.9076923076923077,21,0.8076923076923077,1,1,results
120,It demonstrates again that using attention is crucial to extract relevant information from the context relations .,Held - out evaluation,Held - out evaluation,relation_extraction,6,"['O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",15,0.7894736842105263,119,0.9153846153846154,22,0.8461538461538461,1,1,results
121,"On the relation - specific results we observe that the context - enabled model demonstrates the most improvement on precision and seems to be especially useful for taxonomy relations ( see SUBCLASS OF , PART OF ) .",Held - out evaluation,Held - out evaluation,relation_extraction,6,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.8421052631578947,120,0.9230769230769231,23,0.8846153846153846,1,1,results
2,Neural Relation Extraction via Inner - Sentence Noise Reduction and Transfer Learning,title,title,relation_extraction,7,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.003861003861003861,1,0.0,1,1,research-problem
13,Relation extraction aims to extract relations between pairs of marked entities in raw texts .,Introduction,Introduction,relation_extraction,7,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.030303030303030304,12,0.04633204633204633,1,0.030303030303030304,1,1,research-problem
36,"In this paper , we propose a novel word - level approach for distant supervised relation extraction by reducing inner-sentence noise and improving robustness against noisy words .",Introduction,Introduction,relation_extraction,7,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",24,0.7272727272727273,35,0.13513513513513514,24,0.7272727272727273,1,1,research-problem
37,"To reduce innersentence noise , we utilize a novel Sub - Tree Parse ( STP ) method to remove irrelevant words by intercepting a subtree under the parent of entities ' lowest common ancestor .",Introduction,Introduction,relation_extraction,7,"['B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",25,0.7575757575757576,36,0.138996138996139,25,0.7575757575757576,1,1,approach
39,"Furthermore , the entity - wise attention is adopted to alleviate the influence of noisy words in the subtree and emphasize the task - relevant features .",Introduction,Introduction,relation_extraction,7,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,0.8181818181818182,38,0.14671814671814673,27,0.8181818181818182,1,1,approach
40,"To tackle the second challenge , we initialize our model parameters with a priori knowledge learned from the entity type classification task by transfer learning .",Introduction,Introduction,relation_extraction,7,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",28,0.8484848484848485,39,0.15057915057915058,28,0.8484848484848485,1,1,approach
191,"In the experiment , we utilize word2vec 2 to train word embeddings on NYT corpus .",Experimental Settings,Experimental Settings,relation_extraction,7,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",1,0.025,190,0.7335907335907336,1,0.1111111111111111,1,1,experimental-setup
193,"The grid search approach is used to select optimal learning rate lr for Adam optimizer among { 0.1 , 0.001 , 0.0005 , 0.0001 } , GRU size m ? { 100 , 160 , 230 , 400 } , position embedding size l ? { 5 , 10 , 15 , 20}. shows all parameters for our task .",Experimental Settings,Experimental Settings,relation_extraction,7,"['O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.075,192,0.7413127413127413,3,0.3333333333333333,1,1,experimental-setup
195,GRU size m 230,Experimental Settings,Experimental Settings,relation_extraction,7,"['B', 'I', 'I', 'B']","['B-p', 'I-p', 'I-p', 'B-n']","['B-p', 'I-p', 'I-p', 'B-ob']",5,0.125,194,0.749034749034749,5,0.5555555555555556,1,1,experimental-setup
196,Word embedding dimension k 50 POS embedding dimension l 5 Batch size n 50 Entity - Task weights ( ?,Experimental Settings,Experimental Settings,relation_extraction,7,"['B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O']",,,6,0.15,195,0.752895752895753,6,0.6666666666666666,1,1,experimental-setup
197,"head , ? tail ) 0.5,0.5 Entity - Relation Task weight ?",Experimental Settings,Experimental Settings,relation_extraction,7,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O']",7,0.175,196,0.7567567567567568,7,0.7777777777777778,1,1,experimental-setup
198,0.3 Learning rate lr 0.001 Dropout probability p 0.5 l 2 penalty ?,Experimental Settings,Experimental Settings,relation_extraction,7,"['B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'I-p', 'I-p', 'O']","['B-ob', 'B-p', 'I-p', 'I-p', 'B-ob', 'B-p', 'I-p', 'I-p', 'B-ob', 'B-p', 'I-p', 'I-p', 'O']",8,0.2,197,0.7606177606177607,8,0.8888888888888888,1,1,experimental-setup
199,0.0001,Experimental Settings,Experimental Settings,relation_extraction,7,['B'],['B-n'],['B-ob'],9,0.225,198,0.7644787644787645,9,1.0,1,1,experimental-setup
205,"From , we can observe that the model with the STP performs best , and the SDP model obtains an even worse result than the pure one .",Experimental Settings,Effect of the STP,relation_extraction,7,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",15,0.375,204,0.7876447876447876,3,0.10714285714285714,1,1,results
206,"The PR curve areas of BGRU + SDP and BGRU are about 0.332 and 0.337 respectively , while BGRU + STP increases it to 0.366 .",Experimental Settings,Effect of the STP,relation_extraction,7,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'O']",16,0.4,205,0.7915057915057915,4,0.14285714285714285,1,1,results
207,The result indicates : ( 1 ) Our STP can get rid of irrelevant words in each instance and obtain more precise sentence representation for relation extraction .,Experimental Settings,Effect of the STP,relation_extraction,7,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",17,0.425,206,0.7953667953667953,5,0.17857142857142858,1,1,results
209,( 2 ) The SDP method is not appropriate to handle low - quality sentences where key relation words are not in the SDP .,Experimental Settings,Effect of the STP,relation_extraction,7,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",19,0.475,208,0.803088803088803,7,0.25,1,1,results
214,"From and , we can obtain : ( 1 ) Regardless of the dataset that we employ , BGRU - WLA ( + STP ) + EWA outperforms BGRU (+ STP ) .",Experimental Settings,Effect of the STP,relation_extraction,7,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",24,0.6,213,0.8223938223938224,12,0.42857142857142855,1,1,results
215,"To be more specific , the PR curve area has a relative improvement of over 2.3 % , which demonstrates that entity - wise hidden states in the BGRU present more precise relational features than other word states .",Experimental Settings,Effect of the STP,relation_extraction,7,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",25,0.625,214,0.8262548262548263,13,0.4642857142857143,1,1,results
217,"EWA achieves further improvements and outperforms the baseline by over 4.6 % , because it considers more information than entity or relational words alone .",Experimental Settings,Effect of the STP,relation_extraction,7,"['B', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",27,0.675,216,0.833976833976834,15,0.5357142857142857,1,1,results
227,"( 1 ) Regardless of the dataset that we use , models with TL achieve better performance , which improve the PR curve area by over 4.7 % .",Experimental Settings,Effect of Parameter - Transfer Initializer,relation_extraction,7,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",37,0.925,226,0.8725868725868726,25,0.8928571428571429,1,1,results
229,"( 2 ) BGRU + STP + TL achieves the best performance and increases the area to 0.383 , while areas of BGRU , BGRU + STP and BGRU + TL are 0.337 , 0.366 and 0.372 respectively .",Experimental Settings,Effect of Parameter - Transfer Initializer,relation_extraction,7,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",39,0.975,228,0.8803088803088803,27,0.9642857142857143,1,1,results
233,Mintz proposes the humandesigned feature model .,Comparison with Baselines,Comparison with Baselines,relation_extraction,7,"['B', 'B', 'O', 'B', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.10526315789473684,232,0.8957528957528957,2,0.10526315789473684,1,1,baselines
234,MultiR puts forward a graphical model .,Comparison with Baselines,Comparison with Baselines,relation_extraction,7,"['B', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",3,0.15789473684210525,233,0.8996138996138996,3,0.15789473684210525,1,1,baselines
235,MIML proposes a multi -instance multi-label model .,Comparison with Baselines,Comparison with Baselines,relation_extraction,7,"['B', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.21052631578947367,234,0.9034749034749034,4,0.21052631578947367,1,1,baselines
236,PCNN puts forward a piecewise CNN for relation extraction .,Comparison with Baselines,Comparison with Baselines,relation_extraction,7,"['B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.2631578947368421,235,0.9073359073359073,5,0.2631578947368421,1,1,baselines
237,PCNN + ATT proposes the selective attention mechanism with PCNN .,Comparison with Baselines,Comparison with Baselines,relation_extraction,7,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",6,0.3157894736842105,236,0.9111969111969112,6,0.3157894736842105,1,1,baselines
238,BGRU proposes a BGRU with the word - level attention mechanism .,Comparison with Baselines,Comparison with Baselines,relation_extraction,7,"['B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.3684210526315789,237,0.915057915057915,7,0.3684210526315789,1,1,baselines
2,Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks,title,title,relation_extraction,8,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.0037174721189591076,1,0.0,1,1,research-problem
15,"In relation extraction , one challenge that is faced when building a machine learning system is the generation of training examples .",Introduction,Introduction,relation_extraction,8,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.022727272727272728,14,0.05204460966542751,1,0.022727272727272728,1,1,research-problem
36,"In this paper , we propose a novel model dubbed Piecewise Convolutional Neural Networks ( PC - NNs ) with multi-instance learning to address the two problems described above .",Introduction,Introduction,relation_extraction,8,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.5,35,0.13011152416356878,22,0.5,1,1,model
37,"To address the first problem , distant supervised relation extraction is treated as a multi-instance problem similar to previous studies .",Introduction,Introduction,relation_extraction,8,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",23,0.5227272727272727,36,0.13382899628252787,23,0.5227272727272727,1,1,research-problem
40,We design an objective function at the bag level .,Introduction,Introduction,relation_extraction,8,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",26,0.5909090909090909,39,0.1449814126394052,26,0.5909090909090909,1,1,model
41,"In the learning process , the uncertainty of instance labels can be taken into account ; this alleviates the wrong label problem .",Introduction,Introduction,relation_extraction,8,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",27,0.6136363636363636,40,0.14869888475836432,27,0.6136363636363636,1,1,model
42,"To address the second problem , we adopt convolutional architecture to automatically learn relevant features without complicated NLP preprocessing inspired by .",Introduction,Introduction,relation_extraction,8,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",28,0.6363636363636364,41,0.1524163568773234,28,0.6363636363636364,1,1,model
51,"To capture structural and other latent information , we divide the convolution results into three segments based on the positions of the two given entities and devise a piecewise max pooling layer instead of the single max pooling layer .",Introduction,Introduction,relation_extraction,8,"['B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",37,0.8409090909090909,50,0.18587360594795538,37,0.8409090909090909,1,1,model
52,The piecewise max pooling procedure returns the maximum value in each segment instead of a single maximum value over the entire sentence .,Introduction,Introduction,relation_extraction,8,"['O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",38,0.8636363636363636,51,0.1895910780669145,38,0.8636363636363636,1,1,model
202,"In this paper , we use the Skip - gram model ( word2 vec ) 5 to train the word embeddings on the NYT corpus .",Experimental Settings,Experimental Settings,relation_extraction,8,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",2,0.10526315789473684,201,0.7472118959107806,1,0.25,1,1,experimental-setup
213,"Following , we tune all of the models using three - fold validation on the training set .",Experimental Settings,Parameter Settings,relation_extraction,8,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",13,0.6842105263157895,212,0.7881040892193308,2,0.25,1,1,experimental-setup
214,"We use a grid search to determine the optimal parameters and manually specify subsets of the parameter spaces : w ? { 1 , 2 , 3 , , 7 } and n ? { 50 , 60 , , 300}. shows all parameters used in the experiments .",Experimental Settings,Parameter Settings,relation_extraction,8,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.7368421052631579,213,0.79182156133829,3,0.375,1,1,experimental-setup
215,"Because the position dimension has little effect on the result , we heuristically choose d p = 5 .",Experimental Settings,Parameter Settings,relation_extraction,8,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",15,0.7894736842105263,214,0.7955390334572491,4,0.5,1,1,experimental-setup
216,The batch size is fixed to 50 .,Experimental Settings,,relation_extraction,8,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",16,0.8421052631578947,215,0.7992565055762082,5,0.625,1,1,experimental-setup
217,"We use Adadelta in the update procedure ; it relies on two main parameters , ? and ? , which do not significantly affect the performance .",Experimental Settings,The batch size is fixed to 50 .,relation_extraction,8,"['O', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.8947368421052632,216,0.8029739776951673,6,0.75,1,1,experimental-setup
219,"In the dropout operation , we randomly set the hidden unit activities to zero with a probability of 0.5 during training .",Experimental Settings,The batch size is fixed to 50 .,relation_extraction,8,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'O']",19,1.0,218,0.8104089219330854,8,1.0,1,1,experimental-setup
226,Mintz represents a traditional distantsupervision - based model that was proposed by .,Held - out Evaluation,Held - out Evaluation,relation_extraction,8,"['B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",5,0.3333333333333333,225,0.8364312267657993,6,0.375,1,1,baselines
227,MultiR is a multi-instance learning method that was proposed by .,Held - out Evaluation,Held - out Evaluation,relation_extraction,8,"['B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",6,0.4,226,0.8401486988847584,7,0.4375,1,1,baselines
228,MIML is a multi-instance multilabel model that was proposed by .,Held - out Evaluation,Held - out Evaluation,relation_extraction,8,"['B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",7,0.4666666666666667,227,0.8438661710037175,8,0.5,1,1,baselines
229,"shows the precision - recall curves for each method , where PCNNs + MIL denotes our method , and demonstrates that PCNNs + MIL achieves higher precision over the entire range of recall .",Held - out Evaluation,Held - out Evaluation,relation_extraction,8,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.5333333333333333,228,0.8475836431226765,9,0.5625,1,1,results
230,PCNNs + MIL enhances the recall to ap - proximately 34 % without any loss of precision .,Held - out Evaluation,Held - out Evaluation,relation_extraction,8,"['B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'O']",9,0.6,229,0.8513011152416357,10,0.625,1,1,results
231,"In terms of both precision and recall , PCNNs + MIL outperforms all other evaluated approaches .",Held - out Evaluation,Held - out Evaluation,relation_extraction,8,"['B', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.6666666666666666,230,0.8550185873605948,11,0.6875,1,1,results
235,Automatically learning features via PCNNs can alleviate the error propagation that occurs in traditional feature extraction .,Held - out Evaluation,Held - out Evaluation,relation_extraction,8,"['B', 'I', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.9333333333333333,234,0.8698884758364313,15,0.9375,1,1,results
236,Incorporating multi-instance learning into a convolutional neural network is an effective means of addressing the wrong label problem .,Held - out Evaluation,Held - out Evaluation,relation_extraction,8,"['B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",15,1.0,235,0.8736059479553904,16,1.0,1,1,results
2,Relation Classification via Multi - Level Attention CNNs,title,,relation_extraction,9,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.004784688995215311,1,0.0,1,1,research-problem
24,We propose a novel CNN architecture that addresses some of the shortcomings of previous approaches .,Introduction,Introduction,relation_extraction,9,"['O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.7272727272727273,23,0.11004784688995216,16,0.7272727272727273,1,1,model
27,"Our CNN architecture relies on a novel multi-level attention mechanism to capture both entity - specific attention ( primary attention at the input level , with respect to the target entities ) and relation - specific pooling attention ( secondary attention with respect to the target relations ) .",Introduction,Introduction,relation_extraction,9,"['O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O']",,,19,0.8636363636363636,26,0.12440191387559808,19,0.8636363636363636,1,1,model
29,2 . We introduce a novel pair - wise margin - based objective function that proves superior to standard loss functions .,Introduction,Introduction,relation_extraction,9,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",21,0.9545454545454546,28,0.1339712918660287,21,0.9545454545454546,1,1,model
149,We use the word2 vec skip - gram model to learn initial word representations on Wikipedia .,Experimental Setup,Settings .,relation_extraction,9,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",10,0.4166666666666667,148,0.7081339712918661,10,0.4166666666666667,1,1,experimental-setup
150,Other matrices are initialized with random values following a Gaussian distribution .,Experimental Setup,Settings .,relation_extraction,9,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",11,0.4583333333333333,149,0.7129186602870813,11,0.4583333333333333,1,1,experimental-setup
151,We apply a cross-validation procedure on the training data to select suitable hyperparameters .,Experimental Setup,Settings .,relation_extraction,9,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",12,0.5,150,0.7177033492822966,12,0.5,1,1,experimental-setup
153,We observe that our novel attentionbased architecture achieves new state - of - the - art results on this relation classification dataset .,Experimental Setup,Settings .,relation_extraction,9,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.5833333333333334,152,0.7272727272727273,14,0.5833333333333334,1,1,results
154,"Att - Input - CNN relies only on the primal attention at the input level , performing standard max - pooling after the convolution layer to generate the network output w O , in which the new objective function is utilized .",Experimental Setup,Settings .,relation_extraction,9,"['B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.625,153,0.7320574162679426,15,0.625,1,1,results
155,"With Att - Input - CNN , we achieve an F1-score of 87.5 % , thus already outperforming not only the original winner of the SemEval task , an SVM - based approach ( 82.2 % ) , but also the wellknown CR - CNN model ( 84.1 % ) with a relative improvement of 4.04 % , and the newly released DRNNs ( 85.8 % ) with a relative improvement of 2.0 % , although the latter approach depends on the Stanford parser to obtain dependency parse information .",Experimental Setup,Settings .,relation_extraction,9,"['B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.6666666666666666,154,0.7368421052631579,16,0.6666666666666666,1,1,results
156,Our full dual attention model Att - Pooling - CNN achieves an even more favorable F1- score of 88 % .,Experimental Setup,Settings .,relation_extraction,9,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",17,0.7083333333333334,155,0.7416267942583732,17,0.7083333333333334,1,1,results
159,"To better quantify the contribution of the different components of our model , we also conduct an ablation study evaluating several simplified models .",Experimental Setup,Settings .,relation_extraction,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O']",20,0.8333333333333334,158,0.7559808612440191,20,0.8333333333333334,1,1,ablation-analysis
160,The first simplification is to use our model without the input attention mechanism but with the pooling attention layer .,Experimental Setup,Settings .,relation_extraction,9,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",21,0.875,159,0.7607655502392344,21,0.875,1,1,ablation-analysis
161,The second removes both attention mechanisms .,Experimental Setup,Settings .,relation_extraction,9,"['O', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",22,0.9166666666666666,160,0.7655502392344498,22,0.9166666666666666,1,1,ablation-analysis
162,The third removes both forms of attention and additionally uses a regular objective function based on the inner product s = r w for a sentence representation r and relation class embedding w.,Experimental Setup,Settings .,relation_extraction,9,"['O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",23,0.9583333333333334,161,0.7703349282296651,23,0.9583333333333334,1,1,ablation-analysis
163,We observe that all three of our components lead to noticeable improvements over these baselines .,Experimental Setup,Settings .,relation_extraction,9,"['O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",24,1.0,162,0.7751196172248804,24,1.0,1,1,ablation-analysis
4,"We introduce the Self - Annotated Reddit Corpus ( SARC ) , a large corpus for sarcasm research and for training and evaluating systems for sarcasm detection .",abstract,abstract,sarcasm_detection,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",1,0.25,3,0.017045454545454544,1,0.25,1,1,research-problem
12,"In this work , we make available the first corpus 1 for sarcasm detection that has both unbalanced and self - annotated labels and does not consist of short text snippets from Twitter 2 .",Introduction,Introduction,sarcasm_detection,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.5,11,0.0625,4,0.5,1,1,dataset
13,"With more than a million examples of sarcastic statements , each provided with author , topic , and contex information , the dataset exceeds all previous sarcasm corpora by an order of magnitude in size .",Introduction,Introduction,sarcasm_detection,0,"['B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.625,12,0.06818181818181818,5,0.625,1,1,dataset
120,Code to reproduce our results is provided at https://github.com/NLPrinceton/,Limitations of Our Approach,Benchmarks for Sarcasm Detection,sarcasm_detection,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob']",37,0.9736842105263158,119,0.6761363636363636,5,0.8333333333333334,1,1,code
169,"The baselines in perform reasonably well and much better than the random baseline , but none of them match human performance on either dataset .",Baselines,Baselines,sarcasm_detection,0,"['O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.3333333333333333,168,0.9545454545454546,1,0.3333333333333333,1,1,results
170,"There is clear scope for improvement for machine learning methods , starting with the use of context provided to make better decisions about sarcasm .",Baselines,Baselines,sarcasm_detection,0,"['O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.6666666666666666,169,0.9602272727272727,2,0.6666666666666666,1,1,results
2,CASCADE : Contextual Sarcasm Detection in Online Discussion Forums,title,,sarcasm_detection,1,"['O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.0029940119760479044,1,0.0,1,1,research-problem
4,"The literature in automated sarcasm detection has mainly focused on lexical , syntactic and semantic - level analysis of text .",abstract,abstract,sarcasm_detection,1,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.16666666666666666,3,0.008982035928143712,1,0.16666666666666666,1,1,research-problem
6,"In this paper , we propose CASCADE ( a ContextuAl SarCasm DEtector ) that adopts a hybrid approach of both content and context - driven modeling for sarcasm detection in online social media discussions .",abstract,abstract,sarcasm_detection,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.5,5,0.014970059880239521,3,0.5,1,1,research-problem
25,"Particularly , we propose a hybrid network , named CASCADE , that utilizes both content and contextual - information required for sarcasm detection .",Introduction,Introduction,sarcasm_detection,1,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",15,0.5,24,0.0718562874251497,15,0.5,1,1,model
27,"First , it performs user profiling to create user embeddings that capture indicative behavioral traits for sarcasm .",Introduction,Introduction,sarcasm_detection,1,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",17,0.5666666666666667,26,0.07784431137724551,17,0.5666666666666667,1,1,model
29,"It makes use of users ' historical posts to model their writing style ( stylometry ) and personality indicators , which are then fused into comprehensive user embeddings using a multi-view fusion approach , Canonical Correlation Analysis ( CCA ) .",Introduction,Introduction,sarcasm_detection,1,"['O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.6333333333333333,28,0.08383233532934131,19,0.6333333333333333,1,1,model
30,"Second , it extracts contextual information from the discourse of comments in the discussion forums .",Introduction,Introduction,sarcasm_detection,1,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",20,0.6666666666666666,29,0.08682634730538923,20,0.6666666666666666,1,1,model
31,This is done by document modeling of these consolidated comments belonging to the same forum .,Introduction,Introduction,sarcasm_detection,1,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",21,0.7,30,0.08982035928143713,21,0.7,1,1,model
33,"After the contextual modeling phase , CASCADE is provided with a comment for sarcasm detection .",Introduction,Introduction,sarcasm_detection,1,"['B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",23,0.7666666666666667,32,0.09580838323353294,23,0.7666666666666667,1,1,model
34,It performs content - modeling using a Convolutional Neural Network ( CNN ) to extract its syntactic features .,Introduction,Introduction,sarcasm_detection,1,"['O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",24,0.8,33,0.09880239520958084,24,0.8,1,1,model
35,This CNN representation is then concatenated with the relevant user embedding and discourse features to get the final representation which is used for classification .,Introduction,Introduction,sarcasm_detection,1,"['O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",25,0.8333333333333334,34,0.10179640718562874,25,0.8333333333333334,1,1,model
247,We holdout 10 % of the training data for validation .,Training details,Training details,sarcasm_detection,1,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'O']",1,0.1111111111111111,246,0.7365269461077845,1,0.1111111111111111,1,1,hyperparameters
249,"To optimize the parameters , Adam optimizer ( Kingma and Ba , 2014 ) is used , starting with an initial learning rate of 1e ? 4 .",Training details,Training details,sarcasm_detection,1,"['B', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.3333333333333333,248,0.7425149700598802,3,0.3333333333333333,1,1,hyperparameters
251,Training termination is decided using early stopping technique with a patience of 12 .,Training details,Training details,sarcasm_detection,1,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O']",5,0.5555555555555556,250,0.7485029940119761,5,0.5555555555555556,1,1,hyperparameters
252,"For the batched - modeling of comments in CNNs , each comment is either restricted or padded to 100 words for uniformity .",Training details,Training details,sarcasm_detection,1,"['B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'O']",6,0.6666666666666666,251,0.7514970059880239,6,0.6666666666666666,1,1,hyperparameters
258,Bag - of - Words :,Baseline Models,Baseline Models,sarcasm_detection,1,"['B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",2,0.08,257,0.7694610778443114,2,0.08,1,1,baselines
259,This model uses a comment 's word - counts as features in a vector .,Baseline Models,Baseline Models,sarcasm_detection,1,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'O']",3,0.12,258,0.7724550898203593,3,0.12,1,1,baselines
261,CNN : We compare our model with this individual CNN version .,Baseline Models,Baseline Models,sarcasm_detection,1,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",5,0.2,260,0.7784431137724551,5,0.2,1,1,baselines
264,CNN - SVM :,Baseline Models,Baseline Models,sarcasm_detection,1,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",8,0.32,263,0.7874251497005988,8,0.32,1,1,baselines
265,"This model proposed by consists of a CNN for content modeling and other pre-trained CNNs for extracting sentiment , emotion and personality features from the given comment .",Baseline Models,Baseline Models,sarcasm_detection,1,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",9,0.36,264,0.7904191616766467,9,0.36,1,1,baselines
267,CUE - CNN :,Baseline Models,Baseline Models,sarcasm_detection,1,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",11,0.44,266,0.7964071856287425,11,0.44,1,1,baselines
268,This method proposed by also models user embeddings with a method akin to ParagraphVector .,Baseline Models,Baseline Models,sarcasm_detection,1,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'O']",12,0.48,267,0.7994011976047904,12,0.48,1,1,baselines
273,CASCADE manages to achieve major improvement across all datasets with statistical significance .,Baseline Models,Baseline Models,sarcasm_detection,1,"['B', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",17,0.68,272,0.8143712574850299,17,0.68,1,1,results
274,The lowest performance is obtained by the Bag - of - words approach whereas all neural architectures outperform it .,Baseline Models,Baseline Models,sarcasm_detection,1,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.72,273,0.8173652694610778,18,0.72,1,1,results
275,"Amongst the neural networks , the CNN baseline receives the least performance .",Baseline Models,Baseline Models,sarcasm_detection,1,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",19,0.76,274,0.8203592814371258,19,0.76,1,1,results
276,CASCADE comfortably beats the state - of - the - art neural models CNN - SVM and CUE - CNN .,Baseline Models,Baseline Models,sarcasm_detection,1,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",20,0.8,275,0.8233532934131736,20,0.8,1,1,results
277,Its improved performance on the Main imbalanced dataset also reflects its robustness towards class imbalance and establishes it as a real - world deployable network .,Baseline Models,Baseline Models,sarcasm_detection,1,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",21,0.84,276,0.8263473053892215,21,0.84,1,1,results
279,"Since CUE - CNN generates its user embeddings using a method similar to the ParagraphVector , we test the importance of personality features being included in our user profiling .",Baseline Models,Baseline Models,sarcasm_detection,1,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",23,0.92,278,0.8323353293413174,23,0.92,1,1,results
286,"First , we test performance for the content - based CNN only ( row 1 ) .",Ablation Study,Ablation Study,sarcasm_detection,1,"['O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O']",3,0.06521739130434782,285,0.8532934131736527,3,0.21428571428571427,1,1,ablation-analysis
287,This setting provides the worst relative performance with almost 10 % lesser accuracy than optimal .,Ablation Study,Ablation Study,sarcasm_detection,1,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",4,0.08695652173913043,286,0.8562874251497006,4,0.2857142857142857,1,1,ablation-analysis
288,"Next , we include contextual features to this network .",Ablation Study,Ablation Study,sarcasm_detection,1,"['O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O']",5,0.10869565217391304,287,0.8592814371257484,5,0.35714285714285715,1,1,ablation-analysis
289,"Here , the effect of discourse features is primarily seen in the Pol dataset getting an increase of 3 % in F1 ( row 2 ) .",Ablation Study,Ablation Study,sarcasm_detection,1,"['O', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']",,,6,0.13043478260869565,288,0.8622754491017964,6,0.42857142857142855,1,1,ablation-analysis
290,A major boost in performance is observed ( 8 ? 12 % accuracy and F1 ) when user embeddings are introduced ( row 5 ) .,Ablation Study,Ablation Study,sarcasm_detection,1,"['O', 'B', 'I', 'B', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O']",7,0.15217391304347827,289,0.8652694610778443,7,0.5,1,1,ablation-analysis
292,"Overall , CASCADE consisting of CNN with user embeddings and contextual discourse features provide the best performance in all three datasets ( row 6 ) .",Ablation Study,Ablation Study,sarcasm_detection,1,"['O', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",9,0.1956521739130435,291,0.8712574850299402,9,0.6428571428571429,1,1,ablation-analysis
293,We challenge the use of CCA for the generation of user embeddings and thus replace it with simple concatenation .,Ablation Study,Ablation Study,sarcasm_detection,1,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'O']",10,0.21739130434782608,292,0.874251497005988,10,0.7142857142857143,1,1,ablation-analysis
294,This however causes a significant drop in performance ( row 3 ) .,Ablation Study,Ablation Study,sarcasm_detection,1,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O']",11,0.2391304347826087,293,0.8772455089820359,11,0.7857142857142857,1,1,ablation-analysis
2,Spider : A Large - Scale Human - Labeled Dataset for Complex and Cross - Domain Semantic Parsing and Text - to - SQL Task,title,title,semantic_parsing,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.0,1,0.0035971223021582736,1,0.0,1,1,research-problem
11,Our dataset and task are publicly available at https://yale-lily. github.io/ spider .,abstract,abstract,semantic_parsing,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,1.0,10,0.03597122302158273,8,1.0,1,1,code
13,Semantic parsing ( SP ) is one of the most important tasks in natural language processing ( NLP ) .,Introduction,Introduction,semantic_parsing,0,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.006097560975609756,12,0.04316546762589928,1,0.03225806451612903,1,1,research-problem
19,Existing datasets for SP have two shortcomings .,Introduction,Introduction,semantic_parsing,0,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O']",7,0.042682926829268296,18,0.06474820143884892,7,0.22580645161290322,1,1,research-problem
34,"To address the need for a large and high - quality dataset for a new complex and cross-domain semantic parsing task , we introduce Spider , which consists of 200 databases with multiple tables , 10,181 questions , and 5,693 corresponding complex SQL queries , all written by 11 college students spending a total of 1,000 man-hours .",Introduction,Introduction,semantic_parsing,0,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.13414634146341464,33,0.11870503597122302,22,0.7096774193548387,1,1,dataset
35,"As illustrates , given a database with multiple tables including foreign keys , our corpus creates and annotates complex questions and SQL queries including different SQL clauses such as joining and nested query .",Introduction,Introduction,semantic_parsing,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",23,0.1402439024390244,34,0.1223021582733813,23,0.7419354838709677,1,1,dataset
248,"The performances of the Seq2Seq - based basic models including Seq2Seq , Seq2Seq + Attention , and Seq2Seq + Copying are very low .",Experimental Results and Discussion,Overall Performance,semantic_parsing,0,"['O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.2972972972972973,247,0.8884892086330936,11,0.2972972972972973,1,1,results
253,"In contrast , SQLNet and TypeSQL that utilize SQL structure information to guide the SQL generation process significantly outperform other Seq2Seq models .",Experimental Results and Discussion,Overall Performance,semantic_parsing,0,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",16,0.43243243243243246,252,0.9064748201438849,16,0.43243243243243246,1,1,results
255,"As Component Matching results in shows , all models struggle with WHERE clause prediction the most .",Experimental Results and Discussion,Overall Performance,semantic_parsing,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",18,0.4864864864864865,254,0.9136690647482014,18,0.4864864864864865,1,1,results
258,"In general , the over all performances of all models are low , indicating that our task is challenging and there is still a large room for improvement .",Experimental Results and Discussion,Overall Performance,semantic_parsing,0,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.5675675675675675,257,0.9244604316546763,21,0.5675675675675675,1,1,results
2,TRANX : A Transition - based Neural Abstract Syntax Parser for Semantic Parsing and Code Generation,title,title,semantic_parsing,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.006993006993006993,1,0.0,1,1,research-problem
18,"Inspired by this existing research , we have developed TRANX , a TRANsition - based abstract syntaX parser for semantic parsing and code generation .",Introduction,Introduction,semantic_parsing,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.5882352941176471,17,0.11888111888111888,10,0.5882352941176471,1,1,model
19,TRANX is designed with the following principles in mind :,Introduction,Introduction,semantic_parsing,1,"['B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O']","['B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O']","['B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O']",11,0.6470588235294118,18,0.1258741258741259,11,0.6470588235294118,1,1,model
20,"Generalization ability TRANX employs ASTs as a general - purpose intermediate meaning representation , and the task - dependent grammar is provided to the system as external knowledge to guide the parsing process , therefore decoupling the semantic parsing procedure with specificities of grammars .",Introduction,Introduction,semantic_parsing,1,"['B', 'I', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,12,0.7058823529411765,19,0.13286713286713286,12,0.7058823529411765,1,1,model
21,Extensibility TRANX uses a simple transition system to parse NL utterances into tree -,Introduction,Introduction,semantic_parsing,1,"['B', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O']","['B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O']","['B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O']",13,0.7647058823529411,20,0.13986013986013987,13,0.7647058823529411,1,1,model
24,Effectiveness,Introduction,,semantic_parsing,1,['B'],['B-n'],['B-b'],16,0.9411764705882353,23,0.16083916083916083,16,0.9411764705882353,1,1,model
25,"We test TRANX on four semantic parsing ( ATIS , GEO ) and code generation ( DJANGO , WIKISQL ) tasks , and demonstrate that TRANX is capable of generalizing to different domains while registering strong performance , out - performing existing neural networkbased approaches on three of the four datasets ( GEO , ATIS , DJANGO ) .",Introduction,Effectiveness,semantic_parsing,1,"['O', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'O', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,1.0,24,0.16783216783216784,17,1.0,1,1,model
126,Semantic Parsing Tab.,Results,,semantic_parsing,1,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-b', 'I-b', 'O']",3,0.15,125,0.8741258741258742,3,0.15,1,1,results
129,Our system outperforms existing neural network - based approaches .,Results,Semantic Parsing Tab.,semantic_parsing,1,"['B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.3,128,0.8951048951048951,6,0.3,1,1,results
131,"Interestingly , we found the model without parent feeding achieves slightly better accuracy on GEO , probably because that its relative simple grammar does not require extra handling of parent information .",Results,Semantic Parsing Tab.,semantic_parsing,1,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.4,130,0.9090909090909091,8,0.4,1,1,results
132,Code Generation Tab.,Results,,semantic_parsing,1,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-b', 'I-b', 'O']",9,0.45,131,0.916083916083916,9,0.45,1,1,results
133,2 lists the results on DJANGO .,Results,Code Generation Tab.,semantic_parsing,1,"['O', 'O', 'O', 'O', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-ob', 'O']",10,0.5,132,0.9230769230769231,10,0.5,1,1,results
134,TRANX achieves state - of - the - art results on DJANGO .,Results,Code Generation Tab.,semantic_parsing,1,"['B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O']",11,0.55,133,0.9300699300699301,11,0.55,1,1,results
135,"We also find parent feeding yields + 1 point gain in accuracy , suggesting the importance of modeling parental connections in ASTs with complex domain grammars ( e.g. , Python ) .",Results,Code Generation Tab.,semantic_parsing,1,"['O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.6,134,0.9370629370629371,12,0.6,1,1,results
138,"3 . We find TRANX , although just with simple extensions to adapt to this dataset , achieves impressive results and outperforms many task - specific methods .",Results,Code Generation Tab.,semantic_parsing,1,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.75,137,0.958041958041958,15,0.75,1,1,results
2,Coarse - to - Fine Decoding for Neural Semantic Parsing,title,title,semantic_parsing,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.003436426116838488,1,0.0,1,1,research-problem
4,Semantic parsing aims at mapping natural language utterances into structured meaning representations .,abstract,abstract,semantic_parsing,2,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.010309278350515464,1,0.2,1,1,research-problem
14,"In this work , we propose to decompose the decoding process into two stages .",Introduction,Introduction,semantic_parsing,2,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",5,0.17857142857142858,13,0.044673539518900345,5,0.17857142857142858,1,1,model
15,"The first decoder focuses on predicting a rough sketch of the meaning representation , which omits low - level details , such as arguments and variable names .",Introduction,Introduction,semantic_parsing,2,"['O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.21428571428571427,14,0.048109965635738834,6,0.21428571428571427,1,1,model
17,"Then , a second decoder fills in missing details by conditioning on the natural language input and the sketch itself .",Introduction,Introduction,semantic_parsing,2,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'O', 'O']",8,0.2857142857142857,16,0.054982817869415807,8,0.2857142857142857,1,1,model
18,"Specifically , the sketch constrains the generation process and is encoded into vectors to guide decoding .",Introduction,Introduction,semantic_parsing,2,"['O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'O']",9,0.32142857142857145,17,0.058419243986254296,9,0.32142857142857145,1,1,model
20,"Firstly , the decomposition disentangles high - level from low - level semantic information , which enables the decoders to model meaning at different levels of granularity .",Introduction,Introduction,semantic_parsing,2,"['O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.39285714285714285,19,0.06529209621993128,11,0.39285714285714285,1,1,model
22,"Secondly , the model can explicitly share knowledge of coarse structures for the examples that have the same sketch ( i.e. , basic meaning ) , even though their actual meaning representations are different ( e.g. , due to different details ) .",Introduction,Introduction,semantic_parsing,2,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.4642857142857143,21,0.07216494845360824,13,0.4642857142857143,1,1,model
23,"Thirdly , after generating the sketch , the decoder knows what the basic meaning of the utterance looks like , and the model can use it as global context to improve the prediction of the final details .",Introduction,Introduction,semantic_parsing,2,"['O', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'O', 'B-n', 'O', 'O', 'B-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'O', 'B-b', 'O', 'O', 'B-b', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",14,0.5,22,0.07560137457044673,14,0.5,1,1,model
230,Our implementation and pretrained models are available at https :// github.com/donglixp/coarse2fine.,Experiments,Experiments,semantic_parsing,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,1.0,229,0.7869415807560137,2,1.0,1,1,code
237,"Dimensions of hidden vectors and word embeddings were selected from { 250 , 300 } and { 150 , 200 , 250 , 300 } , respectively .",Experimental Setup,Experimental Setup,semantic_parsing,2,"['B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",6,0.35294117647058826,236,0.8109965635738832,6,0.3,1,1,hyperparameters
238,"The dropout rate was selected from { 0.3 , 0.5 } .",Experimental Setup,Experimental Setup,semantic_parsing,2,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.4117647058823529,237,0.8144329896907216,7,0.35,1,1,hyperparameters
239,Label smoothing was employed for GEO and ATIS .,Experimental Setup,Experimental Setup,semantic_parsing,2,"['B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'B-ob', 'O']",8,0.47058823529411764,238,0.8178694158075601,8,0.4,1,1,hyperparameters
240,The smoothing parameter was set to 0.1 .,Experimental Setup,Experimental Setup,semantic_parsing,2,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",9,0.5294117647058824,239,0.8213058419243986,9,0.45,1,1,hyperparameters
242,"Word embeddings were initialized by GloVe , and were shared by table encoder and input encoder in Section 4.3 .",Experimental Setup,Experimental Setup,semantic_parsing,2,"['B', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",11,0.6470588235294118,241,0.8281786941580757,11,0.55,1,1,hyperparameters
243,We appended 10 - dimensional part - of - speech tag vectors to embeddings of the question words in WIKISQL .,Experimental Setup,Experimental Setup,semantic_parsing,2,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",12,0.7058823529411765,242,0.8316151202749141,12,0.6,1,1,hyperparameters
244,The part - of - speech tags were obtained by the spaCy toolkit .,Experimental Setup,Experimental Setup,semantic_parsing,2,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",13,0.7647058823529411,243,0.8350515463917526,13,0.65,1,1,hyperparameters
245,We used the RMSProp optimizer to train the models .,Experimental Setup,Experimental Setup,semantic_parsing,2,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",14,0.8235294117647058,244,0.8384879725085911,14,0.7,1,1,hyperparameters
246,"The learning rate was selected from { 0.002 , 0.005 } .",Experimental Setup,Experimental Setup,semantic_parsing,2,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.8823529411764706,245,0.8419243986254296,15,0.75,1,1,hyperparameters
247,"The batch size was 200 for WIKISQL , and was 64 for other datasets .",Experimental Setup,Experimental Setup,semantic_parsing,2,"['O', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'O']",,,16,0.9411764705882353,246,0.845360824742268,16,0.8,1,1,hyperparameters
248,Early stopping was used to determine the number of epochs .,Experimental Setup,Experimental Setup,semantic_parsing,2,"['B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",17,1.0,247,0.8487972508591065,17,0.85,1,1,hyperparameters
257,"Overall , we observe that COARSE2FINE outperforms ONESTAGE , which suggests that disentangling high - level from low - level information dur - 62.3 SNM + COPY 71 and .",Results and Analysis,Results and Analysis,semantic_parsing,2,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.15151515151515152,256,0.8797250859106529,5,0.15151515151515152,1,1,results
260,"Compared with previous neural models that utilize syntax or grammatical information ( SEQ2 TREE , ASN ; the second block in ) , our method performs competitively despite the use of relatively simple decoders .",Results and Analysis,Results and Analysis,semantic_parsing,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.24242424242424243,259,0.8900343642611683,8,0.24242424242424243,1,1,results
262,"As can be seen , predicting the sketch correctly boosts performance .",Results and Analysis,Results and Analysis,semantic_parsing,2,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-ob', 'B-p', 'B-ob', 'O']",10,0.30303030303030304,261,0.8969072164948454,10,0.30303030303030304,1,1,results
267,Again we observe that the sketch encoder is beneficial and that there is an 8.9 point difference in accuracy between COARSE2FINE and the oracle .,Results and Analysis,Results and Analysis,semantic_parsing,2,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.45454545454545453,266,0.9140893470790378,15,0.45454545454545453,1,1,results
269,Our model is superior to ONESTAGE as well as to previous best performing systems .,Results and Analysis,Results and Analysis,semantic_parsing,2,"['B', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.5151515151515151,268,0.9209621993127147,17,0.5151515151515151,1,1,results
270,"COARSE2FINE 's accuracies on aggregation agg op and agg col are 90.2 % and 92.0 % , respectively , which is comparable to SQLNET .",Results and Analysis,Results and Analysis,semantic_parsing,2,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",18,0.5454545454545454,269,0.9243986254295533,18,0.5454545454545454,1,1,results
271,So the most gain is obtained by the improved decoder of the WHERE clause .,Results and Analysis,Results and Analysis,semantic_parsing,2,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",19,0.5757575757575758,270,0.9278350515463918,19,0.5757575757575758,1,1,results
272,"We also find that a tableaware input encoder is critical for doing well on this task , since the same question might lead to different SQL queries depending on the table schemas .",Results and Analysis,Results and Analysis,semantic_parsing,2,"['O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.6060606060606061,271,0.9312714776632303,20,0.6060606060606061,1,1,results
279,Sketches produced by COARSE2FINE are more accurate across the board .,Results and Analysis,Results and Analysis,semantic_parsing,2,"['B', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",27,0.8181818181818182,278,0.9553264604810997,27,0.8181818181818182,1,1,results
282,"On WIKISQL , the sketches predicted by COARSE2FINE are marginally better compared with ONESTAGE .",Results and Analysis,Results and Analysis,semantic_parsing,2,"['B', 'B', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'O']","['B-p', 'B-n', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",30,0.9090909090909091,281,0.9656357388316151,30,0.9090909090909091,1,1,results
2,Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling,title,title,semantic_role_labeling,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.009523809523809525,1,0.0,1,1,research-problem
10,"Semantic role labeling ( SRL ) captures predicateargument relations , such as "" who did what to whom . """,Introduction,Introduction,semantic_role_labeling,0,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.07692307692307693,9,0.08571428571428572,1,0.07692307692307693,1,1,research-problem
11,"Recent high - performing SRL models are BIO - taggers , labeling argument spans for a single predicate at a time ( as shown in .",Introduction,Introduction,semantic_role_labeling,0,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.15384615384615385,10,0.09523809523809523,2,0.15384615384615385,1,1,research-problem
13,We propose an end - to - end approach for predicting all the predicates and their argument spans in one forward pass .,Introduction,Introduction,semantic_role_labeling,0,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'O']",4,0.3076923076923077,12,0.11428571428571428,4,0.3076923076923077,1,1,model
14,"Our model builds on a recent coreference resolution model , by making central use of learned , contextualized span representations .",Introduction,Introduction,semantic_role_labeling,0,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.38461538461538464,13,0.12380952380952381,5,0.38461538461538464,1,1,model
15,We use these representations to predict SRL graphs directly over text spans .,Introduction,Introduction,semantic_role_labeling,0,"['O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",6,0.46153846153846156,14,0.13333333333333333,6,0.46153846153846156,1,1,model
16,"Each edge is identified by independently predicting which role , if any , holds between every possible pair of text spans , while using aggressive beam 1 Code and models : https://github.com/luheng/lsgn pruning for efficiency .",Introduction,Introduction,semantic_role_labeling,0,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O']",7,0.5384615384615384,15,0.14285714285714285,7,0.5384615384615384,1,1,model
17,The final graph is simply the union of predicted SRL roles ( edges ) and their associated text spans ( nodes ) .,Introduction,Introduction,semantic_role_labeling,0,"['O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.6153846153846154,16,0.1523809523809524,8,0.6153846153846154,1,1,model
19,"The span representations also generalize the token - level representations in BIObased models , letting the model dynamically decide which spans and roles to include , without using previously standard syntactic features .",Introduction,Introduction,semantic_role_labeling,0,"['O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.7692307692307693,18,0.17142857142857143,10,0.7692307692307693,1,1,model
20,"To the best of our knowledge , this is the first span - based SRL model that does not assume that predicates are given .",Introduction,Introduction,semantic_role_labeling,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",11,0.8461538461538461,19,0.18095238095238095,11,0.8461538461538461,1,1,model
71,"As shown in , 2 our joint model outperforms the previous best pipeline system by an F1 difference of anywhere between 1.3 and 6.0 in every setting .",Experiments,End - to - end results,semantic_role_labeling,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",11,0.8461538461538461,70,0.6666666666666666,11,0.6875,1,1,results
73,"On all datasets , our model is able to predict over 40 % of the sentences completely correctly .",Experiments,End - to - end results,semantic_role_labeling,0,"['B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-ob', 'I-ob', 'O']",13,1.0,72,0.6857142857142857,13,0.8125,1,1,results
2,Linguistically - Informed Self - Attention for Semantic Role Labeling,title,title,semantic_role_labeling,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0045871559633027525,1,0.0,1,1,research-problem
4,Current state - of - the - art semantic role labeling ( SRL ) uses a deep neural network with no explicit linguistic features .,abstract,abstract,semantic_role_labeling,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.1111111111111111,3,0.013761467889908258,1,0.1111111111111111,1,1,research-problem
5,"However , prior work has shown that gold syntax trees can dramatically improve SRL decoding , suggesting the possibility of increased accuracy from explicit modeling of syntax .",abstract,abstract,semantic_role_labeling,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.2222222222222222,4,0.01834862385321101,2,0.2222222222222222,1,1,research-problem
21,"In response , we propose linguistically - informed self - attention ( LISA ) : a model that combines multi-task learning with stacked layers of multi-head self - attention ; the model is trained to : ( 1 ) jointly predict parts of speech and predicates ; ( 2 ) perform parsing ; and ( 3 ) attend to syntactic parse parents , while ( 4 ) assigning semantic role labels .",Introduction,Introduction,semantic_role_labeling,1,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.4,20,0.09174311926605505,8,0.4,1,1,model
22,"Whereas prior work typically requires separate models to provide linguistic analysis , including most syntaxfree neural models which still rely on external predicate detection , our model is truly end - to - end : earlier layers are trained to predict prerequisite parts - of - speech and predicates , the latter of which are supplied to later layers for scoring .",Introduction,Introduction,semantic_role_labeling,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",9,0.45,21,0.0963302752293578,9,0.45,1,1,model
23,"Though prior work re-encodes each sentence to predict each desired task and again with respect to each predicate to perform SRL , we more efficiently encode each sentence only once , predict its predicates , part - of - speech tags and labeled syntactic parse , then predict the semantic roles for all predicates in the sentence in parallel .",Introduction,Introduction,semantic_role_labeling,1,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.5,22,0.10091743119266056,10,0.5,1,1,model
128,"We train the model using Nadam ( Dozat , 2016 ) SGD combined with the learning rate schedule in .",Training,Training,semantic_role_labeling,1,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.6666666666666666,127,0.5825688073394495,6,0.6666666666666666,1,1,hyperparameters
129,"In addition to MTL , we regularize our model using dropout .",Training,Training,semantic_role_labeling,1,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",7,0.7777777777777778,128,0.5871559633027523,7,0.7777777777777778,1,1,hyperparameters
130,We use gradient clipping to avoid exploding gradients .,Training,,semantic_role_labeling,1,"['O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",8,0.8888888888888888,129,0.591743119266055,8,0.8888888888888888,1,1,hyperparameters
151,"We present results on the CoNLL - 2005 shared task and the CoNLL - 2012 English subset of OntoNotes 5.0 , achieving state - of - the - art results for a single model with predicted predicates on both corpora .",Experimental results,Experimental results,semantic_role_labeling,1,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O']",,,1,0.0196078431372549,150,0.6880733944954128,1,0.05263157894736842,1,1,results
159,"We demonstrate that our models benefit from injecting state - of - the - art predicted parses at test time ( + D&M ) by fixing the attention to parses predicted by Dozat and Manning ( 2017 ) , the winner of the 2017 CoNLL shared task which we re-train using ELMo embeddings .",Experimental results,Experimental results,semantic_role_labeling,1,"['O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.17647058823529413,158,0.7247706422018348,9,0.47368421052631576,1,1,results
165,"For models using GloVe embeddings , our syntax - free SA model already achieves a new state - of - the - art by jointly predicting predicates , POS and SRL .",Experimental results,Experimental results,semantic_role_labeling,1,"['B', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'O']","['B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O']","['B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O']",15,0.29411764705882354,164,0.7522935779816514,15,0.7894736842105263,1,1,results
166,"LISA with it s own parses performs comparably to SA , but when supplied with D&M parses LISA out - performs the previous state - of - the - art by 2.5 F1 points .",Experimental results,Experimental results,semantic_role_labeling,1,"['B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",16,0.3137254901960784,165,0.7568807339449541,16,0.8421052631578947,1,1,results
167,"On the out - ofdomain Brown test set , LISA also performs comparably to its syntax - free counterpart with its own parses , but with D&M parses LISA performs exceptionally well , more than 3.5 F1 points higher than He et al ..",Experimental results,Experimental results,semantic_role_labeling,1,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,17,0.3333333333333333,166,0.7614678899082569,17,0.8947368421052632,1,1,results
168,Incorporating ELMo em-beddings improves all scores .,Experimental results,,semantic_role_labeling,1,"['B', 'B', 'I', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",18,0.35294117647058826,167,0.7660550458715596,18,0.9473684210526315,1,1,results
2,Deep Semantic Role Labeling : What Works and What 's Next,title,title,semantic_role_labeling,2,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.004464285714285714,1,0.0,1,1,research-problem
4,"We introduce a new deep learning model for semantic role labeling ( SRL ) that significantly improves the state of the art , along with detailed analyses to reveal its strengths and limitations .",abstract,abstract,semantic_role_labeling,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.25,3,0.013392857142857142,1,0.25,1,1,research-problem
10,Recently breakthroughs involving end - to - end deep models for SRL without syntactic input seem to overturn the long - held belief that syntactic parsing is a prerequisite for this task .,Introduction,Introduction,semantic_role_labeling,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.13333333333333333,9,0.04017857142857143,2,0.13333333333333333,1,1,research-problem
11,"In this paper , we show that this result can be pushed further using deep highway bidirectional LSTMs with constrained decoding , again significantly moving the state of the art ( another 2 points on CoNLL 2005 ) .",Introduction,Introduction,semantic_role_labeling,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.2,10,0.044642857142857144,3,0.2,1,1,model
14,"Fol - lowing , we treat SRL as a BIO tagging problem and use deep bidirectional LSTMs .",Introduction,Introduction,semantic_role_labeling,2,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O']",6,0.4,13,0.05803571428571429,6,0.4,1,1,model
15,"However , we differ by ( 1 ) simplifying the input and output layers , ( 2 ) introducing highway connections , ( 3 ) using recurrent dropout , ( 4 ) decoding with BIOconstraints , and ( 5 ) ensembling with a product of experts .",Introduction,Introduction,semantic_role_labeling,2,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O']",,,7,0.4666666666666667,14,0.0625,7,0.4666666666666667,1,1,model
87,"Our network consists of 8 BiLSTM layers ( 4 forward LSTMs and 4 reversed LSTMs ) with 300 dimensional hidden units , and a softmax layer for predicting the output distribution .",Model Setup,Model Setup,semantic_role_labeling,2,"['O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",1,0.07142857142857142,86,0.38392857142857145,1,0.07692307692307693,1,1,hyperparameters
89,"All the weight matrices in BiL - STMs are initialized with random orthonormal matrices as described in. ,",Model Setup,Initialization,semantic_role_labeling,2,"['O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",3,0.21428571428571427,88,0.39285714285714285,3,0.23076923076923078,1,1,hyperparameters
91,All tokens are lower - cased and initialized with 100 - dimensional GloVe embeddings pre-trained on 6B tokens and updated during training .,Model Setup,Initialization,semantic_role_labeling,2,"['O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'O']",5,0.35714285714285715,90,0.4017857142857143,5,0.38461538461538464,1,1,hyperparameters
92,Tokens that are not covered by GloVe are replaced with a randomly initialized UNK embedding .,Model Setup,Initialization,semantic_role_labeling,2,"['B', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.42857142857142855,91,0.40625,6,0.46153846153846156,1,1,hyperparameters
93,"Training We use Adadelta ( Zeiler , 2012 ) with = 1e ?6 and ? = 0.95 and mini-batches of size 80 .",Model Setup,Initialization,semantic_role_labeling,2,"['O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'O']","['O', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'B-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'O', 'B-p', 'B-ob', 'O']",7,0.5,92,0.4107142857142857,7,0.5384615384615384,1,1,hyperparameters
94,We set RNN - dropout probability to 0.1 and clip gradients with norm larger than 1 .,Model Setup,Initialization,semantic_role_labeling,2,"['O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'O']",8,0.5714285714285714,93,0.41517857142857145,8,0.6153846153846154,1,1,hyperparameters
95,All the models are trained for 500 epochs with early stopping based on development results .,Model Setup,Initialization,semantic_role_labeling,2,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",9,0.6428571428571429,94,0.41964285714285715,9,0.6923076923076923,1,1,hyperparameters
103,Our ensemble ( PoE ) has an absolute improvement of 2.1 F1 on both CoNLL 2005 and CoNLL 2012 over the previous state of the art .,Results,Results,semantic_role_labeling,2,"['B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",2,0.0196078431372549,102,0.45535714285714285,2,0.125,1,1,results
104,Our single model also achieves more than a 0.4 improvement on both datasets .,Results,Results,semantic_role_labeling,2,"['B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",3,0.029411764705882353,103,0.45982142857142855,3,0.1875,1,1,results
105,"In comparison with the best reported results , our percentage of completely correct predicates improves by 5.9 points .",Results,Results,semantic_role_labeling,2,"['B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",4,0.0392156862745098,104,0.4642857142857143,4,0.25,1,1,results
106,"While the continuing trend of improving SRL without syntax seems to suggest that neural end - to - end systems no longer needs parsers , our analysis in Section 4.4 will show that accurate syntactic information can improve these deep models .",Results,Results,semantic_role_labeling,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.049019607843137254,105,0.46875,5,0.3125,1,1,results
108,"Without dropout , the model overfits at around 300 epochs at 78 F1 .",Results,Results,semantic_role_labeling,2,"['B', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O']",7,0.06862745098039216,107,0.47767857142857145,7,0.4375,1,1,ablation-analysis
109,"Orthonormal parameter initialization is surprisingly important - without this , the model achieves only 65 F1 within the first 50 epochs .",Results,Results,semantic_role_labeling,2,"['B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.0784313725490196,108,0.48214285714285715,8,0.5,1,1,ablation-analysis
110,All 8 layer ablations suffer a loss of more than 1.7 in absolute F 1 compared to the full model .,Results,Results,semantic_role_labeling,2,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",9,0.08823529411764706,109,0.48660714285714285,9,0.5625,1,1,ablation-analysis
2,Deep Semantic Role Labeling with Self - Attention,title,,semantic_role_labeling,3,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.003787878787878788,1,0.0,1,1,research-problem
4,Semantic Role Labeling ( SRL ) is believed to be a crucial step towards natural language understanding and has been widely studied .,abstract,abstract,semantic_role_labeling,3,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.011363636363636364,1,0.14285714285714285,1,1,research-problem
7,"In this paper , we present a simple and effective architecture for SRL which aims to address these problems .",abstract,abstract,semantic_role_labeling,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.5714285714285714,6,0.022727272727272728,4,0.5714285714285714,1,1,research-problem
12,"Semantic Role Labeling is a shallow semantic parsing task , whose goal is to determine essentially "" who did what to whom "" , "" when "" and "" where "" .",Introduction,Introduction,semantic_role_labeling,3,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.007352941176470588,11,0.041666666666666664,1,0.037037037037037035,1,1,research-problem
29,"To address these problems above , we present a deep attentional neural network ( DEEPATT ) for the task of SRL 1 .",Introduction,Introduction,semantic_role_labeling,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'B', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'O', 'B-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'O', 'B-ob', 'O', 'O']",18,0.1323529411764706,28,0.10606060606060606,18,0.6666666666666666,1,1,model
30,Our models rely on the self - attention mechanism which directly draws the global dependencies of the inputs .,Introduction,Introduction,semantic_role_labeling,3,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",19,0.13970588235294118,29,0.10984848484848485,19,0.7037037037037037,1,1,model
31,"In contrast to RNNs , a major advantage of self - attention is that it conducts direct connections between two arbitrary tokens in a sentence .",Introduction,Introduction,semantic_role_labeling,3,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",20,0.14705882352941177,30,0.11363636363636363,20,0.7407407407407407,1,1,model
32,"Therefore , distant elements can interact with each other by shorter paths ( O ( 1 ) v.s. O ( n ) ) , which allows unimpeded information flow through the network .",Introduction,Introduction,semantic_role_labeling,3,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",21,0.15441176470588236,31,0.11742424242424243,21,0.7777777777777778,1,1,model
33,"Self - attention also provides a more flexible way to select , represent and synthesize the information of the inputs and is complementary to RNN based models .",Introduction,Introduction,semantic_role_labeling,3,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",22,0.16176470588235295,32,0.12121212121212122,22,0.8148148148148148,1,1,model
34,"Along with self - attention , DEEP - ATT comes with three variants which uses recurrent ( RNN ) , convolutional ( CNN ) and feed - forward ( FFN ) neural network to further enhance the representations .",Introduction,Introduction,semantic_role_labeling,3,"['B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'O']",23,0.16911764705882354,33,0.125,23,0.8518518518518519,1,1,model
157,We initialize the weights of all sub-layers as random orthogonal matrices .,Model Setup,Initialization,semantic_role_labeling,3,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.08695652173913043,156,0.5909090909090909,2,0.3333333333333333,1,1,hyperparameters
158,"For other parameters , we initialize them by sampling each element from a Gaussian distribution with mean 0 and variance 1 ? d .",Model Setup,Initialization,semantic_role_labeling,3,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.13043478260869565,157,0.5946969696969697,3,0.5,1,1,hyperparameters
159,The embedding layer can be initialized randomly or using pre-trained word embeddings .,Model Setup,Initialization,semantic_role_labeling,3,"['O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.17391304347826086,158,0.5984848484848485,4,0.6666666666666666,1,1,hyperparameters
164,The dimension of word embeddings and predicate mask embeddings is set to 100 and the number of hidden layers is set to 10 .,Model Setup,Settings and Regularization,semantic_role_labeling,3,"['O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O']",,,9,0.391304347826087,163,0.6174242424242424,2,0.125,1,1,hyperparameters
165,We set the number of hidden units d to 200 .,Model Setup,Settings and Regularization,semantic_role_labeling,3,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",10,0.43478260869565216,164,0.6212121212121212,3,0.1875,1,1,hyperparameters
166,The number of heads h is set to 8 .,Model Setup,Settings and Regularization,semantic_role_labeling,3,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",11,0.4782608695652174,165,0.625,4,0.25,1,1,hyperparameters
168,Dropout layers are added before residual connections with a keep probability of 0.8 .,Model Setup,Settings and Regularization,semantic_role_labeling,3,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",13,0.5652173913043478,167,0.6325757575757576,6,0.375,1,1,hyperparameters
169,"Dropout is also applied before the attention softmax layer and the feed - froward ReLU hidden layer , and the keep probabilities are set to 0.9 .",Model Setup,Settings and Regularization,semantic_role_labeling,3,"['B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",14,0.6086956521739131,168,0.6363636363636364,7,0.4375,1,1,hyperparameters
170,We also employ label smoothing technique with a smoothing value of 0.1 during training .,Model Setup,Settings and Regularization,semantic_role_labeling,3,"['O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O']",15,0.6521739130434783,169,0.6401515151515151,8,0.5,1,1,hyperparameters
171,Learning Parameter optimization is performed using stochastic gradient descent .,Model Setup,Settings and Regularization,semantic_role_labeling,3,"['B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",16,0.6956521739130435,170,0.6439393939393939,9,0.5625,1,1,hyperparameters
172,We adopt Adadelta ) ( = 10 6 and ? = 0.95 ) as the optimizer .,Model Setup,Settings and Regularization,semantic_role_labeling,3,"['O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O']","['O', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'O']","['O', 'B-p', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'O']",17,0.7391304347826086,171,0.6477272727272727,10,0.625,1,1,hyperparameters
173,"To avoid exploding gradients problem , we clip the norm of gradients with a predefined threshold 1.0 .",Model Setup,Settings and Regularization,semantic_role_labeling,3,"['B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",18,0.782608695652174,172,0.6515151515151515,11,0.6875,1,1,hyperparameters
174,Each SGD contains a mini-batch of approximately 4096 tokens for the CoNLL - 2005 dataset and 8192 tokens for the CoNLL - 2012 dataset .,Model Setup,Settings and Regularization,semantic_role_labeling,3,"['O', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']",,,19,0.8260869565217391,173,0.6553030303030303,12,0.75,1,1,hyperparameters
175,The learning rate is initialized to 1.0 .,Model Setup,Settings and Regularization,semantic_role_labeling,3,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",20,0.8695652173913043,174,0.6590909090909091,13,0.8125,1,1,hyperparameters
176,"After training 400 k steps , we halve the learning rate every 100 K steps .",Model Setup,Settings and Regularization,semantic_role_labeling,3,"['B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",21,0.9130434782608695,175,0.6628787878787878,14,0.875,1,1,hyperparameters
177,We train all models for 600 K steps .,Model Setup,Settings and Regularization,semantic_role_labeling,3,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",22,0.9565217391304348,176,0.6666666666666666,15,0.9375,1,1,hyperparameters
178,"For DEEP - ATT with FFN sub - layers , the whole training stage takes about two days to finish on a single Titan X GPU , which is 2.5 times faster than the previous approach ) .",Model Setup,Settings and Regularization,semantic_role_labeling,3,"['B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",23,1.0,177,0.6704545454545454,16,1.0,1,1,hyperparameters
180,"In Remarkably , we get 74.1 F 1 score on the out - of - domain dataset , which outperforms the previous state - of - the - art system by 2.0 F 1 score .",Results,Results,semantic_role_labeling,3,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,179,0.678030303030303,1,0.25,1,1,results
182,"When ensembling 5 models with FFN nonlinear sub - layers , our approach achieves an F 1 score of 84.6 and 83.9 on the two datasets respectively , which has an absolute improvement of 1.4 and 0.5 over the previous state - of - the - art .",Results,Results,semantic_role_labeling,3,"['B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,3,0.42857142857142855,181,0.6856060606060606,3,0.75,1,1,results
183,These results are consistent with our intuition that the self - attention layers is helpful to capture structural information and long distance dependencies .,Results,Results,semantic_role_labeling,3,"['O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.5714285714285714,182,0.6893939393939394,4,1.0,1,1,results
2,A Span Selection Model for Semantic Role Labeling,title,,semantic_role_labeling,4,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0033333333333333335,1,0.0,1,1,research-problem
4,We present a simple and accurate span - based model for semantic role labeling ( SRL ) .,abstract,abstract,semantic_role_labeling,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.2,3,0.01,1,0.2,1,1,research-problem
11,"Given a sentence and a target predicate , SRL systems have to predict semantic arguments of the predicate .",Introduction,Introduction,semantic_role_labeling,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.02531645569620253,10,0.03333333333333333,2,0.07692307692307693,1,1,research-problem
23,"To fill this gap , this paper presents a simple and accurate span - based model .",Introduction,Introduction,semantic_role_labeling,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.17721518987341772,22,0.07333333333333333,14,0.5384615384615384,1,1,model
24,"Inspired by recent span - based models in syntactic parsing and coreference resolution , our model directly scores all possible labeled spans based on span representations induced from neural networks .",Introduction,Introduction,semantic_role_labeling,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",15,0.189873417721519,23,0.07666666666666666,15,0.5769230769230769,1,1,model
25,"At decoding time , we greedily select higher scoring labeled spans .",Introduction,Introduction,semantic_role_labeling,4,"['B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.20253164556962025,24,0.08,16,0.6153846153846154,1,1,model
26,The model parameters are learned by optimizing loglikelihood of correct labeled spans .,Introduction,Introduction,semantic_role_labeling,4,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.21518987341772153,25,0.08333333333333333,17,0.6538461538461539,1,1,model
157,"For comparison , as a model based on BIO tagging approaches , we use the BiLSTM - CRF model proposed by .",Baseline Model,Baseline Model,semantic_role_labeling,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",1,0.5,156,0.52,1,0.5,1,1,baselines
160,"As the base function f base , we use 4 BiLSTM layers with 300 dimensional hidden units .",Model Setup,Model Setup,semantic_role_labeling,4,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.08333333333333333,159,0.53,1,0.3333333333333333,1,1,hyperparameters
161,"To optimize the model parameters , we use Adam .",Model Setup,Model Setup,semantic_role_labeling,4,"['O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'O']",2,0.16666666666666666,160,0.5333333333333333,2,0.6666666666666666,1,1,hyperparameters
165,"To validate the model performance , we use two types of word embeddings .",Model Setup,Word Embeddings,semantic_role_labeling,4,"['B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.5,164,0.5466666666666666,2,0.25,1,1,hyperparameters
166,"Typical word embeddings , SENNA 6 ( Collobert et al. , 2011 ) Contextualized word embeddings , ELMo 7 SENNA and ELMo can be regarded as different types of embeddings in terms of the context sensitivity .",Model Setup,Word Embeddings,semantic_role_labeling,4,"['B', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.5833333333333334,165,0.55,3,0.375,1,1,hyperparameters
171,These embeddings are fixed during training .,Model Setup,Word Embeddings,semantic_role_labeling,4,"['O', 'B', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",12,1.0,170,0.5666666666666667,8,1.0,1,1,hyperparameters
173,"As the objective function , we use the crossentropy L ? in Eq. 3 with L2 weight decay ,",Training,Training,semantic_role_labeling,4,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.3333333333333333,172,0.5733333333333334,1,0.3333333333333333,1,1,hyperparameters
177,We report averaged scores across five different runs of the model training .,Results,Results,semantic_role_labeling,4,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O']",1,0.010526315789473684,176,0.5866666666666667,1,0.14285714285714285,1,1,results
179,"Overall , our span - based ensemble model using ELMo achieved the best F1 scores , 87.4 F1 and 87.0 F1 on the CoNLL - 2005 and CoNLL - 2012 datasets , respectively .",Results,Results,semantic_role_labeling,4,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",3,0.031578947368421054,178,0.5933333333333334,3,0.42857142857142855,1,1,results
180,"In comparison with the CRF - based single model , our span - based single model consistently yielded better F 1 scores regardless of the word embeddings , SENNA and ELMO .",Results,Results,semantic_role_labeling,4,"['B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.042105263157894736,179,0.5966666666666667,4,0.5714285714285714,1,1,results
183,Our single and ensemble models using ELMO achieved the best F 1 scores on all the test sets except the Brown test set .,Results,Results,semantic_role_labeling,4,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",7,0.07368421052631578,182,0.6066666666666667,7,1.0,1,1,results
2,Structural Scaffolds for Citation Intent Classification in Scientific Publications,title,title,sentence_classification,0,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.003745318352059925,1,0.0,1,1,research-problem
4,"Identifying the intent of a citation in scientific papers ( e.g. , background information , use of methods , comparing results ) is critical for machine reading of individual publications and automated analysis of the scientific literature .",abstract,abstract,sentence_classification,0,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.011235955056179775,1,0.2,1,1,research-problem
8,Our code and data are available at : https://github.com/ allenai/scicite .,abstract,abstract,sentence_classification,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",5,1.0,7,0.026217228464419477,5,1.0,1,1,code
19,"In this work , we approach the problem of citation intent classification by modeling the language expressed in the citation context .",Introduction,The nature of citations can be different .,sentence_classification,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.5555555555555556,18,0.06741573033707865,10,0.5555555555555556,1,1,research-problem
23,"To this end , we propose a neural multitask learning framework to incorporate knowledge into citations from the structure of scientific papers .",Introduction,The nature of citations can be different .,sentence_classification,0,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.7777777777777778,22,0.08239700374531835,14,0.7777777777777778,1,1,model
24,"In particular , we propose two auxiliary tasks as structural scaffolds to improve citation intent prediction : 1 ( 1 ) predicting the section title in which the citation occurs and ( 2 ) predicting whether a sentence needs a citation .",Introduction,The nature of citations can be different .,sentence_classification,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.8333333333333334,23,0.08614232209737828,15,0.8333333333333334,1,1,model
26,"On two datasets , we show that the proposed neural scaffold model outperforms existing methods by large margins .",Introduction,The nature of citations can be different .,sentence_classification,0,"['B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",17,0.9444444444444444,25,0.09363295880149813,17,0.9444444444444444,1,1,model
27,"Our contributions are : ( i ) we propose a neural scaffold framework for citation intent classification to incorporate into citations knowledge from structure of scientific papers ; ( ii ) we achieve a new state - of - the - art of 67.9 % F1 on the ACL - ARC citations benchmark , an absolute 13.3 % increase over the previous state - of - the - art ; and ( iii ) we introduce SciCite , a new dataset of citation intents which is at least five times as large as existing datasets and covers a variety of scientific domains .",Introduction,The nature of citations can be different .,sentence_classification,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,1.0,26,0.09737827715355805,18,1.0,1,1,model
121,"To address these limitations , we introduce Sci - Cite , a new dataset of citation intents that is significantly larger , more coarse - grained and generaldomain compared with existing datasets .",Method,SciCite dataset,sentence_classification,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",21,0.40384615384615385,120,0.449438202247191,5,0.5,1,1,dataset
125,"We consider three intent categories outlined in : BACK - GROUND , METHOD and RESULTCOMPARISON .",Method,SciCite dataset,sentence_classification,0,"['O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'B-ob', 'O']",25,0.4807692307692308,124,0.46441947565543074,9,0.9,1,1,dataset
128,Citation intent of sentence extractions was labeled through the crowdsourcing platform .,Method,Data collection and annotation,sentence_classification,0,"['B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",28,0.5384615384615384,127,0.4756554307116105,1,0.05555555555555555,1,1,dataset
142,"Citation contexts were annotated by 850 crowdsource workers who made a total of 29,926 annotations and individually made between 4 and 240 annotations .",Method,Annotations were dynamically collected .,sentence_classification,0,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",42,0.8076923076923077,141,0.5280898876404494,15,0.8333333333333334,1,1,dataset
143,"Each sentence was annotated , on average , 3.74 times .",Method,Annotations were dynamically collected .,sentence_classification,0,"['O', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",43,0.8269230769230769,142,0.5318352059925093,16,0.8888888888888888,1,1,dataset
144,"This resulted in a total 9,159 crowdsourced instances which were divided to training and validation sets with 90 % of the data used for the training set .",Method,Annotations were dynamically collected .,sentence_classification,0,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",44,0.8461538461538461,143,0.5355805243445693,17,0.9444444444444444,1,1,dataset
155,We implement our proposed scaffold framework using the AllenNLP library .,Implementation,Implementation,sentence_classification,0,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",1,0.0625,154,0.5767790262172284,1,0.0625,1,1,hyperparameters
156,"For word representations , we use 100 - dimensional GloVe vectors trained on a corpus of 6B tokens from Wikipedia and Gigaword .",Implementation,Implementation,sentence_classification,0,"['B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.125,155,0.5805243445692884,2,0.125,1,1,hyperparameters
157,"For contextual representations , we use ELMo vectors released by with output dimension size of 1,024 which have been trained on a dataset of 5.5 B tokens .",Implementation,Implementation,sentence_classification,0,"['O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'O']",,,3,0.1875,156,0.5842696629213483,3,0.1875,1,1,hyperparameters
158,We use a single - layer BiLSTM with a hidden dimension size of 50 for each direction 11 .,Implementation,Implementation,sentence_classification,0,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O']",4,0.25,157,0.5880149812734082,4,0.25,1,1,hyperparameters
159,"For each of scaffold tasks , we use a single - layer MLP with 20 hidden nodes , ReLU activation and a Dropout rate of 0.2 between the hidden and input layers .",Implementation,Implementation,sentence_classification,0,"['O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",5,0.3125,158,0.5917602996254682,5,0.3125,1,1,hyperparameters
164,Batch size is 8 for ACL - ARC dataset and 32 for SciCite dataset ( recall that SciCite is larger than ACL - ARC ) .,Implementation,Implementation,sentence_classification,0,"['B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,10,0.625,163,0.6104868913857678,10,0.625,1,1,hyperparameters
165,We use Beaker 12 for running the experiments .,Implementation,,sentence_classification,0,"['O', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",11,0.6875,164,0.6142322097378277,11,0.6875,1,1,hyperparameters
173,BiLSTM Attention ( with and without ELMo ) .,Baselines,,sentence_classification,0,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",2,0.2857142857142857,172,0.6441947565543071,2,0.2857142857142857,1,1,baselines
174,"This baseline uses a similar architecture to our proposed neural multitask learning framework , except that it only optimizes the network for the main loss regarding the citation intent classification ( L 1 ) and does not include the structural scaffolds .",Baselines,BiLSTM Attention ( with and without ELMo ) .,sentence_classification,0,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.42857142857142855,173,0.6479400749063671,3,0.42857142857142855,1,1,baselines
181,We observe that our scaffold - enhanced models achieve clear improvements over the state - of - the - art approach on this task .,Results,Results,sentence_classification,0,"['O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",2,0.03333333333333333,180,0.6741573033707865,2,0.09523809523809523,1,1,results
182,"Starting with the ' BiLSTM - Attn ' baseline with a macro F1 score of 51.8 , adding the first scaffold task in ' BiLSTM - Attn + section title scaffold ' improves the F1 score to 56.9 (?= 5.1 ) .",Results,Results,sentence_classification,0,"['B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.05,181,0.6779026217228464,3,0.14285714285714285,1,1,results
183,Adding the second scaffold in ' BiLSTM - Attn + citation worthiness scaffold ' also results in similar improvements : 56.3 (?= 4.5 ) .,Results,Results,sentence_classification,0,"['B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.06666666666666667,182,0.6816479400749064,4,0.19047619047619047,1,1,results
184,"When both scaffolds are used simultaneously in ' BiLSTM - Attn + both scaffolds ' , the F1 score further improves to 63.1 ( ?= 11.3 ) , suggesting that the two tasks provide complementary signal that is useful for citation intent prediction .",Results,Results,sentence_classification,0,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.08333333333333333,183,0.6853932584269663,5,0.23809523809523808,1,1,results
185,"The best result is achieved when we also add ELMo vectors to the input representations in ' BiLSTM - Attn w / ELMo + both scaffolds ' , achieving an F1 of 67.9 , a major improvement from the previous state - of - the - art results of 54.6 ( ?= 13.3 ) .",Results,Results,sentence_classification,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']",,,6,0.1,184,0.6891385767790262,6,0.2857142857142857,1,1,results
186,"We note that the scaffold tasks provide major contributions on top of the ELMo - enabled baseline ( ?= 13.6 ) , demonstrating the efficacy of using structural scaffolds for citation intent prediction .",Results,Results,sentence_classification,0,"['O', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.11666666666666667,185,0.6928838951310862,7,0.3333333333333333,1,1,results
188,"We also experimented with adding features used in to our best model and not only we did not see any improvements , but we observed at least 1.7 % decline in performance .",Results,Results,sentence_classification,0,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",9,0.15,187,0.700374531835206,9,0.42857142857142855,1,1,results
191,Each scaffold task improves model performance .,Results,,sentence_classification,0,"['B', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",12,0.2,190,0.7116104868913857,12,0.5714285714285714,1,1,results
192,Adding both scaffolds results in further improvements .,Results,,sentence_classification,0,"['O', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",13,0.21666666666666667,191,0.7153558052434457,13,0.6190476190476191,1,1,results
193,And the best results are obtained by using ELMo representation in addition to both scaffolds .,Results,Adding both scaffolds results in further improvements .,sentence_classification,0,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-s', 'I-s', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",14,0.23333333333333334,192,0.7191011235955056,14,0.6666666666666666,1,1,results
197,Generally we observe that results on categories with more number of instances are higher .,Results,Adding both scaffolds results in further improvements .,sentence_classification,0,"['O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",18,0.3,196,0.7340823970037453,18,0.8571428571428571,1,1,results
198,"For example on ACL - ARC , the results on the BACKGROUND category are the highest as this category is the most common .",Results,Adding both scaffolds results in further improvements .,sentence_classification,0,"['O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O']",,,19,0.31666666666666665,197,0.7378277153558053,19,0.9047619047619048,1,1,results
199,"Conversely , the results on the FUTUREWORK category are the lowest .",Results,Adding both scaffolds results in further improvements .,sentence_classification,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",20,0.3333333333333333,198,0.7415730337078652,20,0.9523809523809523,1,1,results
200,This category has the fewest data points ( see distribution of the categories in ) and thus it is harder for the model to learn the optimal parameters for correct classification in this category .,Results,Adding both scaffolds results in further improvements .,sentence_classification,0,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O']",,,21,0.35,199,0.7453183520599251,21,1.0,1,1,results
2,Hierarchical Neural Networks for Sequential Sentence Classification in Medical Scientific Abstracts,title,title,sentence_classification,1,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.005780346820809248,1,0.0,1,1,research-problem
5,"This hampers the traditional sentence classification approaches to the problem of sequential sentence classification , where structured prediction is needed for better over all classification performance .",abstract,abstract,sentence_classification,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.5,4,0.023121387283236993,2,0.5,1,1,research-problem
21,"In this work , we present a hierarchical neural network model for the sequential sentence classification task , which we call a hierarchical sequential labeling network ( HSLN ) .",Introduction,Introduction,sentence_classification,1,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.48148148148148145,20,0.11560693641618497,13,0.48148148148148145,1,1,model
22,"Our model first uses a RNN or CNN layer to individually encode the sentence representation from the sequence of word embeddings , then uses another bi - LSTM layer to take as input the individual sentence representation and output the contextualized sentence representation , subsequently uses a single - hidden - layer feed - forward network to transform the sentence representation to the probability vector , and finally optimizes the predicted label sequence jointly via a CRF layer .",Introduction,Introduction,sentence_classification,1,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,14,0.5185185185185185,21,0.12138728323699421,14,0.5185185185185185,1,1,model
110,"The token embeddings were pre-trained on a large corpus combining Wikipedia , PubMed , and PMC texts ( Moen and Ananiadou , 2013 ) using the word2vec tool 4 ( denoted as "" Word2vec- wiki+P.M. "" ) .",Training Settings,Training Settings,sentence_classification,1,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.13333333333333333,109,0.630057803468208,2,0.13333333333333333,1,1,hyperparameters
111,They are fixed during the training phase to avoid over-fitting .,Training Settings,Training Settings,sentence_classification,1,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",3,0.2,110,0.6358381502890174,3,0.2,1,1,hyperparameters
115,"The model is trained using the Adam optimization method ( Kingma and Ba , 2014 ) .",Training Settings,Training Settings,sentence_classification,1,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.4666666666666667,114,0.6589595375722543,7,0.4666666666666667,1,1,hyperparameters
116,The learning rate is initially set as 0.003 and decayed by 0.9 after each epoch .,Training Settings,Training Settings,sentence_classification,1,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.5333333333333333,115,0.6647398843930635,8,0.5333333333333333,1,1,hyperparameters
117,"For regularization , dropout ( Srivastava et al. , 2014 ) is applied to each layer .",Training Settings,Training Settings,sentence_classification,1,"['B', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['B-p', 'B-n', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",9,0.6,116,0.6705202312138728,9,0.6,1,1,hyperparameters
119,"To reduce this gap , we adopted the dropout with expectation - linear regularization introduced by to explicitly control the inference gap and thus improve the generaliza - tion performance .",Training Settings,Training Settings,sentence_classification,1,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.7333333333333333,118,0.6820809248554913,11,0.7333333333333333,1,1,hyperparameters
120,Hyperparameters were optimized via grid search based on the validation set and the best configuration is shown in .,Training Settings,Training Settings,sentence_classification,1,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.8,119,0.6878612716763006,12,0.8,1,1,hyperparameters
121,"The window sizes of the CNN encoder in the sentence encoding layer are 2 , 3 , 4 and 5 .",Training Settings,Training Settings,sentence_classification,1,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.8666666666666667,120,0.6936416184971098,13,0.8666666666666667,1,1,hyperparameters
129,"As can be seen from , our HSLN - CNN model uni-formly suffers a little more from the component removal than the HSLN - RNN model , indicating that the HSLN - RNN model is more robust .",Results and Discussion,Results and Discussion,sentence_classification,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.625,128,0.7398843930635838,5,0.125,1,1,ablation-analysis
130,"When the context enriching layer is removed , both models experience the most significant performance drop and can only be on par with the previous stateof - the - art results , strongly demonstrating that this proposed component is the key to the performance improvement of our model .",Results and Discussion,Results and Discussion,sentence_classification,1,"['B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.75,129,0.7456647398843931,6,0.15,1,1,ablation-analysis
131,"Furthermore , even without the label sequence optimization layer , our model still significantly outperforms the best published methods that are empowered by this layer , indicating that the context enriching layer we propose can help optimize the label sequence by considering the context information from the surrounding sentences .",Results and Discussion,Results and Discussion,sentence_classification,1,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.875,130,0.7514450867052023,7,0.175,1,1,ablation-analysis
132,"Last but not the least , the dropout regularization and attention - based pooling components we add to our system can help further improve the model in a limited extent . :",Results and Discussion,Results and Discussion,sentence_classification,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O']",8,1.0,131,0.7572254335260116,8,0.2,1,1,ablation-analysis
2,Translations as Additional Contexts for Sentence Classification,title,,sentence_classification,2,"['O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.003968253968253968,1,0.0,1,1,research-problem
20,"In this paper , we propose the usage of translations as compelling and effective domain - free contexts , or contexts that are always available no matter what the task domain is .",Introduction,Introduction,sentence_classification,2,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.12162162162162163,19,0.07539682539682539,9,0.21951219512195122,1,1,approach
37,"In this paper , we propose a method to mitigate the possible problems when using translated sentences as context based on the following observations .",Introduction,Introduction,sentence_classification,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O']",26,0.35135135135135137,36,0.14285714285714285,26,0.6341463414634146,1,1,approach
42,"Based on these observations , we present a neural attentionbased multiple context fixing attachment ( MCFA ) .",Introduction,Introduction,sentence_classification,2,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",31,0.4189189189189189,41,0.1626984126984127,31,0.7560975609756098,1,1,approach
43,"MCFA is a series of modules that uses all the sentence vectors ( e.g. Arabic , English , Korean , etc. ) as context to fix a sentence vector ( e.g. Korean ) .",Introduction,Introduction,sentence_classification,2,"['B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",32,0.43243243243243246,42,0.16666666666666666,32,0.7804878048780488,1,1,approach
46,MCFA computes two sentence usability metrics to control the noise when fixing vectors : ( a ) self usability ? i ( a ) weighs the confidence of using sentence a in solving the task .,Introduction,Introduction,sentence_classification,2,"['O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",35,0.47297297297297297,45,0.17857142857142858,35,0.8536585365853658,1,1,approach
47,"( b ) relative usability ? r ( a , b ) weighs the confidence of using sentence a in fixing sentence b.",Introduction,Introduction,sentence_classification,2,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'O']",36,0.4864864864864865,46,0.18253968253968253,36,0.8780487804878049,1,1,approach
49,"( 1 ) MCFA is attached after encoding the sentence , which makes it widely adaptable to other models .",Introduction,Introduction,sentence_classification,2,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",38,0.5135135135135135,48,0.19047619047619047,38,0.926829268292683,1,1,approach
51,"( 3 ) MCFA moves the vectors inside the same space , thus preserves the meaning of vector dimensions .",Introduction,Introduction,sentence_classification,2,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",40,0.5405405405405406,50,0.1984126984126984,40,0.975609756097561,1,1,approach
150,Tokenization is done using the polyglot library 7 .,Experimental Setting,Experimental Setting,sentence_classification,2,"['B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O']","['B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O']","['B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O']",10,0.38461538461538464,149,0.5912698412698413,10,0.38461538461538464,1,1,hyperparameters
151,We experiment on using only one additional context ( N = 1 ) and using all ten languages at once ( N = 10 ) .,Experimental Setting,Experimental Setting,sentence_classification,2,"['O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.4230769230769231,150,0.5952380952380952,11,0.4230769230769231,1,1,hyperparameters
153,"For our CNN , we use rectified linear units and three filters with different window sizes h = 3 , 4 , 5 with 100 feature maps each , following .",Experimental Setting,Experimental Setting,sentence_classification,2,"['B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.5,152,0.6031746031746031,13,0.5,1,1,hyperparameters
154,"For the final sentence vector , we concatenate the feature maps to get a 300 - dimension vector .",Experimental Setting,Experimental Setting,sentence_classification,2,"['O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.5384615384615384,153,0.6071428571428571,14,0.5384615384615384,1,1,hyperparameters
155,We use dropout on all nonlinear connections with a dropout rate of 0.5 .,Experimental Setting,Experimental Setting,sentence_classification,2,"['O', 'B', 'B', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",15,0.5769230769230769,154,0.6111111111111112,15,0.5769230769230769,1,1,hyperparameters
156,"We also use an l 2 constraint of 3 , following for accurate comparisons .",Experimental Setting,Experimental Setting,sentence_classification,2,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.6153846153846154,155,0.6150793650793651,16,0.6153846153846154,1,1,hyperparameters
157,We use FastText pre-trained vectors 8 for all our data sets and their corresponding additional context .,Experimental Setting,Experimental Setting,sentence_classification,2,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.6538461538461539,156,0.6190476190476191,17,0.6538461538461539,1,1,hyperparameters
158,"During training , we use mini-batch size of 50 .",Experimental Setting,Experimental Setting,sentence_classification,2,"['B', 'B', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",18,0.6923076923076923,157,0.623015873015873,18,0.6923076923076923,1,1,hyperparameters
159,Training is done via stochastic gradient descent over shuffled mini-batches with the Adadelta update rule .,Experimental Setting,Experimental Setting,sentence_classification,2,"['B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",19,0.7307692307692307,158,0.626984126984127,19,0.7307692307692307,1,1,hyperparameters
160,We perform early stopping using a random 10 % of the training set as the development set .,Experimental Setting,Experimental Setting,sentence_classification,2,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",20,0.7692307692307693,159,0.6309523809523809,20,0.7692307692307693,1,1,hyperparameters
169,We show that CNN + MCFA achieves state of the art performance on three of the four data sets and performs competitively on one data set .,Results and Discussion,Results and Discussion,sentence_classification,2,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'O']",,,2,0.08333333333333333,168,0.6666666666666666,2,0.08333333333333333,1,1,results
170,"When N = 1 , MCFA increases the performance of a normal CNN from 85.0 to 87.6 , beating the current state of the art on the CR data set .",Results and Discussion,Results and Discussion,sentence_classification,2,"['B', 'B', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.125,169,0.6706349206349206,3,0.125,1,1,results
171,"When N = 10 , MCFA additionally beats the state of the art on the TREC data set .",Results and Discussion,Results and Discussion,sentence_classification,2,"['O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.16666666666666666,170,0.6746031746031746,4,0.16666666666666666,1,1,results
172,"Finally , our ensemble classifier additionally outperforms all competing models on the MR data set .",Results and Discussion,Results and Discussion,sentence_classification,2,"['O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",5,0.20833333333333334,171,0.6785714285714286,5,0.20833333333333334,1,1,results
186,"On all data sets except SUBJ , the accuracy of CNN + B1 decreases from the base CNN accuracy , while the accuracy of our model always improves from the base CNN accuracy .",Results and Discussion,Results and Discussion,sentence_classification,2,"['B', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.7916666666666666,185,0.7341269841269841,19,0.7916666666666666,1,1,results
188,"We also compare two different kinds of additional context : topics ( TopCNN ) and translations ( CNN + B1 , CNN + B2 , CNN + MCFA ) .",Results and Discussion,Results and Discussion,sentence_classification,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.875,187,0.7420634920634921,21,0.875,1,1,results
189,"Overall , we conclude that translations are better additional contexts than topics .",Results and Discussion,Results and Discussion,sentence_classification,2,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'O']",22,0.9166666666666666,188,0.746031746031746,22,0.9166666666666666,1,1,results
190,"When using a single context ( i.e. TopCNN word , TopCNN sent , and our models when N = 1 ) , translations always outperform topics even when using the baseline methods .",Results and Discussion,Results and Discussion,sentence_classification,2,"['O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",23,0.9583333333333334,189,0.75,23,0.9583333333333334,1,1,results
191,"Using topics as additional context also decreases the performance of the CNN classifier on most data sets , giving an adverse effect to the CNN classifier .",Results and Discussion,Results and Discussion,sentence_classification,2,"['B', 'B', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",24,1.0,190,0.753968253968254,24,1.0,1,1,results
2,Can Syntax Help ? Improving an LSTM - based Sentence Compression Model for New Domains,title,title,sentence_compression,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.0035842293906810036,1,0.0,1,1,research-problem
28,"To this end , we extend the deletionbased LSTM model for sentence compression by .",Introduction,Introduction,sentence_compression,0,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O']",20,0.5714285714285714,27,0.0967741935483871,20,0.5714285714285714,1,1,model
35,"Specifically , we propose two major changes to the model by : We explicitly introduce POS embeddings and dependency relation embeddings into the neural network model .",Introduction,Introduction,sentence_compression,0,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",27,0.7714285714285715,34,0.12186379928315412,27,0.7714285714285715,1,1,model
36,"( 2 ) Inspired by a previous method , we formulate the final predictions as an Integer Linear Programming problem to incorporate constraints based on syntactic relations between words and expected lengths of the compressed sentences .",Introduction,Introduction,sentence_compression,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",28,0.8,35,0.12544802867383512,28,0.8,1,1,model
37,"In addition to the two major changes above , we also use bi-directional LSTM to include contextual information from both directions into the model .",Introduction,Introduction,sentence_compression,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",29,0.8285714285714286,36,0.12903225806451613,29,0.8285714285714286,1,1,model
165,"In the experiments , our model was trained using the Adam algorithm with a learning rate initialized at 0.001 .",Datasets and Experiment Settings,Datasets and Experiment Settings,sentence_compression,0,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",19,0.5,164,0.5878136200716846,19,0.5,1,1,hyperparameters
166,The dimension of the hidden layers of bi - LSTM is 100 .,Datasets and Experiment Settings,Datasets and Experiment Settings,sentence_compression,0,"['O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'O']",,,20,0.5263157894736842,165,0.5913978494623656,20,0.5263157894736842,1,1,hyperparameters
167,Word embeddings are initialized from GloVe 100 dimensional pre-trained embeddings .,Datasets and Experiment Settings,Datasets and Experiment Settings,sentence_compression,0,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",21,0.5526315789473685,166,0.5949820788530465,21,0.5526315789473685,1,1,hyperparameters
168,POS and dependency embeddings are randomly initialized with 40 - dimensional vectors .,Datasets and Experiment Settings,Datasets and Experiment Settings,sentence_compression,0,"['B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",22,0.5789473684210527,167,0.5985663082437276,22,0.5789473684210527,1,1,hyperparameters
169,The embeddings are all updated during training .,Datasets and Experiment Settings,Datasets and Experiment Settings,sentence_compression,0,"['O', 'B', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",23,0.6052631578947368,168,0.6021505376344086,23,0.6052631578947368,1,1,hyperparameters
170,Dropping probability for dropout layers between stacked LSTM layers is 0.5 .,Datasets and Experiment Settings,Datasets and Experiment Settings,sentence_compression,0,"['B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",24,0.631578947368421,169,0.6057347670250897,24,0.631578947368421,1,1,hyperparameters
171,The batch size is set as 30 .,Datasets and Experiment Settings,Datasets and Experiment Settings,sentence_compression,0,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",25,0.6578947368421053,170,0.6093189964157706,25,0.6578947368421053,1,1,hyperparameters
174,We utilize an open source ILP solver 4 in our method .,Datasets and Experiment Settings,Datasets and Experiment Settings,sentence_compression,0,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",28,0.7368421052631579,173,0.6200716845878136,28,0.7368421052631579,1,1,hyperparameters
176,LSTM : This is the basic LSTM - based deletion method proposed by .,Datasets and Experiment Settings,Datasets and Experiment Settings,sentence_compression,0,"['B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['B-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",30,0.7894736842105263,175,0.6272401433691757,30,0.7894736842105263,1,1,baselines
178,"LSTM + : This is advanced version of the model proposed by , where the authors incorporated some dependency parse tree information into the LSTM model and used the prediction on the previous word to help the prediction on the current word .",Datasets and Experiment Settings,Datasets and Experiment Settings,sentence_compression,0,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O']",,,32,0.8421052631578947,177,0.6344086021505376,32,0.8421052631578947,1,1,baselines
179,Traditional ILP :,Datasets and Experiment Settings,Datasets and Experiment Settings,sentence_compression,0,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-b', 'I-b', 'O']",33,0.868421052631579,178,0.6379928315412187,33,0.868421052631579,1,1,baselines
180,This is the ILP - based method proposed by .,Datasets and Experiment Settings,Datasets and Experiment Settings,sentence_compression,0,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",34,0.8947368421052632,179,0.6415770609318996,34,0.8947368421052632,1,1,baselines
183,Abstractive seq2seq :,Datasets and Experiment Settings,Datasets and Experiment Settings,sentence_compression,0,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-b', 'I-b', 'O']",37,0.9736842105263158,182,0.6523297491039427,37,0.9736842105263158,1,1,baselines
184,This is an abstractive sequence - to - sequence model trained on 3.8 million Gigaword title - article pairs as described in Section 1 .,Datasets and Experiment Settings,Datasets and Experiment Settings,sentence_compression,0,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",38,1.0,183,0.6559139784946236,38,1.0,1,1,baselines
197,We can see that indeed this abstractive method performed poorly in cross - domain settings .,Automatic Evaluation,Automatic Evaluation,sentence_compression,0,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.375,196,0.7025089605734767,12,0.375,1,1,results
198,"( 2 ) In the in - domain setting , with the same amount of training data ( 8,000 ) , our BiLSTM method with syntactic features ( BiLSTM + SynFeat and BiL - STM + SynFeat + ILP ) performs similarly to or better than the LSTM + method proposed by , in terms of both F1 and accuracy .",Automatic Evaluation,Automatic Evaluation,sentence_compression,0,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.40625,197,0.7060931899641577,13,0.40625,1,1,results
199,This shows that our method is comparable to the LSTM + method in the in - domain setting .,Automatic Evaluation,Automatic Evaluation,sentence_compression,0,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.4375,198,0.7096774193548387,14,0.4375,1,1,results
202,"( 4 ) In the out - of - domain setting , our BiLSTM + SynFeat and BiLSTM+SynFeat+ILP methods clearly outperform the LSTM and LSTM + methods .",Automatic Evaluation,Automatic Evaluation,sentence_compression,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.53125,201,0.7204301075268817,17,0.53125,1,1,results
204,( 5 ) The Traditional ILP method also works better than the LSTM and LSTM + methods in the out - of - domain setting .,Automatic Evaluation,Automatic Evaluation,sentence_compression,0,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.59375,203,0.7275985663082437,19,0.59375,1,1,results
206,But the Traditional ILP method performs worse in the in - domain setting than both the LSTM and LSTM + methods and our methods .,Automatic Evaluation,Automatic Evaluation,sentence_compression,0,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",21,0.65625,205,0.7347670250896058,21,0.65625,1,1,results
208,"Therefore , our method works reasonably well for both in - domain and out - ofdomain data .",Automatic Evaluation,Automatic Evaluation,sentence_compression,0,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",23,0.71875,207,0.7419354838709677,23,0.71875,1,1,results
209,"We also notice that on Google News , adding the ILP layer decreased the sentence compression performance .",Automatic Evaluation,Automatic Evaluation,sentence_compression,0,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",24,0.75,208,0.7455197132616488,24,0.75,1,1,results
216,"We can see that in the in - domain setting , our method does not have any advantage over the LSTM + method .",Automatic Evaluation,Automatic Evaluation,sentence_compression,0,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-s', 'I-s', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",31,0.96875,215,0.7706093189964157,31,0.96875,1,1,results
217,"But in the cross - domain setting , our method that uses ILP to impose syntax - based constraints clearly performs better than LSTM + when the amount of training data is relatively small .",Automatic Evaluation,Automatic Evaluation,sentence_compression,0,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",32,1.0,216,0.7741935483870968,32,1.0,1,1,results
2,Sentence Compression by Deletion with LSTMs,title,,sentence_compression,1,"['B', 'I', 'I', 'I', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",1,0.0,1,0.004784688995215311,1,0.0,1,1,research-problem
4,"We present an LSTM approach to deletion - based sentence compression where the task is to translate a sentence into a sequence of zeros and ones , corresponding to token deletion decisions .",abstract,abstract,sentence_compression,1,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.25,3,0.014354066985645933,1,0.25,1,1,research-problem
9,Sentence compression is a standard NLP task where the goal is to generate a shorter paraphrase of a sentence .,Introduction,Introduction,sentence_compression,1,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0625,8,0.03827751196172249,1,0.0625,1,1,research-problem
19,"In particular , we will present a model which benefits from the very recent advances in deep learning and uses word embeddings and Long Short Term Memory models ( LSTMs ) to output surprisingly readable and informative compressions .",Introduction,Introduction,sentence_compression,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.6875,18,0.0861244019138756,11,0.6875,1,1,model
20,"Trained on a corpus of less than two million automatically extracted parallel sentences and using a standard tool to obtain word embeddings , in its best and most simple configuration it achieves 4.5 points out of 5 in readability and 3.8 points in informativeness in an extensive evaluation with human judges .",Introduction,Introduction,sentence_compression,1,"['B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.75,19,0.09090909090909091,12,0.75,1,1,model
144,"There is a significant difference in performance of the MIRA baseline and the LSTM models , both in terms of F1 - score and in accuracy .",Experiments,Experiments,sentence_compression,1,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.18309859154929578,143,0.6842105263157895,13,0.18309859154929578,1,1,results
145,More than 30 % of golden compressions could be fully regenerated by the LSTM systems which is in sharp contrast with the 20 % of MIRA .,Experiments,Experiments,sentence_compression,1,"['B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,14,0.19718309859154928,144,0.6889952153110048,14,0.19718309859154928,1,1,results
146,"The differences in F- score between the three versions of LSTM are not significant , all scores are close to 0.81 .",Experiments,Experiments,sentence_compression,1,"['O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",15,0.2112676056338028,145,0.69377990430622,15,0.2112676056338028,1,1,results
2,Improving sentence compression by learning to predict gaze,title,title,sentence_compression,2,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.009900990099009901,1,0.0,1,1,research-problem
12,We go beyond this by suggesting that eye - tracking recordings can be used to induce better models for sentence compression for text simplification .,Introduction,Introduction,sentence_compression,2,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O']",,,5,0.08196721311475409,11,0.10891089108910891,5,0.4166666666666667,1,1,model
13,"Specifically , we show how to use existing eye - tracking recordings to improve the induction of Long Short - Term Memory models ( LSTMs ) for sentence compression .",Introduction,Introduction,sentence_compression,2,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",6,0.09836065573770492,12,0.1188118811881188,6,0.5,1,1,model
14,Our proposed model does not require that the gaze data and the compression data come from the same source .,Introduction,Introduction,sentence_compression,2,"['B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",7,0.11475409836065574,13,0.12871287128712872,7,0.5833333333333334,1,1,model
15,"Indeed , in this work we use gaze data from readers of the Dundee Corpus to improve sentence compression results on several datasets .",Introduction,Introduction,sentence_compression,2,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.13114754098360656,14,0.13861386138613863,8,0.6666666666666666,1,1,model
16,"While not explored here , an intriguing potential of this work is in deriving sentence simplification models that are personalized for individual users , based on their reading behavior .",Introduction,Introduction,sentence_compression,2,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.14754098360655737,15,0.1485148514851485,9,0.75,1,1,model
85,Both the baseline and our systems are three - layer bi - LSTM models trained for 30 iterations with pretrained ( SENNA ) embeddings .,Baselines and system,Baselines and system,sentence_compression,2,"['B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.16666666666666666,84,0.8316831683168316,1,0.16666666666666666,1,1,hyperparameters
86,"The input and hidden layers are 50 dimensions , and at the output layer we predict sequences of two labels , indicating whether to delete the labeled word or not .",Baselines and system,Baselines and system,sentence_compression,2,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.3333333333333333,85,0.8415841584158416,2,0.3333333333333333,1,1,hyperparameters
87,Our baseline ( BASELINE - LSTM ) is a multi - task learning 1 http://groups.inf.ed.ac.uk/ccg/,Baselines and system,Baselines and system,sentence_compression,2,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O']",3,0.5,86,0.8514851485148515,3,0.5,1,1,baselines
88,bi -LSTM predicting both CCG supertags and sentence compression ( word deletion ) at the outer layer .,Baselines and system,Baselines and system,sentence_compression,2,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",4,0.6666666666666666,87,0.8613861386138614,4,0.6666666666666666,1,1,baselines
93,"We observe that across all three datasets , including all three annotations of BROADCAST , gaze features lead to improvements over our baseline 3 - layer bi - LSTM .",Results and discussion,Results and discussion,sentence_compression,2,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.2,92,0.9108910891089109,2,0.2,1,1,results
94,"Also , CASCADED - LSTM is consistently better than MULTITASK - LSTM . : Results ( F1 ) .",Results and discussion,Results and discussion,sentence_compression,2,"['O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.3,93,0.9207920792079208,3,0.3,1,1,results
95,"For all three datasets , the inclusion of gaze measures ( first pass duration ( FP ) and regression duration ( Regr. ) ) leads to improvements over the baseline .",Results and discussion,Results and discussion,sentence_compression,2,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'O']",4,0.4,94,0.9306930693069307,4,0.4,1,1,results
100,"With the harder datasets , the impact of the gaze information becomes stronger , consistently favouring the cascaded architecture , and with improvements using both first pass duration and regression duration , the late measure associated with interpretation of content .",Results and discussion,Results and discussion,sentence_compression,2,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.9,99,0.9801980198019802,9,0.9,1,1,results
2,A Language Model based Evaluator for Sentence Compression,title,,sentence_compression,3,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.008064516129032258,1,0.0,1,1,research-problem
4,"We herein present a language - modelbased evaluator for deletion - based sentence compression , and viewed this task as a series of deletion - and - evaluation operations using the evaluator .",abstract,abstract,sentence_compression,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.024193548387096774,1,0.2,1,1,research-problem
19,"To answer the above questions , a syntax - based neural language model is trained on large - scale datasets as a readability evaluator .",Introduction,Introduction,sentence_compression,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",10,0.625,18,0.14516129032258066,10,0.625,1,1,model
20,The neural language model is supposed to learn the correct word collocations in terms of both syntax and semantics .,Introduction,Introduction,sentence_compression,3,"['O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'O', 'B-ob', 'O']",11,0.6875,19,0.1532258064516129,11,0.6875,1,1,model
21,"Subsequently , we formulate the deletionbased sentence compression as a series of trialand - error deletion operations through a reinforcement learning framework .",Introduction,Introduction,sentence_compression,3,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.75,20,0.16129032258064516,12,0.75,1,1,model
22,"The policy network performs either RETAIN or REMOVE action to form a compression , and receives a reward ( e.g. , readability score ) to update the network .",Introduction,Introduction,sentence_compression,3,"['O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'B-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",13,0.8125,21,0.1693548387096774,13,0.8125,1,1,model
72,We choose several strong baselines ; the first one is the dependency - tree - based method that considers the sentence compression task as an optimization problem by using integer linear programming 5 .,Comparison Methods,Comparison Methods,sentence_compression,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",1,0.058823529411764705,71,0.5725806451612904,1,0.058823529411764705,1,1,baselines
82,The second method is the long short - term memory networks ( LSTMs ) which showed strong promise in sentence compression by .,Comparison Methods,Comparison Methods,sentence_compression,3,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O']",11,0.6470588235294118,81,0.6532258064516129,11,0.6470588235294118,1,1,baselines
90,"The embedding size for word , part - of - speech tag , and the dependency relation is 128 .",Training,Training,sentence_compression,3,"['O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'O']",1,0.1,89,0.717741935483871,1,0.1,1,1,hyperparameters
91,We employed the vanilla RNN with a hidden size of 512 for both the policy network and neural language model .,Training,Training,sentence_compression,3,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.2,90,0.7258064516129032,2,0.2,1,1,hyperparameters
92,"The mini - batch size was chosen from [ 5 , 50 , 100 ] .",Training,Training,sentence_compression,3,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.3,91,0.7338709677419355,3,0.3,1,1,hyperparameters
93,"Vocabulary size was 50,000 .",Training,Training,sentence_compression,3,"['B', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'B-p', 'B-ob', 'O']",4,0.4,92,0.7419354838709677,4,0.4,1,1,hyperparameters
94,"The learning rate for neural language model is 2.5 e - 4 , and 1e - 05 for the policy network .",Training,Training,sentence_compression,3,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,5,0.5,93,0.75,5,0.5,1,1,hyperparameters
95,"For policy learning , we used the REINFORCE algorithm to update the parameters of the policy network and find an policy that maximizes the reward .",Training,Training,sentence_compression,3,"['B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'O', 'B-p', 'O', 'B-ob', 'O']",6,0.6,94,0.7580645161290323,6,0.6,1,1,hyperparameters
99,6 https://github.com/code4conference/code4sc,Training,Training,sentence_compression,3,"['O', 'B']","['O', 'B-n']","['O', 'B-ob']",10,1.0,98,0.7903225806451613,10,1.0,1,1,code
107,"( 1 ) As shown in , our Evaluator - SLMbased method yields a large improvement over the baselines , demonstrating that the language - modelbased evaluator is effective as a post-hoc grammar checker for the compressed sentences .",Result and Discussion,Result and Discussion,sentence_compression,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.35,106,0.8548387096774194,7,0.5,1,1,results
109,"( 3 ) As for Google news dataset , LSTMs ( LSTM + pos+dep ) ( & 3 ) is a relatively strong baseline , suggesting that incorporating dependency relations and part - of - speech tags may help model learn the syntactic relations and thus make a better prediction .",Result and Discussion,Result and Discussion,sentence_compression,3,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.45,108,0.8709677419354839,9,0.6428571428571429,1,1,results
110,"When further applying Evaluator - SLM , only a tiny improvement is observed ( &3 vs & 4 ) , not comparable to the improvement between # 3 and # 5 .",Result and Discussion,Result and Discussion,sentence_compression,3,"['O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.5,109,0.8790322580645161,10,0.7142857142857143,1,1,results
112,"For Gigaword dataset with 1.02 million instances , the perplexity of the language model is 20.3 , while for the Google news dataset with 0.2 million instances , the perplexity is 76.5 .",Result and Discussion,Result and Discussion,sentence_compression,3,"['B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'O']",,,12,0.6,111,0.8951612903225806,12,0.8571428571428571,1,1,results
114,"The results shows that small improvements are observed on two datasets ( # 4 vs # 5 ; & 4 vs & 5 ) , suggesting that incorporating syntactic knowledge may help evaluator to encourage more unseen but reasonable word collocations .",Result and Discussion,Result and Discussion,sentence_compression,3,"['O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.7,113,0.9112903225806451,14,1.0,1,1,results
2,MULTIMODAL SPEECH EMOTION RECOGNITION USING AUDIO AND TEXT,title,title,sentiment_analysis,0,"['O', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.0056179775280898875,1,0.0,1,1,research-problem
23,"To overcome these limitations , we propose a model that uses high - level text transcription , as well as low - level audio signals , to utilize the information contained within low - resource datasets to a greater degree .",INTRODUCTION,INTRODUCTION,sentiment_analysis,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",13,0.41935483870967744,22,0.12359550561797752,13,0.41935483870967744,1,1,model
27,"In this paper , we propose a novel deep dual recurrent encoder model that simultaneously utilizes audio and text data in recognizing emotions from speech .",INTRODUCTION,INTRODUCTION,sentiment_analysis,0,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O']",17,0.5483870967741935,26,0.14606741573033707,17,0.5483870967741935,1,1,model
123,"Among the variants of the RNN function , we use GRUs as they yield comparable performance to that of the LSTM and include a smaller number of weight parameters .",Implementation details,Implementation details,sentiment_analysis,0,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O']",1,0.2,122,0.6853932584269663,1,0.2,1,1,hyperparameters
124,"We use a max encoder step of 750 for the audio input , based on the implementation choices presented in and 128 for the text input because it covers the maximum length of the transcripts .",Implementation details,Implementation details,sentiment_analysis,0,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O']",,,2,0.4,123,0.6910112359550562,2,0.4,1,1,hyperparameters
125,"The vocabulary size of the dataset is 3,747 , including the "" UNK "" token , which represents unknown words , and the "" PAD "" token , which is used to indicate padding information added while preparing mini-batch data .",Implementation details,Implementation details,sentiment_analysis,0,"['O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",3,0.6,124,0.6966292134831461,3,0.6,1,1,hyperparameters
126,"The number of hidden units and the number of layers in the RNN for each model ( ARE , TRE , MDRE and MDREA ) are selected based on extensive hyperparameter search experiments .",Implementation details,Implementation details,sentiment_analysis,0,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.8,125,0.702247191011236,4,0.8,1,1,hyperparameters
127,The weights of the hidden units are initialized using orthogonal ,Implementation details,Implementation details,sentiment_analysis,0,"['O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']",,,5,1.0,126,0.7078651685393258,5,1.0,1,1,
133,"weights ] , and the text embedding layer is initialized from pretrained word - embedding vectors .",Model WAP,Model WAP,sentiment_analysis,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.5555555555555556,132,0.7415730337078652,5,0.625,1,1,hyperparameters
134,"In preparing the textual dataset , we first use the released transcripts of the IEMOCAP dataset for simplicity .",Model WAP,Model WAP,sentiment_analysis,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",6,0.6666666666666666,133,0.7471910112359551,6,0.75,1,1,hyperparameters
144,"First , our ARE model shows the baseline performance because we use minimal audio features , such as the MFCC and prosodic features with simple architectures .",Performance evaluation,Performance evaluation,sentiment_analysis,0,"['O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",6,0.1875,143,0.8033707865168539,6,0.3,1,1,results
145,"On the other hand , the TRE model shows higher performance gain compared to the ARE .",Performance evaluation,Performance evaluation,sentiment_analysis,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",7,0.21875,144,0.8089887640449438,7,0.35,1,1,results
146,"From this result , we note that textual data are informative in emotion prediction tasks , and the recurrent encoder model is effective in understanding these types of sequential data .",Performance evaluation,Performance evaluation,sentiment_analysis,0,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.25,145,0.8146067415730337,8,0.4,1,1,results
147,"Second , the newly proposed model , MDRE , shows a substantial performance gain .",Performance evaluation,Performance evaluation,sentiment_analysis,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.28125,146,0.8202247191011236,9,0.45,1,1,results
148,It thus achieves the state - of - the - art performance with a WAP value of 0.718 .,Performance evaluation,Performance evaluation,sentiment_analysis,0,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",10,0.3125,147,0.8258426966292135,10,0.5,1,1,results
150,"Lastly , the attention model , MDREA , also outperforms the best existing research results ( WAP 0.690 to 0.688 ) .",Performance evaluation,Performance evaluation,sentiment_analysis,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.375,149,0.8370786516853933,12,0.6,1,1,results
156,The label accuracy of the processed transcripts is 5.53 % WER .,Performance evaluation,Performance evaluation,sentiment_analysis,0,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",18,0.5625,155,0.8707865168539326,18,0.9,1,1,results
157,"The TRE - ASR , MDRE - ASR and MDREA - ASR models reflect degraded performance compared to that of the TRE , MDRE and MDREA models .",Performance evaluation,Performance evaluation,sentiment_analysis,0,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.59375,156,0.8764044943820225,19,0.95,1,1,results
162,"The ARE model ( ) incorrectly classifies most instances of happy as neutral ( 43.51 % ) ; thus , it shows reduced accuracy ( 35.15 % ) in predicting the the happy class .",Performance evaluation,Error analysis,sentiment_analysis,0,"['O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",24,0.75,161,0.9044943820224719,3,0.2727272727272727,1,1,ablation-analysis
163,"Overall , most of the emotion classes are frequently confused with the neutral class .",Performance evaluation,Error analysis,sentiment_analysis,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",25,0.78125,162,0.9101123595505618,4,0.36363636363636365,1,1,ablation-analysis
165,"Interestingly , the TRE model ( ) shows greater prediction gains in predicting the happy class when compared to the ARE model ( 35.15 % to 75. 73 % ) .",Performance evaluation,Error analysis,sentiment_analysis,0,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,27,0.84375,164,0.9213483146067416,6,0.5454545454545454,1,1,ablation-analysis
168,The MDRE model ) compensates for the weaknesses of the previous two models ( ARE and TRE ) and benefits from their strengths to a surprising degree .,Performance evaluation,Error analysis,sentiment_analysis,0,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",30,0.9375,167,0.9382022471910112,9,0.8181818181818182,1,1,ablation-analysis
170,"Furthermore , the occurrence of the incorrect "" sad - to - happy "" cases in the TRE model is reduced from 16 . 20 % to 9.15 % .",Performance evaluation,Error analysis,sentiment_analysis,0,"['O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",32,1.0,169,0.949438202247191,11,1.0,1,1,ablation-analysis
2,EEG - Based Emotion Recognition Using Regularized Graph Neural Networks,title,title,sentiment_analysis,1,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.0025252525252525255,1,0.0,1,1,research-problem
15,"E MOTION recognition is an important subarea of affective computing , which focuses on recognizing human emotions based on a variety of modalities , such as audio- visual expressions , body language , physiological signals , etc .",INTRODUCTION,INTRODUCTION,sentiment_analysis,1,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.003816793893129771,14,0.03535353535353535,1,0.017857142857142856,1,1,research-problem
49,"In this paper , we propose a regularized graph neural network ( RGNN ) aiming to address all three aforementioned challenges .",INTRODUCTION,INTRODUCTION,sentiment_analysis,1,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",35,0.13358778625954199,48,0.12121212121212122,35,0.625,1,1,model
52,"Inspired by , , we consider each channel in EEG signals as a node in our graph .",INTRODUCTION,INTRODUCTION,sentiment_analysis,1,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O']",,,38,0.1450381679389313,51,0.12878787878787878,38,0.6785714285714286,1,1,model
53,"Our RGNN model extends the simple graph convolution network ( SGC ) and leverages the topological structure of EEG signals , i.e. , according to the economy of brain network organization , we propose a biologically supported sparse adjacency matrix to capture both local and global inter-channel relations .",INTRODUCTION,INTRODUCTION,sentiment_analysis,1,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",39,0.14885496183206107,52,0.13131313131313133,39,0.6964285714285714,1,1,model
54,"Local interchannel relations connect nearby groups of neurons and may reveal anatomical connectivity at macroscale , .",INTRODUCTION,INTRODUCTION,sentiment_analysis,1,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O']",40,0.15267175572519084,53,0.13383838383838384,40,0.7142857142857143,1,1,model
55,"Global inter-channel relations connect distant groups of neurons between the left and right hemispheres and may reveal emotion - related functional connectivity , .",INTRODUCTION,INTRODUCTION,sentiment_analysis,1,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",41,0.15648854961832062,54,0.13636363636363635,41,0.7321428571428571,1,1,model
312,"For our RGNN in all experiments , we empirically set the number of convolutional layers L = 2 , dropout rate of 0.7 at the output fully - connected layer , and batch size of 16 .",Model Settings in RGNN,Model Settings in RGNN,sentiment_analysis,1,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'O']",,,1,0.029411764705882353,311,0.7853535353535354,1,0.2,1,1,hyperparameters
313,"We use Adam optimization with default values , i.e. , ? 1 = 0.9 and ? 2 = 0.999 .",Model Settings in RGNN,Model Settings in RGNN,sentiment_analysis,1,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.058823529411764705,312,0.7878787878787878,2,0.4,1,1,hyperparameters
314,"We only tune the output feature dimension d , label noise level , learning rate ? , L1 regularization factor ? , and L2 regularization for each experiment .",Model Settings in RGNN,Model Settings in RGNN,sentiment_analysis,1,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",3,0.08823529411764706,313,0.7904040404040404,3,0.6,1,1,hyperparameters
322,It is encouraging to see that our model achieves superior performance on both datasets as compared to all baselines including the stateof - the - art BiHDM when DE features from all frequency bands are used .,Model Settings in RGNN,Model Settings in RGNN,sentiment_analysis,1,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.3235294117647059,321,0.8106060606060606,5,0.5555555555555556,1,1,results
323,It is worth noting that our model improves the accuracy of the state - of - the - art model on SEED - IV by around 5 % .,Model Settings in RGNN,Model Settings in RGNN,sentiment_analysis,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.35294117647058826,322,0.8131313131313131,6,0.6666666666666666,1,1,results
324,"In particular , our model performs better than DGCNN , which is another GNN - based model that leverages the topological structure in EEG signals .",Model Settings in RGNN,Model Settings in RGNN,sentiment_analysis,1,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",13,0.38235294117647056,323,0.8156565656565656,7,0.7777777777777778,1,1,results
329,"In subject - dependent experiments on SEED , STRNN achieves the highest accuracy in delta , theta and alpha bands , BiDANN performs best in beta band , and our model performs best in gamma band .",Model Settings in RGNN,Performance Comparison of Frequency Bands,sentiment_analysis,1,"['B', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O']",,,18,0.5294117647058824,328,0.8282828282828283,2,0.25,1,1,results
330,"In subject - independent experiments on SEED , BiDANN - S achieves the highest accuracy in theta and alpha bands , and our model performs best in delta , beta and gamma bands .",Model Settings in RGNN,Performance Comparison of Frequency Bands,sentiment_analysis,1,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']",,,19,0.5588235294117647,329,0.8308080808080808,3,0.375,1,1,results
332,"For both subject - dependent and subjectindependent settings on SEED , we compare the performance of each model across different frequency bands .",Model Settings in RGNN,Performance Comparison of Frequency Bands,sentiment_analysis,1,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.6176470588235294,331,0.8358585858585859,5,0.625,1,1,results
333,"In general , most models including our model achieve better performance on beta and gamma bands than delta , theta and alpha bands , with one exception of STRNN , which performs the worst on gamma band .",Model Settings in RGNN,Performance Comparison of Frequency Bands,sentiment_analysis,1,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O']",,,22,0.6470588235294118,332,0.8383838383838383,6,0.75,1,1,results
335,"One subtle difference between our model and other models is that our model performs consistently better in gamma band than beta band , whereas other models perform comparably in both bands , indicating that gamma band maybe the most discriminative band for our model .",Model Settings in RGNN,Performance Comparison of Frequency Bands,sentiment_analysis,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",24,0.7058823529411765,334,0.8434343434343434,8,1.0,1,1,results
349,"The two major designs in our adjacency matrix A , i.e. , global connection and symmetric adjacency matrix designs , are helpful in recognizing emotions .",Ablation Study,Ablation Study,sentiment_analysis,1,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",3,0.08108108108108109,348,0.8787878787878788,3,0.23076923076923078,1,1,ablation-analysis
350,"The global connection models the asymmetric difference between neuronal activities in the left and right hemispheres and have been shown to reveal certain emotions , , .",Ablation Study,Ablation Study,sentiment_analysis,1,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O']",4,0.10810810810810811,349,0.8813131313131313,4,0.3076923076923077,1,1,ablation-analysis
352,"Our NodeDAT regularizer has a noticeable positive impact on the performance of our model , which demonstrates that domain adaptation is significantly helpful in crosssubject classification .",Ablation Study,Ablation Study,sentiment_analysis,1,"['O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.16216216216216217,351,0.8863636363636364,6,0.46153846153846156,1,1,ablation-analysis
355,"In addition , if NodeDAT is removed , the performance of our model has a greater variance , demonstrating the importance of NodeDAT in improving the robustness of our model against cross - subject variations .",Ablation Study,Ablation Study,sentiment_analysis,1,"['O', 'O', 'O', 'B', 'B', 'B', 'B', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,9,0.24324324324324326,354,0.8939393939393939,9,0.6923076923076923,1,1,ablation-analysis
357,DL regularizer improves performance of our model by around 3 % in accuracy on both datasets .,Ablation Study,Our Emotion,sentiment_analysis,1,"['B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'O']",,,11,0.2972972972972973,356,0.898989898989899,11,0.8461538461538461,1,1,ablation-analysis
2,DialogueRNN : An Attentive RNN for Emotion Detection in Conversations,title,title,sentiment_analysis,10,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0038910505836575876,1,0.0,1,1,research-problem
18,Our proposed DialogueRNN system employs three gated recurrent units ( GRU ) to model these aspects .,Introduction,Introduction,sentiment_analysis,10,"['O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",10,0.4,17,0.06614785992217899,10,0.4,1,1,model
19,"The incoming utterance is fed into two GRUs called global GRU and party GRU to update the context and party Copyright 2019 , Association for the Advancement of Artificial Intelligence ( www.aaai.org ) .",Introduction,Introduction,sentiment_analysis,10,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.44,18,0.07003891050583658,11,0.44,1,1,model
22,The global GRU encodes corresponding party information while encoding an utterance .,Introduction,Introduction,sentiment_analysis,10,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",14,0.56,21,0.08171206225680934,14,0.56,1,1,model
23,Attending over this GRU gives contextual representation that has information of all preceding utterances by different parties in the conversation .,Introduction,Introduction,sentiment_analysis,10,"['B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'O']","['B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",15,0.6,22,0.08560311284046693,15,0.6,1,1,model
24,The speaker state depends on this context through attention and the speaker 's previous state .,Introduction,Introduction,sentiment_analysis,10,"['O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.64,23,0.08949416342412451,16,0.64,1,1,model
25,"This ensures that at time t , the speaker state directly gets information from the speaker 's previous state and global GRU which has information on the preceding parties .",Introduction,Introduction,sentiment_analysis,10,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",17,0.68,24,0.0933852140077821,17,0.68,1,1,model
26,"Finally , the updated speaker state is fed into the emotion GRU to decode the emotion representation of the given utterance , which is used for emotion classification .",Introduction,Introduction,sentiment_analysis,10,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",18,0.72,25,0.09727626459143969,18,0.72,1,1,model
27,"At time t , the emotion GRU cell gets the emotion representation of t ? 1 and the speaker state of t .",Introduction,Introduction,sentiment_analysis,10,"['B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.76,26,0.10116731517509728,19,0.76,1,1,model
149,c - LSTM : Biredectional LSTM is used to capture the context from the surrounding utterances to generate contextaware utterance representation .,Experimental Setting,Baselines and State of the Art,sentiment_analysis,10,"['B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.3076923076923077,148,0.5758754863813229,2,0.11764705882352941,1,1,baselines
151,c- LSTM+ Att :,Experimental Setting,Baselines and State of the Art,sentiment_analysis,10,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",10,0.38461538461538464,150,0.5836575875486382,4,0.23529411764705882,1,1,baselines
152,In this variant attention is applied applied to the c - LSTM output at each timestamp by following Eqs. and .,Experimental Setting,Baselines and State of the Art,sentiment_analysis,10,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",11,0.4230769230769231,151,0.5875486381322957,5,0.29411764705882354,1,1,baselines
154,TFN :,Experimental Setting,Baselines and State of the Art,sentiment_analysis,10,"['B', 'O']","['B-n', 'O']","['B-b', 'O']",13,0.5,153,0.5953307392996109,7,0.4117647058823529,1,1,baselines
155,This is specific to multimodal scenario .,Experimental Setting,Baselines and State of the Art,sentiment_analysis,10,"['O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",14,0.5384615384615384,154,0.5992217898832685,8,0.47058823529411764,1,1,baselines
156,Tensor outer product is used to capture intermodality and intra-modality interactions .,Experimental Setting,Baselines and State of the Art,sentiment_analysis,10,"['B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.5769230769230769,155,0.603112840466926,9,0.5294117647058824,1,1,baselines
158,"MFN ) : Specific to multimodal scenario , this model utilizes multi-view learning by modeling view - specific and cross - view interactions .",Experimental Setting,Baselines and State of the Art,sentiment_analysis,10,"['B', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.6538461538461539,157,0.6108949416342413,11,0.6470588235294118,1,1,baselines
160,CNN : This is identical to our textual feature extractor network ( Section 3.2 ) and it does not use contextual information from the surrounding utterances .,Experimental Setting,Baselines and State of the Art,sentiment_analysis,10,"['B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",19,0.7307692307692307,159,0.6186770428015564,13,0.7647058823529411,1,1,baselines
161,"Memnet : As described in , the current utterance is fed to a memory network , where the memories correspond to preceding utterances .",Experimental Setting,Baselines and State of the Art,sentiment_analysis,10,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",20,0.7692307692307693,160,0.622568093385214,14,0.8235294117647058,1,1,baselines
162,The output from the memory network is used as the final utterance representation for emotion classification .,Experimental Setting,Baselines and State of the Art,sentiment_analysis,10,"['O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",21,0.8076923076923077,161,0.6264591439688716,15,0.8823529411764706,1,1,baselines
163,CMN : This state - of - the - art method models utterance context from dialogue history using two distinct GRUs for two speakers .,Experimental Setting,Baselines and State of the Art,sentiment_analysis,10,"['B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",22,0.8461538461538461,162,0.6303501945525292,16,0.9411764705882353,1,1,baselines
170,"As expected , on average Di - alogue RNN outperforms all the baseline methods , including the state - of - the - art CMN , on both of the datasets .",Results and Discussion,Results and Discussion,sentiment_analysis,10,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.02666666666666667,169,0.6575875486381323,2,1.0,1,1,results
174,"As evidenced by , for IEMOCAP dataset , our model surpasses the state - of - the - art method CMN by 2.77 % accuracy and 3.76 % f 1 - score on average .",Results and Discussion,IEMOCAP,sentiment_analysis,10,"['O', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",6,0.08,173,0.6731517509727627,3,0.23076923076923078,1,1,results
182,"AVEC DialogueRNN outperforms CMN for valence , arousal , expectancy , and power attributes ; see .",Results and Discussion,IEMOCAP,sentiment_analysis,10,"['B', 'B', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['B-n', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['B-b', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",14,0.18666666666666668,181,0.7042801556420234,11,0.8461538461538461,1,1,results
185,DialogueRNN vs. DialogueRNN Variants,Results and Discussion,IEMOCAP,sentiment_analysis,10,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",17,0.22666666666666666,184,0.7159533073929961,0,0.0,1,1,results
187,DialogueRNN l :,Results and Discussion,IEMOCAP,sentiment_analysis,10,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-b', 'I-b', 'O']",19,0.25333333333333335,186,0.7237354085603113,2,0.125,1,1,results
188,"Following , using explicit listener state update yields slightly worse performance than regular DialogueRNN .",Results and Discussion,IEMOCAP,sentiment_analysis,10,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",20,0.26666666666666666,187,0.7276264591439688,3,0.1875,1,1,results
193,"BiDialogueRNN : Since BiDialogueRNN captures context from the future utterances , we expect improved performance from it over DialogueRNN .",Results and Discussion,IEMOCAP,sentiment_analysis,10,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",25,0.3333333333333333,192,0.7470817120622568,8,0.5,1,1,results
194,"This is confirmed in , where BiDialogueRNN outperforms Dialogue RNN on average on both datasets .",Results and Discussion,IEMOCAP,sentiment_analysis,10,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'O']",26,0.3466666666666667,193,0.7509727626459144,9,0.5625,1,1,results
2,Conversational Memory Network for Emotion Recognition in Dyadic Dialogue Videos,title,title,sentiment_analysis,11,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0029069767441860465,1,0.0,1,1,research-problem
4,Emotion recognition in conversations is crucial for the development of empathetic machines .,abstract,abstract,sentiment_analysis,11,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.00872093023255814,1,0.14285714285714285,1,1,research-problem
16,"Emotion detection from such resources can benefit numerous fields like counseling , public opinion mining , financial forecasting , and intelligent systems such as smart homes and chatbots .",Introduction,Introduction,sentiment_analysis,11,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.10869565217391304,15,0.0436046511627907,5,0.10869565217391304,1,1,research-problem
17,"In this paper , we analyze emotion detection in videos of dyadic conversations .",Introduction,Introduction,sentiment_analysis,11,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.13043478260869565,16,0.046511627906976744,6,0.13043478260869565,1,1,research-problem
19,"We propose a conversational memory network ( CMN ) , which uses a multimodal approach for emotion detection in utterances ( a unit of speech bound by breathes or pauses ) of such conversational videos .",Introduction,Introduction,sentiment_analysis,11,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",8,0.17391304347826086,18,0.05232558139534884,8,0.17391304347826086,1,1,model
28,Our proposed CMN incorporates these factors by using emotional context information present in the conversation history .,Introduction,Introduction,sentiment_analysis,11,"['O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",17,0.3695652173913043,27,0.07848837209302326,17,0.3695652173913043,1,1,model
29,It improves speakerbased emotion modeling by using memory networks which are efficient in capturing long - term dependencies and summarizing task - specific details using attention models .,Introduction,Introduction,sentiment_analysis,11,"['O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']",,,18,0.391304347826087,28,0.08139534883720931,18,0.391304347826087,1,1,model
30,"Specifically , the memory cells of CMN are continuous vectors that store the context information found in the utterance histories .",Introduction,Introduction,sentiment_analysis,11,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",19,0.41304347826086957,29,0.08430232558139535,19,0.41304347826086957,1,1,model
31,CMN also models interplay of these memories to capture interspeaker dependencies .,Introduction,Introduction,sentiment_analysis,11,"['B', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'O']","['B-n', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",20,0.43478260869565216,30,0.0872093023255814,20,0.43478260869565216,1,1,model
32,"CMN first extracts multimodal features ( audio , visual , and text ) for all utterances in a video .",Introduction,Introduction,sentiment_analysis,11,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",21,0.45652173913043476,31,0.09011627906976744,21,0.45652173913043476,1,1,model
245,We use 10 % of the training set as a held - out validation set for hyperparameter tuning .,Training Details,Training Details,sentiment_analysis,11,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",1,0.1,244,0.7093023255813954,1,0.1,1,1,hyperparameters
246,"To optimize the parameters , we use Stochastic Gradient Descent ( SGD ) optimizer , starting with an initial learning Utterances whose history has atleast 3 similar emotion labels in either own history or the history of the other person , is counted in case 1 or 2 , respectively .",Training Details,Training Details,sentiment_analysis,11,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.2,245,0.7122093023255814,2,0.2,1,1,hyperparameters
249,An annealing approach halves the lr every 20 epochs and termination is decided using an early - stop measure with a patience of 12 by monitoring the validation loss .,Training Details,Training Details,sentiment_analysis,11,"['O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.5,248,0.7209302325581395,5,0.5,1,1,hyperparameters
250,Gradient clipping is used for regularization with a norm set to 40 .,Training Details,Training Details,sentiment_analysis,11,"['B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'O']",6,0.6,249,0.7238372093023255,6,0.6,1,1,hyperparameters
251,Hyperparameters are decided using a Random Search .,Training Details,Training Details,sentiment_analysis,11,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",7,0.7,250,0.7267441860465116,7,0.7,1,1,hyperparameters
252,"Based on validation performance , context window length K is set to be 40 and the number of hops R is fixed at 3 hops .",Training Details,Training Details,sentiment_analysis,11,"['B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",8,0.8,251,0.7296511627906976,8,0.8,1,1,hyperparameters
254,The dimension size of the memory cells d is set as 50 .,Training Details,Training Details,sentiment_analysis,11,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",10,1.0,253,0.7354651162790697,10,1.0,1,1,hyperparameters
257,SVM - ensemble :,Baselines,Baselines,sentiment_analysis,11,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",2,0.06451612903225806,256,0.7441860465116279,2,0.06451612903225806,1,1,baselines
258,A strong context - free benchmark model which uses similar multimodal approach on an ensemble of trees .,Baselines,Baselines,sentiment_analysis,11,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.0967741935483871,257,0.747093023255814,3,0.0967741935483871,1,1,baselines
260,bc - LSTM :,Baselines,Baselines,sentiment_analysis,11,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",5,0.16129032258064516,259,0.752906976744186,5,0.16129032258064516,1,1,baselines
261,"A bi-directional LSTM equipped with hierarchical fusion , proposed by .",Baselines,Baselines,sentiment_analysis,11,"['O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",6,0.1935483870967742,260,0.7558139534883721,6,0.1935483870967742,1,1,baselines
266,"Memn2n : The original memory network as proposed by Contrasting to CMN , the model generates the memory representations for each historical utterance using an embedding matrix B as used in equation 7 , without sequential modeling .",Baselines,Baselines,sentiment_analysis,11,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.3548387096774194,265,0.7703488372093024,11,0.3548387096774194,1,1,baselines
271,"[ 1 , K ] } for ? ? {a , b}. CMN Self :",Baselines,Baselines,sentiment_analysis,11,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O']",16,0.5161290322580645,270,0.7848837209302325,16,0.5161290322580645,1,1,baselines
272,"In this baseline , we use only self history for classifying emotion of utterance u i .",Baselines,Baselines,sentiment_analysis,11,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.5483870967741935,271,0.7877906976744186,17,0.5483870967741935,1,1,baselines
275,CMN N A : Single layer variant of the CMN with no attention module .,Baselines,Baselines,sentiment_analysis,11,"['B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",20,0.6451612903225806,274,0.7965116279069767,20,0.6451612903225806,1,1,baselines
289,This suggests that gathering contexts temporally through sequential processing is indeed a superior method over non-temporal memory representations .,Results,Results,sentiment_analysis,11,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.038461538461538464,288,0.8372093023255814,2,0.10526315789473684,1,1,results
290,CMN self which uses only single history channel also provides lesser performance when compared to CMN .,Results,Results,sentiment_analysis,11,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",3,0.057692307692307696,289,0.8401162790697675,3,0.15789473684210525,1,1,results
292,"Overall , predictions on valence and arousal levels also show similar results which reinforce our hypothesis of CMN 's ability to model emotional dynamics .",Results,Results,sentiment_analysis,11,"['O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.09615384615384616,291,0.8459302325581395,5,0.2631578947368421,1,1,results
2,Progressive Self - Supervised Attention Learning for Aspect - Level Sentiment Analysis,title,title,sentiment_analysis,12,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004464285714285714,1,0.0,1,1,research-problem
4,"In aspect - level sentiment classification ( ASC ) , it is prevalent to equip dominant neural models with attention mechanisms , for the sake of acquiring the importance of each context word on the given aspect .",abstract,abstract,sentiment_analysis,12,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.125,3,0.013392857142857142,1,0.125,1,1,research-problem
6,"In this paper , we propose a progressive self - supervised attention learning approach for neural ASC models , which automatically mines useful attention supervision information from a training corpus to refine attention mechanisms .",abstract,abstract,sentiment_analysis,12,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.375,5,0.022321428571428572,3,0.375,1,1,research-problem
13,"Aspect - level sentiment classification ( ASC ) , as an indispensable task in sentiment analysis , aims at inferring the sentiment polarity of an input sentence in a certain aspect .",Introduction,Introduction,sentiment_analysis,12,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.03125,12,0.05357142857142857,1,0.03125,1,1,research-problem
18,"However , the existing attention mechanism in ASC suffers from a major drawback .",Introduction,Introduction,sentiment_analysis,12,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.1875,17,0.07589285714285714,6,0.1875,1,1,research-problem
30,"In this paper , we propose a novel progressive self - supervised attention learning approach for neural ASC models .",Introduction,Introduction,sentiment_analysis,12,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",18,0.5625,29,0.12946428571428573,18,0.5625,1,1,approach
31,"Our method is able to automatically and incrementally mine attention supervision information from a training corpus , which can be exploited to guide the training of attention mechanisms in ASC models .",Introduction,Introduction,sentiment_analysis,12,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",19,0.59375,30,0.13392857142857142,19,0.59375,1,1,approach
32,The basic idea behind our approach roots in the following fact : the context word with the maximum attention weight has the greatest impact on the sentiment prediction of an input sentence .,Introduction,Introduction,sentiment_analysis,12,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",20,0.625,31,0.13839285714285715,20,0.625,1,1,approach
150,We used pre-trained Glo Ve vectors to initialize the word embeddings with vector dimension 300 .,Training Details .,Training Details .,sentiment_analysis,12,"['O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-ob', 'O']",1,0.05,149,0.6651785714285714,12,0.5714285714285714,1,1,hyperparameters
151,"For out - of - vocabulary words , we randomly sampled their embeddings from the uniform distribution , as implemented in .",Training Details .,Training Details .,sentiment_analysis,12,"['B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",2,0.1,150,0.6696428571428571,13,0.6190476190476191,1,1,hyperparameters
153,"To alleviate overfitting , we employed dropout strategy ( Hinton et al. , 2012 ) on the input word embeddings of the LSTM and the ultimate aspect - related sentence representation .",Training Details .,Training Details .,sentiment_analysis,12,"['B', 'I', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.2,152,0.6785714285714286,15,0.7142857142857143,1,1,hyperparameters
154,"Adam ( Kingma and Ba , 2015 ) was adopted as the optimizer with the learning rate 0.001 .",Training Details .,Training Details .,sentiment_analysis,12,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-ob', 'O']",5,0.25,153,0.6830357142857143,16,0.7619047619047619,1,1,hyperparameters
155,"When implementing our approach , we empirically set the maximum iteration number K as 5 , ? in Equation 3 as 0.1 on LAPTOP data set , 0.5 on REST data set and 0.1 on TWITTER data set , respectively .",Training Details .,Training Details .,sentiment_analysis,12,"['B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O']",,,6,0.3,154,0.6875,17,0.8095238095238095,1,1,hyperparameters
156,All hyper - parameters were tuned on 20 % randomly held - out training data .,Training Details .,Training Details .,sentiment_analysis,12,"['B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.35,155,0.6919642857142857,18,0.8571428571428571,1,1,hyperparameters
174,"First , both of our reimplemented MN and TNet are comparable to their original models reported in .",Overall Results,Overall Results,sentiment_analysis,12,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O']",4,0.2857142857142857,173,0.7723214285714286,4,0.2857142857142857,1,1,results
176,"When we replace the CNN of TNet with an attention mechanism , TNet - ATT is slightly inferior to TNet .",Overall Results,Overall Results,sentiment_analysis,12,"['O', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O']",,,6,0.42857142857142855,175,0.78125,6,0.42857142857142855,1,1,results
177,"Moreover , when we perform additional K+1 - iteration of training on these models , their performance has not changed significantly , suggesting simply increasing training time is unable to enhance the performance of the neural ASC models .",Overall Results,Overall Results,sentiment_analysis,12,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O']",7,0.5,176,0.7857142857142857,7,0.5,1,1,results
183,"Finally , when we use both kinds of attention supervision information , no matter for which metric , MN ( + AS ) remarkably outperforms MN on all test sets .",Overall Results,Overall Results,sentiment_analysis,12,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",13,0.9285714285714286,182,0.8125,13,0.9285714285714286,1,1,results
2,BERT Post - Training for Review Reading Comprehension and Aspect - based Sentiment Analysis,title,title,sentiment_analysis,13,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0035971223021582736,1,0.0,1,1,research-problem
10,"To show the generality of the approach , the proposed post - training is also applied to some other review - based tasks such as aspect extraction and aspect sentiment classification in aspect - based sentiment analysis .",abstract,abstract,sentiment_analysis,13,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.875,9,0.03237410071942446,7,0.875,1,1,research-problem
40,"This work first builds an RRC dataset called ReviewRC , using reviews from SemEval 2016 Task 5 2 , which is a popular dataset for aspect - based sentiment analysis ( ABSA ) in the domains of laptop and restaurant .",Introduction,All the newer MacBooks do not .,sentiment_analysis,13,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",28,0.6511627906976745,39,0.14028776978417265,28,0.6511627906976745,1,1,dataset
43,This work adopts BERT ) as the base model as it achieves the state - of the - art performance on MRC .,Introduction,We detail ReviewRC in Sec.,sentiment_analysis,13,"['O', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",31,0.7209302325581395,42,0.1510791366906475,31,0.7209302325581395,1,1,model
48,"To address all the above challenges , we propose a novel joint post - training technique that takes BERT 's pre-trained weights as the initialization 4 for basic language understanding and adapt BERT with both domain knowledge and task ( MRC ) knowledge before fine - tuning using the domain end task annotated data for the domain RRC .",Introduction,We detail ReviewRC in Sec.,sentiment_analysis,13,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,36,0.8372093023255814,47,0.16906474820143885,36,0.8372093023255814,1,1,model
49,"This technique leverages knowledge from two sources : unsupervised domain reviews and supervised ( yet out - of - domain ) MRC data 5 , where the former enhances domain - awareness and the latter strengthens MRC task - awareness .",Introduction,We detail ReviewRC in Sec.,sentiment_analysis,13,"['O', 'O', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",37,0.8604651162790697,48,0.17266187050359713,37,0.8604651162790697,1,1,model
210,We adopt BERT BASE ( uncased ) as the basis for all experiments,Post - training datasets,Hyper-parameters,sentiment_analysis,13,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob']",11,0.6470588235294118,209,0.7517985611510791,1,0.14285714285714285,1,1,hyperparameters
211,"10 . Since post - training may take a large footprint on GPU memory ( as BERT pretraining ) , we leverage FP16 computation 11 to reduce the size of both the model and hidden representations of data .",Post - training datasets,Hyper-parameters,sentiment_analysis,13,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",12,0.7058823529411765,210,0.7553956834532374,2,0.2857142857142857,1,1,hyperparameters
212,"We set a static loss scale of 2 in FP16 , which can avoid any over / under - flow of floating point computation .",Post - training datasets,Hyper-parameters,sentiment_analysis,13,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.7647058823529411,211,0.7589928057553957,3,0.42857142857142855,1,1,hyperparameters
213,The maximum length of post -training is set to 320 with a batch size of 16 for each type of knowledge .,Post - training datasets,Hyper-parameters,sentiment_analysis,13,"['O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'O']",,,14,0.8235294117647058,212,0.762589928057554,4,0.5714285714285714,1,1,hyperparameters
214,"The number of subbatch u is set to 2 , which is good enough to store each sub - batch iteration into a GPU memory of 11G .",Post - training datasets,Hyper-parameters,sentiment_analysis,13,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",15,0.8823529411764706,213,0.7661870503597122,5,0.7142857142857143,1,1,hyperparameters
215,We use Adam optimizer and set the learning rate to be 3e - 5 .,Post - training datasets,Hyper-parameters,sentiment_analysis,13,"['O', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",16,0.9411764705882353,214,0.7697841726618705,6,0.8571428571428571,1,1,hyperparameters
216,"We train 70,000 steps for the laptop domain and 140,000 steps for the restaurant domain , which roughly have one pass over the preprocessed data on the respective domain .",Post - training datasets,Hyper-parameters,sentiment_analysis,13,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,17,1.0,215,0.7733812949640287,7,1.0,1,1,hyperparameters
250,"To answer RQ1 , we observed that the proposed joint post - training ( BERT - PT ) has the best performance over all tasks in all domains , which show the benefits of having two types of knowledge .",Result Analysis,Result Analysis,sentiment_analysis,13,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.08,249,0.89568345323741,2,1.0,1,1,results
252,"Rest. Methods EM F1 EM F1 DrQA 38.26 50.99 49.52 63.73 DrQA+MRC 40 To answer RQ2 , to our surprise we found that the vanilla pre-trained weights of BERT do not work well for review - based tasks , although it achieves state - of - the - art results on many other NLP tasks .",Result Analysis,Domain Laptop,sentiment_analysis,13,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.16,251,0.9028776978417267,1,0.045454545454545456,1,1,results
254,"To answer RQ3 , we noticed that the roles of domain knowledge and task knowledge vary for different tasks and domains .",Result Analysis,Domain Laptop,sentiment_analysis,13,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.24,253,0.9100719424460432,3,0.13636363636363635,1,1,results
255,"For RRC , we found that the performance gain of BERT - PT mostly comes from task - awareness ( MRC ) post -training ( as indicated by BERT - MRC ) .",Result Analysis,Domain Laptop,sentiment_analysis,13,"['B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.28,254,0.9136690647482014,4,0.18181818181818182,1,1,results
258,We further investigated the examples improved by BERT - MRC and found that the boundaries of spans ( especially short spans ) were greatly improved .,Result Analysis,Domain Laptop,sentiment_analysis,13,"['O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",10,0.4,257,0.9244604316546763,7,0.3181818181818182,1,1,results
259,"For AE , we found that great performance boost comes mostly from domain knowledge posttraining , which indicates that contextualized representations of domain knowledge are very important for AE .",Result Analysis,Domain Laptop,sentiment_analysis,13,"['O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.44,258,0.9280575539568345,8,0.36363636363636365,1,1,results
260,"BERT - MRC has almost no improvement on restaurant , which indicates Wikipedia may have no knowledge about aspects of restaurant .",Result Analysis,Domain Laptop,sentiment_analysis,13,"['B', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.48,259,0.9316546762589928,9,0.4090909090909091,1,1,results
262,"For ASC , we observed that large - scale annotated MRC data is very useful .",Result Analysis,Domain Laptop,sentiment_analysis,13,"['O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",14,0.56,261,0.9388489208633094,11,0.5,1,1,results
267,The errors on RRC mainly come from boundaries of spans that are not concise enough and incorrect location of spans that may have certain nearby words related to the question .,Result Analysis,Domain Laptop,sentiment_analysis,13,"['O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'O']",,,19,0.76,266,0.9568345323741008,16,0.7272727272727273,1,1,results
269,"For AE , errors mostly come from annotation inconsistency and boundaries of aspects ( e.g. , apple OS is predicted as OS ) .",Result Analysis,Domain Laptop,sentiment_analysis,13,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.84,268,0.9640287769784173,18,0.8181818181818182,1,1,results
271,"ASC tends to have more errors as the decision boundary between the negative and neutral examples is unclear ( e.g. , even annotators may not sure whether the reviewer shows no opinion or slight negative opinion when mentioning an aspect ) .",Result Analysis,Domain Laptop,sentiment_analysis,13,"['B', 'B', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",23,0.92,270,0.9712230215827338,20,0.9090909090909091,1,1,results
2,Emo2 Vec : Learning Generalized Emotion Representation by Multi- task Training,title,title,sentiment_analysis,14,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.006578947368421052,1,0.0,1,1,research-problem
14,This work demonstrates the effectiveness of incorporating sentiment labels in a wordlevel information for sentiment - related tasks compared to other word embeddings .,Introduction,Introduction,sentiment_analysis,14,"['O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.3157894736842105,13,0.08552631578947369,6,0.3157894736842105,1,1,model
24,"1 ) We propose Emo2Vec 1 which are word - level representations that encode emotional semantics into fixed - sized , real - valued vectors .",Introduction,Introduction,sentiment_analysis,14,"['O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.8421052631578947,23,0.1513157894736842,16,0.8421052631578947,1,1,model
25,2 ) We propose to learn Emo2Vec with a multi-task learning framework by including six different emotion - related tasks .,Introduction,Introduction,sentiment_analysis,14,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.8947368421052632,24,0.15789473684210525,17,0.8947368421052632,1,1,model
87,Pre-training Emo2Vec,CNN model,"For sentiment , we include 8 datasets .",sentiment_analysis,14,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",44,0.88,86,0.5657894736842105,0,0.0,1,1,hyperparameters
88,Emo2 Vec embedding matrix and the CNN model are pre-trained using hashtag corpus alone .,CNN model,"For sentiment , we include 8 datasets .",sentiment_analysis,14,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O']",45,0.9,87,0.5723684210526315,1,0.09090909090909091,1,1,hyperparameters
89,Parameters of T and CNN are randomly initialized and Adam is used for optimization .,CNN model,"For sentiment , we include 8 datasets .",sentiment_analysis,14,"['B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",46,0.92,88,0.5789473684210527,2,0.18181818181818182,1,1,hyperparameters
91,"For the best model , we use the batch size of 16 , embedding size of 100 , 1024 filters and filter sizes are 1 , 3 ,5 and 7 respectively .",CNN model,"For sentiment , we include 8 datasets .",sentiment_analysis,14,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O']",,,48,0.96,90,0.5921052631578947,4,0.36363636363636365,1,1,hyperparameters
94,Multi - task training,,,sentiment_analysis,14,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",0,0.0,93,0.6118421052631579,7,0.6363636363636364,1,1,hyperparameters
95,"We tune our parameters of learning rate , L2 regularization , whether to pre-train our model and batch size with the average accuracy of the development set of all datasets .",Multi - task training,Multi - task training,sentiment_analysis,14,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.25,94,0.618421052631579,8,0.7272727272727273,1,1,hyperparameters
96,We early stop our model when the averaged dev accuracy stop increasing .,Multi - task training,Multi - task training,sentiment_analysis,14,"['O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",2,0.5,95,0.625,9,0.8181818181818182,1,1,hyperparameters
97,"Our best model uses learning rate of 0.001 , L2 regularization of 1.0 , batch size of 32 .",Multi - task training,Multi - task training,sentiment_analysis,14,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,3,0.75,96,0.631578947368421,10,0.9090909090909091,1,1,hyperparameters
98,We save the best model and take the embedding layer as Emo2Vec vectors .,Multi - task training,Multi - task training,sentiment_analysis,14,"['O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",4,1.0,97,0.6381578947368421,11,1.0,1,1,hyperparameters
115,"Compared with CNN embedding : Emo2 Vec works better than CNN embedding on 14 / 18 datasets , giving 2.6 % absolute accuracy improvement for the sentiment task and 1.6 % absolute f1score improvement on the other tasks .",Results,The results can be found in .,sentiment_analysis,14,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,3,0.125,114,0.75,3,0.125,1,1,results
116,It shows multi-task training helps to create better generalized word emotion representations than just using a single task .,Results,The results can be found in .,sentiment_analysis,14,"['O', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",4,0.16666666666666666,115,0.756578947368421,4,0.16666666666666666,1,1,results
117,"Compared with SSWE : Emo2 Vec works much better on all datasets except SS - T datasets , which gives 3.3 % accuracy improvement and 4.7 % f 1 score improvement respectively on sentiment and other tasks .",Results,The results can be found in .,sentiment_analysis,14,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O']",,,5,0.20833333333333334,116,0.7631578947368421,5,0.20833333333333334,1,1,results
121,"On average , it gives 1.3 % improvement in accuracy for the sentiment task and 1.1 % improvement of f 1 - score on the other tasks .",Results,Compared with DeepMoji embedding : Emo2 Vec outperforms,sentiment_analysis,14,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",9,0.375,120,0.7894736842105263,9,0.375,1,1,results
124,"Since Emo2 Vec is not trained by predicting contextual words , it is weak on capturing synthetic and semantic meaning .",Results,Compared with DeepMoji embedding : Emo2 Vec outperforms,sentiment_analysis,14,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.5,123,0.8092105263157895,12,0.5,1,1,results
128,"Here , we want to highlight that solely using a simple classifier with good word representation can achieve promising results .",Results,Compared with DeepMoji embedding : Emo2 Vec outperforms,sentiment_analysis,14,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",16,0.6666666666666666,127,0.8355263157894737,16,0.6666666666666666,1,1,results
131,"Compared with GloVe+ DeepMoji , GloVe + Emo2 Vec achieves same or better results on 11 / 14 datasets , which on average gives 1.0 % improvement .",Results,Glo Ve on 13 / 14 datasets .,sentiment_analysis,14,"['B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",19,0.7916666666666666,130,0.8552631578947368,19,0.7916666666666666,1,1,results
132,"GloVe + Emo2 Vec achieves better performances on SOTA results on three datasets ( SE0714 , stress and tube tablet ) and comparable result to SOTA on dataset Previous SOTA results",Results,Glo Ve on 13 / 14 datasets .,sentiment_analysis,14,"['B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'O', 'O']",,,20,0.8333333333333334,131,0.8618421052631579,20,0.8333333333333334,1,1,results
136,"Thus , to detect the corresponding emotion , more attention needs to be paid to words .",Results,Glo Ve on 13 / 14 datasets .,sentiment_analysis,14,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'O']",24,1.0,135,0.8881578947368421,24,1.0,1,1,results
2,Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank,title,title,sentiment_analysis,15,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.003703703703703704,1,0.0,1,1,research-problem
5,Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition .,abstract,abstract,sentiment_analysis,15,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.2222222222222222,4,0.014814814814814815,2,0.2222222222222222,1,1,research-problem
20,The Stanford Sentiment Treebank is the first corpus with fully labeled parse trees that allows for a complete analysis of the compositional effects of sentiment in language .,Introduction,Introduction,sentiment_analysis,15,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']",,,7,0.3333333333333333,19,0.07037037037037037,7,0.3333333333333333,1,1,dataset
21,"The corpus is based on the dataset introduced by and consists of 11,855 single sentences extracted from movie reviews .",Introduction,Introduction,sentiment_analysis,15,"['O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",8,0.38095238095238093,20,0.07407407407407407,8,0.38095238095238093,1,1,dataset
22,"It was parsed with the Stanford parser and includes a total of 215,154 unique phrases from those parse trees , each annotated by 3 human judges .",Introduction,Introduction,sentiment_analysis,15,"['O', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.42857142857142855,21,0.07777777777777778,9,0.42857142857142855,1,1,dataset
23,This new dataset allows us to analyze the intricacies of sentiment and to capture complex linguistic phenomena .,Introduction,Introduction,sentiment_analysis,15,"['O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.47619047619047616,22,0.08148148148148149,10,0.47619047619047616,1,1,dataset
25,The granularity and size of this dataset will enable the community to train compositional models that are based on supervised and structured machine learning techniques .,Introduction,Introduction,sentiment_analysis,15,"['O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.5714285714285714,24,0.08888888888888889,12,0.5714285714285714,1,1,dataset
27,"In order to capture the compositional effects with higher accuracy , we propose a new model called the Recursive Neural Tensor Network ( RNTN ) .",Introduction,Introduction,sentiment_analysis,15,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.6666666666666666,26,0.0962962962962963,14,0.6666666666666666,1,1,model
28,Recursive Neural Tensor Networks take as input phrases of any length .,Introduction,Introduction,sentiment_analysis,15,"['B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",15,0.7142857142857143,27,0.1,15,0.7142857142857143,1,1,model
29,They represent a phrase through word vectors and a parse tree and then compute vectors for higher nodes in the tree using the same tensor - based composition function .,Introduction,Introduction,sentiment_analysis,15,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.7619047619047619,28,0.1037037037037037,16,0.7619047619047619,1,1,model
202,Optimal performance for all models was achieved at word vector sizes between 25 and 35 dimensions and batch sizes between 20 and 30 .,Experiments,Experiments,sentiment_analysis,15,"['B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']",,,5,0.07352941176470588,201,0.7444444444444445,5,0.2,1,1,hyperparameters
206,The RNTN would usually achieve its best performance on the dev set after training for 3 - 5 hours .,Experiments,Experiments,sentiment_analysis,15,"['O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.1323529411764706,205,0.7592592592592593,9,0.36,1,1,hyperparameters
208,We use f = tanh in all experiments .,Experiments,Experiments,sentiment_analysis,15,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.16176470588235295,207,0.7666666666666667,11,0.44,1,1,hyperparameters
209,"We compare to commonly used methods that use bag of words features with Naive Bayes and SVMs , as well as Naive Bayes with bag of bigram features .",Experiments,Experiments,sentiment_analysis,15,"['O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']",,,12,0.17647058823529413,208,0.7703703703703704,12,0.48,1,1,baselines
211,We also compare to a model that averages neural word vectors and ignores word order ( VecAvg ) .,Experiments,Experiments,sentiment_analysis,15,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.20588235294117646,210,0.7777777777777778,14,0.56,1,1,baselines
212,"The sentences in the treebank were split into a train ( 8544 ) , dev ( 1101 ) and test splits ( 2210 ) and these splits are made available with the data release .",Experiments,Experiments,sentiment_analysis,15,"['O', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.22058823529411764,211,0.7814814814814814,15,0.6,1,1,hyperparameters
217,showed that a fine grained classification into 5 classes is a reasonable approximation to capture most of the data variation .,Experiments,Fine - grained Sentiment For All Phrases,sentiment_analysis,15,"['B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",20,0.29411764705882354,216,0.8,20,0.8,1,1,results
219,"The RNTN gets the highest performance , followed by the MV - RNN and RNN .",Experiments,Fine - grained Sentiment For All Phrases,sentiment_analysis,15,"['O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",22,0.3235294117647059,218,0.8074074074074075,22,0.88,1,1,results
220,"The recursive models work very well on shorter phrases , where negation and composition are important , while bag of features baselines perform well only with longer sentences .",Experiments,Fine - grained Sentiment For All Phrases,sentiment_analysis,15,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",23,0.3382352941176471,219,0.8111111111111111,23,0.92,1,1,results
229,The combination of the new sentiment treebank and the RNTN pushes the state of the art on short phrases up to 85.4 % .,Experiments,Full Sentence Binary Sentiment,sentiment_analysis,15,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",32,0.47058823529411764,228,0.8444444444444444,6,0.14285714285714285,1,1,results
247,"The RNTN has the highest reversal accuracy , showing its ability to structurally learn negation of positive sentences .",Experiments,Model Analysis : High Level Negation,sentiment_analysis,15,"['O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",50,0.7352941176470589,246,0.9111111111111111,24,0.5714285714285714,1,1,ablation-analysis
255,shows a typical case in which sentiment was made more positive by switching the main class from negative to neutral even though both not and dull were negative .,Experiments,Model Analysis : High Level Negation,sentiment_analysis,15,"['B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",58,0.8529411764705882,254,0.9407407407407408,32,0.7619047619047619,1,1,ablation-analysis
259,Therefore we can conclude that the RNTN is best able to identify the effect of negations upon both positive and negative sentiment sentences . :,Experiments,Model Analysis : High Level Negation,sentiment_analysis,15,"['O', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",62,0.9117647058823529,258,0.9555555555555556,36,0.8571428571428571,1,1,ablation-analysis
2,Target - Sensitive Memory Networks for Aspect Sentiment Classification,title,,sentiment_analysis,16,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0031446540880503146,1,0.0,1,1,research-problem
4,Aspect sentiment classification ( ASC ) is a fundamental task in sentiment analysis .,abstract,abstract,sentiment_analysis,16,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",1,0.1111111111111111,3,0.009433962264150943,1,0.1111111111111111,1,1,research-problem
8,"However , we found an important problem with the current MNs in performing the ASC task .",abstract,abstract,sentiment_analysis,16,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O']",5,0.5555555555555556,7,0.0220125786163522,5,0.5555555555555556,1,1,research-problem
51,"To address this problem , we propose target - sensitive memory networks ( TMNs ) , which can capture the sentiment interaction between targets and contexts .",Introduction,Introduction,sentiment_analysis,16,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",38,0.3486238532110092,50,0.15723270440251572,38,0.9743589743589743,1,1,model
229,AMN : A state - of - the - art memory network used for ASC .,Experiments,Experiments,sentiment_analysis,16,"['B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'O']","['B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",5,0.3333333333333333,228,0.7169811320754716,5,0.3333333333333333,1,1,baselines
231,"BL - MN : Our basic memory network presented in Section 2 , which does not use the proposed techniques for capturing target - sensitive sentiments .",Experiments,Experiments,sentiment_analysis,16,"['B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.4666666666666667,230,0.7232704402515723,7,0.4666666666666667,1,1,baselines
232,AE - LSTM : RNN / LSTM is another popular attention based neural model .,Experiments,Experiments,sentiment_analysis,16,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.5333333333333333,231,0.7264150943396226,8,0.5333333333333333,1,1,baselines
233,"Here we compare with a state - of - the - art attention - based LSTM for ASC , AE - LSTM .",Experiments,Experiments,sentiment_analysis,16,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O']",9,0.6,232,0.7295597484276729,9,0.6,1,1,baselines
234,ATAE - LSTM :,Experiments,Experiments,sentiment_analysis,16,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",10,0.6666666666666666,233,0.7327044025157232,10,0.6666666666666666,1,1,baselines
235,Another attention - based LSTM for ASC reported in .,Experiments,Experiments,sentiment_analysis,16,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O']",11,0.7333333333333333,234,0.7358490566037735,11,0.7333333333333333,1,1,baselines
236,Target - sensitive Memory Networks ( TMNs ) :,Experiments,Experiments,sentiment_analysis,16,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",12,0.8,235,0.7389937106918238,12,0.8,1,1,baselines
237,"The six proposed techniques , NP , CNP , IT , CI , JCI , and JPI give six target - sensitive memory networks .",Experiments,Experiments,sentiment_analysis,16,"['O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O', 'O', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.8666666666666667,236,0.7421383647798742,13,0.8666666666666667,1,1,baselines
247,We use the open - domain word embeddings 1 for the initialization of word vectors .,Training Details,Training Details,sentiment_analysis,16,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",1,0.09090909090909091,246,0.7735849056603774,1,0.09090909090909091,1,1,hyperparameters
248,"We initialize other model parameters from a uniform distribution U ( - 0.05 , 0.05 ) .",Training Details,Training Details,sentiment_analysis,16,"['O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.18181818181818182,247,0.7767295597484277,2,0.18181818181818182,1,1,hyperparameters
249,The dimension of the word embedding and the size of the hidden layers are 300 .,Training Details,Training Details,sentiment_analysis,16,"['O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'O']",3,0.2727272727272727,248,0.779874213836478,3,0.2727272727272727,1,1,hyperparameters
250,The learning rate is set to 0.01 and the dropout rate is set to 0.1 .,Training Details,Training Details,sentiment_analysis,16,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']",,,4,0.36363636363636365,249,0.7830188679245284,4,0.36363636363636365,1,1,hyperparameters
251,Stochastic gradient descent is used as our optimizer .,Training Details,Training Details,sentiment_analysis,16,"['B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",5,0.45454545454545453,250,0.7861635220125787,5,0.45454545454545453,1,1,hyperparameters
253,"We also compare the memory networks in their multiple computational layers version ( i.e. , multiple hops ) and the number of hops is set to 3 as used in the mentioned previous studies .",Training Details,Training Details,sentiment_analysis,16,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.6363636363636364,252,0.7924528301886793,7,0.6363636363636364,1,1,hyperparameters
254,"We implemented all models in the TensorFlow environment using same input , embedding size , dropout rate , optimizer , etc.",Training Details,Training Details,sentiment_analysis,16,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",8,0.7272727272727273,253,0.7955974842767296,8,0.7272727272727273,1,1,hyperparameters
265,"Comparing the 1 - hop memory networks ( first nine rows ) , we see significant performance gains achieved by CNP , CI , JCI , and JPI on both datasets , where each of them has p < 0.01 over the strongest baseline ( BL - MN ) from paired t- test using F1 - Macro .",Result Analysis,Result Analysis,sentiment_analysis,16,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",7,0.13725490196078433,264,0.8301886792452831,7,0.13725490196078433,1,1,results
268,"2 . In the 3 - hop setting , TMNs achieve much better results on Restaurant .",Result Analysis,Result Analysis,sentiment_analysis,16,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",10,0.19607843137254902,267,0.839622641509434,10,0.19607843137254902,1,1,results
269,"JCI , IT , and CI achieve the best scores , outperforming the strongest baseline AMN by 2.38 % , 2.18 % , and 2.03 % .",Result Analysis,Result Analysis,sentiment_analysis,16,"['B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.21568627450980393,268,0.8427672955974843,11,0.21568627450980393,1,1,results
270,"On Laptop , BL - MN and most TMNs ( except CNP and JPI ) perform similarly .",Result Analysis,Result Analysis,sentiment_analysis,16,"['B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O']","['B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O']","['B-p', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'O']",12,0.23529411764705882,269,0.8459119496855346,12,0.23529411764705882,1,1,results
272,"3 . Comparing all TMNs , we see that JCI works the best as it always obtains the top - three scores on two datasets and in two settings .",Result Analysis,Result Analysis,sentiment_analysis,16,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.27450980392156865,271,0.8522012578616353,14,0.27450980392156865,1,1,results
273,CI and JPI also perform well in most cases .,Result Analysis,Result Analysis,sentiment_analysis,16,"['B', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",15,0.29411764705882354,272,0.8553459119496856,15,0.29411764705882354,1,1,results
274,"IT , NP , and CNP can achieve very good scores in some cases but are less stable .",Result Analysis,Result Analysis,sentiment_analysis,16,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",16,0.3137254901960784,273,0.8584905660377359,16,0.3137254901960784,1,1,results
2,Improved Semantic Representations From Tree - Structured Long Short - Term Memory Networks,title,title,sentiment_analysis,17,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.0044444444444444444,1,0.0,1,1,research-problem
8,"Tree - LSTMs outperform all existing systems and strong LSTM baselines on two tasks : predicting the semantic relatedness of two sentences ( Sem Eval 2014 , Task 1 ) and sentiment classification ( Stanford Sentiment Treebank ) .",abstract,abstract,sentiment_analysis,17,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",5,1.0,7,0.03111111111111111,5,1.0,1,1,research-problem
33,"In this paper , we introduce a generalization of the standard LSTM architecture to tree - structured network topologies and show its superiority for representing sentence meaning over a sequential LSTM .",Introduction,Introduction,sentiment_analysis,17,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",24,0.2222222222222222,32,0.14222222222222222,24,0.7741935483870968,1,1,model
34,"While the standard LSTM composes its hidden state from the input at the current time step and the hidden state of the LSTM unit in the previous time step , the tree - structured LSTM , or Tree - LSTM , composes its state from an input vector and the hidden states of arbitrarily many child units .",Introduction,Introduction,sentiment_analysis,17,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",25,0.23148148148148148,33,0.14666666666666667,25,0.8064516129032258,1,1,model
39,Implementations of our models and experiments are available at https :// github.com/stanfordnlp/treelstm.,Introduction,Introduction,sentiment_analysis,17,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",30,0.2777777777777778,38,0.1688888888888889,30,0.967741935483871,1,1,code
182,The hyperparameters for our models were tuned on the development set for each task .,Hyperparameters and Training Details,Hyperparameters and Training Details,sentiment_analysis,17,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.1111111111111111,181,0.8044444444444444,1,0.1111111111111111,1,1,hyperparameters
183,We initialized our word representations using publicly available 300 - dimensional Glove vectors,Hyperparameters and Training Details,Hyperparameters and Training Details,sentiment_analysis,17,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",2,0.2222222222222222,182,0.8088888888888889,2,0.2222222222222222,1,1,hyperparameters
185,"For the sentiment classification task , word representations were updated during training with a learning rate of 0.1 .",Hyperparameters and Training Details,Hyperparameters and Training Details,sentiment_analysis,17,"['B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",4,0.4444444444444444,184,0.8177777777777778,4,0.4444444444444444,1,1,hyperparameters
186,"For the semantic relatedness task , word representations were held fixed as we did not observe any significant improvement when the representations were tuned .",Hyperparameters and Training Details,Hyperparameters and Training Details,sentiment_analysis,17,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.5555555555555556,185,0.8222222222222222,5,0.5555555555555556,1,1,hyperparameters
187,Our models were trained using AdaGrad with a learning rate of 0.05 and a minibatch size of 25 .,Hyperparameters and Training Details,Hyperparameters and Training Details,sentiment_analysis,17,"['B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O']",,,6,0.6666666666666666,186,0.8266666666666667,6,0.6666666666666666,1,1,hyperparameters
188,The model parameters were regularized with a per-minibatch L2 regularization strength of 10 ?4 .,Hyperparameters and Training Details,Hyperparameters and Training Details,sentiment_analysis,17,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.7777777777777778,187,0.8311111111111111,7,0.7777777777777778,1,1,hyperparameters
189,The sentiment classifier was additionally regularized using dropout with a dropout rate of 0.5 .,Hyperparameters and Training Details,Hyperparameters and Training Details,sentiment_analysis,17,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",8,0.8888888888888888,188,0.8355555555555556,8,0.8888888888888888,1,1,hyperparameters
2,Effective Attention Modeling for Aspect - Level Sentiment Classification,title,,sentiment_analysis,18,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0041841004184100415,1,0.0,1,1,research-problem
16,Aspect - level sentiment classification is an important task in fine - grained sentiment analysis .,Introduction,Introduction,sentiment_analysis,18,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.02702702702702703,15,0.06276150627615062,1,0.02702702702702703,1,1,research-problem
27,We propose two novel approaches for improving the effectiveness of attention models .,Introduction,Introduction,sentiment_analysis,18,"['O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.32432432432432434,26,0.1087866108786611,12,0.32432432432432434,1,1,approach
28,The first approach is a new way of encoding a target which better captures the aspect semantics of the target expression .,Introduction,Introduction,sentiment_analysis,18,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.35135135135135137,27,0.11297071129707113,13,0.35135135135135137,1,1,approach
40,"To address this problem , inspired by , we instead model each target as a mixture of K aspect embeddings where we would like each embedded aspect to represent a cluster of closely related targets .",Introduction,Introduction,sentiment_analysis,18,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",25,0.6756756756756757,39,0.16317991631799164,25,0.6756756756756757,1,1,approach
41,We use an autoencoder structure to learn both the aspect embeddings as well as the representation of the target as a weighted combination of the aspect embeddings .,Introduction,Introduction,sentiment_analysis,18,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",26,0.7027027027027027,40,0.16736401673640167,26,0.7027027027027027,1,1,approach
43,The autoencoder structure is jointly trained with a neural attention - based sentiment classifier to provide a good target representation as well as a high accuracy on the predicted sentiment .,Introduction,Introduction,sentiment_analysis,18,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",28,0.7567567567567568,42,0.17573221757322174,28,0.7567567567567568,1,1,approach
46,Our second approach exploits syntactic information to construct a syntax - based attention model .,Introduction,Introduction,sentiment_analysis,18,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",31,0.8378378378378378,45,0.18828451882845187,31,0.8378378378378378,1,1,approach
50,"Instead , our syntax - based attention mechanism selectively focuses on a small subset of context words that are close to the target on the syntactic path which is obtained by applying a dependency parser on the review sentence .",Introduction,Introduction,sentiment_analysis,18,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,35,0.9459459459459459,49,0.20502092050209206,35,0.9459459459459459,1,1,approach
165,( 1 ) Feature - based SVM :,Model Comparisons,Model Comparisons,sentiment_analysis,18,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",2,0.08333333333333333,164,0.6861924686192469,2,0.08333333333333333,1,1,baselines
166,We compare with the reported results of a top system in SemEval 2014 .,Model Comparisons,Model Comparisons,sentiment_analysis,18,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",3,0.125,165,0.6903765690376569,3,0.125,1,1,baselines
168,( 2 ) LSTM : An LSTM network is built on top of word embeddings .,Model Comparisons,Model Comparisons,sentiment_analysis,18,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.20833333333333334,167,0.698744769874477,5,0.20833333333333334,1,1,baselines
179,"1 ) Feature - based SVM is still a strong baseline , our best model achieves competitive results on D1 and D2 without relying on so many manually - designed features and external resources .",Model Comparisons,Model Comparisons,sentiment_analysis,18,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.6666666666666666,178,0.7447698744769874,16,0.6666666666666666,1,1,results
180,"2 ) Compared with all other neural baselines , our full model achieves statistically significant improvements ( p < 0.05 ) on both accuracies and macro - F1 scores for D1 , D3 , D4 .",Model Comparisons,Model Comparisons,sentiment_analysis,18,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.7083333333333334,179,0.7489539748953975,17,0.7083333333333334,1,1,results
181,"3 ) Compared with LSTM + ATT , all three settings of our model are able to achieve statistically significant improvements ( p < 0.05 ) on all datasets .",Model Comparisons,Model Comparisons,sentiment_analysis,18,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",18,0.75,180,0.7531380753138075,18,0.75,1,1,results
183,4 ) The integrated full model over all achieves the best performance compared to using only one of the two proposed approaches .,Model Comparisons,Model Comparisons,sentiment_analysis,18,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",20,0.8333333333333334,182,0.7615062761506276,20,0.8333333333333334,1,1,results
185,"5 ) The proposed target representation is more helpful on restaurant domain ( D1 , D3 , and D4 ) than laptop domain ( D2 ) .",Model Comparisons,Model Comparisons,sentiment_analysis,18,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",22,0.9166666666666666,184,0.7698744769874477,22,0.9166666666666666,1,1,results
2,Improved Sentence Modeling using Suffix Bidirectional LSTM,title,,sentiment_analysis,19,"['B', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.006535947712418301,1,0.0,1,1,research-problem
4,"Recurrent neural networks have become ubiquitous in computing representations of sequential data , especially textual data in natural language processing .",abstract,abstract,sentiment_analysis,19,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.07692307692307693,3,0.0196078431372549,1,0.07692307692307693,1,1,research-problem
12,Using SuBiLSTM we achieve new state - of - the - art results for fine - grained sentiment classification and question classification .,abstract,abstract,sentiment_analysis,19,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",9,0.6923076923076923,11,0.0718954248366013,9,0.6923076923076923,1,1,research-problem
18,Recurrent Neural Networks ( RNN ) ) have emerged as a powerful tool for modeling sequential data .,Introduction,Introduction,sentiment_analysis,19,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.010416666666666666,17,0.1111111111111111,1,0.02857142857142857,1,1,research-problem
30,"In this paper , we propose a simple , general and effective technique to compute contextual representations that capture long range dependencies .",Introduction,Vanilla,sentiment_analysis,19,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",13,0.13541666666666666,29,0.1895424836601307,13,0.37142857142857144,1,1,model
31,"For each token t , we encode both its prefix and suffix in both the forward and reverse direction .",Introduction,Vanilla,sentiment_analysis,19,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.14583333333333334,30,0.19607843137254902,14,0.4,1,1,model
34,"Further , we combine the prefix and suffix representations by a simple max - pooling operation to produce a richer contextual representation of t in both the forward and reverse direction .",Introduction,Vanilla,sentiment_analysis,19,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.17708333333333334,33,0.21568627450980393,17,0.4857142857142857,1,1,model
35,We call our model Suffix BiLSTM or SuBiLSTM in short .,Introduction,Vanilla,sentiment_analysis,19,"['O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'O', 'B-b', 'B-p', 'B-ob', 'O']",18,0.1875,34,0.2222222222222222,18,0.5142857142857142,1,1,model
115,"For each of the tasks , we compare SuBiLSTM and SuBiLSTM - Tied with a single - layer BiLSTM and a 2 - layer BiLSTM encoder with the same hidden dimension .",Baselines,Baselines,sentiment_analysis,19,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']",,,1,0.25,114,0.7450980392156863,1,0.25,1,1,baselines
125,"The relative performance of SuBiL - STM and SuBiLSTM - Tied are fairly close to each other , as shown by the relative gains in .",Model,Model,sentiment_analysis,19,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.5714285714285714,124,0.8104575163398693,4,0.5714285714285714,1,1,results
126,"SuBiLSTM - Tied works better on small datasets ( SST and TREC ) , probably owing to the regularizing effect of using the same LSTM to encode both suffixes and prefixes .",Model,Model,sentiment_analysis,19,"['B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.7142857142857143,125,0.8169934640522876,5,0.7142857142857143,1,1,results
127,"For the larger datasets ( SNLI and QUORA ) , SuBILSTM slightly edges out the tied version owing to its larger capacity .",Model,Model,sentiment_analysis,19,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",6,0.8571428571428571,126,0.8235294117647058,6,0.8571428571428571,1,1,results
128,"The training complexity for both the models is similar and hence , with half the parameters , SuBILSTM - Tied should be the more favored model for sentence modeling tasks .",Model,Model,sentiment_analysis,19,"['O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",7,1.0,127,0.8300653594771242,7,1.0,1,1,results
2,A Position - aware Bidirectional Attention Network for Aspect - level Sentiment Analysis,title,title,sentiment_analysis,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004405286343612335,1,0.0,1,1,research-problem
18,"Sentiment analysis , also known as opinion mining , is a vital task in Natural Language Processing ( NLP ) .",Introduction,Introduction,sentiment_analysis,2,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.03125,17,0.07488986784140969,1,0.03125,1,1,research-problem
39,"Inspired by this , we go one step further and propose a position - aware bidirectional attention network ( PBAN ) based on bidirectional Gated Recurrent Units ( Bi - GRU ) .",Introduction,Introduction,sentiment_analysis,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",22,0.6875,38,0.16740088105726872,22,0.6875,1,1,model
40,"In addition to utilizing the position information , PBAN also mutually models the relationship between the sentence and different words in the aspect term by adopting a bidirectional attention mechanism .",Introduction,Introduction,sentiment_analysis,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']",,,23,0.71875,39,0.17180616740088106,23,0.71875,1,1,
42,"1 ) Obtaining position information of each word in corresponding sentence based on the current aspect term , then converting the position information into position embedding .",Introduction,Introduction,sentiment_analysis,2,"['O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",25,0.78125,41,0.18061674008810572,25,0.78125,1,1,model
43,2 ) The PBAN composes of two Bi - GRU networks focusing on extracting the aspectlevel features and sentence - level features respectively .,Introduction,Introduction,sentiment_analysis,2,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",26,0.8125,42,0.18502202643171806,26,0.8125,1,1,model
44,3 ) Using the bidirectional attention mechanism to model the mutual relation between aspect term and its corresponding sentence .,Introduction,Introduction,sentiment_analysis,2,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,0.84375,43,0.1894273127753304,27,0.84375,1,1,model
120,"In our experiments , all word embedding are initialized by the pre-trained Glove vector 2 .",Experiments Setting,Experiments Setting,sentiment_analysis,2,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",2,0.18181818181818182,119,0.5242290748898678,2,0.18181818181818182,1,1,hyperparameters
121,"All the weight matrices are given the initial value by sampling from the uniform distribution U ( ?0.1 , 0.1 ) , and all the biases are set to zero .",Experiments Setting,Experiments Setting,sentiment_analysis,2,"['O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'O']",3,0.2727272727272727,120,0.5286343612334802,3,0.2727272727272727,1,1,hyperparameters
122,"The dimension of the word embedding and aspect term embedding are set to 300 , and the number of the hidden units are set to 200 .",Experiments Setting,Experiments Setting,sentiment_analysis,2,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']",,,4,0.36363636363636365,121,0.5330396475770925,4,0.36363636363636365,1,1,hyperparameters
123,"The dimension of position embedding is set to 100 , which is randomly initialized and updated during the training process .",Experiments Setting,Experiments Setting,sentiment_analysis,2,"['O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.45454545454545453,122,0.5374449339207048,5,0.45454545454545453,1,1,hyperparameters
124,"We use Tensorflow to implement our proposed model and employ the Momentum as the training method , whose momentum parameter ? is set to 0.9 , ? is set to 10 ? 6 , and the initial learning rate is set to 0.01 .",Experiments Setting,Experiments Setting,sentiment_analysis,2,"['O', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'O']",,,6,0.5454545454545454,123,0.5418502202643172,6,0.5454545454545454,1,1,hyperparameters
134,LSTM : LSTM takes the sentence as input so as to get the hidden representation of each word .,Model Comparison,Datasets,sentiment_analysis,2,"['B', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']",,,4,0.13333333333333333,133,0.5859030837004405,2,0.07142857142857142,1,1,baselines
135,"Then it regards the average value of all hidden states as the representation of sentence , and puts it into softmax layer to predict the probability of each sentiment polarity .",Model Comparison,Datasets,sentiment_analysis,2,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'O']",,,5,0.16666666666666666,134,0.5903083700440529,3,0.10714285714285714,1,1,baselines
137,"AE - LSTM : AE - LSTM first models the words in sentence via LSTM network and concatenate the aspect embedding to the hidden contextual representation for calculating the attention weights , which are employed to produce the final representation for the input sentence to judge the sentiment polarity .",Model Comparison,Datasets,sentiment_analysis,2,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",7,0.23333333333333334,136,0.5991189427312775,5,0.17857142857142858,1,1,baselines
138,"ATAE - LSTM : ATAE - LSTM extended AE - LSTM by appending the aspect embedding to each word embedding so as to represent the input sentence , which highlights the role of aspect embedding .",Model Comparison,Datasets,sentiment_analysis,2,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.26666666666666666,137,0.6035242290748899,6,0.21428571428571427,1,1,baselines
140,IAN : IAN considers the separate modeling of aspect terms and sentences respectively .,Model Comparison,Datasets,sentiment_analysis,2,"['B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O']","['B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",10,0.3333333333333333,139,0.6123348017621145,8,0.2857142857142857,1,1,baselines
143,"MemNet : MemNet applies attention multiple times on the word embedding , so that more abstractive evidences could be selected from the external memory .",Model Comparison,Datasets,sentiment_analysis,2,"['B', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O']","['B-n', 'O', 'O', 'B-p', 'B-n', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-p', 'B-b', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",13,0.43333333333333335,142,0.6255506607929515,11,0.39285714285714285,1,1,baselines
145,shows the performance of our model and other baseline models on datasets Restaurant and Laptop respectively .,Model Comparison,Datasets,sentiment_analysis,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O']",15,0.5,144,0.6343612334801763,13,0.4642857142857143,1,1,results
146,We can observe that our proposed PBAN model achieves the best performance among all methods .,Model Comparison,Datasets,sentiment_analysis,2,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",16,0.5333333333333333,145,0.6387665198237885,14,0.5,1,1,results
160,"Generally speaking , by integrating the position information and the bidirectional attention mechanism , PBAN achieves the state - of - the - art performances , and it can effectively judge the sentiment polarity of different aspect term in its corresponding sentence so as to improve the classification accuracy .",Model Comparison,Datasets,sentiment_analysis,2,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",30,1.0,159,0.7004405286343612,28,1.0,1,1,results
2,DataStories at SemEval-2017 Task 4 : Deep LSTM with Attention for Message - level and Topic - based Sentiment Analysis,title,title,sentiment_analysis,20,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.005376344086021506,1,0.0,1,1,research-problem
4,"In this paper we present two deep - learning systems that competed at SemEval - 2017 Task 4 "" Sentiment Analysis in Twitter "" .",abstract,abstract,sentiment_analysis,20,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",1,0.14285714285714285,3,0.016129032258064516,1,0.14285714285714285,1,1,research-problem
12,"Sentiment analysis is an area in Natural Language Processing ( NLP ) , studying the identification and quantification of the sentiment expressed in text .",Introduction,Introduction,sentiment_analysis,20,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.015384615384615385,11,0.05913978494623656,1,0.07142857142857142,1,1,research-problem
17,"In this paper , we present two deep - learning systems that competed at SemEval - 2017 Task 4 .",Introduction,Introduction,sentiment_analysis,20,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.09230769230769231,16,0.08602150537634409,6,0.42857142857142855,1,1,model
18,Our first model is designed for addressing the problem of messagelevel sentiment analysis .,Introduction,Introduction,sentiment_analysis,20,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.1076923076923077,17,0.0913978494623656,7,0.5,1,1,model
19,"We employ a 2 - layer Bidirectional LSTM , equipped with an attention mechanism .",Introduction,Introduction,sentiment_analysis,20,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",8,0.12307692307692308,18,0.0967741935483871,8,0.5714285714285714,1,1,model
20,"For the topic - based sentiment analysis tasks , we propose a Siamese Bidirectional LSTM with a contextaware attention mechanism .",Introduction,Introduction,sentiment_analysis,20,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.13846153846153847,19,0.10215053763440861,9,0.6428571428571429,1,1,model
79,MSA Model ( message - level ),Models Description,Models Description,sentiment_analysis,20,"['B', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'O', 'O', 'O', 'O']",2,0.029411764705882353,78,0.41935483870967744,2,0.04,1,1,hyperparameters
103,TSA Model ( topic - based ),Models Description,Output Layer .,sentiment_analysis,20,"['B', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'O', 'O', 'O', 'O']",26,0.38235294117647056,102,0.5483870967741935,26,0.52,1,1,hyperparameters
156,"The size of the embedding layer is 300 , and the LSTM layers 150 ( 300 for BiLSTM ) .",Training,Hyper-parameters,sentiment_analysis,20,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.625,155,0.8333333333333334,3,0.3333333333333333,1,1,hyperparameters
157,"We add Gaussian noise with ? = 0.2 and dropout of 0.3 at the embedding layer , dropout of 0.5 at the LSTM layers and dropout of 0.25 at the recurrent connections of the LSTM .",Training,Hyper-parameters,sentiment_analysis,20,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O']",,,11,0.6875,156,0.8387096774193549,4,0.4444444444444444,1,1,hyperparameters
158,"Finally , we add L 2 regularization of 0.0001 at the loss function .",Training,Hyper-parameters,sentiment_analysis,20,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",12,0.75,157,0.8440860215053764,5,0.5555555555555556,1,1,hyperparameters
160,"The size of the embedding layer is 300 , and the LSTM layers 64 ( 128 for BiLSTM ) .",Training,Hyper-parameters,sentiment_analysis,20,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O']",,,14,0.875,159,0.8548387096774194,7,0.7777777777777778,1,1,hyperparameters
161,"We insert Gaussian noise with ? = 0.2 at the embedding layer of both inputs and dropout of 0.3 at the embedding layer of the message , dropout of 0.2 at the LSTM layer and the recurrent connection of the LSTM layer and dropout of 0.3 at the attention layer and the Maxout layer .",Training,Hyper-parameters,sentiment_analysis,20,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']",,,15,0.9375,160,0.8602150537634409,8,0.8888888888888888,1,1,hyperparameters
162,"Finally , we add L 2 regularization of 0.001 at the loss function .",Training,Hyper-parameters,sentiment_analysis,20,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",16,1.0,161,0.8655913978494624,9,1.0,1,1,hyperparameters
165,"Our official ranking is 1/38 ( tie ) in Subtask A , 2/24 in Subtask B , 2/16 in Subtask C , 2/16 in Subtask D and 11/12 in Subtask E.",Semeval Results .,Semeval Results .,sentiment_analysis,20,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'O', 'O']",,,1,0.06666666666666667,164,0.8817204301075269,2,0.125,1,1,results
2,Sentiment Classification using Document Embeddings trained with Cosine Similarity,title,,sentiment_analysis,21,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.007142857142857143,1,0.0,1,1,research-problem
4,"In document - level sentiment classification , each document must be mapped to a fixed length vector .",abstract,abstract,sentiment_analysis,21,"['O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.02142857142857143,1,0.2,1,1,research-problem
10,"In document classification tasks such as sentiment classification ( in this paper we focus on binary sentiment classification of long movie reviews , i.e. determining whether each review is positive or negative ) , the choice of document representation is usually more important than the choice of classifier .",Introduction,Introduction,sentiment_analysis,21,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.09090909090909091,9,0.06428571428571428,1,0.09090909090909091,1,1,research-problem
13,This paper aims to improve existing document embedding models by training document embeddings using cosine similarity instead of dot product .,Introduction,Introduction,sentiment_analysis,21,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",4,0.36363636363636365,12,0.08571428571428572,4,0.36363636363636365,1,1,model
14,"For example , in the basic model of trying to predict given a document - the words / n - grams in the document , instead of trying to maximize the dot product between a document vector and vectors of the words / n - grams in the document over the training set , we 'll be trying to maximize the cosine similarity instead .",Introduction,Introduction,sentiment_analysis,21,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O']",,,5,0.45454545454545453,13,0.09285714285714286,5,0.45454545454545453,1,1,model
92,Code to reproduce all experiments is available at https://github.com/tanthongtan/dv-cosine.,Experiments,Experiments,sentiment_analysis,21,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,1.0,91,0.65,10,1.0,1,1,code
94,Grid search was performed using 20 % of the training data as a validation set in order to determine the optimal hyperparameters as well as whether to use a constant learning rate or learning rate annealing .,Optimal Hyperparameters,Optimal Hyperparameters,sentiment_analysis,21,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.08333333333333333,93,0.6642857142857143,1,0.08333333333333333,1,1,hyperparameters
97,"We did however tune the number of iterations from , learning rate from [ 0.25 , 0.025 , 0.0025 , 0.001 ] and ? from .",Optimal Hyperparameters,Optimal Hyperparameters,sentiment_analysis,21,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",4,0.3333333333333333,96,0.6857142857142857,4,0.3333333333333333,1,1,hyperparameters
100,"In the case of using L2 regularized dot product , ? ( regularization strength ) was chosen from [ 1 , 0.1 , 0.01 ] .",Optimal Hyperparameters,Optimal Hyperparameters,sentiment_analysis,21,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.5833333333333334,99,0.7071428571428572,7,0.5833333333333334,1,1,hyperparameters
101,"The optimal learning rate in the case of cosine similarity is extremely small , suggesting a chaotic error surface .",Optimal Hyperparameters,Optimal Hyperparameters,sentiment_analysis,21,"['O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.6666666666666666,100,0.7142857142857143,8,0.6666666666666666,1,1,hyperparameters
103,The model in turn requires a larger number of epochs for convergence .,Optimal Hyperparameters,Optimal Hyperparameters,sentiment_analysis,21,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",10,0.8333333333333334,102,0.7285714285714285,10,0.8333333333333334,1,1,hyperparameters
104,"For the distribution for sampling negative words , we used the n-gram distribution raised to the 3 / 4 th power in accordance with .",Optimal Hyperparameters,Optimal Hyperparameters,sentiment_analysis,21,"['B', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",11,0.9166666666666666,103,0.7357142857142858,11,0.9166666666666666,1,1,hyperparameters
105,"The weights of the networks were initialized from a uniform distribution in the range of [ - 0.001 , 0.001 ] .",Optimal Hyperparameters,Optimal Hyperparameters,sentiment_analysis,21,"['O', 'B', 'B', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']",,,12,1.0,104,0.7428571428571429,12,1.0,1,1,hyperparameters
109,From here we see that using cosine similarity instead of dot product improves accuracy across the board .,Results,Results,sentiment_analysis,21,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O']",3,0.13043478260869565,108,0.7714285714285715,3,0.3,1,1,results
111,However it is not to suggest that switching from dot product to cosine similarity alone improves accuracy as other minor ad - justments and hyperparameter tuning as explained was done .,Results,Results,sentiment_analysis,21,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.21739130434782608,110,0.7857142857142857,5,0.5,1,1,results
115,"As seen during grid search , whenever the initial learning rate was 0.25 , accuracy was always poor .",Results,Results,sentiment_analysis,21,"['O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.391304347826087,114,0.8142857142857143,9,0.9,1,1,results
116,"Introducing L2 regularization to dot product improves accuracy for all cases except a depreciation in the case of using unigrams only , lucikily cosine similarity does not suffer from this same depreciation .",Results,Results,sentiment_analysis,21,"['B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.43478260869565216,115,0.8214285714285714,10,1.0,1,1,results
2,Hierarchical Attention Based Position-aware Network for Aspect-level Sentiment Analysis,title,,sentiment_analysis,22,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004366812227074236,0,0.0,1,1,research-problem
12,"Aspect - level sentiment analysis is a fine - grained task in sentiment analysis , which aims to identify the sentiment polarity ( i.e. , negative , neutral , or positive ) of a specific opinion target expressed in a comment / review by a reviewer .",Introduction,Introduction,sentiment_analysis,22,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.03125,11,0.048034934497816595,1,0.03125,1,1,research-problem
37,"Based on the analysis above , in this paper , we propose a hierarchical attention based positionaware network ( HAPN ) for aspect - level sentiment classification .",Introduction,Introduction,sentiment_analysis,22,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",26,0.8125,36,0.1572052401746725,26,0.8125,1,1,model
38,A position - aware encoding layer is introduced for modelling the sentence to achieve the position - aware abstract representation of each word .,Introduction,Introduction,sentiment_analysis,22,"['O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",27,0.84375,37,0.1615720524017467,27,0.84375,1,1,model
39,"On this basis , a succinct fusion mechanism is further proposed to fuse the information of aspects and the contexts , achieving the final sentence representation .",Introduction,Introduction,sentiment_analysis,22,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",28,0.875,38,0.16593886462882096,28,0.875,1,1,model
40,"Finally , we feed the achieved sentence representation into a softmax layer to predict the sentiment polarity .",Introduction,Introduction,sentiment_analysis,22,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",29,0.90625,39,0.1703056768558952,29,0.90625,1,1,model
43,We make our source code public at https://github.com/DUT-LiuYang/Aspect-Sentiment-Analysis.,Introduction,Introduction,sentiment_analysis,22,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",32,1.0,42,0.18340611353711792,32,1.0,1,1,code
128,"We use 300 - dimension word vectors pre-trained by GloVe ( whose vocabulary size is 1.9M ) for our experiments , as previous works did .",Experiment Settings,Experiment Settings,sentiment_analysis,22,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.4,127,0.5545851528384279,4,0.4,1,1,hyperparameters
129,"All out - of - vocabulary words are initialized as zero vectors , and all biases are set to zero .",Experiment Settings,Experiment Settings,sentiment_analysis,22,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",5,0.5,128,0.5589519650655022,5,0.5,1,1,hyperparameters
130,The dimensions of hidden states and fused embeddings are set to 300 .,Experiment Settings,Experiment Settings,sentiment_analysis,22,"['O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'O']",6,0.6,129,0.5633187772925764,6,0.6,1,1,hyperparameters
131,The dimension of position embeddings is set to 50 .,Experiment Settings,Experiment Settings,sentiment_analysis,22,"['O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",7,0.7,130,0.5676855895196506,7,0.7,1,1,hyperparameters
132,Keras is used for implementing our neural network model .,Experiment Settings,Experiment Settings,sentiment_analysis,22,"['B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.8,131,0.5720524017467249,8,0.8,1,1,hyperparameters
133,"In model training , we set the learning rate to 0.001 , the batch size to 64 , and dropout rate to 0.5 .",Experiment Settings,Experiment Settings,sentiment_analysis,22,"['B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O']",,,9,0.9,132,0.5764192139737991,9,0.9,1,1,hyperparameters
134,The paired t- test is used for the significance testing .,Experiment Settings,Experiment Settings,sentiment_analysis,22,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",10,1.0,133,0.5807860262008734,10,1.0,1,1,hyperparameters
137,Majority assigns the sentiment polarity with most frequent occurrences in the training set to each sample in test set .,Compared Methods,Compared Methods,sentiment_analysis,22,"['B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O']",,,2,0.1111111111111111,136,0.5938864628820961,2,0.1111111111111111,1,1,baselines
139,Bi - LSTM and Bi - GRU adopt a Bi - LSTM and a Bi - GRU network to model the sentence and use the hidden state of the final word for prediction respectively .,Compared Methods,Compared Methods,sentiment_analysis,22,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O']",4,0.2222222222222222,138,0.6026200873362445,4,0.2222222222222222,1,1,baselines
141,TD - LSTM adopts two LSTMs to model the left context with target and the right context with target respectively ; It takes the hidden states of LSTM at last time - step to represent the sentence for prediction .,Compared Methods,Compared Methods,sentiment_analysis,22,"['B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'O']",,,6,0.3333333333333333,140,0.611353711790393,6,0.3333333333333333,1,1,baselines
143,"MemNet applies attention multiple times on the word embeddings , and the output of last attention is fed to softmax for prediction .",Compared Methods,Compared Methods,sentiment_analysis,22,"['B', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'O']","['B-n', 'B-p', 'B-n', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O']","['B-b', 'B-p', 'B-b', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O']",8,0.4444444444444444,142,0.6200873362445415,8,0.4444444444444444,1,1,baselines
145,"IAN interactively learns attentions in the contexts and targets , and generates the representations for targets and contexts separately .",Compared Methods,Compared Methods,sentiment_analysis,22,"['B', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O']","['B-n', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O']","['B-b', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",10,0.5555555555555556,144,0.62882096069869,10,0.5555555555555556,1,1,baselines
147,RAM ) is a multilayer architecture where each layer consists of attention - based aggregation of word features and a GRU cell to learn the sentence representation .,Compared Methods,Compared Methods,sentiment_analysis,22,"['B', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",12,0.6666666666666666,146,0.6375545851528385,12,0.6666666666666666,1,1,baselines
149,"LCR - Rot employs three Bi- LSTMs to model the left context , the target and the right context .",Compared Methods,Compared Methods,sentiment_analysis,22,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'O', 'O', 'B-ob', 'I-ob', 'O']",14,0.7777777777777778,148,0.6462882096069869,14,0.7777777777777778,1,1,baselines
152,AOA - LSTM introduces an attention - over- attention ( AOA ) based network to model aspects and sentences in a joint way and explicitly capture the interaction between aspects and context sentences .,Compared Methods,Compared Methods,sentiment_analysis,22,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.9444444444444444,151,0.6593886462882096,17,0.9444444444444444,1,1,baselines
155,"( 2 ) The TD - LSTM model , which has been shown to be better than LSTM , gets the worst performance of all RNN based models and the accuracy achieved by TD - LSTM is 2.94 % and 2.4 % lower than those by Bi - LSTM on the two datasets respectively .",System Performance Comparision,System Performance Comparision,sentiment_analysis,22,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.014285714285714285,154,0.6724890829694323,1,0.14285714285714285,1,1,results
159,"( 3 ) Compared with the state - of - the - art methods , our model achieves the best performance , which illustrates the effectiveness of the proposed approach .",System Performance Comparision,System Performance Comparision,sentiment_analysis,22,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.07142857142857142,158,0.6899563318777293,5,0.7142857142857143,1,1,results
160,"Our method achieves accuracies of 82.23 % as well as 77 . 27 % on the Restaurant and Laptop dataset respectively , which are 0.89 % and 2.03 % higher than the current best method .",System Performance Comparision,System Performance Comparision,sentiment_analysis,22,"['B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.08571428571428572,159,0.6943231441048034,6,0.8571428571428571,1,1,results
170,"After introducing the position embeddings , the accuracy has an increase of 0.62 % and 2.67 % on two datasets .",System Performance Comparision,Effects of Position Embeddings,sentiment_analysis,22,"['O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",16,0.22857142857142856,169,0.7379912663755459,8,0.6666666666666666,1,1,results
172,"In addition , another observation is that Bi - GRU - PW performs even worse than Bi - GRU .",System Performance Comparision,Effects of Position Embeddings,sentiment_analysis,22,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",18,0.2571428571428571,171,0.7467248908296943,10,0.8333333333333334,1,1,results
173,The accuracy achieved by Bi - GRU - PW is 0.72 % as well as 1.41 % lower than that by Bi - GRU on the Restaurant and Laptop dataset respectively .,System Performance Comparision,Effects of Position Embeddings,sentiment_analysis,22,"['O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",19,0.2714285714285714,172,0.7510917030567685,11,0.9166666666666666,1,1,results
180,HAPN achieves improvement of 0.35 % and 0.78 % on accuracy respectively on the two dataset .,System Performance Comparision,Effects of the Information Fusion,sentiment_analysis,22,"['B', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O']",26,0.37142857142857144,179,0.7816593886462883,5,0.8333333333333334,1,1,results
192,( 1 ) The information fusion operation is only used to calculate the Source2context attention value .,System Performance Comparision,Effects of The Hierarchical Attention,sentiment_analysis,22,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",38,0.5428571428571428,191,0.834061135371179,10,0.7142857142857143,1,1,results
193,The output of Source2aspect attention is only used for information fusion .,System Performance Comparision,Effects of The Hierarchical Attention,sentiment_analysis,22,"['O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",39,0.5571428571428572,192,0.8384279475982532,11,0.7857142857142857,1,1,results
195,"And the achieved model is "" Bi - GRU - PE "" reported in the , achieving the accuracies of 80.89 % and 76.02 % on the two datasets respectively , which are 1.34 % and 1.25 % lower than the proposed model .",System Performance Comparision,Effects of The Hierarchical Attention,sentiment_analysis,22,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",41,0.5857142857142857,194,0.8471615720524017,13,0.9285714285714286,1,1,results
2,Discriminative Neural Sentence Modeling by Tree - Based Convolution,title,,sentiment_analysis,23,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.003424657534246575,1,0.0,1,1,research-problem
26,"In this paper , we propose a novel neural architecture for discriminative sentence modeling , called the Tree - Based Convolutional Neural Network ( TBCNN ) .",Introduction,Introduction,sentiment_analysis,23,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.6521739130434783,25,0.08561643835616438,15,0.6521739130434783,1,1,model
27,"Our models can leverage different sentence parsing trees , e.g. , constituency trees and dependency trees .",Introduction,Introduction,sentiment_analysis,23,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.6956521739130435,26,0.08904109589041095,16,0.6956521739130435,1,1,model
28,"The model variants are denoted as c- TBCNN and d - TBCNN , respectively .",Introduction,Introduction,sentiment_analysis,23,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",17,0.7391304347826086,27,0.09246575342465753,17,0.7391304347826086,1,1,model
29,"The idea of tree - based convolution is to apply a set of subtree feature detectors , sliding over the entire parsing tree of a sentence ; then pooling aggregates these extracted feature vectors by taking the maximum value in each dimension .",Introduction,Introduction,sentiment_analysis,23,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",18,0.782608695652174,28,0.0958904109589041,18,0.782608695652174,1,1,model
193,"In our d-TBCNN model , the number of units is 300 for convolution and 200 for the last hidden layer .",Training Details,Training Details,sentiment_analysis,23,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O']",,,6,0.13953488372093023,192,0.6575342465753424,6,0.375,1,1,hyperparameters
194,"Word embeddings are 300 dimensional , pretrained ourselves using word2vec To train our model , we compute gradient by back - propagation and apply stochastic gradient descent with mini-batch 200 .",Training Details,Training Details,sentiment_analysis,23,"['B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.16279069767441862,193,0.660958904109589,7,0.4375,1,1,hyperparameters
195,We use ReLU as the activation function .,Training Details,Training Details,sentiment_analysis,23,"['O', 'B', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",8,0.18604651162790697,194,0.6643835616438356,8,0.5,1,1,hyperparameters
196,"For regularization , we add 2 penalty for weights with a coefficient of 10 ?5 .",Training Details,Training Details,sentiment_analysis,23,"['B', 'B', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",9,0.20930232558139536,195,0.6678082191780822,9,0.5625,1,1,hyperparameters
197,Dropout is further applied to both weights and embeddings .,Training Details,Training Details,sentiment_analysis,23,"['B', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.23255813953488372,196,0.6712328767123288,10,0.625,1,1,hyperparameters
198,"All hidden layers are dropped out by 50 % , and embeddings 40 % .",Training Details,Training Details,sentiment_analysis,23,"['B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'B-ob', 'I-ob', 'O']",11,0.2558139534883721,197,0.6746575342465754,11,0.6875,1,1,hyperparameters
208,"Nonetheless , our d-TBCNN model achieves",Training Details,Performance,sentiment_analysis,23,"['O', 'O', 'O', 'B', 'I', 'B']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p']",21,0.4883720930232558,207,0.708904109589041,4,0.4444444444444444,1,1,results
209,"87.9 % accuracy , ranking third in the list .",Training Details,Performance,sentiment_analysis,23,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.5116279069767442,208,0.7123287671232876,5,0.5555555555555556,1,1,results
210,"In a more controlled comparison - with shallow architectures and the basic interaction ( linearly transformed and non-linearly squashed ) - TBCNNs , of both variants , consistently outperform RNNs to a large extent ( 50.4 - 51.4 % versus 43.2 % ) ; they also consistently outperform "" flat "" CNNs by more than 10 % .",Training Details,Performance,sentiment_analysis,23,"['B', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",23,0.5348837209302325,209,0.7157534246575342,6,0.6666666666666666,1,1,results
212,We also observe d- TBCNN achieves higher performance than c - TBCNN .,Training Details,Performance,sentiment_analysis,23,"['O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",25,0.5813953488372093,211,0.7226027397260274,8,0.8888888888888888,1,1,results
2,An Interactive Multi - Task Learning Network for End - to - End Aspect - Based Sentiment Analysis,title,title,sentiment_analysis,24,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.003215434083601286,1,0.0,1,1,research-problem
11,Aspect - based sentiment analysis ( ABSA ) aims to determine people 's attitude towards specific aspects in a review .,Introduction,Introduction,sentiment_analysis,24,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.05263157894736842,10,0.03215434083601286,1,0.05263157894736842,1,1,research-problem
12,"This is done by extracting explicit aspect mentions , referred to as aspect term extraction ( AE ) , and detecting the sentiment orientation towards each extracted aspect term , referred to as aspect - level sentiment classification ( AS ) .",Introduction,Introduction,sentiment_analysis,24,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.10526315789473684,11,0.03536977491961415,2,0.10526315789473684,1,1,research-problem
20,"In this work , we propose an interactive multitask learning network ( IMN ) , which solves both tasks simultaneously , enabling the interactions between both tasks to be better exploited .",Introduction,Introduction,sentiment_analysis,24,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.5263157894736842,19,0.06109324758842444,10,0.5263157894736842,1,1,model
21,"Furthermore , IMN allows AE and AS to be trained together with related document - level tasks , exploiting the knowledge from larger document - level corpora .",Introduction,Introduction,sentiment_analysis,24,"['O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.5789473684210527,20,0.06430868167202572,11,0.5789473684210527,1,1,model
22,IMN introduces a novel message passing mechanism that allows informative interactions between tasks .,Introduction,Introduction,sentiment_analysis,24,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",12,0.631578947368421,21,0.06752411575562701,12,0.631578947368421,1,1,model
23,"Specifically , it sends useful information from different tasks back to a shared latent representation .",Introduction,Introduction,sentiment_analysis,24,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",13,0.6842105263157895,22,0.0707395498392283,13,0.6842105263157895,1,1,model
24,The information is then combined with the shared latent representation and made available to all tasks for further processing .,Introduction,Introduction,sentiment_analysis,24,"['O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",14,0.7368421052631579,23,0.07395498392282958,14,0.7368421052631579,1,1,model
26,"In contrast to most multi-task learning schemes which share information through learning a common feature representation , IMN not only allows shared features , but also explicitly models the interactions between tasks through the message passing mechanism , allowing different tasks to better influence each other .",Introduction,Introduction,sentiment_analysis,24,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",16,0.8421052631578947,25,0.08038585209003216,16,0.8421052631578947,1,1,model
27,"In addition , IMN allows fined - grained tokenlevel classification tasks to be trained together with document - level classification tasks .",Introduction,Introduction,sentiment_analysis,24,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.8947368421052632,26,0.08360128617363344,17,0.8947368421052632,1,1,model
28,"We incorporated two document - level classification tasks - sentiment classification ( DS ) and domain classification ( DD ) - to be jointly trained with AE and AS , allowing the aspect - level tasks to benefit from document - level information .",Introduction,Introduction,sentiment_analysis,24,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.9473684210526315,27,0.08681672025723473,18,0.9473684210526315,1,1,model
157,We adopt the multi - layer - CNN structure from as the CNN - based encoders in our proposed network .,Proposed Method,Network details .,sentiment_analysis,24,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",101,0.8278688524590164,156,0.5016077170418006,28,0.4666666666666667,1,1,hyperparameters
160,"For word embedding initialization , we concatenate a general - purpose embedding matrix and a domain - specific embedding matrix 7 following .",Proposed Method,A for implementation details .,sentiment_analysis,24,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",104,0.8524590163934426,159,0.5112540192926045,31,0.5166666666666667,1,1,hyperparameters
161,"We adopt their released domainspecific embeddings for restaurant and laptop domains with 100 dimensions , which are trained on a large domain - specific corpus using fast Text .",Proposed Method,A for implementation details .,sentiment_analysis,24,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",105,0.860655737704918,160,0.5144694533762058,32,0.5333333333333333,1,1,hyperparameters
162,The general - purpose embeddings are pre-trained Glove vectors with 300 dimensions .,Proposed Method,A for implementation details .,sentiment_analysis,24,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",106,0.8688524590163934,161,0.5176848874598071,33,0.55,1,1,hyperparameters
171,We tune the maximum number of iterations T in the message passing mechanism by training IMN ?d via cross validation on D1 .,Proposed Method,A for implementation details .,sentiment_analysis,24,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O']",115,0.9426229508196722,170,0.5466237942122186,42,0.7,1,1,hyperparameters
172,It is set to 2 .,Proposed Method,,sentiment_analysis,24,"['O', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",116,0.9508196721311475,171,0.5498392282958199,43,0.7166666666666667,1,1,hyperparameters
175,"We use Adam optimizer with learning rate set to 10 ? 4 , and we set batch size to 32 .",Proposed Method,It is set to 2 as well .,sentiment_analysis,24,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",119,0.9754098360655737,174,0.5594855305466238,46,0.7666666666666667,1,1,hyperparameters
176,Learning rate and batch size are set to conventional values without specific tuning for our task .,Proposed Method,It is set to 2 as well .,sentiment_analysis,24,"['B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",120,0.9836065573770492,175,0.5627009646302251,47,0.7833333333333333,1,1,hyperparameters
177,"At training phase , we randomly sample 20 % of the training data from the aspect - level dataset as the development set and only use the remaining 80 % for training .",Proposed Method,It is set to 2 as well .,sentiment_analysis,24,"['B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",121,0.9918032786885246,176,0.5659163987138264,48,0.8,1,1,hyperparameters
220,"From , we observe that IMN ?d is able to significantly outperform other baselines on F1 - I .",Main results .,Main results .,sentiment_analysis,24,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'O', 'O', 'O']",5,0.2777777777777778,219,0.7041800643086816,6,0.10526315789473684,1,1,results
221,"IMN further boosts the performance and outperforms the best F1 - I results from the baselines by 2.29 % , 1.77 % , and 2.61 % on D1 , D2 , and D3 .",Main results .,Main results .,sentiment_analysis,24,"['B', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'O', 'B-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.3333333333333333,220,0.707395498392283,7,0.12280701754385964,1,1,results
222,"Specifically , for AE ( F1 - a and F1 - o ) , IMN ?d performs the best in most cases .",Main results .,Main results .,sentiment_analysis,24,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.3888888888888889,221,0.7106109324758842,8,0.14035087719298245,1,1,results
223,"For AS ( acc - s and F1 - s ) , IMN outperforms other methods by large margins .",Main results .,Main results .,sentiment_analysis,24,"['B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.4444444444444444,222,0.7138263665594855,9,0.15789473684210525,1,1,results
229,IMN wo DE performs only marginally below IMN .,Main results .,,sentiment_analysis,24,"['B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",14,0.7777777777777778,228,0.7331189710610932,15,0.2631578947368421,1,1,results
231,"IMN ?d is more affected without domain - specific embeddings , while it still outperforms all other baselines except DECNN - d Trans .",Main results .,IMN wo DE performs only marginally below IMN .,sentiment_analysis,24,"['B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.8888888888888888,230,0.7395498392282959,17,0.2982456140350877,1,1,results
232,DECNN - dTrans is a very strong baseline as it exploits additional knowledge from larger corpora for both tasks .,Main results .,IMN wo DE performs only marginally below IMN .,sentiment_analysis,24,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",17,0.9444444444444444,231,0.7427652733118971,18,0.3157894736842105,1,1,results
233,"IMN ?d wo DE is competitive with DECNN - dTrans even without utilizing additional knowledge , which suggests the effectiveness of the proposed network structure .",Main results .,IMN wo DE performs only marginally below IMN .,sentiment_analysis,24,"['B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,1.0,232,0.7459807073954984,19,0.3333333333333333,1,1,results
242,"We observe that + Message passing - a and + Message passing - d contribute to the performance gains the most , which demonstrates the effectiveness of the proposed message passing mechanism .",Ablation study .,Ablation study .,sentiment_analysis,24,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.21621621621621623,241,0.77491961414791,28,0.49122807017543857,1,1,ablation-analysis
243,We also observe that simply adding documentlevel tasks ( + DS / DD ) with parameter sharing only marginally improves the performance of IMN ?d .,Ablation study .,Ablation study .,sentiment_analysis,24,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",9,0.24324324324324326,242,0.7781350482315113,29,0.5087719298245614,1,1,ablation-analysis
245,"However , + Message passing -d is still helpful with considerable performance gains , showing that aspect - level tasks can benefit from knowing predictions of the relevant document - level tasks .",Ablation study .,Ablation study .,sentiment_analysis,24,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.2972972972972973,244,0.7845659163987139,31,0.543859649122807,1,1,ablation-analysis
2,Aspect Based Sentiment Analysis with Gated Convolutional Networks,title,,sentiment_analysis,25,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.0045045045045045045,1,0.0,1,1,research-problem
4,"Aspect based sentiment analysis ( ABSA ) can provide more detailed information than general sentiment analysis , because it aims to predict the sentiment polarities of the given aspects or entities in text .",abstract,abstract,sentiment_analysis,25,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.1111111111111111,3,0.013513513513513514,1,0.1111111111111111,1,1,research-problem
5,We summarize previous approaches into two subtasks : aspect - category sentiment analysis ( ACSA ) and aspect - term sentiment analysis ( ATSA ) .,abstract,abstract,sentiment_analysis,25,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.2222222222222222,4,0.018018018018018018,2,0.2222222222222222,1,1,research-problem
18,"A number of models have been developed for ABSA , but there are two different subtasks , namely aspect - category sentiment analysis ( ACSA ) and aspect - term sentiment analysis ( ATSA ) .",Introduction,Introduction,sentiment_analysis,25,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.1724137931034483,17,0.07657657657657657,5,0.1724137931034483,1,1,research-problem
19,"The goal of ACSA is to predict the sentiment polarity with regard to the given aspect , which is one of a few predefined categories .",Introduction,Introduction,sentiment_analysis,25,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.20689655172413793,18,0.08108108108108109,6,0.20689655172413793,1,1,research-problem
20,"On the other hand , the goal of ATSA is to identify the sentiment polarity concerning the target entities that appear in the text instead , which could be a multi-word phrase or a single word .",Introduction,Introduction,sentiment_analysis,25,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.2413793103448276,19,0.08558558558558559,7,0.2413793103448276,1,1,research-problem
33,"In this paper , we propose a fast and effective neural network for ACSA and ATSA based on convolutions and gating mechanisms , which has much less training time than LSTM based networks , but with better accuracy .",Introduction,Introduction,sentiment_analysis,25,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.6896551724137931,32,0.14414414414414414,20,0.6896551724137931,1,1,model
34,"For ACSA task , our model has two separate convolutional layers on the top of the embedding layer , whose outputs are combined by novel gating units .",Introduction,Introduction,sentiment_analysis,25,"['B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",21,0.7241379310344828,33,0.14864864864864866,21,0.7241379310344828,1,1,model
36,"The proposed gating units have two nonlinear gates , each of which is connected to one convolutional layer .",Introduction,Introduction,sentiment_analysis,25,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",23,0.7931034482758621,35,0.15765765765765766,23,0.7931034482758621,1,1,model
40,"For ATSA task , where the aspect terms consist of multiple words , we extend our model to include another convolutional layer for the target expressions .",Introduction,Introduction,sentiment_analysis,25,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",27,0.9310344827586207,39,0.17567567567567569,27,0.9310344827586207,1,1,model
148,"In our experiments , word embedding vectors are initialized with 300 - dimension GloVe vectors which are pre-trained on unlabeled data of 840 billion tokens .",Datasets and Experiment Preparation,Datasets and Experiment Preparation,sentiment_analysis,25,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",23,0.8518518518518519,147,0.6621621621621622,23,0.8518518518518519,1,1,hyperparameters
149,"Words out of the vocabulary of Glo Ve are randomly initialized with a uniform distribution U ( ? 0.25 , 0.25 ) .",Datasets and Experiment Preparation,Datasets and Experiment Preparation,sentiment_analysis,25,"['B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",24,0.8888888888888888,148,0.6666666666666666,24,0.8888888888888888,1,1,hyperparameters
150,"We use Adagrad with a batch size of 32 instances , default learning rate of 1 e ? 2 , and maximal epochs of 30 .",Datasets and Experiment Preparation,Datasets and Experiment Preparation,sentiment_analysis,25,"['O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'O']",,,25,0.9259259259259259,149,0.6711711711711712,25,0.9259259259259259,1,1,hyperparameters
151,We only fine tune early stopping with 5 - fold cross validation on training datasets .,Datasets and Experiment Preparation,Datasets and Experiment Preparation,sentiment_analysis,25,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",26,0.9629629629629629,150,0.6756756756756757,26,0.9629629629629629,1,1,hyperparameters
152,All neural models are implemented in PyTorch .,Datasets and Experiment Preparation,Datasets and Experiment Preparation,sentiment_analysis,25,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",27,1.0,151,0.6801801801801802,27,1.0,1,1,hyperparameters
155,NRC - Canada is the top method in SemEval 2014 Task 4 for ACSA and ATSA task .,Compared Methods,Compared Methods,sentiment_analysis,25,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.15384615384615385,154,0.6936936936936937,2,0.15384615384615385,1,1,baselines
158,CNN is widely used on text classification task .,Compared Methods,Compared Methods,sentiment_analysis,25,"['B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",5,0.38461538461538464,157,0.7072072072072072,5,0.38461538461538464,1,1,baselines
161,TD - LSTM uses two LSTM networks to model the preceding and following contexts of the target to generate target - dependent representation for sentiment prediction .,Compared Methods,Compared Methods,sentiment_analysis,25,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.6153846153846154,160,0.7207207207207207,8,0.6153846153846154,1,1,baselines
162,ATAE - LSTM is an attention - based LSTM for ACSA task .,Compared Methods,Compared Methods,sentiment_analysis,25,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",9,0.6923076923076923,161,0.7252252252252253,9,0.6923076923076923,1,1,baselines
164,"IAN stands for interactive attention network for ATSA task , which is also based on LSTM and attention mechanisms .",Compared Methods,Compared Methods,sentiment_analysis,25,"['B', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.8461538461538461,163,0.7342342342342343,11,0.8461538461538461,1,1,baselines
165,"RAM is a recurrent attention network for ATSA task , which uses LSTM and multiple attention mechanisms .",Compared Methods,Compared Methods,sentiment_analysis,25,"['B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.9230769230769231,164,0.7387387387387387,12,0.9230769230769231,1,1,baselines
166,"GCN stands for gated convolutional neural network , in which GTRU does not have the aspect embedding as an additional input .",Compared Methods,Compared Methods,sentiment_analysis,25,"['B', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",13,1.0,165,0.7432432432432432,13,1.0,1,1,baselines
172,LSTM based model ATAE - LSTM has the worst performance of all neural networks .,Results and Analysis,ACSA,sentiment_analysis,25,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",5,0.14285714285714285,171,0.7702702702702703,4,0.17391304347826086,1,1,results
177,GCAE improves the performance by 1.1 % to 2.5 % compared with ATAE - LSTM .,Results and Analysis,ACSA,sentiment_analysis,25,"['B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.2857142857142857,176,0.7927927927927928,9,0.391304347826087,1,1,results
184,"Without the large amount of sentiment lexicons , SVM perform worse than neural methods .",Results and Analysis,ACSA,sentiment_analysis,25,"['B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",17,0.4857142857142857,183,0.8243243243243243,16,0.6956521739130435,1,1,results
185,"With multiple sentiment lexicons , the performance is increased by 7.6 % .",Results and Analysis,ACSA,sentiment_analysis,25,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",18,0.5142857142857142,184,0.8288288288288288,17,0.7391304347826086,1,1,results
189,GCAE achieves 4 % higher accuracy than ATAE - LSTM on Restaurant - Large and 5 % higher on SemEval - 2014 on ACSA task .,Results and Analysis,ACSA,sentiment_analysis,25,"['B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']",,,22,0.6285714285714286,188,0.8468468468468469,21,0.9130434782608695,1,1,results
190,"However , GCN , which does not have aspect modeling part , has higher score than GCAE on the original restaurant dataset .",Results and Analysis,ACSA,sentiment_analysis,25,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",23,0.6571428571428571,189,0.8513513513513513,22,0.9565217391304348,1,1,results
192,ATSA,Results and Analysis,,sentiment_analysis,25,['B'],['B-n'],['B-b'],25,0.7142857142857143,191,0.8603603603603603,0,0.0,1,1,results
197,"IAN has better performance than TD - LSTM and ATAE - LSTM , because two attention layers guides the representation learning of the context and the entity interactively .",Results and Analysis,ATSA,sentiment_analysis,25,"['B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",30,0.8571428571428571,196,0.8828828828828829,5,0.5,1,1,results
198,"RAM also achieves good accuracy by combining multiple attentions with a recurrent neural network , but it needs more training time as shown in the following section .",Results and Analysis,ATSA,sentiment_analysis,25,"['B', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",31,0.8857142857142857,197,0.8873873873873874,6,0.6,1,1,results
199,"On the hard test dataset , GCAE has 1 % higher accuracy than RAM on restaurant data and 1.7 % higher on laptop data .",Results and Analysis,ATSA,sentiment_analysis,25,"['B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']",,,32,0.9142857142857143,198,0.8918918918918919,7,0.7,1,1,results
201,"Because of the gating mechanisms and the convolutional layer over aspect terms , GCAE outperforms other neural models and basic SVM .",Results and Analysis,ATSA,sentiment_analysis,25,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",34,0.9714285714285714,200,0.9009009009009009,9,0.9,1,1,results
2,A Helping Hand : Transfer Learning for Deep Sentiment Analysis,title,title,sentiment_analysis,26,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004081632653061225,1,0.0,1,1,research-problem
9,"Over the past decades , sentiment analysis has grown from an academic endeavour to an essential analytics tool .",Introduction,Introduction,sentiment_analysis,26,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.07692307692307693,8,0.0326530612244898,1,0.07692307692307693,1,1,research-problem
12,"In recent years , deep neural architectures based on convolutional or recurrent layers have become established as the preeminent models for supervised sentiment polarity classification .",Introduction,Introduction,sentiment_analysis,26,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.3076923076923077,11,0.044897959183673466,4,0.3076923076923077,1,1,research-problem
16,"In this paper , we investigate how extrinsic signals can be incorporated into deep neural networks for sentiment analysis .",Introduction,Introduction,sentiment_analysis,26,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.6153846153846154,15,0.061224489795918366,8,0.6153846153846154,1,1,model
18,"In our paper , we instead consider word embeddings specifically specialized for the task of sentiment analysis , studying how they can lead to stronger and more consistent gains , despite the fact that the embeddings were obtained using out - of - domain data .",Introduction,Introduction,sentiment_analysis,26,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.7692307692307693,17,0.06938775510204082,10,0.7692307692307693,1,1,model
20,We instead propose a bespoke convolutional neural network architecture with a separate memory module dedicated to the sentiment embeddings .,Introduction,Introduction,sentiment_analysis,26,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",12,0.9230769230769231,19,0.07755102040816327,12,0.9230769230769231,1,1,model
125,Embeddings .,Experimental Setup,,sentiment_analysis,26,"['B', 'O']","['B-n', 'O']","['B-b', 'O']",17,0.4473684210526316,124,0.5061224489795918,17,0.4473684210526316,1,1,experimental-setup
126,"The standard pre-trained word vectors used for English are the GloVe ones trained on 840 billion tokens of Common Crawl data 1 , while for other languages , we rely on the Facebook fastText Wikipedia embeddings as input representations .",Experimental Setup,Embeddings .,sentiment_analysis,26,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",18,0.47368421052631576,125,0.5102040816326531,18,0.47368421052631576,1,1,experimental-setup
127,All of these are 300 - dimensional .,Experimental Setup,Embeddings .,sentiment_analysis,26,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'O']",,,19,0.5,126,0.5142857142857142,19,0.5,1,1,experimental-setup
128,"The vectors are either fed to the CNN , or to the convolutional module of the DM - MCNN during initialization , while unknown words are initialized with zeros .",Experimental Setup,Embeddings .,sentiment_analysis,26,"['O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",20,0.5263157894736842,127,0.5183673469387755,20,0.5263157894736842,1,1,experimental-setup
129,"All words , including the unknown ones , are fine - tuned during the training process .",Experimental Setup,Embeddings .,sentiment_analysis,26,"['B', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",21,0.5526315789473685,128,0.5224489795918368,21,0.5526315789473685,1,1,experimental-setup
130,"For our transfer learning approach , our experiments rely on the multi-domain sentiment dataset by , collected from Amazon customers reviews .",Experimental Setup,Embeddings .,sentiment_analysis,26,"['B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",22,0.5789473684210527,129,0.5265306122448979,22,0.5789473684210527,1,1,experimental-setup
132,"Specifically , we train linear SVMs using scikit - learn to extract word coefficients in each domain and also for the union of all domains together , yielding a 26 - dimensional sentiment embedding .",Experimental Setup,Embeddings .,sentiment_analysis,26,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",24,0.631578947368421,131,0.5346938775510204,24,0.631578947368421,1,1,experimental-setup
133,"For comparison and analysis , we also consider several alternative forms of infusing external cues .",Experimental Setup,Embeddings .,sentiment_analysis,26,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",25,0.6578947368421053,132,0.5387755102040817,25,0.6578947368421053,1,1,experimental-setup
135,We consider a recent sentiment lexicon called VADER .,Experimental Setup,Embeddings .,sentiment_analysis,26,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'O']",27,0.7105263157894737,134,0.5469387755102041,27,0.7105263157894737,1,1,experimental-setup
137,"These contain separate domain - specific scores for 250 different Reddit communities , and hence result in 250 - dimensional embeddings .",Experimental Setup,Embeddings .,sentiment_analysis,26,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",29,0.7631578947368421,136,0.5551020408163265,29,0.7631578947368421,1,1,experimental-setup
138,"For cross - lingual projection , we extract links between words from a 2017 dump of the English edition of Wiktionary .",Experimental Setup,Embeddings .,sentiment_analysis,26,"['O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",30,0.7894736842105263,137,0.5591836734693878,30,0.7894736842105263,1,1,experimental-setup
139,"We restrict the vocabulary link set to include the languages in , mining corresponding translation , synonymy , derivation , and etymological links from Wiktionary .",Experimental Setup,Embeddings .,sentiment_analysis,26,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'B-p', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'B-p', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O', 'O', 'B-ob', 'I-ob', 'O', 'B-b', 'O']",31,0.8157894736842105,138,0.563265306122449,31,0.8157894736842105,1,1,experimental-setup
141,"For CNNs , we make use of the well - known CNN - non-static architecture and hyperparameters proposed by , with a learning rate of 0.0006 , obtained by tuning on the validation data .",Experimental Setup,Neural Network Details .,sentiment_analysis,26,"['B', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",33,0.868421052631579,140,0.5714285714285714,33,0.868421052631579,1,1,experimental-setup
142,"For our DM - MCNN models , the configuration of the convolutional module is the same as for CNNs , and the remaining hyperparameter values were as well tuned on the validation sets .",Experimental Setup,Neural Network Details .,sentiment_analysis,26,"['O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",34,0.8947368421052632,141,0.5755102040816327,34,0.8947368421052632,1,1,experimental-setup
144,"For greater efficiency and better convergence properties , the training relies on mini-batches .",Experimental Setup,Neural Network Details .,sentiment_analysis,26,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'O']",36,0.9473684210526315,143,0.5836734693877551,36,0.9473684210526315,1,1,experimental-setup
145,"Our implementation considers the maximal sentence length in each mini-batch and zero - pads all other sentences to this length under convolutional module , thus enabling uniform and fast processing of each mini-batch .",Experimental Setup,Neural Network Details .,sentiment_analysis,26,"['O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']",,,37,0.9736842105263158,144,0.5877551020408164,37,0.9736842105263158,1,1,experimental-setup
146,All neural network architectures are implemented using the PyTorch framework 2 .,Experimental Setup,Neural Network Details .,sentiment_analysis,26,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'O']",38,1.0,145,0.5918367346938775,38,1.0,1,1,experimental-setup
152,"Comparing this to CNNs with GloVe / fastText embeddings , where Glo Ve is used for English , and fastText is used for all other languages , we observe substantial improvements across all datasets .",Baseline Results .,Baseline Results .,sentiment_analysis,26,"['B', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'O']",,,4,0.17391304347826086,151,0.6163265306122448,5,0.06493506493506493,1,1,results
153,This shows that word vectors do tend to convey pertinent word semantics signals that enable models to generalize better .,Baseline Results .,Baseline Results .,sentiment_analysis,26,"['O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'O']",5,0.21739130434782608,152,0.6204081632653061,6,0.07792207792207792,1,1,results
154,Note also that the accuracy using GloVe on the English movies review dataset is consistent with numbers reported in previous work .,Baseline Results .,Baseline Results .,sentiment_analysis,26,"['B', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O']","['B-p', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-p', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",6,0.2608695652173913,153,0.6244897959183674,7,0.09090909090909091,1,1,results
156,"Next , we consider our DM - MCNNs with their dual - module mechanism to take advantage of transfer learning .",Baseline Results .,Baseline Results .,sentiment_analysis,26,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.34782608695652173,155,0.6326530612244898,9,0.11688311688311688,1,1,results
157,We observe fairly consistent and sometimes quite substan - tial gains over CNNs with just the GloVe / fastText vectors .,Baseline Results .,Baseline Results .,sentiment_analysis,26,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.391304347826087,156,0.636734693877551,10,0.12987012987012986,1,1,results
171,"Although the automatically projected cross - lingual embeddings are very noisy and limited in their coverage , particularly with respect to inflected forms , our model succeeds in exploiting them to obtain substantial gains in several different languages and domains .",Baseline Results .,Baseline Results .,sentiment_analysis,26,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",23,1.0,170,0.6938775510204082,24,0.3116883116883117,1,1,results
2,Modeling Sentiment Dependencies with Graph Convolutional Networks for Aspect - level Sentiment Classification,title,title,sentiment_analysis,27,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0036231884057971015,1,0.0,1,1,research-problem
14,"It is a fine - grained task in sentiment analysis , which aims to infer the sentiment polarities of aspects in their context .",Introduction,Introduction,sentiment_analysis,27,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.04878048780487805,13,0.04710144927536232,2,0.04878048780487805,1,1,research-problem
39,"In this paper , we propose a novel method to model Sentiment Dependencies with Graph Convolutional Networks ( SDGCN ) for aspect - level sentiment classification .",Introduction,Introduction,sentiment_analysis,27,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,0.6585365853658537,38,0.13768115942028986,27,0.6585365853658537,1,1,model
40,"GCN is a simple and effective convolutional neural network operating on graphs , which can catch inter-dependent information from rich relational data .",Introduction,Introduction,sentiment_analysis,27,"['B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",28,0.6829268292682927,39,0.14130434782608695,28,0.6829268292682927,1,1,model
41,"For every node in graph , GCN encodes relevant information about its neighborhoods as a new feature representation vector .",Introduction,Introduction,sentiment_analysis,27,"['B', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",29,0.7073170731707317,40,0.14492753623188406,29,0.7073170731707317,1,1,model
42,"In our case , an aspect is treated as a node , and an edge represents the sentiment dependency relation of two nodes .",Introduction,Introduction,sentiment_analysis,27,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",30,0.7317073170731707,41,0.14855072463768115,30,0.7317073170731707,1,1,model
43,Our model learns the sentiment dependencies of aspects via this graph structure .,Introduction,Introduction,sentiment_analysis,27,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",31,0.7560975609756098,42,0.15217391304347827,31,0.7560975609756098,1,1,model
44,"As far as we know , our work is the first to consider the sentiment dependencies between aspects in one sentence for aspect - level sentiment classification task .",Introduction,Introduction,sentiment_analysis,27,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",32,0.7804878048780488,43,0.15579710144927536,32,0.7804878048780488,1,1,model
45,"Furthermore , in order to capture the aspect - specific representations , our model applies bidirectional attention mechanism with position encoding before GCN .",Introduction,Introduction,sentiment_analysis,27,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",33,0.8048780487804879,44,0.15942028985507245,33,0.8048780487804879,1,1,model
184,"In our implementation , we respectively use the GloVe 3 word vector and the pre-trained language model word representation BERT 4 to initialize the word embeddings .",Experiments,Experiments,sentiment_analysis,27,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O']",14,0.6086956521739131,183,0.6630434782608695,13,0.5909090909090909,1,1,hyperparameters
185,The dimension of each word vector is 300 for GloVe and 768 for BERT .,Experiments,Experiments,sentiment_analysis,27,"['O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'O']",,,15,0.6521739130434783,184,0.6666666666666666,14,0.6363636363636364,1,1,hyperparameters
186,"The number of LSTM hidden units is set to 300 , and the output dimension of GCN layer is set to 600 .",Experiments,Experiments,sentiment_analysis,27,"['O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O']",,,16,0.6956521739130435,185,0.6702898550724637,15,0.6818181818181818,1,1,hyperparameters
187,"The weight matrix of last fully connect layer is randomly initialized by a normal distribution N ( 0 , 1 ) .",Experiments,Experiments,sentiment_analysis,27,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.7391304347826086,186,0.6739130434782609,16,0.7272727272727273,1,1,hyperparameters
188,"Besides the last fully connect layer , all the weight matrices are randomly initialized by a uniform distribution U ( ? 0.01 , 0.01 ) .",Experiments,Experiments,sentiment_analysis,27,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.782608695652174,187,0.677536231884058,17,0.7727272727272727,1,1,hyperparameters
189,"In addition , we add L2-regularization to the last fully connect layer with a weight of 0.01 .",Experiments,Experiments,sentiment_analysis,27,"['O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O']",19,0.8260869565217391,188,0.6811594202898551,18,0.8181818181818182,1,1,hyperparameters
190,"During training , we set dropout to 0.5 , the batch size is set to 32 and the optimizer is Adam Optimizer with a learning rate of 0.001 .",Experiments,Experiments,sentiment_analysis,27,"['B', 'B', 'O', 'O', 'B', 'B', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-p', 'I-p', 'B-n', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'B-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",20,0.8695652173913043,189,0.6847826086956522,19,0.8636363636363636,1,1,hyperparameters
191,We implement our proposed model using Tensorflow 5 .,Experiments,Experiments,sentiment_analysis,27,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O']",21,0.9130434782608695,190,0.6884057971014492,20,0.9090909090909091,1,1,hyperparameters
196,"TD - LSTM constructs aspect-specific representation by the left context with aspect and the right context with aspect , then employs two LSTMs to model them respectively .",Comparative methods,Comparative methods,sentiment_analysis,27,"['B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O']",,,2,0.09090909090909091,195,0.7065217391304348,2,0.09090909090909091,1,1,baselines
197,The last hidden states of the two LSTMs are finally concatenated for predicting the sentiment polarity of the aspect .,Comparative methods,Comparative methods,sentiment_analysis,27,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O']",,,3,0.13636363636363635,196,0.7101449275362319,3,0.13636363636363635,1,1,baselines
198,"ATAE - LSTM first attaches the aspect embedding to each word embedding to capture aspect - dependent information , and then employs attention mechanism to get the sentence representation for final classification .",Comparative methods,Comparative methods,sentiment_analysis,27,"['B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",4,0.18181818181818182,197,0.7137681159420289,4,0.18181818181818182,1,1,baselines
199,Mem Net uses a deep memory network on the context word embeddings for sentence representation to capture the relevance between each context word and the aspect .,Comparative methods,Comparative methods,sentiment_analysis,27,"['B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.22727272727272727,198,0.717391304347826,5,0.22727272727272727,1,1,baselines
201,IAN generates the representations for aspect terms and contexts with two attention - based LSTM network separately .,Comparative methods,Comparative methods,sentiment_analysis,27,"['B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",7,0.3181818181818182,200,0.7246376811594203,7,0.3181818181818182,1,1,baselines
203,"RAM [ 10 ] employs a gated recurrent unit network to model a multiple attention mechanism , and captures the relevance between each context word and the aspect .",Comparative methods,Comparative methods,sentiment_analysis,27,"['B', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']",,,9,0.4090909090909091,202,0.7318840579710145,9,0.4090909090909091,1,1,baselines
205,PBAN appends the position embedding into each word embedding .,Comparative methods,Comparative methods,sentiment_analysis,27,"['B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",11,0.5,204,0.7391304347826086,11,0.5,1,1,baselines
207,TSN is a two - stage framework for aspect - level sentiment analysis .,Comparative methods,Comparative methods,sentiment_analysis,27,"['B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.5909090909090909,206,0.7463768115942029,13,0.5909090909090909,1,1,baselines
210,"AEN mainly consists of an embedding layer , an attentional encoder layer , an aspect - specific attention layer , and an output layer .",Comparative methods,Comparative methods,sentiment_analysis,27,"['B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O']","['B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",16,0.7272727272727273,209,0.7572463768115942,16,0.7272727272727273,1,1,baselines
212,AEN - BERT is AEN with BERT embedding .,Comparative methods,Comparative methods,sentiment_analysis,27,"['B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",18,0.8181818181818182,211,0.7644927536231884,18,0.8181818181818182,1,1,baselines
218,"Among all the GloVe - based methods , the TD - LSTM approach performs worst because it takes the aspect information into consideration in a very coarse way .",Overall results,Overall results,sentiment_analysis,27,"['B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.02040816326530612,217,0.7862318840579711,1,0.0625,1,1,results
220,"After taking the importance of the aspect into account with attention mechanism , they achieve a stable improvement comparing to the TD - LSTM .",Overall results,Overall results,sentiment_analysis,27,"['B', 'I', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.061224489795918366,219,0.7934782608695652,3,0.1875,1,1,results
221,"RAM achieves a better performance than other basic attention - based models , because it combines multiple attentions with a recurrent neural network to capture aspect - specific representations .",Overall results,Overall results,sentiment_analysis,27,"['B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.08163265306122448,220,0.7971014492753623,4,0.25,1,1,results
222,PBAN achieves a similar performance as RAM by employing a position embedding .,Overall results,Overall results,sentiment_analysis,27,"['B', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.10204081632653061,221,0.8007246376811594,5,0.3125,1,1,results
223,"To be specific , PBAN is better than RAM on Restaurant dataset , but worse than RAN on Laptop dataset .",Overall results,Overall results,sentiment_analysis,27,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O']",,,6,0.12244897959183673,222,0.8043478260869565,6,0.375,1,1,results
224,"Compared with RAM and PBAN , the over all performance of TSN is not perform well on both Restaurant dataset and Laptop dataset , which might because the framework of TSN is too simple to model the representations of context and aspect effectively .",Overall results,Overall results,sentiment_analysis,27,"['B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.14285714285714285,223,0.8079710144927537,7,0.4375,1,1,results
225,"AEN is slightly better than TSN , but still worse than RAM and PBAN .",Overall results,Overall results,sentiment_analysis,27,"['B', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.16326530612244897,224,0.8115942028985508,8,0.5,1,1,results
227,"Comparing the results of SDGCN - A w/o position and SDGCN - G w/o position , SDGCN - A and SDGCN - G , respectively , we observe that the GCN built with global - relation is slightly higher than built with adjacent - relation in both accuracy and Macro - F1 measure .",Overall results,Overall results,sentiment_analysis,27,"['B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.20408163265306123,226,0.8188405797101449,10,0.625,1,1,results
229,"Moreover , the two models ( SDGCN - A and SDGCN - G ) with position information gain a significant improvement compared to the two models without position information .",Overall results,Overall results,sentiment_analysis,27,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']",,,12,0.24489795918367346,228,0.8260869565217391,12,0.75,1,1,results
231,"Benefits from the power of pre-trained BERT , BERT - based models have shown huge superiority over GloVe - based models .",Overall results,Overall results,sentiment_analysis,27,"['B', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.2857142857142857,230,0.8333333333333334,14,0.875,1,1,results
232,"Furthermore , compared with AEN - BERT , on the Restaurant dataset , SDGCN - BERT achieves absolute increases of 1.09 % and 1.86 % in accuracy and Macro - F1 measure respectively , and gains absolute increases of 1.42 % and 2.03 % in accuracy and Macro - F1 measure respectively on the Laptop dataset .",Overall results,Overall results,sentiment_analysis,27,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O']",,,15,0.30612244897959184,231,0.8369565217391305,15,0.9375,1,1,results
2,Attentional Encoder Network for Targeted Sentiment Classification,title,,sentiment_analysis,28,"['O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.005555555555555556,1,0.0,1,1,research-problem
12,"Targeted sentiment classification is a fine - grained sentiment analysis task , which aims at determining the sentiment polarities ( e.g. , negative , neutral , or positive ) of a sentence over "" opinion targets "" that explicitly appear in the sentence .",Introduction,Introduction,sentiment_analysis,28,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.03571428571428571,11,0.06111111111111111,1,0.03571428571428571,1,1,research-problem
16,"However , these neural network models are still in infancy to deal with the fine - grained targeted sentiment classification task .",Introduction,Introduction,sentiment_analysis,28,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",5,0.17857142857142858,15,0.08333333333333333,5,0.17857142857142858,1,1,research-problem
26,This paper propose an attention based model to solve the problems above .,Introduction,Introduction,sentiment_analysis,28,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.5357142857142857,25,0.1388888888888889,15,0.5357142857142857,1,1,model
27,"Specifically , our model eschews recurrence and employs attention as a competitive alternative to draw the introspective and interactive semantics between target and context words .",Introduction,Introduction,sentiment_analysis,28,"['O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.5714285714285714,26,0.14444444444444443,16,0.5714285714285714,1,1,model
28,"To deal with the label unreliability issue , we employ a label smoothing regularization to encourage the model to be less confident with fuzzy labels .",Introduction,Introduction,sentiment_analysis,28,"['B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",17,0.6071428571428571,27,0.15,17,0.6071428571428571,1,1,model
29,We also apply pre-trained BERT to this task and show our model enhances the performance of basic BERT model .,Introduction,Introduction,sentiment_analysis,28,"['O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.6428571428571429,28,0.15555555555555556,18,0.6428571428571429,1,1,model
126,shows the number of training and test instances in each category .,Datasets and Experimental Settings,Datasets and Experimental Settings,sentiment_analysis,28,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",4,0.36363636363636365,125,0.6944444444444444,4,0.36363636363636365,1,1,hyperparameters
127,"Word embeddings in AEN - Glo Ve do not get updated in the learning process , but we fine - tune pre-trained BERT 3 in AEN - BERT .",Datasets and Experimental Settings,Datasets and Experimental Settings,sentiment_analysis,28,"['B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'O']",,,5,0.45454545454545453,126,0.7,5,0.45454545454545453,1,1,hyperparameters
128,Embedding dimension d dim is 300 for GloVe and is 768 for pretrained BERT .,Datasets and Experimental Settings,Datasets and Experimental Settings,sentiment_analysis,28,"['B', 'I', 'I', 'I', 'B', 'B', 'B', 'B', 'O', 'O', 'B', 'B', 'B', 'I', 'O']",,,6,0.5454545454545454,127,0.7055555555555556,6,0.5454545454545454,1,1,hyperparameters
129,Dimension of hidden states d hid is set to 300 .,Datasets and Experimental Settings,Datasets and Experimental Settings,sentiment_analysis,28,"['B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",7,0.6363636363636364,128,0.7111111111111111,7,0.6363636363636364,1,1,hyperparameters
130,The weights of our model are initialized with Glorot initialization .,Datasets and Experimental Settings,Datasets and Experimental Settings,sentiment_analysis,28,"['O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",8,0.7272727272727273,129,0.7166666666666667,8,0.7272727272727273,1,1,hyperparameters
131,"During training , we set label smoothing parameter to 0.2 , the coefficient ? of L 2 regularization item is 10 ? 5 and dropout rate is 0.1 .",Datasets and Experimental Settings,Datasets and Experimental Settings,sentiment_analysis,28,"['B', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'O']",,,9,0.8181818181818182,130,0.7222222222222222,9,0.8181818181818182,1,1,hyperparameters
132,"Adam optimizer ( Kingma and Ba , 2014 ) is applied to update all the parameters .",Datasets and Experimental Settings,Datasets and Experimental Settings,sentiment_analysis,28,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.9090909090909091,131,0.7277777777777777,10,0.9090909090909091,1,1,hyperparameters
136,We also design a basic BERT - based model to evaluate the performance of AEN - BERT .,Model Comparisons,Model Comparisons,sentiment_analysis,28,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.08333333333333333,135,0.75,2,0.08333333333333333,1,1,baselines
137,Non - RNN based baselines :,Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",3,0.125,136,0.7555555555555555,3,0.125,1,1,baselines
138,Feature - based SVM is a traditional support vector machine based model with extensive feature engineering .,Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.16666666666666666,137,0.7611111111111111,4,0.16666666666666666,1,1,baselines
139,"Rec - NN firstly uses rules to transform the dependency tree and put the opinion target at the root , and then learns the sentence representation toward target via semantic composition using Recursive NNs .",Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",5,0.20833333333333334,138,0.7666666666666667,5,0.20833333333333334,1,1,baselines
140,MemNet uses multi-hops of attention layers on the context word embeddings for sentence representation to explicitly captures the importance of each context word .,Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.25,139,0.7722222222222223,6,0.25,1,1,baselines
141,RNN based baselines :,Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",7,0.2916666666666667,140,0.7777777777777778,7,0.2916666666666667,1,1,baselines
142,TD - LSTM extends LSTM by using two LSTM networks to model the left context with target and the right context with target respectively .,Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'O']",,,8,0.3333333333333333,141,0.7833333333333333,8,0.3333333333333333,1,1,baselines
144,ATAE - LSTM,Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",10,0.4166666666666667,143,0.7944444444444444,10,0.4166666666666667,1,1,baselines
145,"( Wang et al. , 2016 ) strengthens the effect of target embeddings , which appends the target embeddings with each word embeddings and use LSTM with attention to get the final representation for classification .",Model Comparisons,Model Comparisons,sentiment_analysis,28,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O']",,,11,0.4583333333333333,144,0.8,11,0.4583333333333333,1,1,baselines
146,"IAN learns the representations of the target and context with two LSTMs and attentions interactively , which generates the representations for targets and contexts with respect to each other .",Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'O']",,,12,0.5,145,0.8055555555555556,12,0.5,1,1,baselines
147,RAM strengthens Mem - Net by representing memory with bidirectional LSTM and using a gated recurrent unit network to combine the multiple attention outputs for sentence representation .,Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",13,0.5416666666666666,146,0.8111111111111111,13,0.5416666666666666,1,1,baselines
148,AEN - Glo Ve ablations :,Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",14,0.5833333333333334,147,0.8166666666666667,14,0.5833333333333334,1,1,baselines
149,AEN - GloVe w/ o PCT ablates PCT module .,Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",15,0.625,148,0.8222222222222222,15,0.625,1,1,baselines
150,AEN - GloVe w/ o MHA ablates MHA module .,Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",16,0.6666666666666666,149,0.8277777777777777,16,0.6666666666666666,1,1,baselines
151,AEN - GloVe w/ o LSR ablates label smoothing regularization .,Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.7083333333333334,150,0.8333333333333334,17,0.7083333333333334,1,1,baselines
152,AEN-GloVe-BiLSTM replaces the attentional encoder layer with two bidirectional LSTM .,Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",18,0.75,151,0.8388888888888889,18,0.75,1,1,baselines
153,Basic BERT - based model :,Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",19,0.7916666666666666,152,0.8444444444444444,19,0.7916666666666666,1,1,baselines
154,"BERT - SPC feeds sequence "" [ CLS ] + context + [ SEP ] + target + [ SEP ] "" into the basic BERT model for sentence pair classification task .",Model Comparisons,Model Comparisons,sentiment_analysis,28,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",20,0.8333333333333334,153,0.85,20,0.8333333333333334,1,1,baselines
160,The over all performance of TD - LSTM is not good since it only makes a rough treatment of the target words .,Main Results,Main Results,sentiment_analysis,28,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,1,0.16666666666666666,159,0.8833333333333333,1,0.16666666666666666,1,1,results
161,"ATAE - LSTM , IAN and RAM are attention based models , they stably exceed the TD - LSTM method on Restaurant and Laptop datasets .",Main Results,Main Results,sentiment_analysis,28,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.3333333333333333,160,0.8888888888888888,2,0.3333333333333333,1,1,results
162,"RAM is better than other RNN based models , but it does not perform well on Twitter dataset , which might because bidirectional LSTM is not good at modeling small and ungrammatical text .",Main Results,Main Results,sentiment_analysis,28,"['B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.5,161,0.8944444444444445,3,0.5,1,1,results
163,"Feature - based SVM is still a competitive baseline , but relying on manually - designed features .",Main Results,Main Results,sentiment_analysis,28,"['B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.6666666666666666,162,0.9,4,0.6666666666666666,1,1,results
164,Rec - NN gets the worst performances among all neural network baselines as dependency parsing is not guaranteed to work well on ungrammatical short texts such as tweets and comments .,Main Results,Main Results,sentiment_analysis,28,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.8333333333333334,163,0.9055555555555556,5,0.8333333333333334,1,1,results
165,"Like AEN , Mem Net also eschews recurrence , but its over all performance is not good since it does not model the hidden semantic of embeddings , and the result of the last attention is essentially a linear combination of word embeddings .",Main Results,Main Results,sentiment_analysis,28,"['B', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,1.0,164,0.9111111111111111,6,1.0,1,1,results
169,"Comparing the results of AEN - GloVe and AEN - Glo Ve w / o LSR , we observe that the accuracy of AEN - Glo Ve w / o LSR drops significantly on all three datasets .",Model Analysis,Model Analysis,sentiment_analysis,28,"['B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.21428571428571427,168,0.9333333333333333,3,0.21428571428571427,1,1,ablation-analysis
171,"The over all performance of AEN - GloVe and AEN - Glo Ve - BiLSTM is relatively close , AEN - Glo Ve performs better on the Restaurant dataset .",Model Analysis,Model Analysis,sentiment_analysis,28,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.35714285714285715,170,0.9444444444444444,5,0.35714285714285715,1,1,ablation-analysis
172,"More importantly , AEN - Glo Ve has fewer parameters and is easier to parallelize .",Model Analysis,Model Analysis,sentiment_analysis,28,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",6,0.42857142857142855,171,0.95,6,0.42857142857142855,1,1,ablation-analysis
179,"AEN - Glo Ve 's lightweight level ranks second , since it takes some more parameters than MemNet in modeling hidden states of sequences .",Model Analysis,Model Analysis,sentiment_analysis,28,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.9285714285714286,178,0.9888888888888889,13,0.9285714285714286,1,1,ablation-analysis
180,"As a comparison , the model size of AEN - Glo Ve - BiLSTM is more than twice that of AEN - GloVe , but does not bring any performance improvements .",Model Analysis,Model Analysis,sentiment_analysis,28,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O']",,,14,1.0,179,0.9944444444444445,14,1.0,1,1,ablation-analysis
2,Aspect Level Sentiment Classification with Attention - over - Attention Neural Networks,title,title,sentiment_analysis,29,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.005747126436781609,1,0.0,1,1,research-problem
4,Aspect - level sentiment classification aims to identify the sentiment expressed towards some aspects given context sentences .,abstract,abstract,sentiment_analysis,29,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.017241379310344827,1,0.2,1,1,research-problem
24,"Because of advantages of neural networks , we approach this aspect level sentiment classification problem based on long short - term memory ( LSTM ) neural networks .",Introduction,Introduction,sentiment_analysis,29,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.28846153846153844,23,0.13218390804597702,15,0.28846153846153844,1,1,approach
25,"Previous LSTM - based methods mainly focus on modeling texts separately , while our approach models aspects and texts simultaneously using LSTMs .",Introduction,Introduction,sentiment_analysis,29,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",16,0.3076923076923077,24,0.13793103448275862,16,0.3076923076923077,1,1,approach
26,"Furthermore , the target representation and text representation generated from LSTMs interact with each other by an attention - over - attention ( AOA ) module .",Introduction,Introduction,sentiment_analysis,29,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.3269230769230769,25,0.14367816091954022,17,0.3269230769230769,1,1,approach
27,AOA automatically generates mutual attentions not only from aspect - to - text but also text - to - aspect .,Introduction,Introduction,sentiment_analysis,29,"['B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.34615384615384615,26,0.14942528735632185,18,0.34615384615384615,1,1,approach
33,That is why we choose AOA to attend to the most important parts in both aspect and sentence .,Introduction,Introduction,sentiment_analysis,29,"['O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",24,0.46153846153846156,32,0.1839080459770115,24,0.46153846153846156,1,1,approach
120,"In experiments , we first randomly select 20 % of training data as validation set to tune the hyperparameters .",Hyperparameters Setting,Hyperparameters Setting,sentiment_analysis,29,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'O']",1,0.1111111111111111,119,0.6839080459770115,1,0.1111111111111111,1,1,hyperparameters
121,"All weight matrices are randomly initialized from uniform distribution U ( ?10 ?4 , 10 ?4 ) and all bias terms are set to zero .",Hyperparameters Setting,Hyperparameters Setting,sentiment_analysis,29,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",2,0.2222222222222222,120,0.6896551724137931,2,0.2222222222222222,1,1,hyperparameters
122,The L 2 regularization coefficient is set to 10 ? 4 and the dropout keep rate is set to 0.2 .,Hyperparameters Setting,Hyperparameters Setting,sentiment_analysis,29,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O']",,,3,0.3333333333333333,121,0.6954022988505747,3,0.3333333333333333,1,1,hyperparameters
123,The word embeddings are initialized with 300 - dimensional Glove vectors and are fixed during training .,Hyperparameters Setting,Hyperparameters Setting,sentiment_analysis,29,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",4,0.4444444444444444,122,0.7011494252873564,4,0.4444444444444444,1,1,hyperparameters
124,"For the out of vocabulary words we initialize them randomly from uniform distribution U ( ? 0.01 , 0.01 ) .",Hyperparameters Setting,Hyperparameters Setting,sentiment_analysis,29,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.5555555555555556,123,0.7068965517241379,5,0.5555555555555556,1,1,hyperparameters
125,The dimension of LSTM hidden states is set to 150 .,Hyperparameters Setting,Hyperparameters Setting,sentiment_analysis,29,"['O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",6,0.6666666666666666,124,0.7126436781609196,6,0.6666666666666666,1,1,hyperparameters
126,The initial learning rate is 0.01 for the Adam optimizer .,Hyperparameters Setting,Hyperparameters Setting,sentiment_analysis,29,"['O', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",7,0.7777777777777778,125,0.7183908045977011,7,0.7777777777777778,1,1,hyperparameters
127,"If the training loss does not drop after every three epochs , we decrease the learning rate by half .",Hyperparameters Setting,Hyperparameters Setting,sentiment_analysis,29,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",8,0.8888888888888888,126,0.7241379310344828,8,0.8888888888888888,1,1,hyperparameters
128,The batch size is set as 25 .,Hyperparameters Setting,,sentiment_analysis,29,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",9,1.0,127,0.7298850574712644,9,1.0,1,1,hyperparameters
134,"Majority is a basic baseline method , which assigns the largest sentiment polarity in the training set to each sample in the test set .",Model Comparisons,We use accuracy metric to measure the performance .,sentiment_analysis,29,"['B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,5,0.3333333333333333,133,0.764367816091954,5,0.3333333333333333,1,1,baselines
135,"LSTM uses one LSTM network to model the sentence , and the last hidden state is used as the sentence representation for the final classification .",Model Comparisons,We use accuracy metric to measure the performance .,sentiment_analysis,29,"['B', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",6,0.4,134,0.7701149425287356,6,0.4,1,1,baselines
136,TD - LSTM uses two LSTM networks to model the preceding and following contexts surrounding the aspect term .,Model Comparisons,We use accuracy metric to measure the performance .,sentiment_analysis,29,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",7,0.4666666666666667,135,0.7758620689655172,7,0.4666666666666667,1,1,baselines
138,AT - LSTM first models the sentence via a LSTM model .,Model Comparisons,We use accuracy metric to measure the performance .,sentiment_analysis,29,"['B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",9,0.6,137,0.7873563218390804,9,0.6,1,1,baselines
141,ATAE - LSTM further extends AT - LSTM by appending the aspect embedding into each word vector .,Model Comparisons,We use accuracy metric to measure the performance .,sentiment_analysis,29,"['B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.8,140,0.8045977011494253,12,0.8,1,1,baselines
142,IAN uses two LSTM networks to model the sentence and aspect term respectively .,Model Comparisons,We use accuracy metric to measure the performance .,sentiment_analysis,29,"['B', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",13,0.8666666666666667,141,0.8103448275862069,13,0.8666666666666667,1,1,baselines
150,"In our implementation , we found that the performance fluctuates with different random initialization , which is a well - known issue in training neural networks .",Comparison results .,Comparison results .,sentiment_analysis,29,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.1111111111111111,149,0.8563218390804598,5,0.625,1,1,results
153,"On average , our algorithm is better than these baseline methods and our best trained model outperforms them in a large margin .",Comparison results .,Comparison results .,sentiment_analysis,29,"['B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",6,0.2222222222222222,152,0.8735632183908046,8,1.0,1,1,results
2,Knowledge - Enriched Transformer for Emotion Detection in Textual Conversations,title,title,sentiment_analysis,3,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.003424657534246575,1,0.0,1,1,research-problem
5,The task of detecting emotions in textual conversations leads to a wide range of applications such as opinion mining in social networks .,abstract,abstract,sentiment_analysis,3,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.3333333333333333,4,0.0136986301369863,2,0.3333333333333333,1,1,research-problem
14,"This work addresses the task of detecting emotions ( e.g. , happy , sad , angry , etc. ) in textual conversations , where the emotion of an utterance is detected in the conversational context .",Introduction,Introduction,sentiment_analysis,3,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.125,13,0.04452054794520548,4,0.125,1,1,research-problem
29,"To this end , we propose a Knowledge - Enriched Transformer ( KET ) to effectively incorporate contextual information and external knowledge bases to address the aforementioned challenges .",Introduction,Introduction,sentiment_analysis,3,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.59375,28,0.0958904109589041,19,0.59375,1,1,model
31,"The self - attention and cross-attention modules in the Transformer capture the intra-sentence and inter-sentence correlations , respectively .",Introduction,Introduction,sentiment_analysis,3,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O']",,,21,0.65625,30,0.10273972602739725,21,0.65625,1,1,
32,The shorter path of information flow in these two modules compared to gated RNNs and CNNs allows KET to model contextual information more efficiently .,Introduction,Introduction,sentiment_analysis,3,"['O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'O']",,,22,0.6875,31,0.10616438356164383,22,0.6875,1,1,
33,"In addition , we propose a hierarchical self - attention mechanism allowing KET to model the hierarchical structure of conversations .",Introduction,Introduction,sentiment_analysis,3,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",23,0.71875,32,0.1095890410958904,23,0.71875,1,1,model
34,"Our model separates context and response into the encoder and decoder , respectively , which is different from other Transformer - based models , e.g. , BERT , which directly concatenate context and response , and then train language models using only the encoder part .",Introduction,Introduction,sentiment_analysis,3,"['O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",24,0.75,33,0.11301369863013698,24,0.75,1,1,model
35,"Moreover , to exploit commonsense knowledge , we leverage external knowledge bases to facilitate the understanding of each word in the utterances by referring to related knowledge entities .",Introduction,Introduction,sentiment_analysis,3,"['O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",25,0.78125,34,0.11643835616438356,25,0.78125,1,1,model
36,The referring process is dynamic and balances between relatedness and affectiveness of the retrieved knowledge entities using a context - aware affective graph attention mechanism .,Introduction,Introduction,sentiment_analysis,3,"['O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",26,0.8125,35,0.11986301369863013,26,0.8125,1,1,model
199,c LSTM : A contextual LSTM model .,Baselines and Model Variants,Baselines and Model Variants,sentiment_analysis,3,"['B', 'I', 'O', 'O', 'B', 'I', 'I', 'O']",,,2,0.08695652173913043,198,0.678082191780822,2,0.08695652173913043,1,1,
200,An utterance - level bidirectional LSTM is used to encode each utterance .,Baselines and Model Variants,Baselines and Model Variants,sentiment_analysis,3,"['O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",3,0.13043478260869565,199,0.6815068493150684,3,0.13043478260869565,1,1,baselines
201,A context - level unidirectional LSTM is used to encode the context .,Baselines and Model Variants,Baselines and Model Variants,sentiment_analysis,3,"['O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",4,0.17391304347826086,200,0.684931506849315,4,0.17391304347826086,1,1,baselines
204,CNN+cLSTM : An CNN is used to extract utterance features .,Baselines and Model Variants,Baselines and Model Variants,sentiment_analysis,3,"['B', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['B-n', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",7,0.30434782608695654,203,0.6952054794520548,7,0.30434782608695654,1,1,baselines
205,An c LSTM is then applied to learn context representations .,Baselines and Model Variants,Baselines and Model Variants,sentiment_analysis,3,"['O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",8,0.34782608695652173,204,0.6986301369863014,8,0.34782608695652173,1,1,baselines
206,BERT BASE :,Baselines and Model Variants,Baselines and Model Variants,sentiment_analysis,3,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-b', 'I-b', 'O']",9,0.391304347826087,205,0.702054794520548,9,0.391304347826087,1,1,baselines
208,We treat each utterance with its context as a single document .,Baselines and Model Variants,Baselines and Model Variants,sentiment_analysis,3,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",11,0.4782608695652174,207,0.708904109589041,11,0.4782608695652174,1,1,baselines
209,We limit the document length to the last 100 tokens to allow larger batch size .,Baselines and Model Variants,Baselines and Model Variants,sentiment_analysis,3,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.5217391304347826,208,0.7123287671232876,12,0.5217391304347826,1,1,baselines
211,DialogueRNN : The stateof - the - art model for emotion detection in textual conversations .,Baselines and Model Variants,Baselines and Model Variants,sentiment_analysis,3,"['B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",14,0.6086956521739131,210,0.7191780821917808,14,0.6086956521739131,1,1,baselines
212,It models both context and speakers information .,Baselines and Model Variants,Baselines and Model Variants,sentiment_analysis,3,"['O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.6521739130434783,211,0.7226027397260274,15,0.6521739130434783,1,1,baselines
216,KET SingleSelfAttn :,Baselines and Model Variants,Baselines and Model Variants,sentiment_analysis,3,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-b', 'I-b', 'O']",19,0.8260869565217391,215,0.7363013698630136,19,0.8260869565217391,1,1,baselines
217,We replace the hierarchical self - attention by a single self - attention layer to learn context representations .,Baselines and Model Variants,Baselines and Model Variants,sentiment_analysis,3,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",20,0.8695652173913043,216,0.7397260273972602,20,0.8695652173913043,1,1,baselines
218,Contextual utterances are concatenated together prior to the single self - attention layer .,Baselines and Model Variants,Baselines and Model Variants,sentiment_analysis,3,"['B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",21,0.9130434782608695,217,0.7431506849315068,21,0.9130434782608695,1,1,baselines
219,KET StdAttn :,Baselines and Model Variants,Baselines and Model Variants,sentiment_analysis,3,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-b', 'I-b', 'O']",22,0.9565217391304348,218,0.7465753424657534,22,0.9565217391304348,1,1,baselines
220,We replace the dynamic contextaware affective graph attention by the standard graph attention .,Baselines and Model Variants,Baselines and Model Variants,sentiment_analysis,3,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",23,1.0,219,0.75,23,1.0,1,1,baselines
222,We preprocessed all datasets by lower - casing and tokenization using Spacy 2 .,Other Experimental Settings,Other Experimental Settings,sentiment_analysis,3,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O']",1,0.1111111111111111,221,0.7568493150684932,1,0.1111111111111111,1,1,experimental-setup
224,We use the released code for BERT BASE and DialogueRNN .,Other Experimental Settings,Other Experimental Settings,sentiment_analysis,3,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.3333333333333333,223,0.7636986301369864,3,0.3333333333333333,1,1,experimental-setup
225,"For each dataset , all models are fine - tuned based on their performance on the validation set .",Other Experimental Settings,Other Experimental Settings,sentiment_analysis,3,"['B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",4,0.4444444444444444,224,0.7671232876712328,4,0.4444444444444444,1,1,experimental-setup
226,"For our model in all datasets , we use Adam optimization ( Kingma and Ba , 2014 ) with a batch size of 64 and learning rate of 0.0001 throughout the training process .",Other Experimental Settings,Other Experimental Settings,sentiment_analysis,3,"['O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O']",,,5,0.5555555555555556,225,0.7705479452054794,5,0.5555555555555556,1,1,experimental-setup
227,We use Glo Ve embedding for initialization in the word and concept embedding layers,Other Experimental Settings,Other Experimental Settings,sentiment_analysis,3,"['O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",6,0.6666666666666666,226,0.773972602739726,6,0.6666666666666666,1,1,experimental-setup
228,"For the class weights in cross - entropy loss for each dataset , we set them as the ratio of the class distribution in the validation set to the class distribution in the training set .",Other Experimental Settings,Other Experimental Settings,sentiment_analysis,3,"['O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,7,0.7777777777777778,227,0.7773972602739726,7,0.7777777777777778,1,1,experimental-setup
237,"c LSTM performs reasonably well on short conversations ( i.e. , EC and DailyDialog ) , but the worst on long conversations ( i.e. , MELD , EmoryNLP and IEMOCAP ) .",Comparison with Baselines,Comparison with Baselines,sentiment_analysis,3,"['B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,4,0.25,236,0.8082191780821918,4,0.25,1,1,results
239,"In contrast , when the utterance - level LSTM in c LSTM is replaced by features extracted by CNN , i.e. , the CNN + c LSTM , the model performs significantly better than c LSTM on long conversations , which further validates that modelling long conversations using only RNN models may not be sufficient .",Comparison with Baselines,Comparison with Baselines,sentiment_analysis,3,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,6,0.375,238,0.815068493150685,6,0.375,1,1,results
240,BERT BASE achieves very competitive performance on all datasets except EC due to its strong representational power via bi-directional context modelling using the Transformer .,Comparison with Baselines,Comparison with Baselines,sentiment_analysis,3,"['B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",7,0.4375,239,0.8184931506849316,7,0.4375,1,1,results
243,"In particular , DialogueRNN performs better than our model on IEMOCAP , which maybe attributed to its detailed speaker information for modelling the emotion dynamics in each speaker as the conversation flows .",Comparison with Baselines,Comparison with Baselines,sentiment_analysis,3,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.625,242,0.8287671232876712,10,0.625,1,1,results
245,"This finding indicates that our model is robust across datasets with varying training sizes , context lengths and domains .",Comparison with Baselines,Comparison with Baselines,sentiment_analysis,3,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.75,244,0.8356164383561644,12,0.75,1,1,results
246,Our KET variants KET SingleSelfAttn and KET StdAttn perform comparably with the best baselines on all datasets except IEMOCAP .,Comparison with Baselines,Comparison with Baselines,sentiment_analysis,3,"['O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",13,0.8125,245,0.839041095890411,13,0.8125,1,1,results
247,"However , both variants perform noticeably worse than KET on all datasets except EC , validating the importance of our proposed hierarchical self - attention and dynamic context - aware affective graph attention mechanism .",Comparison with Baselines,Comparison with Baselines,sentiment_analysis,3,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,14,0.875,246,0.8424657534246576,14,0.875,1,1,results
248,One observation worth mentioning is that these two variants perform on a par with the KET model on EC .,Comparison with Baselines,Comparison with Baselines,sentiment_analysis,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",15,0.9375,247,0.8458904109589042,15,0.9375,1,1,results
274,It is clear that both context and knowledge are essential to the strong performance of KET on all datasets .,Model Analysis,Model Analysis,sentiment_analysis,3,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",24,0.7058823529411765,273,0.934931506849315,24,0.96,1,1,ablation-analysis
275,"Note that removing context has a greater impact on long conversations than short conversations , which is expected because more contextual information is lost in long conversations .",Model Analysis,Model Analysis,sentiment_analysis,3,"['O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",25,0.7352941176470589,274,0.9383561643835616,25,1.0,1,1,ablation-analysis
2,Recurrent Entity Networks with Delayed Memory Update for Targeted Aspect - based Sentiment Analysis,title,title,sentiment_analysis,30,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0078125,1,0.0,1,1,research-problem
4,"While neural networks have been shown to achieve impressive results for sentence - level sentiment analysis , targeted aspect - based sentiment analysis ( TABSA ) - extraction of finegrained opinion polarity w.r.t. a pre-defined set of aspects - remains a difficult task .",abstract,abstract,sentiment_analysis,30,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.25,3,0.0234375,1,0.25,1,1,research-problem
26,"In this work , we propose a novel model architecture for TABSA , augmented with multiple "" memory chains "" , and equipped with a delayed memory update mechanism , to keep track of numerous entities independently .",Introduction,Introduction,sentiment_analysis,30,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",18,0.9473684210526315,25,0.1953125,18,0.9473684210526315,1,1,model
90,"We initialise our model with GloVe ( 300 - D , trained on 42B tokens , 1.9 M vocab , not updated during training : ) 4 and pre-process the corpus with tokenisation using NLTK ) and case folding .",Model configuration .,Model configuration .,sentiment_analysis,30,"['O', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'O', 'B', 'I', 'O']",,,1,0.07692307692307693,89,0.6953125,9,0.3103448275862069,1,1,hyperparameters
91,Training is carried out over 800 epochs with the FTRL optimiser and a batch size of 128 and learning rate of 0.05 .,Model configuration .,Model configuration .,sentiment_analysis,30,"['B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,2,0.15384615384615385,90,0.703125,10,0.3448275862068966,1,1,hyperparameters
92,"We use the following hyper - parameters for weight matrices in both directions : R ? R 3003 , H , U , V , Ware all matrices of size R 300300 , v ? R 300 , and hidden size of the GRU in Equation is 300 .",Model configuration .,Model configuration .,sentiment_analysis,30,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'O']",3,0.23076923076923078,91,0.7109375,11,0.3793103448275862,1,1,hyperparameters
93,Dropout is applied to the output of ? in the final classifier ( Equation ) with a rate of 0.2 .,Model configuration .,Model configuration .,sentiment_analysis,30,"['B', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'O']","['B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'O', 'B-n', 'O']","['B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'O', 'B-ob', 'O']",4,0.3076923076923077,92,0.71875,12,0.41379310344827586,1,1,hyperparameters
95,"Lastly , to curb overfitting , we regularise the last layer ( Equation ) with an L 2 penalty on its weights : ?",Model configuration .,Model configuration .,sentiment_analysis,30,"['O', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O']",6,0.46153846153846156,94,0.734375,14,0.4827586206896552,1,1,hyperparameters
97,"We empirically set the number of memory chains to 6 , with the keys of two of them set to the same embeddings as the target words LOC1 and LOC2 , resp. , and the other 4 chains with free key embeddings which are updated during training , and therefore free to capture any entities .",Model configuration .,Model configuration .,sentiment_analysis,30,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.6153846153846154,96,0.75,16,0.5517241379310345,1,1,hyperparameters
114,Our model achieves state - of - the - art results for both aspect detection and sentiment classification .,Results,State - of - the - art results .,sentiment_analysis,30,"['B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",3,0.2,113,0.8828125,3,0.5,1,1,results
115,"It is impressive that the proposed model , equipped only with domainindependent general - purpose GloVe embeddings , outperforms Sentic LSTM , an approach heavily reliant on external knowledge bases and domainspecific embeddings .",Results,State - of - the - art results .,sentiment_analysis,30,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.26666666666666666,114,0.890625,4,0.6666666666666666,1,1,results
116,Ent Net vs. our model .,Results,,sentiment_analysis,30,"['B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",5,0.3333333333333333,115,0.8984375,5,0.8333333333333334,1,1,results
117,"We see consistent performance gains for our model in both aspect detection and sentiment classification , compared to EntNet , esp. for aspect detection , underlining the benefit of delayed update gate activation .",Results,Ent Net vs. our model .,sentiment_analysis,30,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.4,116,0.90625,6,1.0,1,1,results
2,Parameterized Convolutional Neural Networks for Aspect Level Sentiment Classification,title,,sentiment_analysis,31,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.006289308176100629,1,0.0,1,1,research-problem
8,Continuous growing of user generated text in social media platforms such as Twitter drives sentiment classification increasingly popular .,Introduction,Introduction,sentiment_analysis,31,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O']",1,0.05555555555555555,7,0.0440251572327044,1,0.05555555555555555,1,1,research-problem
12,"Differing from general sentiment classification , aspect level sentiment classification identifies opinions from text about specific entities and their aspects .",Introduction,Introduction,sentiment_analysis,31,"['O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.2777777777777778,11,0.06918238993710692,5,0.2777777777777778,1,1,research-problem
20,"In the present work , we propose two simple yet effective convolutional neural networks with aspect information incorporated .",Introduction,Introduction,sentiment_analysis,31,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O']",13,0.7222222222222222,19,0.11949685534591195,13,0.7222222222222222,1,1,model
22,"Specifically , we design two novel neural units that take target aspects into account .",Introduction,Introduction,sentiment_analysis,31,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",15,0.8333333333333334,21,0.1320754716981132,15,0.8333333333333334,1,1,model
23,"One is parameterized filter , the other is parameterized gate .",Introduction,Introduction,sentiment_analysis,31,"['B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",16,0.8888888888888888,22,0.13836477987421383,16,0.8888888888888888,1,1,model
24,These units both are generated from aspect - specific features and are further applied on the sentence .,Introduction,Introduction,sentiment_analysis,31,"['O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.9444444444444444,23,0.14465408805031446,17,0.9444444444444444,1,1,model
112,"We use rectifier as non-linear function f in the CNN g , CNN t and sigmoid in the CNN s , filter window sizes of 1 , 2 , 3 , 4 with 100 feature maps each , l 2 regularization term of 0.001 and minibatch size of 25 .",Hyperparameters and Training,Hyperparameters and Training,sentiment_analysis,31,"['O', 'B', 'B', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,1,0.09090909090909091,111,0.6981132075471698,1,0.09090909090909091,1,1,hyperparameters
113,Parameterized filters and gates have the same size and number as normal filters .,Hyperparameters and Training,Hyperparameters and Training,sentiment_analysis,31,"['B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",2,0.18181818181818182,112,0.7044025157232704,2,0.18181818181818182,1,1,hyperparameters
114,"They are generated uniformly by CNN with window sizes of 1 , 2 , 3 , 4 , eg. among 100 parameterized filters with size 3 , 25 of them are generated by aspect CNN with filter size 1 , 2 , 3 , 4 respectively .",Hyperparameters and Training,Hyperparameters and Training,sentiment_analysis,31,"['O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.2727272727272727,113,0.710691823899371,3,0.2727272727272727,1,1,hyperparameters
115,The word embeddings are initialized with 300 - dimensional Glove vectors and are fixed during training .,Hyperparameters and Training,Hyperparameters and Training,sentiment_analysis,31,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",4,0.36363636363636365,114,0.7169811320754716,4,0.36363636363636365,1,1,hyperparameters
116,"For the out of vocabulary words we initialize them randomly from uniform distribution U ( ? 0.01 , 0.01 ) .",Hyperparameters and Training,Hyperparameters and Training,sentiment_analysis,31,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.45454545454545453,115,0.7232704402515723,5,0.45454545454545453,1,1,hyperparameters
117,We apply dropout on the final classification features of PG - CNN .,Hyperparameters and Training,Hyperparameters and Training,sentiment_analysis,31,"['O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.5454545454545454,116,0.7295597484276729,6,0.5454545454545454,1,1,hyperparameters
118,The dropout rate is chosen as 0.3 .,Hyperparameters and Training,Hyperparameters and Training,sentiment_analysis,31,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",7,0.6363636363636364,117,0.7358490566037735,7,0.6363636363636364,1,1,hyperparameters
119,Training is done through mini-batch stochastic gradient descent with Adam update rule .,Hyperparameters and Training,Hyperparameters and Training,sentiment_analysis,31,"['B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.7272727272727273,118,0.7421383647798742,8,0.7272727272727273,1,1,hyperparameters
120,The initial learning rate is 0.001 .,Hyperparameters and Training,Hyperparameters and Training,sentiment_analysis,31,"['O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",9,0.8181818181818182,119,0.7484276729559748,9,0.8181818181818182,1,1,hyperparameters
121,"If the training loss does not drop after every three epochs , we decrease the learning rate by half .",Hyperparameters and Training,Hyperparameters and Training,sentiment_analysis,31,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",10,0.9090909090909091,120,0.7547169811320755,10,0.9090909090909091,1,1,hyperparameters
122,We adopt early stopping based on the validation loss on development sets .,Hyperparameters and Training,Hyperparameters and Training,sentiment_analysis,31,"['O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,1.0,121,0.7610062893081762,11,1.0,1,1,hyperparameters
127,TD - LSTM uses two LSTM networks to model the preceding and following contexts surrounding the aspect term .,Results,Results,sentiment_analysis,31,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",4,0.14285714285714285,126,0.7924528301886793,4,0.23529411764705882,1,1,baselines
129,AT - LSTM combines the sentence hidden states from a LSTM with the aspect term embedding to generate the attention vector .,Results,Results,sentiment_analysis,31,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",6,0.21428571428571427,128,0.8050314465408805,6,0.35294117647058826,1,1,baselines
131,ATAE - LSTM further extends AT - LSTM by appending the aspect embedding into each word vector .,Results,Results,sentiment_analysis,31,"['B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.2857142857142857,130,0.8176100628930818,8,0.47058823529411764,1,1,baselines
132,AF - LSTM introduces a word - aspect fusion attention to learn associative relationships between aspect and context words .,Results,Results,sentiment_analysis,31,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.32142857142857145,131,0.8238993710691824,9,0.5294117647058824,1,1,baselines
133,CNN uses the architecture proposed in without explicitly considering aspect .,Results,Results,sentiment_analysis,31,"['B', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'O']","['B-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'O']",10,0.35714285714285715,132,0.8301886792452831,10,0.5882352941176471,1,1,baselines
137,"Our two models achieve the best performance when compared to these baselines as shown in , which shows that our proposed neural units effectively captures the aspect - specific features .",Results,Results,sentiment_analysis,31,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.5,136,0.8553459119496856,14,0.8235294117647058,1,1,results
138,"Compared to one recently proposed model AF - LSTM , our method achieve 2 % - 5 % improvements .",Results,Results,sentiment_analysis,31,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.5357142857142857,137,0.8616352201257862,15,0.8823529411764706,1,1,results
139,"Surprisingly , a vanilla CNN works quite well on this problem .",Results,Results,sentiment_analysis,31,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",16,0.5714285714285714,138,0.8679245283018868,16,0.9411764705882353,1,1,results
140,"It even beats these welldesigned LSTM models , which further proves that using CNN - based methods is a direction worth exploring .",Results,Results,sentiment_analysis,31,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.6071428571428571,139,0.8742138364779874,17,1.0,1,1,results
2,Interactive Attention Networks for Aspect - Level Sentiment Classification,title,,sentiment_analysis,32,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004347826086956522,1,0.0,1,1,research-problem
5,Previous approaches have realized the importance of targets in sentiment classification and developed various methods with the goal of precisely modeling their contexts via generating target - specific representations .,abstract,abstract,sentiment_analysis,32,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.2857142857142857,4,0.017391304347826087,2,0.2857142857142857,1,1,research-problem
42,"Based on the two points analyzed above , we propose an interactive attention network ( IAN ) model which is based on long - short term memory networks ( LSTM ) and attention mechanism .",Introduction,Introduction,sentiment_analysis,32,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",31,0.8857142857142857,41,0.1782608695652174,31,0.8857142857142857,1,1,model
43,IAN utilizes the attention mechanism associated with a target to get important information from the context and compute context representation for sentiment classification .,Introduction,Introduction,sentiment_analysis,32,"['B', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",32,0.9142857142857143,42,0.1826086956521739,32,0.9142857142857143,1,1,model
44,"Further , IAN makes use of the interactive information from context to supervise the modeling of the target which is helpful to judging sentiment .",Introduction,Introduction,sentiment_analysis,32,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",33,0.9428571428571428,43,0.18695652173913044,33,0.9428571428571428,1,1,model
45,"Finally , with both target representation and context representation concatenated , IAN predicts the sentiment polarity for the target within its context .",Introduction,Introduction,sentiment_analysis,32,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",34,0.9714285714285714,44,0.19130434782608696,34,0.9714285714285714,1,1,model
125,"In our experiments , all word embeddings from context and target are initialized by GloVe 2 , and all out - of - vocabulary words are initialized by sampling from the uniform distribution U ( ?0.1 , 0.1 ) .",Hyperparameters Setting,Hyperparameters Setting,sentiment_analysis,32,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,1,0.2,124,0.5391304347826087,1,0.2,1,1,hyperparameters
126,"All weight matrices are given their initial values by sampling from uniform distribution U ( ?0.1 , 0.1 ) , and all biases are set to zeros .",Hyperparameters Setting,Hyperparameters Setting,sentiment_analysis,32,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",2,0.4,125,0.5434782608695652,2,0.4,1,1,hyperparameters
127,"The dimensions of word embeddings , attention vectors and LSTM hidden states are set to 300 as in .",Hyperparameters Setting,Hyperparameters Setting,sentiment_analysis,32,"['O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O']",3,0.6,126,0.5478260869565217,3,0.6,1,1,hyperparameters
128,"To train the parameters of IAN , we employ the Momentum , which adds a fraction ? of the update vector in the prior step to the current update vector .",Hyperparameters Setting,Hyperparameters Setting,sentiment_analysis,32,"['O', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']",,,4,0.8,127,0.5521739130434783,4,0.8,1,1,hyperparameters
129,"The coefficient of L 2 normalization in the objective function is set to 10 ?5 , and the dropout rate is set to 0.5 .",Hyperparameters Setting,Hyperparameters Setting,sentiment_analysis,32,"['O', 'B', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']",,,5,1.0,128,0.5565217391304348,5,1.0,1,1,hyperparameters
133,"Majority is a basic baseline method , which assigns the largest sentiment polarity in the training set to each sample in the test set .",Model Comparisons,Model Comparisons,sentiment_analysis,32,"['B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,3,0.1,132,0.5739130434782609,3,0.1,1,1,baselines
134,LSTM only uses one LSTM network to model the context and get the hidden state of each word .,Model Comparisons,Model Comparisons,sentiment_analysis,32,"['B', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",4,0.13333333333333333,133,0.5782608695652174,4,0.13333333333333333,1,1,baselines
136,TD - LSTM adopts two long short - term memory ( LSTM ) networks to model the left context with target and the right context with target respectively .,Model Comparisons,Model Comparisons,sentiment_analysis,32,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'O']",,,6,0.2,135,0.5869565217391305,6,0.2,1,1,baselines
138,AE - LSTM represents targets with aspect embeddings .,Model Comparisons,Model Comparisons,sentiment_analysis,32,"['B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.26666666666666666,137,0.5956521739130435,8,0.26666666666666666,1,1,baselines
140,ATAE - LSTM is developed based on AE - LSTM .,Model Comparisons,Model Comparisons,sentiment_analysis,32,"['B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.3333333333333333,139,0.6043478260869565,10,0.3333333333333333,1,1,baselines
143,"All the other methods are based on LSTM models and better than the Majority method , showing that LSTM has potentials in automatically generating representations and can all bring performance improvement for sentiment classification .",Model Comparisons,Model Comparisons,sentiment_analysis,32,"['B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.43333333333333335,142,0.6173913043478261,13,0.43333333333333335,1,1,results
144,"The LSTM method gets the worst performance of all the neural network baseline methods , because it treats targets equally with other context words and does not make full use of the target information .",Model Comparisons,Model Comparisons,sentiment_analysis,32,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.4666666666666667,143,0.6217391304347826,14,0.4666666666666667,1,1,results
146,"TD - LSTM outperforms LSTM over 1 percent and 2 percent on the Restaurant and Laptop category respectively , since it develops from the standard LSTM and processes the left and right contexts with targets .",Model Comparisons,Model Comparisons,sentiment_analysis,32,"['B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.5333333333333333,145,0.6304347826086957,16,0.5333333333333333,1,1,results
148,"Further , both AE - LSTM and ATAE - LSTM stably exceed the TD - LSTM method because of the introduction of attention mechanism .",Model Comparisons,Model Comparisons,sentiment_analysis,32,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.6,147,0.6391304347826087,18,0.6,1,1,results
149,"For AE - LSTM and ATAE - LSTM , they capture important information in the context with the supervision of target and generate more reasonable representations for aspect - level sentiment classification .",Model Comparisons,Model Comparisons,sentiment_analysis,32,"['B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.6333333333333333,148,0.6434782608695652,19,0.6333333333333333,1,1,results
150,"We can also see that AE - LSTM and ATAE - LSTM further emphasize the modeling of targets via the addition of the aspect embedding , which is also the reason of performance improvement .",Model Comparisons,Model Comparisons,sentiment_analysis,32,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.6666666666666666,149,0.6478260869565218,20,0.6666666666666666,1,1,results
151,"Compared with AE - LSTM , ATAE - LSTM especially enhance the interaction between the context words and target and thus has a better performance than AE - LSTM .",Model Comparisons,Model Comparisons,sentiment_analysis,32,"['B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']",,,21,0.7,150,0.6521739130434783,21,0.7,1,1,results
153,We can see that IAN achieves the best performance among all baselines .,Model Comparisons,Model Comparisons,sentiment_analysis,32,"['O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",23,0.7666666666666667,152,0.6608695652173913,23,0.7666666666666667,1,1,results
154,"Compared with ATAE - LSTM model , IAN improves the performance about 1.4 % and 3.2 % on the Restaurant and Laptop categories respectively .",Model Comparisons,Model Comparisons,sentiment_analysis,32,"['B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",24,0.8,153,0.6652173913043479,24,0.8,1,1,results
159,"The more attentions are paid to targets , the higher accuracy the system achieves .",Model Comparisons,Model Comparisons,sentiment_analysis,32,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O']",29,0.9666666666666667,158,0.6869565217391305,29,0.9666666666666667,1,1,results
2,Convolutional Neural Networks with Recurrent Neural Filters,title,title,sentiment_analysis,33,"['B', 'I', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.008,1,0.0,1,1,research-problem
7,"In this work , we model convolution filters with RNNs that naturally capture compositionality and long - term dependencies in language .",abstract,abstract,sentiment_analysis,33,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.6666666666666666,6,0.048,4,0.6666666666666666,1,1,research-problem
18,"To overcome this , we propose to employ recurrent neural networks ( RNNs ) as convolution filters of CNN systems for various NLP tasks .",Introduction,Introduction,sentiment_analysis,33,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",8,0.5333333333333333,17,0.136,8,0.5333333333333333,1,1,model
19,"Our recurrent neural filters ( RNFs ) can naturally deal with language compositionality with a recurrent function that models word relations , and they are also able to implicitly model long - term dependencies .",Introduction,Introduction,sentiment_analysis,33,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.6,18,0.144,9,0.6,1,1,model
20,"RNFs are typically applied to word sequences of moderate lengths , which alleviates some well - known drawbacks of RNNs , including their vulnerability to the gradient vanishing and exploding problems .",Introduction,Introduction,sentiment_analysis,33,"['B', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']",,,10,0.6666666666666666,19,0.152,10,0.6666666666666666,1,1,model
21,"As in conventional CNNs , the computation of the convolution operation with RNFs can be easily parallelized .",Introduction,Introduction,sentiment_analysis,33,"['B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'O']",11,0.7333333333333333,20,0.16,11,0.7333333333333333,1,1,model
22,"As a result , RNF - based CNN models can be 3 - 8 x faster than their RNN counterparts .",Introduction,Introduction,sentiment_analysis,33,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",12,0.8,21,0.168,12,0.8,1,1,model
23,We present two RNF - based CNN architectures for sentence classification and answer sentence selection problems .,Introduction,Introduction,sentiment_analysis,33,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.8666666666666667,22,0.176,13,0.8666666666666667,1,1,model
75,We consider CNN variants with linear filters and RNFs.,Competitive systems,,sentiment_analysis,33,"['O', 'B', 'B', 'I', 'B', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'O', 'O', 'O']",1,0.25,74,0.592,1,0.25,1,1,baselines
76,"For RNFs , we adopt two implementations based on GRUs and LSTMs respectively .",Competitive systems,We consider CNN variants with linear filters and RNFs.,sentiment_analysis,33,"['B', 'B', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",2,0.5,75,0.6,2,0.5,1,1,baselines
77,"We also compare against the following RNN variants : GRU , LSTM , GRU with max pooling , and LSTM with max pooling .",Competitive systems,We consider CNN variants with linear filters and RNFs.,sentiment_analysis,33,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'O']",,,3,0.75,76,0.608,3,0.75,1,1,baselines
81,"In particular , CNN - RNF - LSTM achieves 53.4 % and 90.0 % accuracies on the fine - grained and binary sentiment classification tasks respectively , which match the state - of the - art results on the Stanford Sentiment Treebank .",Results,Results,sentiment_analysis,33,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']",,,2,0.07142857142857142,80,0.64,2,0.2,1,1,results
82,"CNN - RNF - LSTM also obtains competitive results on answer sentence selection datasets , despite the simple model architecture compared to state - of - the - art systems .",Results,Results,sentiment_analysis,33,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.10714285714285714,81,0.648,3,0.3,1,1,results
83,"Conventional RNN models clearly benefit from max pooling , especially on the task of answer sentence selection .",Results,Results,sentiment_analysis,33,"['B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.14285714285714285,82,0.656,4,0.4,1,1,results
87,"As a result , RNF - based CNN models perform consistently better than max - pooled RNN models .",Results,Results,sentiment_analysis,33,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.2857142857142857,86,0.688,8,0.8,1,1,results
2,Mazajak : An Online Arabic Sentiment Analyser,title,,sentiment_analysis,34,"['O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.006756756756756757,1,0.0,1,1,research-problem
4,Sentiment analysis ( SA ) is one of the most useful natural language processing applications .,abstract,abstract,sentiment_analysis,34,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.02027027027027027,1,0.2,1,1,research-problem
14,Sentiment analysis is one of the vital approaches to extract public opinion from large corpora of text .,Introduction,Introduction,sentiment_analysis,34,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.2631578947368421,13,0.08783783783783784,5,0.2631578947368421,1,1,research-problem
17,"Work on SA started in early 2000s , particularly with the work of , where they studied the sentiment of movies ' reviews .",Introduction,Introduction,sentiment_analysis,34,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.42105263157894735,16,0.10810810810810811,8,0.42105263157894735,1,1,research-problem
27,"In this paper , we present Mazajak 2 , an Online Arabic sentiment analysis system that utilises deep learning and massive Arabic word embeddings .",Introduction,Introduction,sentiment_analysis,34,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.9473684210526315,26,0.17567567567567569,18,0.9473684210526315,1,1,model
28,The system is available as an online API that can be used by other researchers .,Introduction,Introduction,sentiment_analysis,34,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",19,1.0,27,0.18243243243243243,19,1.0,1,1,model
113,The best performing system in the SemEval 2017 task is the one described in which achieved an F P N of 0.61 .,Baselines and Evaluation,Baselines and Evaluation,sentiment_analysis,34,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.13333333333333333,112,0.7567567567567568,4,0.3333333333333333,1,1,baselines
114,"For the ASTD , the best reported results are by who used an ensemble system combining output of CNN and Bi - LSTM architectures , which achieved an F P N of 0.71 .",Baselines and Evaluation,Baselines and Evaluation,sentiment_analysis,34,"['B', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.16666666666666666,113,0.7635135135135135,5,0.4166666666666667,1,1,baselines
118,"As shown in the table , Mazajak model outperformed the current state - of - the - art models on the SemEval and ASTD datasets .",Baselines and Evaluation,Baselines and Evaluation,sentiment_analysis,34,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.3,117,0.7905405405405406,9,0.75,1,1,results
119,"In addition , it achieved a high performance on the ArSAS dataset .",Baselines and Evaluation,Baselines and Evaluation,sentiment_analysis,34,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",10,0.3333333333333333,118,0.7972972972972973,10,0.8333333333333334,1,1,results
120,"Our reported scores are higher than current top systems for all the evaluation scores , including average recall , F P N , and accuracy .",Baselines and Evaluation,Baselines and Evaluation,sentiment_analysis,34,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.36666666666666664,119,0.8040540540540541,11,0.9166666666666666,1,1,results
121,These results confirm that our model choice for our tool represents the current state - of - the - art for Arabic SA .,Baselines and Evaluation,Baselines and Evaluation,sentiment_analysis,34,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']",,,12,0.4,120,0.8108108108108109,12,1.0,1,1,results
2,Exploiting Coarse - to - Fine Task Transfer for Aspect - level Sentiment Classification,title,title,sentiment_analysis,35,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004032258064516129,1,0.0,1,1,research-problem
4,"Aspect - level sentiment classification ( ASC ) aims at identifying sentiment polarities towards aspects in a sentence , where the aspect can behave as a general Aspect Category ( AC ) or a specific Aspect Term ( AT ) .",abstract,abstract,sentiment_analysis,35,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.09090909090909091,3,0.012096774193548387,1,0.09090909090909091,1,1,research-problem
22,"To model aspect - oriented sentiment analysis , equipping Recurrent Neural Networks ( RNNs ) with the attention Copyright c 2019 , Association for the Advancement of Artificial Intelligence ( www.aaai.org ) .",Introduction,Introduction,sentiment_analysis,35,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.20588235294117646,21,0.0846774193548387,7,0.20588235294117646,1,1,research-problem
38,"To resolve the challenges , we propose a novel framework named Multi - Granularity Alignment Network ( MGAN ) to simultaneously align aspect granularity and aspect- specific feature representations across domains .",Introduction,Introduction,sentiment_analysis,35,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",23,0.6764705882352942,37,0.14919354838709678,23,0.6764705882352942,1,1,model
39,"Specifically , the MGAN consists of two networks for learning aspect - specific representations for the two domains , respectively .",Introduction,Introduction,sentiment_analysis,35,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O']",24,0.7058823529411765,38,0.1532258064516129,24,0.7058823529411765,1,1,model
40,"First , to reduce the task discrepancy between domains , i.e. , modeling the two tasks at the same fine - grained level , we propose a novel Coarse2 Fine ( C2F ) attention module to help the source task automatically capture the corresponding aspect term in the context towards the given aspect category ( e.g. , "" salmon "" to the "" food "" ) .",Introduction,Introduction,sentiment_analysis,35,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",25,0.7352941176470589,39,0.15725806451612903,25,0.7352941176470589,1,1,model
45,"To prevent false alignment , we adopt the Contrastive Feature Alignment ( CFA ) ( Motiian et al. 2017 ) to semantically align aspect - specific representations .",Introduction,Introduction,sentiment_analysis,35,"['B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",30,0.8823529411764706,44,0.1774193548387097,30,0.8823529411764706,1,1,model
46,"The CFA considers both semantic alignment by maximally ensuring the equivalent distributions from different domains but the same class , and semantic separation by guaranteeing distributions from both different classes and domains to be as dissimilar as possible .",Introduction,Introduction,sentiment_analysis,35,"['O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",31,0.9117647058823529,45,0.1814516129032258,31,0.9117647058823529,1,1,model
184,The word embeddings are initialized with 200 - dimension GloVE vectors and fine - tuned during the training .,Implementation Details,Implementation Details,sentiment_analysis,35,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'O']",1,0.08333333333333333,183,0.7379032258064516,1,0.08333333333333333,1,1,hyperparameters
186,The fc layer size is 300 .,Implementation Details,Implementation Details,sentiment_analysis,35,"['O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",3,0.25,185,0.7459677419354839,3,0.25,1,1,hyperparameters
187,The Adam ( Kingma and Ba 2014 ) is used as the optimizer with the initial learning rate 10 ? 4 .,Implementation Details,Implementation Details,sentiment_analysis,35,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.3333333333333333,186,0.75,4,0.3333333333333333,1,1,hyperparameters
188,Gradients with the 2 norm larger than 40 are normalized to be 40 .,Implementation Details,Implementation Details,sentiment_analysis,35,"['B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'O']",,,5,0.4166666666666667,187,0.7540322580645161,5,0.4166666666666667,1,1,hyperparameters
189,"All weights in networks are randomly initialized from a uniform distribution U ( ? 0.01 , 0.01 ) .",Implementation Details,Implementation Details,sentiment_analysis,35,"['B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.5,188,0.7580645161290323,6,0.5,1,1,hyperparameters
190,"The batch sizes are 64 and 32 for source and target domains , respectively .",Implementation Details,Implementation Details,sentiment_analysis,35,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",7,0.5833333333333334,189,0.7620967741935484,7,0.5833333333333334,1,1,hyperparameters
193,"To alleviate overfitting , we apply dropout on the word embeddings of the context with dropout rate 0.5 .",Implementation Details,Implementation Details,sentiment_analysis,35,"['B', 'I', 'B', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.8333333333333334,192,0.7741935483870968,10,0.8333333333333334,1,1,hyperparameters
194,We also perform early stopping on the validation set during the training process .,Implementation Details,Implementation Details,sentiment_analysis,35,"['O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",11,0.9166666666666666,193,0.7782258064516129,11,0.9166666666666666,1,1,hyperparameters
195,The hyperparameters are tuned on 10 % randomly held - out training data of the target domain in R1?L task and are fixed to be used in all transfer pairs .,Implementation Details,Implementation Details,sentiment_analysis,35,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",12,1.0,194,0.782258064516129,12,1.0,1,1,hyperparameters
198,Non-Transfer,Baseline Methods,,sentiment_analysis,35,['B'],['B-n'],['B-b'],2,0.125,197,0.7943548387096774,2,0.125,1,1,baselines
199,"To demonstrate the benefits from coarse - tofine task transfer , we compare with the following state - of the - art AT - level methods without transfer : Target Network ( TN ) :",Baseline Methods,Non-Transfer,sentiment_analysis,35,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",3,0.1875,198,0.7983870967741935,3,0.1875,1,1,baselines
200,It is our proposed base model ( BiLSTM + C2A + Pas ) trained on D t for the target task .,Baseline Methods,Non-Transfer,sentiment_analysis,35,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",4,0.25,199,0.8024193548387096,4,0.25,1,1,baselines
202,Transfer,Baseline Methods,,sentiment_analysis,35,['B'],['B-n'],['B-b'],6,0.375,201,0.8104838709677419,6,0.375,1,1,baselines
204,Source- only ( SO ) :,Baseline Methods,Transfer,sentiment_analysis,35,"['B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",8,0.5,203,0.8185483870967742,8,0.5,1,1,baselines
205,It uses a source network trained on D s to initialize a target network and then tests it on D t .,Baseline Methods,Transfer,sentiment_analysis,35,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",9,0.5625,204,0.8225806451612904,9,0.5625,1,1,baselines
206,Fine-tuning ( FT ) : It advances SO with further finetuning the target network on D t .,Baseline Methods,Transfer,sentiment_analysis,35,"['B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",10,0.625,205,0.8266129032258065,10,0.625,1,1,baselines
207,M- DAN : It is a multi-adversarial version of Domain Adversarial Network ( DAN ) ) based on multiple domain discriminators .,Baseline Methods,Transfer,sentiment_analysis,35,"['B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",11,0.6875,206,0.8306451612903226,11,0.6875,1,1,baselines
209,"M - MMD : Similar with M - DAN , M - MMD aligns different class distributions between domains based on multiple Maximum Mean Discrepancy ( MMD ) ) .",Baseline Methods,Transfer,sentiment_analysis,35,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",13,0.8125,208,0.8387096774193549,13,0.8125,1,1,baselines
214,Comparison with Non - Transfer,Result Analysis,,sentiment_analysis,35,"['B', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b']",1,0.03333333333333333,213,0.8588709677419355,1,0.1,1,1,results
220,"( 2 ) MGAN consistently outperforms the MGAN w / o C2 F , where C2F module of the source network is removed and the source position information is missed ( we set all p s i to 1 ) , by 1.41 % , 1.03 % , 1.09 % for accuracy and 1.79 % , 3.62 % and 1.16 % for Macro - F1 on average .",Result Analysis,Comparison with Non - Transfer,sentiment_analysis,35,"['O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O']",,,7,0.23333333333333334,219,0.8830645161290323,7,0.7,1,1,results
223,"The MGAN w / o PI , which does not utilize the position information , performs very poorly .",Result Analysis,Comparison with Non - Transfer,sentiment_analysis,35,"['O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",10,0.3333333333333333,222,0.8951612903225806,10,1.0,1,1,results
224,Comparison with Transfer,Result Analysis,,sentiment_analysis,35,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",11,0.36666666666666664,223,0.8991935483870968,0,0.0,1,1,results
227,SO performs poorly due to no adaptation applied .,Result Analysis,Comparison with Transfer,sentiment_analysis,35,"['B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.4666666666666667,226,0.9112903225806451,3,0.375,1,1,results
228,The popular technique FT can not achieve satisfactory results since fine - tuning may cause the oblivion of useful knowledge from the source task .,Result Analysis,Comparison with Transfer,sentiment_analysis,35,"['O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.5,227,0.9153225806451613,4,0.5,1,1,results
229,"The full model MGAN outperforms M - DAN and M - MMD by 1.80 % and 1.33 % for accuracy and 1.90 % and 1.66 % for Marco - F1 on average , respectively .",Result Analysis,Comparison with Transfer,sentiment_analysis,35,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O']",,,16,0.5333333333333333,228,0.9193548387096774,5,0.625,1,1,results
231,"Remarkably , MGAN considers both of them in a point - wise surrogate , which altogether improves the performance of our method .",Result Analysis,Comparison with Transfer,sentiment_analysis,35,"['O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",18,0.6,230,0.9274193548387096,7,0.875,1,1,results
232,"Besides , MGAN outperforms its ablation MGAN w/ o SS removing the semantic separation loss of the CFA by 0.81 % for accuracy and 1.00 % for Macro - F1 on average , which implies that the semantic separation plays an important role in alleviating false alignment .",Result Analysis,Comparison with Transfer,sentiment_analysis,35,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,19,0.6333333333333333,231,0.9314516129032258,8,1.0,1,1,results
233,Effect of C2F Attention Module,Result Analysis,,sentiment_analysis,35,"['B', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b']",20,0.6666666666666666,232,0.9354838709677419,0,0.0,1,1,results
237,"Then , compared with MGAN w / o C2F , MGAN further uses C2F to capture more specific aspect terms from the context towards the aspect category , such as "" shells "" to food seafood sea , which helps the source task capture more fine - grained semantics of aspect category and detailed position information like the target task , such that the sentiment attention can be positionaware and identify more relevant sentiment features towards the aspect .",Result Analysis,Effect of C2F Attention Module,sentiment_analysis,35,"['O', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,24,0.8,236,0.9516129032258065,4,0.4,1,1,results
240,While MGAN w / o C2F locates wrong sentiment contexts and fails in ( c ) .,Result Analysis,Effect of C2F Attention Module,sentiment_analysis,35,"['O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",27,0.9,239,0.9637096774193549,7,0.7,1,1,results
241,"As such , benefited from distilled knowledge from the source task , MGAN can better model the complicated relatedness between the context and aspect term for the target domain L , but MGAN w / o C2F performs poorly though it make true predictions in ( d ) and ( e ) .",Result Analysis,Effect of C2F Attention Module,sentiment_analysis,35,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",28,0.9333333333333333,240,0.967741935483871,8,0.8,1,1,results
2,Transformation Networks for Target - Oriented Sentiment Classification,title,,sentiment_analysis,36,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.5,1,0.004,1,0.5,1,1,research-problem
29,"We propose a new architecture , named Target - Specific Transformation Networks ( TNet ) , to solve the above issues in the task of target sentiment classification .",Introduction,Introduction,sentiment_analysis,36,"['O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.4857142857142857,28,0.112,17,0.4857142857142857,1,1,model
30,TNet firstly encodes the context information into word embeddings and generates the contextualized word representations with LSTMs .,Introduction,Introduction,sentiment_analysis,36,"['B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",18,0.5142857142857142,29,0.116,18,0.5142857142857142,1,1,model
31,"To integrate the target information into the word representations , TNet introduces a novel Target - Specific Transformation ( TST ) component for generating the target - specific word representations .",Introduction,Introduction,sentiment_analysis,36,"['B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.5428571428571428,30,0.12,19,0.5428571428571428,1,1,model
32,"Contrary to the previous attention - based approaches which apply the same target representation to determine the attention scores of individual context words , TST firstly generates different representations of the target conditioned on individual context words , then it consolidates each context word with its tailor - made target representation to obtain the transformed word representation .",Introduction,Introduction,sentiment_analysis,36,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",20,0.5714285714285714,31,0.124,20,0.5714285714285714,1,1,model
37,"As the context information carried by the representations from the LSTM layer will be lost after the non-linear TST , we design a contextpreserving mechanism to contextualize the generated target - specific word representations .",Introduction,Introduction,sentiment_analysis,36,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",25,0.7142857142857143,36,0.144,25,0.7142857142857143,1,1,model
39,"To help the CNN feature extractor locate sentiment indicators more accurately , we adopt a proximity strategy to scale the input of convolutional layer with positional relevance between a word and the target .",Introduction,Introduction,sentiment_analysis,36,"['B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,0.7714285714285715,38,0.152,27,0.7714285714285715,1,1,model
150,SVM : It is a traditional support vector machine based model with extensive feature engineering ;,Experimental Setup,Experimental Setup,sentiment_analysis,36,"['B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",7,0.21212121212121213,149,0.596,7,0.21212121212121213,1,1,baselines
151,AdaRNN : It learns the sentence representation toward target for sentiment prediction via semantic composition over dependency tree ;,Experimental Setup,Experimental Setup,sentiment_analysis,36,"['B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.24242424242424243,150,0.6,8,0.24242424242424243,1,1,baselines
152,"AE - LSTM , and ATAE - LSTM : AE - LSTM is a simple LSTM model incorporating the target embedding as input , while ATAE - LSTM extends AE - LSTM with attention ;",Experimental Setup,Experimental Setup,sentiment_analysis,36,"['B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'O']",,,9,0.2727272727272727,151,0.604,9,0.2727272727272727,1,1,baselines
153,IAN : IAN employs two LSTMs to learn the representations of the context and the target phrase interactively ;,Experimental Setup,Experimental Setup,sentiment_analysis,36,"['B', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O']","['B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",10,0.30303030303030304,152,0.608,10,0.30303030303030304,1,1,baselines
154,CNN - ASP :,Experimental Setup,Experimental Setup,sentiment_analysis,36,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",11,0.3333333333333333,153,0.612,11,0.3333333333333333,1,1,baselines
155,It is a CNN - based model implemented by us which directly concatenates target representation to each word embedding ;,Experimental Setup,Experimental Setup,sentiment_analysis,36,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.36363636363636365,154,0.616,12,0.36363636363636365,1,1,baselines
156,TD - LSTM :,Experimental Setup,Experimental Setup,sentiment_analysis,36,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",13,0.3939393939393939,155,0.62,13,0.3939393939393939,1,1,baselines
157,"It employs two LSTMs to model the left and right contexts of the target separately , then performs predictions based on concatenated context representations ;",Experimental Setup,Experimental Setup,sentiment_analysis,36,"['O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",14,0.42424242424242425,156,0.624,14,0.42424242424242425,1,1,baselines
158,MemNet : It applies attention mechanism over the word embeddings multiple times and predicts sentiments based on the top - most sentence representations ;,Experimental Setup,Experimental Setup,sentiment_analysis,36,"['B', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.45454545454545453,157,0.628,15,0.45454545454545453,1,1,baselines
159,"BILSTM - ATT -G : It models left and right contexts using two attention - based LSTMs and introduces gates to measure the importance of left context , right context , and the entire sentence for the prediction ;",Experimental Setup,Experimental Setup,sentiment_analysis,36,"['B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",16,0.48484848484848486,158,0.632,16,0.48484848484848486,1,1,baselines
160,RAM : RAM is a multilayer architecture where each layer consists of attention - based aggregation of word features and a GRU cell to learn the sentence representation .,Experimental Setup,Experimental Setup,sentiment_analysis,36,"['B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",17,0.5151515151515151,159,0.636,17,0.5151515151515151,1,1,baselines
188,LSTM - based models relying on sequential information can perform well for formal sentences by capturing more useful context features ;,Main Results,Main Results,sentiment_analysis,36,"['B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.1746031746031746,187,0.748,10,0.9090909090909091,1,1,results
189,"For ungrammatical text , CNN - based models may have some advantages because CNN aims to extract the most informative n-gram features and is thus less sensitive to informal texts without strong sequential patterns .",Main Results,Main Results,sentiment_analysis,36,"['B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.19047619047619047,188,0.752,11,1.0,1,1,results
192,"After removing the deep transformation ( i.e. , the techniques introduced in Section 2.2 ) , both TNet - LF and TNet - AS are reduced to TNet w/o transformation ( where position relevance is kept ) , and their results in both accuracy and F 1 measure are incomparable with those of TNet .",Main Results,Performance of Ablated TNet,sentiment_analysis,36,"['O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'O', 'B-ob', 'O']",15,0.23809523809523808,191,0.764,2,0.25,1,1,ablation-analysis
193,It shows that the integration of target information into the word - level representations is crucial for good performance .,Main Results,Performance of Ablated TNet,sentiment_analysis,36,"['O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",16,0.25396825396825395,192,0.768,3,0.375,1,1,ablation-analysis
194,"Comparing the results of TNet and TNet w/o context ( where TST and position relevance are kept ) , we observe that the performance of TNet w/o context drops significantly on LAPTOP and REST 7 , while on TWITTER , TNet w/o context performs very competitive ( p- values with TNet - LF and TNet - AS are 0.066 and 0.053 respectively for Accuracy ) .",Main Results,Performance of Ablated TNet,sentiment_analysis,36,"['B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,17,0.2698412698412698,193,0.772,4,0.5,1,1,ablation-analysis
196,"TNet w/o context performs consistently better than TNet w/o transformation , which verifies the efficacy of the target specific transformation ( TST ) , before applying context - preserving .",Main Results,Performance of Ablated TNet,sentiment_analysis,36,"['B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.30158730158730157,195,0.78,6,0.75,1,1,ablation-analysis
198,"All of the produced p-values are less than 0.05 , suggesting that the improvements brought in by position information are significant .",Main Results,Performance of Ablated TNet,sentiment_analysis,36,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'O']",21,0.3333333333333333,197,0.788,8,1.0,1,1,ablation-analysis
2,IARM : Inter-Aspect Relation Modeling with Memory Networks in Aspect - Based Sentiment Analysis,title,title,sentiment_analysis,37,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.003952569169960474,1,0.0,1,1,research-problem
4,Sentiment analysis has immense implications in modern businesses through user-feedback mining .,abstract,abstract,sentiment_analysis,37,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.011857707509881422,1,0.2,1,1,research-problem
13,Aspect - based sentiment analysis ( ABSA ) caters to these needs .,Introduction,Introduction,sentiment_analysis,37,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",4,0.13793103448275862,12,0.04743083003952569,4,0.13793103448275862,1,1,research-problem
26,The aim of the ABSA classifier is to learn these connections between the aspects and their sentiment bearing phrases .,Introduction,Introduction,sentiment_analysis,37,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.5862068965517241,25,0.09881422924901186,17,0.5862068965517241,1,1,research-problem
33,"To model these scenarios , firstly , following , we independently generate aspect - aware sentence representations for all the aspects using gated recurrent unit ( GRU ) and attention mechanism .",Introduction,Introduction,sentiment_analysis,37,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",24,0.8275862068965517,32,0.12648221343873517,24,0.8275862068965517,1,1,model
34,"Then , we employ memory networks to repeatedly match the target aspect representation with the other aspects to generate more accurate representation of the target aspect .",Introduction,Introduction,sentiment_analysis,37,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",25,0.8620689655172413,33,0.13043478260869565,25,0.8620689655172413,1,1,model
35,This refined representation is fed to a softmax classifier for final classification .,Introduction,Introduction,sentiment_analysis,37,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",26,0.896551724137931,34,0.13438735177865613,26,0.896551724137931,1,1,model
162,LSTM,Baseline Methods,,sentiment_analysis,37,['B'],,,2,0.09090909090909091,161,0.6363636363636364,2,0.1111111111111111,1,1,
163,"Following , the sentence is fed to along short - term memory ( LSTM ) network to propagate context among the constituent words .",Baseline Methods,LSTM,sentiment_analysis,37,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",3,0.13636363636363635,162,0.6403162055335968,3,0.16666666666666666,1,1,baselines
166,TD- LSTM,Baseline Methods,LSTM,sentiment_analysis,37,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",6,0.2727272727272727,165,0.6521739130434783,6,0.3333333333333333,1,1,baselines
167,"Following , sequence of words preceding ( left context ) and succeeding ( right context ) target aspect term are fed to two different LSTMs .",Baseline Methods,LSTM,sentiment_analysis,37,"['O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",7,0.3181818181818182,166,0.6561264822134387,7,0.3888888888888889,1,1,baselines
172,"This representation is fed to softmax classifier. , ATAE - LSTM is identical to AE - LSTM , except the LSTM is fed with the concatenation of aspect - term representation and word representation . , target - aspect and its context are sent to two distinct LSTMs and the means of the hidden outputs are taken as intermediate aspect representation and context representation respectively .",Baseline Methods,LSTM,sentiment_analysis,37,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.5454545454545454,171,0.6758893280632411,12,0.6666666666666666,1,1,baselines
196,"It is evident from the results that our IARM model outperforms all the baseline models , including the state of the art , in both of the domains .",Results and Discussion,Overall Comparison,sentiment_analysis,37,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'O']",4,0.07272727272727272,195,0.7707509881422925,4,0.5714285714285714,1,1,results
197,"We obtained bigger improvement in laptop domain , of 1.7 % , compared to restaurant domain , of 1.4 % .",Results and Discussion,Overall Comparison,sentiment_analysis,37,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'O']",,,5,0.09090909090909091,196,0.7747035573122529,5,0.7142857142857143,1,1,results
13,Representation learning ) plays a critical role in many modern machine learning systems .,Introduction and Motivating Work,Introduction and Motivating Work,sentiment_analysis,38,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.020833333333333332,12,0.07142857142857142,10,0.19607843137254902,1,1,research-problem
49,We focus in on the task of sentiment analysis and attempt to learn an unsupervised representation that accurately contains this concept .,Introduction and Motivating Work,Introduction and Motivating Work,sentiment_analysis,38,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'O', 'O']",37,0.7708333333333334,48,0.2857142857142857,46,0.9019607843137255,1,1,research-problem
51,"As an approach , we consider the popular research benchmark of byte ( character ) level language modelling due to its further simplicity and generality .",Introduction and Motivating Work,Introduction and Motivating Work,sentiment_analysis,38,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",39,0.8125,50,0.2976190476190476,48,0.9411764705882353,1,1,approach
53,We train on a very large corpus picked to have a similar distribution as our task of interest .,Introduction and Motivating Work,Introduction and Motivating Work,sentiment_analysis,38,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",41,0.8541666666666666,52,0.30952380952380953,50,0.9803921568627451,1,1,approach
99,Review Sentiment Analysis,Experimental Setup and Results,,sentiment_analysis,38,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",22,0.24175824175824176,98,0.5833333333333334,0,0.0,1,1,results
105,The representation learned by our model achieves 91.8 % significantly outperforming the state of the art of 90.2 % by a 30 model ensemble .,Experimental Setup and Results,Review Sentiment Analysis,sentiment_analysis,38,"['B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",28,0.3076923076923077,104,0.6190476190476191,6,0.2857142857142857,1,1,results
107,It matches the performance of baselines using as few as a dozen labeled examples and outperforms all previous results with only a few hundred labeled examples .,Experimental Setup and Results,Review Sentiment Analysis,sentiment_analysis,38,"['O', 'B', 'O', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'B-p', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",30,0.32967032967032966,106,0.6309523809523809,8,0.38095238095238093,1,1,results
109,"Confusingly , despite a 16 % relative error reduction on the binary subtask , it does not reach the state of the art of 53.6 % on the fine - grained subtask , achieving 52.9 % .",Experimental Setup and Results,Review Sentiment Analysis,sentiment_analysis,38,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",32,0.3516483516483517,108,0.6428571428571429,10,0.47619047619047616,1,1,results
112,L1 regularization is known to reduce sample complexity when there are many irrelevant features .,Experimental Setup and Results,Review Sentiment Analysis,sentiment_analysis,38,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",35,0.38461538461538464,111,0.6607142857142857,13,0.6190476190476191,1,1,results
117,"Fitting a threshold to this single unit achieves a test accuracy of 92.30 % which outperforms a strong supervised results on the dataset , the 91.87 % of NB - SVM trigram , but is still below the semi-supervised state of the art of 94.09 % .",Experimental Setup and Results,Review Sentiment Analysis,sentiment_analysis,38,"['B', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']",,,40,0.43956043956043955,116,0.6904761904761905,18,0.8571428571428571,1,1,results
118,Using the full 4096 unit representation achieves 92.88 % .,Experimental Setup and Results,Review Sentiment Analysis,sentiment_analysis,38,"['B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",41,0.45054945054945056,117,0.6964285714285714,19,0.9047619047619048,1,1,results
122,Capacity Ceiling,Experimental Setup and Results,,sentiment_analysis,38,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",45,0.4945054945054945,121,0.7202380952380952,0,0.0,1,1,results
124,We try our approach on the binary version of the Yelp Dataset Challenge in 2015 as introduced in .,Experimental Setup and Results,Capacity Ceiling,sentiment_analysis,38,"['O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",47,0.5164835164835165,123,0.7321428571428571,2,0.125,1,1,results
127,"Using the full dataset , we achieve 95 . 22 % test accuracy .",Experimental Setup and Results,Capacity Ceiling,sentiment_analysis,38,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",50,0.5494505494505495,126,0.75,5,0.3125,1,1,results
129,The observed capacity ceiling is an interesting phenomena and stumbling point for scaling our unsupervised representations .,Experimental Setup and Results,Capacity Ceiling,sentiment_analysis,38,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",52,0.5714285714285714,128,0.7619047619047619,7,0.4375,1,1,results
134,"Additionally , there is a notable drop in the relative performance of our approach transitioning from sentence to document datasets .",Experimental Setup and Results,Capacity Ceiling,sentiment_analysis,38,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",57,0.6263736263736264,133,0.7916666666666666,12,0.75,1,1,results
136,"Finally , as the amount of labeled data increases , the performance of the simple linear model we train on top of our static representation will eventually saturate .",Experimental Setup and Results,Capacity Ceiling,sentiment_analysis,38,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-n', 'O', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-b', 'O', 'O', 'B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'O']",59,0.6483516483516484,135,0.8035714285714286,14,0.875,1,1,results
2,SentiHood : Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods,title,title,sentiment_analysis,39,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.004081632653061225,1,0.0,1,1,research-problem
4,"In this paper , we introduce the task of targeted aspect - based sentiment analysis .",abstract,abstract,sentiment_analysis,39,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.09090909090909091,3,0.012244897959183673,1,0.09090909090909091,1,1,research-problem
16,Sentiment analysis is an important task in natural language processing .,Introduction,Introduction,sentiment_analysis,39,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.007633587786259542,15,0.061224489795918366,1,0.025,1,1,research-problem
20,"Aspect - based sentiment analysis ( ABSA ) relates to the task of extracting fine - grained information by identifying the polarity towards different aspects of an entity in the same unit of text , and recognizing the polarity associated with each aspect separately .",Introduction,Introduction,sentiment_analysis,39,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.03816793893129771,19,0.07755102040816327,5,0.125,1,1,research-problem
24,Targeted sentiment analysis investigates the classification of opinion polarities towards certain target entity mentions in given sentences ( often a tweet ) .,Introduction,Introduction,sentiment_analysis,39,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.06870229007633588,23,0.09387755102040816,9,0.225,1,1,research-problem
128,SentiHood currently contains annotated sentences containing one or two location entity mentions .,Introduction,Dataset,sentiment_analysis,39,"['B', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",113,0.8625954198473282,127,0.5183673469387755,1,0.1111111111111111,1,1,dataset
129,2 Sen-tiHood contains 5215 sentences with 3862 sentences containing a single location and 1353 sentences containing multiple ( two ) locations .,Introduction,Dataset,sentiment_analysis,39,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']",,,114,0.8702290076335878,128,0.5224489795918368,2,0.2222222222222222,1,1,dataset
131,""" Positive "" sentiment is dominant for aspects such as dining and shopping .",Introduction,Dataset,sentiment_analysis,39,"['B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",116,0.8854961832061069,130,0.5306122448979592,4,0.4444444444444444,1,1,dataset
133,The general aspect is the most frequent aspect with over 2000 sentences while aspect touristy has occurred in less than 100 sentences .,Introduction,Dataset,sentiment_analysis,39,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",118,0.9007633587786259,132,0.5387755102040817,6,0.6666666666666666,1,1,dataset
134,"Notice that since each sentence can contain one or more opinions , the total number of opinions ( 5920 ) in the dataset is higher than the number of sentences .",Introduction,Dataset,sentiment_analysis,39,"['O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O']",119,0.9083969465648855,133,0.5428571428571428,7,0.7777777777777778,1,1,dataset
135,"Location entity names are masked by location1 and location 2 in the whole dataset , so the task does not involve identification and segmentation of the named entities .",Introduction,Dataset,sentiment_analysis,39,"['B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",120,0.916030534351145,134,0.5469387755102041,8,0.8888888888888888,1,1,dataset
161,Logistic Regression,Baseline,,sentiment_analysis,39,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",8,0.18604651162790697,160,0.6530612244897959,0,0.0,1,1,baselines
162,"Many existing works in the aspect - based sentiment analysis task , 3 use a classifier , such as logistic regression or SVM , based on linguistic features such as n-grams , POS information or more hand - engineered features .",Baseline,Logistic Regression,sentiment_analysis,39,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.20930232558139536,161,0.6571428571428571,1,0.01639344262295082,1,1,baselines
164,"More concretely , we define the following sparse representations of locations :",Baseline,Logistic Regression,sentiment_analysis,39,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",11,0.2558139534883721,163,0.6653061224489796,3,0.04918032786885246,1,1,baselines
165,Mask target entity n-grams :,Baseline,Logistic Regression,sentiment_analysis,39,"['B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.27906976744186046,164,0.6693877551020408,4,0.06557377049180328,1,1,baselines
168,Left - right n- grams : we create an n-gram representation for both the right and the left context around each location mention .,Baseline,Logistic Regression,sentiment_analysis,39,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.3488372093023256,167,0.6816326530612244,7,0.11475409836065574,1,1,baselines
170,Left right pooling :,Baseline,Logistic Regression,sentiment_analysis,39,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-ob', 'I-ob', 'I-ob', 'O']",17,0.3953488372093023,169,0.689795918367347,9,0.14754098360655737,1,1,baselines
177,Long Short - Term Memory ( LSTM ),Baseline,Logistic Regression,sentiment_analysis,39,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",24,0.5581395348837209,176,0.7183673469387755,16,0.26229508196721313,1,1,baselines
178,"Inspired by the recent success of applying deep neural networks on language tasks , we use a bidirectional LSTM to learn a classifier for each of the aspects .",Baseline,Logistic Regression,sentiment_analysis,39,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",25,0.5813953488372093,177,0.7224489795918367,17,0.2786885245901639,1,1,baselines
179,Representations for a location ( e l ) are obtained using one of the following two approaches :,Baseline,Logistic Regression,sentiment_analysis,39,"['B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",26,0.6046511627906976,178,0.726530612244898,18,0.29508196721311475,1,1,baselines
180,Final output state ( LSTM - Final ) : e l is the output embedding of the bidirectional LSTM .,Baseline,Logistic Regression,sentiment_analysis,39,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",27,0.627906976744186,179,0.7306122448979592,19,0.3114754098360656,1,1,baselines
181,Location output state ( LSTM - Location ) :,Baseline,Logistic Regression,sentiment_analysis,39,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",28,0.6511627906976745,180,0.7346938775510204,20,0.32786885245901637,1,1,baselines
211,"As we can see , the n-gram representation with location masking achieves slightly better results over the left - right context .",Training LSTMs,Training LSTMs,sentiment_analysis,39,"['O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.56,210,0.8571428571428571,50,0.819672131147541,1,1,results
213,"Also , by adding POS information , we gain an increase in the performance .",Training LSTMs,Training LSTMs,sentiment_analysis,39,"['O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O']",16,0.64,212,0.8653061224489796,52,0.8524590163934426,1,1,results
215,"Separating the left and the right context ( LR - Left - Right ) for BoW representation , does not improve the performance .",Training LSTMs,Training LSTMs,sentiment_analysis,39,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'O']",18,0.72,214,0.8734693877551021,54,0.8852459016393442,1,1,results
217,"Amongst the two variations of LSTM , the model with final state embeddings does slightly better than the model where we use the embeddings at the location index , however they are not significantly different ( with a p valueless than 0.01 ) .",Training LSTMs,Training LSTMs,sentiment_analysis,39,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,20,0.8,216,0.8816326530612245,56,0.9180327868852459,1,1,results
218,"It is interesting to note that the best LSTM model is not superior to logistic regression model , especially in terms of AUC .",Training LSTMs,Training LSTMs,sentiment_analysis,39,"['O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'O']",21,0.84,217,0.8857142857142857,57,0.9344262295081968,1,1,results
221,Another interesting observation is that the F 1 measure for logistic regression model with n-grams and POS information is very low while this model 's performance is superior to other models in terms of AUC .,Training LSTMs,Training LSTMs,sentiment_analysis,39,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'O']",,,24,0.96,220,0.8979591836734694,60,0.9836065573770492,1,1,results
2,ICON : Interactive Conversational Memory Network for Multimodal Emotion Detection,title,title,sentiment_analysis,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.003067484662576687,1,0.0,1,1,research-problem
4,Emotion recognition in conversations is crucial for building empathetic machines .,abstract,abstract,sentiment_analysis,4,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.16666666666666666,3,0.009202453987730062,1,0.16666666666666666,1,1,research-problem
16,"Analyzing emotional dynamics in conversations , however , poses complex challenges .",Introduction,Introduction,sentiment_analysis,4,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.11538461538461539,15,0.046012269938650305,6,0.13953488372093023,1,1,research-problem
20,"We propose Interactive COnversational memory Network ( ICON ) , a multimodal network for identifying emotions in utterance - videos .",Introduction,Introduction,sentiment_analysis,4,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.19230769230769232,19,0.05828220858895705,10,0.23255813953488372,1,1,model
28,"First , it extracts multimodal features from all utterancevideos .",Introduction,Introduction,sentiment_analysis,4,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",18,0.34615384615384615,27,0.08282208588957055,18,0.4186046511627907,1,1,model
29,"Next , given a test utterance to be classified , ICON considers the preceding utterances of both speakers falling within a context - window and models their self - emotional influences using local gated recurrent units .",Introduction,Introduction,sentiment_analysis,4,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.36538461538461536,28,0.08588957055214724,19,0.4418604651162791,1,1,model
30,"Furthermore , to incorporate inter -speaker influences , a global representation is generated using a GRU that intakes output of the local GRUs .",Introduction,Introduction,sentiment_analysis,4,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",20,0.38461538461538464,29,0.08895705521472393,20,0.46511627906976744,1,1,model
31,"For each instance in the context - window , the output of this global GRU is stored as a memory cell .",Introduction,Introduction,sentiment_analysis,4,"['B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",21,0.40384615384615385,30,0.09202453987730061,21,0.4883720930232558,1,1,model
32,These memories are then subjected to multiple read / write cycles that include attention mechanism for generating contextual summaries of the conversational history .,Introduction,Introduction,sentiment_analysis,4,"['O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",22,0.4230769230769231,31,0.0950920245398773,22,0.5116279069767442,1,1,model
33,"At each iteration , the representation of the test utterance is improved with this summary representation and finally used for prediction .",Introduction,Introduction,sentiment_analysis,4,"['B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",23,0.4423076923076923,32,0.09815950920245399,23,0.5348837209302325,1,1,model
219,20 % of the training set is used as validation set for hyper - parameter tuning .,Training Details,Training Details,sentiment_analysis,4,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.08333333333333333,218,0.6687116564417178,1,0.08333333333333333,1,1,experimental-setup
220,"We use the Adam optimizer ( Kingma and Ba , 2014 ) for training the parameters starting with an initial learning rate of 0.001 .",Training Details,Training Details,sentiment_analysis,4,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",2,0.16666666666666666,219,0.6717791411042945,2,0.16666666666666666,1,1,experimental-setup
221,Termination of the training - phase is decided by early - stopping with a patience of 10 d = 100 dv = 512 dem = 100 K = 40 R = 3 epochs .,Training Details,Training Details,sentiment_analysis,4,"['B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,3,0.25,220,0.6748466257668712,3,0.25,1,1,experimental-setup
222,The network is subjected to regularization in the form of Dropout and Gradient - clipping for a norm of 40 .,Training Details,Training Details,sentiment_analysis,4,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O']",4,0.3333333333333333,221,0.6779141104294478,4,0.3333333333333333,1,1,experimental-setup
223,"Finally , the best hyper - parameters are decided using a gridsearch .",Training Details,Training Details,sentiment_analysis,4,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",5,0.4166666666666667,222,0.6809815950920245,5,0.4166666666666667,1,1,experimental-setup
225,"For multimodal feature extraction , we explore different designs for the employed CNNs .",Training Details,Training Details,sentiment_analysis,4,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",7,0.5833333333333334,224,0.6871165644171779,7,0.5833333333333334,1,1,experimental-setup
226,"For text , we find the single layer CNN to perform at par with deeper variants .",Training Details,Training Details,sentiment_analysis,4,"['O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",8,0.6666666666666666,225,0.6901840490797546,8,0.6666666666666666,1,1,experimental-setup
227,"For visual features , however , a deeper CNN provides better representations .",Training Details,Training Details,sentiment_analysis,4,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",9,0.75,226,0.6932515337423313,9,0.75,1,1,experimental-setup
228,We also find that contextually conditioned features perform better than context - less features .,Training Details,Training Details,sentiment_analysis,4,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.8333333333333334,227,0.696319018404908,10,0.8333333333333334,1,1,experimental-setup
233,memnet is an end - toend memory network .,Baselines,Baselines,sentiment_analysis,4,"['B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.18181818181818182,232,0.7116564417177914,2,0.18181818181818182,1,1,baselines
235,cLSTM 4 classifies utterances using neighboring utterances ( of same speaker ) as context .,Baselines,Baselines,sentiment_analysis,4,"['B', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['B-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",4,0.36363636363636365,234,0.7177914110429447,4,0.36363636363636365,1,1,baselines
237,"TFN 5 models intra-and intermodality dynamics by explicitly aggregating uni - , bi- and trimodal interactions .",Baselines,Baselines,sentiment_analysis,4,"['B', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.5454545454545454,236,0.7239263803680982,6,0.5454545454545454,1,1,baselines
239,"MFN performs multi-view learning by using Delta - memory Attention Network , a fusion mechanism to learn cross - view interactions .",Baselines,Baselines,sentiment_analysis,4,"['B', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.7272727272727273,238,0.7300613496932515,8,0.7272727272727273,1,1,baselines
241,CMN models separate contexts for both speaker and listener to an utterance .,Baselines,Baselines,sentiment_analysis,4,"['B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'O']",10,0.9090909090909091,240,0.7361963190184049,10,0.9090909090909091,1,1,baselines
246,ICON performs better than the compared models with significant performance increase in emotions ( ? 2.1 % acc. ) .,Results,Results,sentiment_analysis,4,"['B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.13043478260869565,245,0.7515337423312883,3,0.13043478260869565,1,1,results
247,"For each emotion , ICON outperforms all the compared models except for happiness emotion .",Results,Results,sentiment_analysis,4,"['B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",4,0.17391304347826086,246,0.754601226993865,4,0.17391304347826086,1,1,results
248,"However , its performance is still at par with c LSTM without a significant gap .",Results,Results,sentiment_analysis,4,"['O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.21739130434782608,247,0.7576687116564417,5,0.21739130434782608,1,1,results
249,"Also , ICON manages to correctly identify the relatively similar excitement emotion by a large margin .",Results,Results,sentiment_analysis,4,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-p', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",6,0.2608695652173913,248,0.7607361963190185,6,0.2608695652173913,1,1,results
251,"In all the labels , ICON attains improved performance over its counterparts , suggesting the efficacy of its context - modeling scheme .",Results,Results,sentiment_analysis,4,"['B', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'O', 'B-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'O', 'B-b', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.34782608695652173,250,0.7668711656441718,8,0.34782608695652173,1,1,results
263,presents the results for different combinations of modes used by ICON on IEMOCAP .,Results,Results,sentiment_analysis,4,"['B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'O']","['B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O']","['B-p', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O']",20,0.8695652173913043,262,0.803680981595092,20,0.8695652173913043,1,1,results
264,"As seen , the trimodal network provides the best performance which is preceded by the bimodal variants .",Results,Results,sentiment_analysis,4,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",21,0.9130434782608695,263,0.8067484662576687,21,0.9130434782608695,1,1,results
265,"Among unimodals , language modality performs the best , reaffirming its significance in multimodal systems .",Results,Results,sentiment_analysis,4,"['B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.9565217391304348,264,0.8098159509202454,22,0.9565217391304348,1,1,results
266,"Interestingly , the audio and visual modality , on their own , do not provide good performance , but when used with text , complementary data is shared to improve over all performance .",Results,Results,sentiment_analysis,4,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",23,1.0,265,0.8128834355828221,23,1.0,1,1,results
272,Self vs Dual History :,Ablation Study,Ablation Study,sentiment_analysis,4,"['B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O']",5,0.09803921568627451,271,0.8312883435582822,5,0.35714285714285715,1,1,ablation-analysis
274,"Compared to the dual - history variants ( variants 3 , 5 , and 7 ) , these models provide lesser performance .",Ablation Study,Ablation Study,sentiment_analysis,4,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.13725490196078433,273,0.8374233128834356,7,0.5,1,1,ablation-analysis
277,DGIM prevents the storage of dynamic influences between speakers at each historical time step and leads to performance deterioration .,Ablation Study,Ablation Study,sentiment_analysis,4,"['B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",10,0.19607843137254902,276,0.8466257668711656,10,0.7142857142857143,1,1,ablation-analysis
278,"Multi - hop vs No - hop : Variants 2 and 3 represent cases where multi-hop is omitted , i.e. , R = 1 . Performance for them are poorer than variants having multi-hop mechanism ( variants 4 - 7 ) .",Ablation Study,Ablation Study,sentiment_analysis,4,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.21568627450980393,277,0.8496932515337423,11,0.7857142857142857,1,1,ablation-analysis
279,"Also , removal of multi-hop leads to worse performance than the removal of DGIM .",Ablation Study,Ablation Study,sentiment_analysis,4,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.23529411764705882,278,0.852760736196319,12,0.8571428571428571,1,1,ablation-analysis
281,"However , best performance is achieved by variant 6 which contains all the proposed modules in its pipeline .",Ablation Study,Ablation Study,sentiment_analysis,4,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",14,0.27450980392156865,280,0.8588957055214724,14,1.0,1,1,ablation-analysis
2,Recurrent Attention Network on Memory for Aspect Sentiment Analysis,title,,sentiment_analysis,40,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004484304932735426,1,0.0,1,1,research-problem
30,"In this paper , we propose a novel framework to solve the above problems in target sentiment analysis .",Introduction,Introduction,sentiment_analysis,40,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",20,0.6060606060606061,29,0.13004484304932734,20,0.6060606060606061,1,1,model
31,"Specifically , our framework first adopts a bidirectional LSTM ( BLSTM ) to produce the memory ( i.e. the states of time steps generated by LSTM ) from the input , as bidirectional recurrent neural networks ( RNNs ) were found effective for a similar purpose in machine translation .",Introduction,Introduction,sentiment_analysis,40,"['O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.6363636363636364,30,0.13452914798206278,21,0.6363636363636364,1,1,model
32,"The memory slices are then weighted according to their relative positions to the target , so that different targets from the same sentence have their own tailor - made memories .",Introduction,Introduction,sentiment_analysis,40,"['O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.6666666666666666,31,0.13901345291479822,22,0.6666666666666666,1,1,model
33,"After that , we pay multiple attentions on the position - weighted memory and nonlinearly combine the attention results with a recurrent network , i.e. GRUs .",Introduction,Introduction,sentiment_analysis,40,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",23,0.696969696969697,32,0.14349775784753363,23,0.696969696969697,1,1,model
34,"Finally , we apply softmax on the output of the GRU network to predict the sentiment on the target .",Introduction,Introduction,sentiment_analysis,40,"['O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'O']",,,24,0.7272727272727273,33,0.14798206278026907,24,0.7272727272727273,1,1,model
35,Our framework introduces a novel way of applying multiple - attention mechanism to synthesize important features in difficult sentence structures .,Introduction,Introduction,sentiment_analysis,40,"['B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",25,0.7575757575757576,34,0.15246636771300448,25,0.7575757575757576,1,1,model
149,Average Context :,Compared Methods,Compared Methods,sentiment_analysis,40,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-b', 'I-b', 'O']",2,0.125,148,0.6636771300448431,2,0.125,1,1,baselines
150,There are two versions of this method .,Compared Methods,Compared Methods,sentiment_analysis,40,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O']",3,0.1875,149,0.6681614349775785,3,0.1875,1,1,baselines
151,"The first one , named AC - S , averages the word vectors before the target and the word vectors after the target separately .",Compared Methods,Compared Methods,sentiment_analysis,40,"['O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O']",,,4,0.25,150,0.672645739910314,4,0.25,1,1,baselines
152,"The second one , named AC , averages the word vectors of the full context .",Compared Methods,Compared Methods,sentiment_analysis,40,"['O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']",,,5,0.3125,151,0.6771300448430493,5,0.3125,1,1,baselines
153,"SVM : The traditional state - of - the - art method using SVMs on surface features , lexicon features and parsing features , which is the best team in SemEval 2014 .",Compared Methods,Compared Methods,sentiment_analysis,40,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.375,152,0.6816143497757847,6,0.375,1,1,baselines
154,"Rec - NN : It firstly uses rules to transform the dependency tree and put the opinion target at the root , and then performs semantic composition with Recursive NNs for sentiment prediction .",Compared Methods,Compared Methods,sentiment_analysis,40,"['B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.4375,153,0.6860986547085202,7,0.4375,1,1,baselines
155,TD- LSTM : It uses a forward LSTM and a backward LSTM to abstract the information before and after the target .,Compared Methods,Compared Methods,sentiment_analysis,40,"['B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'O']","['B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O']","['B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'O']",8,0.5,154,0.6905829596412556,8,0.5,1,1,baselines
158,TD - LSTM - A : We developed TD - LSTM to make it have one attention on the outputs of 3 https://github.com/svn2github/word2vec,Compared Methods,Compared Methods,sentiment_analysis,40,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O']",11,0.6875,157,0.7040358744394619,11,0.6875,1,1,baselines
160,"MemNet : It applies attention multiple times on the word embeddings , and the last attention 's output is fed to softmax for prediction , without combining the results of different attentions .",Compared Methods,Compared Methods,sentiment_analysis,40,"['B', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'B-p', 'B-n', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'O', 'B-p', 'B-b', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.8125,159,0.7130044843049327,13,0.8125,1,1,baselines
167,"As shown by the results in , our RAM consistently outperforms all compared methods on these four datasets .",Main Results,Main Results,sentiment_analysis,40,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",3,0.058823529411764705,166,0.7443946188340808,3,0.2,1,1,results
168,"AC and AC - S perform poorly , because averaging context is equivalent to paying identical attention to each word which would hide the true sentiment word .",Main Results,Main Results,sentiment_analysis,40,"['B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.0784313725490196,167,0.7488789237668162,4,0.26666666666666666,1,1,results
169,Rec - NN is better than TD - LSTM but not as good as our method .,Main Results,Main Results,sentiment_analysis,40,"['B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",5,0.09803921568627451,168,0.7533632286995515,5,0.3333333333333333,1,1,results
172,"TD - LSTM performs less competitive than our method on all the datasets , particularly on the tweet dataset , because in this dataset sentiment words are usually far from person names , for which case the multiple - attention mechanism is designed to work .",Main Results,Main Results,sentiment_analysis,40,"['B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.1568627450980392,171,0.7668161434977578,8,0.5333333333333333,1,1,results
173,"TD - LSTM - A also performs worse than our method , because it s two attentions , i.e. one for the text before the target and the other for the after , can not tackle some cases where more than one features being attended are at the same side of the target .",Main Results,Main Results,sentiment_analysis,40,"['B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.17647058823529413,172,0.7713004484304933,9,0.6,1,1,results
175,"MemNet adopts multiple attentions in order to improve the attention results , given the assumption that the result of an attention at a later hop should be better than that at the beginning .",Main Results,Main Results,sentiment_analysis,40,"['B', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.21568627450980393,174,0.7802690582959642,11,0.7333333333333333,1,1,results
2,Attention - based LSTM for Aspect - level Sentiment Classification,title,title,sentiment_analysis,41,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004484304932735426,1,0.0,1,1,research-problem
4,Aspect - level sentiment classification is a finegrained task in sentiment analysis .,abstract,abstract,sentiment_analysis,41,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",1,0.125,3,0.013452914798206279,1,0.125,1,1,research-problem
15,"In this paper , we deal with aspect - level sentiment classification and we find that the sentiment polarity of a sentence is highly dependent on both content and aspect .",Introduction,Introduction,sentiment_analysis,41,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.125,14,0.06278026905829596,3,0.125,1,1,research-problem
24,"In this paper , we propose an attention mechanism to enforce the model to attend to the important part of a sentence , in response to a specific aspect .",Introduction,Introduction,sentiment_analysis,41,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'B-p', 'I-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.5,23,0.1031390134529148,12,0.5,1,1,model
25,We design an aspect - tosentence attention mechanism that can concentrate on the key part of a sentence given the aspect .,Introduction,Introduction,sentiment_analysis,41,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'B-p', 'O', 'B-ob', 'O']",13,0.5416666666666666,24,0.10762331838565023,13,0.5416666666666666,1,1,model
26,We explore the potential correlation of aspect and sentiment polarity in aspect - level sentiment classification .,Introduction,Introduction,sentiment_analysis,41,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.5833333333333334,25,0.11210762331838565,14,0.5833333333333334,1,1,model
27,"In order to capture important information in response to a given aspect , we design an attentionbased LSTM .",Introduction,Introduction,sentiment_analysis,41,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'O']",15,0.625,26,0.11659192825112108,15,0.625,1,1,model
146,We apply the proposed model to aspect - level sentiment classification .,Experiment,Experiment,sentiment_analysis,41,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.03571428571428571,145,0.6502242152466368,1,0.125,1,1,hyperparameters
147,"In our experiments , all word vectors are initialized by Glove 1 .",Experiment,Experiment,sentiment_analysis,41,"['B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'O', 'O']","['B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O']","['B-p', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'O']",2,0.07142857142857142,146,0.6547085201793722,2,0.25,1,1,hyperparameters
148,The word embedding vectors are pre-trained on an unlabeled corpus whose size is about 840 billion .,Experiment,Experiment,sentiment_analysis,41,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.10714285714285714,147,0.6591928251121076,3,0.375,1,1,hyperparameters
149,"The other parameters are initialized by sampling from a uniform distribution U (?? , ? ) .",Experiment,Experiment,sentiment_analysis,41,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.14285714285714285,148,0.6636771300448431,4,0.5,1,1,hyperparameters
150,"The dimension of word vectors , aspect embeddings and the size of hidden layer are 300 .",Experiment,Experiment,sentiment_analysis,41,"['O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'O']",5,0.17857142857142858,149,0.6681614349775785,5,0.625,1,1,hyperparameters
151,The length of attention weights is the same as the length of sentence .,Experiment,Experiment,sentiment_analysis,41,"['O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'O']",,,6,0.21428571428571427,150,0.672645739910314,6,0.75,1,1,hyperparameters
152,Theano is used for implementing our neural network models .,Experiment,Experiment,sentiment_analysis,41,"['B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['B-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",7,0.25,151,0.6771300448430493,7,0.875,1,1,hyperparameters
153,"We trained all models with a batch size of 25 examples , and a momentum of 0.9 , L 2 - regularization weight of 0.001 and initial learning rate of 0.01 for AdaGrad .",Experiment,Experiment,sentiment_analysis,41,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'O']",,,8,0.2857142857142857,152,0.6816143497757847,8,1.0,1,1,hyperparameters
176,"LSTM : Standard LSTM can not capture any aspect information in sentence , so it must get the same ( a ) the aspect of this sentence : service ( b ) the aspect of this sentence : food : Attention Visualizations .",Comparison with baseline methods,Comparison with baseline methods,sentiment_analysis,41,"['B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.4,175,0.7847533632286996,2,0.4,1,1,results
182,"Since it can not take advantage of the aspect information , not surprisingly the model has worst performance .",Models,Three sentiment polarity although given different aspects .,sentiment_analysis,41,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",2,0.05555555555555555,181,0.8116591928251121,2,0.18181818181818182,1,1,results
183,TD - LSTM : TD - LSTM can improve the performance of sentiment classifier by treating an aspect as a target .,Models,Three sentiment polarity although given different aspects .,sentiment_analysis,41,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O']",3,0.08333333333333333,182,0.8161434977578476,3,0.2727272727272727,1,1,results
184,"Since there is no attention mechanism in TD - LSTM , it can not "" know "" which words are important for a given aspect .",Models,Three sentiment polarity although given different aspects .,sentiment_analysis,41,"['O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",4,0.1111111111111111,183,0.820627802690583,4,0.36363636363636365,1,1,results
186,It is worth noting that TC - LSTM performs worse than LSTM and TD - LSTM in .,Models,Three sentiment polarity although given different aspects .,sentiment_analysis,41,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",6,0.16666666666666666,185,0.8295964125560538,6,0.5454545454545454,1,1,results
190,"ATAE - LSTM not only addresses the shortcoming of the unconformity between word vectors and aspect embeddings , but also can capture the most important information in response to a given aspect .",Models,Three sentiment polarity although given different aspects .,sentiment_analysis,41,"['B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",10,0.2777777777777778,189,0.8475336322869955,10,0.9090909090909091,1,1,results
2,Aspect Level Sentiment Classification with Deep Memory Network,title,,sentiment_analysis,42,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.003968253968253968,1,0.0,1,1,research-problem
12,Aspect level sentiment classification is a fundamental task in the field of sentiment analysis .,Introduction,Introduction,sentiment_analysis,42,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",1,0.009708737864077669,11,0.04365079365079365,1,0.024390243902439025,1,1,research-problem
25,"In pursuit of this goal , we develop deep memory network for aspect level sentiment classification , which is inspired by the recent success of computational models with attention mechanism and explicit memory .",Introduction,Introduction,sentiment_analysis,42,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.13592233009708737,24,0.09523809523809523,14,0.34146341463414637,1,1,approach
26,"Our approach is data - driven , computationally efficient and does not rely on syntactic parser or sentiment lexicon .",Introduction,Introduction,sentiment_analysis,42,"['O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.14563106796116504,25,0.0992063492063492,15,0.36585365853658536,1,1,approach
27,The approach consists of multiple computational layers with shared parameters .,Introduction,Introduction,sentiment_analysis,42,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",16,0.1553398058252427,26,0.10317460317460317,16,0.3902439024390244,1,1,approach
28,"Each layer is a content - and location - based attention model , which first learns the importance / weight of each context word and then utilizes this information to calculate continuous text representation .",Introduction,Introduction,sentiment_analysis,42,"['B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.1650485436893204,27,0.10714285714285714,17,0.4146341463414634,1,1,approach
29,The text representation in the last layer is regarded as the feature for sentiment classification .,Introduction,Introduction,sentiment_analysis,42,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",18,0.17475728155339806,28,0.1111111111111111,18,0.43902439024390244,1,1,approach
30,"As every component is differentiable , the entire model could be efficiently trained end - toend with gradient descent , where the loss function is the cross - entropy error of sentiment classification .",Introduction,Introduction,sentiment_analysis,42,"['O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']",,,19,0.18446601941747573,29,0.11507936507936507,19,0.4634146341463415,1,1,approach
158,"( 1 ) Majority is a basic baseline method , which assigns the majority sentiment label in training set to each instance in the test set .",Comparison to Other Methods,Comparison to Other Methods,sentiment_analysis,42,"['O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O']",,,2,0.07142857142857142,157,0.623015873015873,2,0.08,1,1,baselines
159,( 2 ) Feature - based SVM performs state - of - the - art on aspect level sentiment classification .,Comparison to Other Methods,Comparison to Other Methods,sentiment_analysis,42,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.10714285714285714,158,0.626984126984127,3,0.12,1,1,baselines
161,"( 3 ) We compare with three LSTM models ( Tang et al. , 2015 a ) ) .",Comparison to Other Methods,Comparison to Other Methods,sentiment_analysis,42,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.17857142857142858,160,0.6349206349206349,5,0.2,1,1,baselines
162,"In LSTM , a LSTM based recurrent model is applied from the start to the end of a sentence , and the last hidden vector is used as the sentence representation .",Comparison to Other Methods,Comparison to Other Methods,sentiment_analysis,42,"['B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",6,0.21428571428571427,161,0.6388888888888888,6,0.24,1,1,baselines
163,"TDLSTM extends LSTM by taking into account of the aspect , and uses two LSTM networks , a forward one and a backward one , towards the aspect .",Comparison to Other Methods,Comparison to Other Methods,sentiment_analysis,42,"['B', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'O']",,,7,0.25,162,0.6428571428571429,7,0.28,1,1,baselines
164,"TDLSTM + ATT extends TDLSTM by incorporating an attention mechanism ( Bahdanau et al. , 2015 ) over the hidden vectors .",Comparison to Other Methods,Comparison to Other Methods,sentiment_analysis,42,"['B', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",8,0.2857142857142857,163,0.6468253968253969,8,0.32,1,1,baselines
165,We use the same Glove word vectors for fair comparison .,Comparison to Other Methods,Comparison to Other Methods,sentiment_analysis,42,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",9,0.32142857142857145,164,0.6507936507936508,9,0.36,1,1,baselines
166,"( 4 ) We also implement ContextAVG , a simplistic version of our approach .",Comparison to Other Methods,Comparison to Other Methods,sentiment_analysis,42,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",10,0.35714285714285715,165,0.6547619047619048,10,0.4,1,1,baselines
171,"We can find that feature - based SVM is an extremely strong performer and substantially outperforms other baseline methods , which demonstrates the importance of a powerful feature representation for aspect level sentiment classification .",Comparison to Other Methods,Comparison to Other Methods,sentiment_analysis,42,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.5357142857142857,170,0.6746031746031746,15,0.6,1,1,results
172,"Among three recurrent models , TDLSTM performs better than LSTM , which indicates that taking into account of the aspect information is helpful .",Comparison to Other Methods,Comparison to Other Methods,sentiment_analysis,42,"['B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.5714285714285714,171,0.6785714285714286,16,0.64,1,1,results
175,We consider that each hidden vector of TDLSTM encodes the semantics of word sequence until the current position .,Comparison to Other Methods,Comparison to Other Methods,sentiment_analysis,42,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,19,0.6785714285714286,174,0.6904761904761905,19,0.76,1,1,results
178,"We can also find that the performance of Contex - tAVG is very poor , which means that assigning the same weight / importance to all the context words is not an effective way .",Comparison to Other Methods,Comparison to Other Methods,sentiment_analysis,42,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.7857142857142857,177,0.7023809523809523,22,0.88,1,1,results
179,"Among all our models from single hop to nine hops , we can observe that using more computational layers could generally lead to better performance , especially when the number of hops is less than six .",Comparison to Other Methods,Comparison to Other Methods,sentiment_analysis,42,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",23,0.8214285714285714,178,0.7063492063492064,23,0.92,1,1,results
180,"The best performances are achieved when the model contains seven and nine hops , respectively .",Comparison to Other Methods,Comparison to Other Methods,sentiment_analysis,42,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",24,0.8571428571428571,179,0.7103174603174603,24,0.96,1,1,results
181,"On both datasets , the proposed approach could obtain comparable accuracy compared to the state - of - art feature - based SVM system .",Comparison to Other Methods,Comparison to Other Methods,sentiment_analysis,42,"['B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",25,0.8928571428571429,180,0.7142857142857143,25,1.0,1,1,results
202,We can find that using multiple computational layers could consistently improve the classification accuracy in all these models .,Method,Effects of Location Attention,sentiment_analysis,42,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.8095238095238095,201,0.7976190476190477,12,0.75,1,1,results
203,All these models perform comparably when the number of hops is larger than five .,Method,Effects of Location Attention,sentiment_analysis,42,"['B', 'I', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",18,0.8571428571428571,202,0.8015873015873016,13,0.8125,1,1,results
2,Multi - grained Attention Network for Aspect - Level Sentiment Classification,title,title,sentiment_analysis,43,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004166666666666667,1,0.0,1,1,research-problem
4,We propose a novel multi-grained attention network ( MGAN ) model for aspect level sentiment classification .,abstract,abstract,sentiment_analysis,43,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.125,3,0.0125,1,0.125,1,1,research-problem
29,"In this paper , we propose a multi -grained attention network to address the above two issues in aspect level sentiment classification .",Introduction,Introduction,sentiment_analysis,43,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.7391304347826086,28,0.11666666666666667,17,0.7391304347826086,1,1,model
30,"Specifically , we propose a fine - grained attention mechanism ( i.e. F- Aspect2Context and F - Context2Aspect ) , which is employed to characterize the word - level interactions between aspect and context words , and relieve the information loss occurred in coarse - grained attention mechanism .",Introduction,Introduction,sentiment_analysis,43,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.782608695652174,29,0.12083333333333333,18,0.782608695652174,1,1,model
31,"In addition , we utilize the bidirectional coarsegrained attention ( i.e. C- Aspect2Context and C - Context2Aspect ) and combine them with finegrained attention vectors to compose the multigrained attention network for the final sentiment polarity prediction , which can leverage the advantages of them .",Introduction,Introduction,sentiment_analysis,43,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.8260869565217391,30,0.125,19,0.8260869565217391,1,1,model
32,"More importantly , in order to make use of the valuable aspect - level interaction information , we design an aspect alignment loss in the objective function to enhance the difference of the attention weights towards the aspects which have the same context and different sentiment polarities .",Introduction,Introduction,sentiment_analysis,43,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",20,0.8695652173913043,31,0.12916666666666668,20,0.8695652173913043,1,1,model
171,"In our experiments , word embeddings for both context and aspect words are initialized by Glove .",Experiment Setting,Experiment Setting,sentiment_analysis,43,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",6,0.5454545454545454,170,0.7083333333333334,6,0.5454545454545454,1,1,hyperparameters
172,The dimension of word embedding d v and hidden stated are 1 The detailed task introduction can be found in http://alt.qcri.org/semeval2014/task4/.,Experiment Setting,Experiment Setting,sentiment_analysis,43,"['O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.6363636363636364,171,0.7125,7,0.6363636363636364,1,1,hyperparameters
173,set to 300 .,Experiment Setting,Experiment Setting,sentiment_analysis,43,"['B', 'I', 'B', 'O']","['B-p', 'I-p', 'B-n', 'O']","['B-p', 'I-p', 'B-b', 'O']",8,0.7272727272727273,172,0.7166666666666667,8,0.7272727272727273,1,1,hyperparameters
174,"The weight matrix and bias are initialized by sampling from a uniform distribution U ( 0.01 , 0.01 ) .",Experiment Setting,Experiment Setting,sentiment_analysis,43,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.8181818181818182,173,0.7208333333333333,9,0.8181818181818182,1,1,hyperparameters
175,"The coefficient ? of L 2 regularization item is 10 ? 5 , the parameter ?",Experiment Setting,Experiment Setting,sentiment_analysis,43,"['O', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",10,0.9090909090909091,174,0.725,10,0.9090909090909091,1,1,hyperparameters
176,of aspect alignment loss and dropout rate are set to 0.5 .,Experiment Setting,Experiment Setting,sentiment_analysis,43,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",11,1.0,175,0.7291666666666666,11,1.0,1,1,hyperparameters
179,"Majority is the basic baseline , which chooses the largest sentiment polarity in the training set to each instance in the test set .",Compared Methods,Compared Methods,sentiment_analysis,43,"['B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O']",,,2,0.058823529411764705,178,0.7416666666666667,2,0.14285714285714285,1,1,baselines
180,"MemNet applys multi-hop attentions on the word embeddings , learns the attention weights on context word vectors with respect to the averaged query vector .",Compared Methods,Compared Methods,sentiment_analysis,43,"['B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']",,,3,0.08823529411764706,179,0.7458333333333333,3,0.21428571428571427,1,1,baselines
181,"IAN interactively learns the coarse - grained attentions between the context and aspect , and concatenate the vectors for prediction .",Compared Methods,Compared Methods,sentiment_analysis,43,"['B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'O']","['B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O']","['B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O']",4,0.11764705882352941,180,0.75,4,0.2857142857142857,1,1,baselines
182,"BILSTM - ATT -G ( Liu and Zhang , 2017 ) models left and right context with two attention - based LSTMs and utilizes gates to control the importance of left context , right context and the entire sentence for prediction .",Compared Methods,Compared Methods,sentiment_analysis,43,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",5,0.14705882352941177,181,0.7541666666666667,5,0.35714285714285715,1,1,baselines
183,"RAM learns multi-hop attentions on the hidden states of bidirectional LSTM networks for context words , and proposes to use GRU network to get the aggregated vector from the attentions .",Compared Methods,Compared Methods,sentiment_analysis,43,"['B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",6,0.17647058823529413,182,0.7583333333333333,6,0.42857142857142855,1,1,baselines
186,"MGAN - C only employs the coarse - grained attentions for prediction , which is similar with IAN .",Compared Methods,Compared Methods,sentiment_analysis,43,"['B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.2647058823529412,185,0.7708333333333334,9,0.6428571428571429,1,1,baselines
187,MGAN - F only utilizes the proposed fine - grained attentions for prediction .,Compared Methods,Compared Methods,sentiment_analysis,43,"['B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",10,0.29411764705882354,186,0.775,10,0.7142857142857143,1,1,baselines
188,"MGAN - CF adopts both the coarse - grained and fine - grained attentions , while without applying the aspect alignment loss .",Compared Methods,Compared Methods,sentiment_analysis,43,"['B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.3235294117647059,187,0.7791666666666667,11,0.7857142857142857,1,1,baselines
189,MGAN is the complete multi-grained attention network model .,Compared Methods,,sentiment_analysis,43,"['B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.35294117647058826,188,0.7833333333333333,12,0.8571428571428571,1,1,baselines
193,( 1 ) Majority performs worst since it only utilizes the data distribution information .,Compared Methods,We can have the following observations .,sentiment_analysis,43,"['O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.47058823529411764,192,0.8,1,0.05263157894736842,1,1,results
195,Our method MGAN outperforms Majority and Feature + SVM since MGAN could learn the high quality representation for prediction .,Compared Methods,We can have the following observations .,sentiment_analysis,43,"['O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.5294117647058824,194,0.8083333333333333,3,0.15789473684210525,1,1,results
196,( 2 ) ATAE - LSTM is better than LSTM since it employs attention mechanism on the hidden states and combines with attention embedding to generate the final representation .,Compared Methods,We can have the following observations .,sentiment_analysis,43,"['O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.5588235294117647,195,0.8125,4,0.21052631578947367,1,1,results
197,"TD - LSTM performs slightly better than ATAE - LSTM , and it employs two LSTM networks to capture the left and right context of the aspect .",Compared Methods,We can have the following observations .,sentiment_analysis,43,"['B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.5882352941176471,196,0.8166666666666667,5,0.2631578947368421,1,1,results
198,TD - LSTM performs worse than our method MGAN since it could not properly pay more attentions on the important parts of the context .,Compared Methods,We can have the following observations .,sentiment_analysis,43,"['O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.6176470588235294,197,0.8208333333333333,6,0.3157894736842105,1,1,results
199,"( 3 ) IAN achieves slightly better results with the previous LSTM - based methods , which interactively learns the attended aspect and context vector as final representation .",Compared Methods,We can have the following observations .,sentiment_analysis,43,"['O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.6470588235294118,198,0.825,7,0.3684210526315789,1,1,results
200,Our method consistently performs better than IAN since we utilize the finegrained attention vectors to relieve the information loss in IAN .,Compared Methods,We can have the following observations .,sentiment_analysis,43,"['B', 'I', 'B', 'I', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",23,0.6764705882352942,199,0.8291666666666667,8,0.42105263157894735,1,1,results
202,"BILSTM - ATT - G models left context and right context using attention - based LSTMs , which achieves better performance than MemNet .",Compared Methods,We can have the following observations .,sentiment_analysis,43,"['B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",25,0.7352941176470589,201,0.8375,10,0.5263157894736842,1,1,results
203,RAM performs better than other baselines .,Compared Methods,,sentiment_analysis,43,"['B', 'B', 'B', 'B', 'B', 'I', 'O']","['B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",26,0.7647058823529411,202,0.8416666666666667,11,0.5789473684210527,1,1,results
206,"Our proposed MGAN consistently performs better than MemNet , BILSTM - ATT - G and RAM on all three datasets .",Compared Methods,RAM performs better than other baselines .,sentiment_analysis,43,"['B', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O']",29,0.8529411764705882,205,0.8541666666666666,14,0.7368421052631579,1,1,results
2,Exploring Joint Neural Model for Sentence Level Discourse Parsing and Sentiment Analysis,title,title,sentiment_analysis,44,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004545454545454545,1,0.0,1,1,research-problem
107,Our framework consists of three main sub parts .,Proposed Joint Model,Proposed Joint Model,sentiment_analysis,44,"['O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.045454545454545456,106,0.4818181818181818,1,0.2,1,1,model
108,"Given a segmented sentence , the first step is to create meaningful vector representations for all the EDUs .",Proposed Joint Model,Proposed Joint Model,sentiment_analysis,44,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.09090909090909091,107,0.4863636363636364,2,0.4,1,1,model
109,"Next , we devise three different Recursive Neural Net models , each designed for one of discourse structure prediction , discourse relation prediction and sentiment analysis .",Proposed Joint Model,Proposed Joint Model,sentiment_analysis,44,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",3,0.13636363636363635,108,0.4909090909090909,3,0.6,1,1,model
110,"Finally , we join these Neural Nets in two different ways : Multitasking and Pre-training .",Proposed Joint Model,Proposed Joint Model,sentiment_analysis,44,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'O', 'B-ob', 'O']",4,0.18181818181818182,109,0.4954545454545455,4,0.8,1,1,model
161,All the neural models presented in this paper were implemented using the Tensor Flow python pack - .,Neural Net Models,Training and Evaluating the Models,sentiment_analysis,44,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",32,0.4155844155844156,160,0.7272727272727273,1,0.02857142857142857,1,1,hyperparameters
162,We minimize the crossentropy error using the Adam optimizer and L2regularization on the set of weights .,Neural Net Models,Training and Evaluating the Models,sentiment_analysis,44,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",33,0.42857142857142855,161,0.7318181818181818,2,0.05714285714285714,1,1,hyperparameters
163,"For the individual models ( before joining ) , we use 200 training epochs and a batch size of 100 .",Neural Net Models,Training and Evaluating the Models,sentiment_analysis,44,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",34,0.44155844155844154,162,0.7363636363636363,3,0.08571428571428572,1,1,hyperparameters
169,"From the results , we see some improvement on Discourse Structure prediction when we are using a joint model but the improvement is statistically significant only for the Nuclearity and Relation predictions .",Neural Net Models,Training and Evaluating the Models,sentiment_analysis,44,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",40,0.5194805194805194,168,0.7636363636363637,9,0.2571428571428571,1,1,results
170,"The improvements on the Relation predictions were mainly on the Contrastive set , specifically the class of Contrast , Comparison and Cause relations as .",Neural Net Models,Training and Evaluating the Models,sentiment_analysis,44,"['O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'O', 'O']","['O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O', 'O', 'O']","['O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'O', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O', 'O', 'O']",41,0.5324675324675324,169,0.7681818181818182,10,0.2857142857142857,1,1,results
178,In the fine grained setting we compute the accuracy of exact match across five classes .,Neural Net Models,Training and Evaluating the Models,sentiment_analysis,44,"['B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",49,0.6363636363636364,177,0.8045454545454546,18,0.5142857142857142,1,1,results
2,Utilizing BERT for Aspect - Based Sentiment Analysis via Constructing Auxiliary Sentence,title,title,sentiment_analysis,45,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.006944444444444444,1,0.0,1,1,research-problem
4,"Aspect - based sentiment analysis ( ABSA ) , which aims to identify fine - grained opinion polarity towards a specific aspect , is a challenging subtask of sentiment analysis ( SA ) .",abstract,abstract,sentiment_analysis,45,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.3333333333333333,3,0.020833333333333332,1,0.3333333333333333,1,1,research-problem
16,"Both SA and ABSA are sentence - level or document - level tasks , but one comment may refer to more than one object , and sentence - level tasks can not handle sentences with multiple targets .",Introduction,Introduction,sentiment_analysis,45,"['O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.3333333333333333,15,0.10416666666666667,9,0.3333333333333333,1,1,research-problem
17,"Therefore , introduce the task of targeted aspect - based sentiment analysis ( TABSA ) , which aims to identify fine - grained opinion polarity towards a specific aspect associated with a given target .",Introduction,Introduction,sentiment_analysis,45,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.37037037037037035,16,0.1111111111111111,10,0.37037037037037035,1,1,research-problem
27,"In this paper , we investigate several methods of constructing an auxiliary sentence and transform ( T ) ABSA into a sentence - pair classification task .",Introduction,Introduction,sentiment_analysis,45,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",20,0.7407407407407407,26,0.18055555555555555,20,0.7407407407407407,1,1,approach
28,We fine - tune the pre-trained model from BERT and achieve new state - of - the - art results on ( T ) ABSA task .,Introduction,Introduction,sentiment_analysis,45,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.7777777777777778,27,0.1875,21,0.7777777777777778,1,1,approach
100,We use the pre-trained uncased BERT - base model 5 for fine - tuning .,Hyperparameters,Hyperparameters,sentiment_analysis,45,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.05555555555555555,99,0.6875,1,0.05555555555555555,1,1,hyperparameters
101,"The number of Transformer blocks is 12 , the hidden layer size is 768 , the number of self - attention heads is 12 , and the total number of parameters for the pretrained model is 110M .",Hyperparameters,Hyperparameters,sentiment_analysis,45,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,2,0.1111111111111111,100,0.6944444444444444,2,0.1111111111111111,1,1,hyperparameters
105,"the dropout probability at 0.1 , set the number of epochs to 4 .",Hyperparameters,Hyperparameters,sentiment_analysis,45,"['O', 'B', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",6,0.3333333333333333,104,0.7222222222222222,6,0.3333333333333333,1,1,hyperparameters
106,"The initial learning rate is 2 e - 5 , and the batch size is 24 .",Hyperparameters,Hyperparameters,sentiment_analysis,45,"['O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'O']",,,7,0.3888888888888889,105,0.7291666666666666,7,0.3888888888888889,1,1,hyperparameters
109,LR : a logistic regression classifier with n-gram and pos-tag features .,Hyperparameters,Hyperparameters,sentiment_analysis,45,"['B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.5555555555555556,108,0.75,10,0.5555555555555556,1,1,baselines
110,LSTM - Final ) : a biLSTM model with the final state as a representation .,Hyperparameters,Hyperparameters,sentiment_analysis,45,"['B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.6111111111111112,109,0.7569444444444444,11,0.6111111111111112,1,1,baselines
111,LSTM - Loc ) : a biLSTM model with the state associated with the target position as a representation .,Hyperparameters,Hyperparameters,sentiment_analysis,45,"['B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.6666666666666666,110,0.7638888888888888,12,0.6666666666666666,1,1,baselines
112,LSTM + TA + SA ) : a biLSTM model which introduces complex target - level and sentence - level attention mechanisms .,Hyperparameters,Hyperparameters,sentiment_analysis,45,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.7222222222222222,111,0.7708333333333334,13,0.7222222222222222,1,1,baselines
113,SenticLSTM : an upgraded version of the LSTM + TA + SA model which introduces external information from Sentic - Net .,Hyperparameters,Hyperparameters,sentiment_analysis,45,"['B', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.7777777777777778,112,0.7777777777777778,14,0.7777777777777778,1,1,baselines
114,"Dmu - Entnet : a bidirectional EntNet with external "" memory chains "" with a delayed memory update mechanism to track entities .",Hyperparameters,Hyperparameters,sentiment_analysis,45,"['B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'O']",,,15,0.8333333333333334,113,0.7847222222222222,15,0.8333333333333334,1,1,baselines
120,"We find that BERT - single has achieved better results on these two subtasks , and BERT - pair has achieved further improvements over BERT - single .",Results,Results,sentiment_analysis,45,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']",,,2,0.09523809523809523,119,0.8263888888888888,2,0.2222222222222222,1,1,results
121,The BERT - pair - NLI - B model achieves the best performance for aspect category detection .,Results,Results,sentiment_analysis,45,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.14285714285714285,120,0.8333333333333334,3,0.3333333333333333,1,1,results
122,"For aspect category polarity , BERTpair - QA - B performs best on all 4 - way , 3 - way , and binary settings .",Results,Results,sentiment_analysis,45,"['B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.19047619047619047,121,0.8402777777777778,4,0.4444444444444444,1,1,results
2,A Multi-sentiment - resource Enhanced Attention Network for Sentiment Classification,title,title,sentiment_analysis,46,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.00819672131147541,1,0.0,1,1,research-problem
15,"In this work , we propose a Multi- sentimentresource Enhanced Attention Network ( MEAN ) for sentence - level sentiment classification to integrate many kinds of sentiment linguistic knowledge into deep neural networks via multi -path attention mechanism .",Introduction,Introduction,sentiment_analysis,46,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.4666666666666667,14,0.11475409836065574,7,0.4666666666666667,1,1,model
16,"Specifically , we first design a coupled word embedding module to model the word representation from character - level and word - level semantics .",Introduction,Introduction,sentiment_analysis,46,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.5333333333333333,15,0.12295081967213115,8,0.5333333333333333,1,1,model
18,"Then , we propose a multisentiment - resource attention module to learn more comprehensive and meaningful sentiment - specific sentence representation by using the three types of sentiment resource words as attention sources attending to the context words respectively .",Introduction,Introduction,sentiment_analysis,46,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O']",10,0.6666666666666666,17,0.13934426229508196,10,0.6666666666666666,1,1,model
19,"In this way , we can attend to different sentimentrelevant information from different representation subspaces implied by different types of sentiment sources and capture the over all semantics of the sentiment , negation and intensity words for sentiment prediction .",Introduction,Introduction,sentiment_analysis,46,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.7333333333333333,18,0.14754098360655737,11,0.7333333333333333,1,1,model
90,RNTN : Recursive Tensor Neural Network ) is used to model correlations between different dimensions of child nodes vectors .,Baselines,Baselines,sentiment_analysis,46,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.2222222222222222,89,0.7295081967213115,2,0.2222222222222222,1,1,baselines
91,LSTM / Bi-LSTM : Cho et al. ( 2014 ) employs Long Short - Term Memory and the bidirectional variant to capture sequential information .,Baselines,Baselines,sentiment_analysis,46,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",3,0.3333333333333333,90,0.7377049180327869,3,0.3333333333333333,1,1,baselines
92,"Tree-LSTM : Memory cells was introduced by Tree - Structured Long Short - Term Memory and gates into tree - structured neural network , which is beneficial to capture semantic relatedness by parsing syntax trees .",Baselines,Baselines,sentiment_analysis,46,"['B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.4444444444444444,91,0.7459016393442623,4,0.4444444444444444,1,1,baselines
93,CNN : Convolutional Neural Networks ) is applied to generate task - specific sentence representation .,Baselines,Baselines,sentiment_analysis,46,"['B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.5555555555555556,92,0.7540983606557377,5,0.5555555555555556,1,1,baselines
94,NCSL : designs a Neural Context - Sensitive Lexicon ( NSCL ) to obtain prior sentiment scores of words in the sentence .,Baselines,Baselines,sentiment_analysis,46,"['B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O']","['B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['B-b', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",6,0.6666666666666666,93,0.7622950819672131,6,0.6666666666666666,1,1,baselines
95,LR - Bi-LSTM : imposes linguistic roles into neural networks by applying linguistic regularization on intermediate outputs with KL divergence .,Baselines,Baselines,sentiment_analysis,46,"['B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.7777777777777778,94,0.7704918032786885,7,0.7777777777777778,1,1,baselines
96,Self - attention : proposes a selfattention mechanism to learn structured sentence embedding .,Baselines,Baselines,sentiment_analysis,46,"['B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.8888888888888888,95,0.7786885245901639,8,0.8888888888888888,1,1,baselines
97,ID - LSTM : uses reinforcement learning to learn structured sentence representation for sentiment classification .,Baselines,Baselines,sentiment_analysis,46,"['B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",9,1.0,96,0.7868852459016393,9,1.0,1,1,baselines
99,"In our experiments , the dimensions of characterlevel embedding and word embedding ( Glo Ve ) are both set to 300 .",Implementation Details,Implementation Details,sentiment_analysis,46,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",1,0.1111111111111111,98,0.8032786885245902,1,0.1111111111111111,1,1,hyperparameters
100,"Kernel sizes of multi-gram convolution for Char - CNN are set to 2 , 3 , respectively .",Implementation Details,Implementation Details,sentiment_analysis,46,"['B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",2,0.2222222222222222,99,0.8114754098360656,2,0.2222222222222222,1,1,hyperparameters
101,"All the weight matrices are initialized as random orthogonal matrices , and we set all the bias vectors as zero vectors .",Implementation Details,Implementation Details,sentiment_analysis,46,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",3,0.3333333333333333,100,0.819672131147541,3,0.3333333333333333,1,1,hyperparameters
102,"We optimize the proposed model with RMSprop algorithm , using mini-batch training .",Implementation Details,Implementation Details,sentiment_analysis,46,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",4,0.4444444444444444,101,0.8278688524590164,4,0.4444444444444444,1,1,hyperparameters
103,The size of mini-batch is 60 .,Implementation Details,Implementation Details,sentiment_analysis,46,"['O', 'B', 'B', 'B', 'B', 'B', 'O']","['O', 'B-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O']",5,0.5555555555555556,102,0.8360655737704918,5,0.5555555555555556,1,1,hyperparameters
104,"The dropout rate is 0.5 , and the coefficient ?",Implementation Details,Implementation Details,sentiment_analysis,46,"['O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'B-b', 'O']",6,0.6666666666666666,103,0.8442622950819673,6,0.6666666666666666,1,1,hyperparameters
105,of L 2 normalization is set to 10 ?5 . is set to 10 ? 4 . ?,Implementation Details,Implementation Details,sentiment_analysis,46,"['B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.7777777777777778,104,0.8524590163934426,7,0.7777777777777778,1,1,hyperparameters
112,"First , our model brings a substantial improvement over the methods that do not leverage sentiment linguistic knowledge ( e.g. , RNTN , LSTM , BiLSTM , CNN and ID - LSTM ) on both datasets .",Experiment Results,Experiment Results,sentiment_analysis,46,"['O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.3333333333333333,111,0.9098360655737705,4,0.3333333333333333,1,1,results
114,"Second , our model also consistently outperforms LR - Bi - LSTM which integrates linguistic roles of sentiment , negation and intensity words into neural networks via the linguistic regularization .",Experiment Results,Experiment Results,sentiment_analysis,46,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",6,0.5,113,0.9262295081967213,6,0.5,1,1,results
115,"For example , our model achieves 2.4 % improvements over the MR dataset and 0.8 % improvements over the SST dataset compared to LR - Bi - LSTM .",Experiment Results,Experiment Results,sentiment_analysis,46,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,7,0.5833333333333334,114,0.9344262295081968,7,0.5833333333333334,1,1,results
2,Left - Center - Right Separated Neural Network for Aspect - based Sentiment Analysis with Rotatory Attention,title,title,sentiment_analysis,47,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",1,0.0,1,0.004651162790697674,1,0.0,1,1,research-problem
16,"Aspect - based sentiment analysis is a fine - grained classification task in sentiment analysis , identifying sentiment polarity of a sentence expressed toward a target .",Introduction,Introduction,sentiment_analysis,47,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.02631578947368421,15,0.06976744186046512,1,0.02631578947368421,1,1,research-problem
17,"In the early studies , methods for the aspect - based sentiment classification task were similar as that used in standard sentiment classification task .",Introduction,Introduction,sentiment_analysis,47,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.05263157894736842,16,0.07441860465116279,2,0.05263157894736842,1,1,research-problem
38,"With the attempt to better address the two problems , in this paper we propose a left - center - right separated neural network with rotatory attention mechanism ( LCR - Rot ) .",Introduction,Introduction,sentiment_analysis,47,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",23,0.6052631578947368,37,0.17209302325581396,23,0.6052631578947368,1,1,model
39,"Specifically , we design a left - center - right separated LSTMs that contains three LSTMs , i.e. , left - , center - and right - LSTM , respectively modeling the three parts of a review ( left context , target phrase and right context ) .",Introduction,Introduction,sentiment_analysis,47,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O']",24,0.631578947368421,38,0.17674418604651163,24,0.631578947368421,1,1,model
40,"On this basis , we further propose a rotatory attention mechanism to take into account the interaction between targets and contexts to better represent targets and contexts .",Introduction,Introduction,sentiment_analysis,47,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'O']",,,25,0.6578947368421053,39,0.1813953488372093,25,0.6578947368421053,1,1,model
41,The target2context attention is used to capture the most indicative sentiment words in left / right contexts .,Introduction,Introduction,sentiment_analysis,47,"['O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",26,0.6842105263157895,40,0.18604651162790697,26,0.6842105263157895,1,1,model
42,"Subsequently , the context2target attention is used to capture the most important word in the target .",Introduction,Introduction,sentiment_analysis,47,"['O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",27,0.7105263157894737,41,0.19069767441860466,27,0.7105263157894737,1,1,model
43,This leads to a two - side representation of the target : left - aware target and right - aware target .,Introduction,Introduction,sentiment_analysis,47,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",28,0.7368421052631579,42,0.19534883720930232,28,0.7368421052631579,1,1,model
44,"Finally , we concatenate the component representations as the final representation of the sentence and feed it into a softmax layer to predict the sentiment polarity .",Introduction,Introduction,sentiment_analysis,47,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",29,0.7631578947368421,43,0.2,29,0.7631578947368421,1,1,model
131,"In our work , the dimension of word embedding vectors and hidden state vectors is 300 .",Experimental Setting,Experimental Setting,sentiment_analysis,47,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'O']",5,0.45454545454545453,130,0.6046511627906976,5,0.45454545454545453,1,1,hyperparameters
132,"We use GloVe 2 vectors with 300 dimensions to initialize the word embeddings , the same as .",Experimental Setting,Experimental Setting,sentiment_analysis,47,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",6,0.5454545454545454,131,0.6093023255813953,6,0.5454545454545454,1,1,hyperparameters
133,"All out - ofvocabulary words and weight matrices are randomly initialized by a uniform distribution U ( - 0.1 , 0.1 ) , and all bias are set to zero .",Experimental Setting,Experimental Setting,sentiment_analysis,47,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",7,0.6363636363636364,132,0.6139534883720931,7,0.6363636363636364,1,1,hyperparameters
134,Tensor Flow is used for implementing our neural network model .,Experimental Setting,Experimental Setting,sentiment_analysis,47,"['B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.7272727272727273,133,0.6186046511627907,8,0.7272727272727273,1,1,hyperparameters
135,"In model training , the learning rate is set to 0.1 , the weight for L 2 - norm regularization is set to 1 e - 5 , and dropout rate is set to 0.5 .",Experimental Setting,Experimental Setting,sentiment_analysis,47,"['B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']",,,9,0.8181818181818182,134,0.6232558139534884,9,0.8181818181818182,1,1,hyperparameters
136,We train the model use stochastic gradient descent optimizer with momentum of 0.9 .,Experimental Setting,Experimental Setting,sentiment_analysis,47,"['O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O']",10,0.9090909090909091,135,0.627906976744186,10,0.9090909090909091,1,1,hyperparameters
137,The paired t- test is used for the significance testing .,Experimental Setting,Experimental Setting,sentiment_analysis,47,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",11,1.0,136,0.6325581395348837,11,1.0,1,1,hyperparameters
141,"Majority assigns the sentiment polarity that has the largest probability in the training set ; 2 . Simple SVM is a SVM classifier with simple features such as unigrams and bigrams ; 3 . Feature - enhanced SVM is a SVM classifier with a state - of - the - art feature template which contains n-gram features , parse features and lexicon features ; 4 . LSTM represents a standard LSTM for aspect - based sentiment classification task ; 5 . TD - LSTM adopts two LSTMs to model the left context with target and the right context with target respectively ; 74.30 66.50 66.50 TD- LSTM 75.60 68.10 70.80 AE - LSTM 76.60 68.90 - ATAE - LSTM 77.20 68.70 - GRNN- G3 79.55 * 71.47 * 70.09 * MemNet 79.98 * 70.33 * 70.52 * IAN 78.60 72.10 - LCR - Rot ( our approach ) 81.34 75.24 72.69 : The performance ( classification accuracy ) of different methods on three datasets .",Compared Systems,Compared Systems,sentiment_analysis,47,"['B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,3,0.21428571428571427,140,0.6511627906976745,3,0.21428571428571427,1,1,baselines
143,6 . AE - LSTM is an upgraded version of LSTM .,Compared Systems,Compared Systems,sentiment_analysis,47,"['O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",5,0.35714285714285715,142,0.6604651162790698,5,0.35714285714285715,1,1,baselines
146,7 . ATAE - LSTM is developed based on AE - LSTM .,Compared Systems,Compared Systems,sentiment_analysis,47,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.5714285714285714,145,0.6744186046511628,8,0.5714285714285714,1,1,baselines
148,8 . GRNN - G3 adopts a Gated - RNN to represent sentence and use a three - way structure to leverage contexts .,Compared Systems,Compared Systems,sentiment_analysis,47,"['O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",10,0.7142857142857143,147,0.6837209302325581,10,0.7142857142857143,1,1,baselines
150,MemNet is a deep memory network which considers the content and position of target .,Compared Systems,Compared Systems,sentiment_analysis,47,"['B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",12,0.8571428571428571,149,0.6930232558139535,12,0.8571428571428571,1,1,baselines
152,"IAN interactively learns attentions in the contexts and targets , and generate the representations for targets and contexts separately .",Compared Systems,Compared Systems,sentiment_analysis,47,"['B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O']","['B-n', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O']","['B-b', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",14,1.0,151,0.7023255813953488,14,1.0,1,1,baselines
155,"We can find that the Majority method is the worst , which means the majority sentiment polarity occupies 53.50 % , 65.00 % and 50 % of all samples on the Restaurant , Laptop and Twitter testing datasets respectively .",System Performance Comparison,System Performance Comparison,sentiment_analysis,47,"['O', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",2,0.03508771929824561,154,0.7162790697674418,2,0.125,1,1,results
156,The Simple SVM model performs better than Majority .,System Performance Comparison,System Performance Comparison,sentiment_analysis,47,"['O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'O']",3,0.05263157894736842,155,0.7209302325581395,3,0.1875,1,1,results
157,"With the help of feature engineering , the Feature - enhanced SVM achieves much better results .",System Performance Comparison,System Performance Comparison,sentiment_analysis,47,"['B', 'I', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.07017543859649122,156,0.7255813953488373,4,0.25,1,1,results
159,Our model achieves significantly better results than feature - enhanced SVM .,System Performance Comparison,System Performance Comparison,sentiment_analysis,47,"['B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.10526315789473684,158,0.7348837209302326,6,0.375,1,1,results
161,"Among LSTM based neural networks described in this paper , the basic LSTM approach performs the worst .",System Performance Comparison,System Performance Comparison,sentiment_analysis,47,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",8,0.14035087719298245,160,0.7441860465116279,8,0.5,1,1,results
162,TD - LSTM obtains an improvement of 1 - 2 % over LSTM when target signals are taken into consideration .,System Performance Comparison,System Performance Comparison,sentiment_analysis,47,"['B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",9,0.15789473684210525,161,0.7488372093023256,9,0.5625,1,1,results
165,"MemNet achieves better results than other models on the Restaurant dataset , since it considers not only the contexts of targets but also the position of each context word related to the target .",System Performance Comparison,System Performance Comparison,sentiment_analysis,47,"['B', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.21052631578947367,164,0.7627906976744186,12,0.75,1,1,results
166,IAN considers separate representations of targets and obtains better result on the Laptop dataset .,System Performance Comparison,System Performance Comparison,sentiment_analysis,47,"['B', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",13,0.22807017543859648,165,0.7674418604651163,13,0.8125,1,1,results
167,GRNN - G3 achieves competitive results on all datasets because of its three - way structure and special gated - RNN model .,System Performance Comparison,System Performance Comparison,sentiment_analysis,47,"['B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.24561403508771928,166,0.772093023255814,14,0.875,1,1,results
168,"In the contrast , our LCR - Rot model achieves the best results on the all datasets among all models .",System Performance Comparison,System Performance Comparison,sentiment_analysis,47,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",15,0.2631578947368421,167,0.7767441860465116,15,0.9375,1,1,results
2,Variational Semi-supervised Aspect - term Sentiment Analysis via Transformer,title,title,sentiment_analysis,48,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",1,0.0,1,0.00423728813559322,1,0.0,1,1,research-problem
13,"Aspect based sentiment analysis ( ABSA ) has two sub - tasks , namely aspect - term sentiment analysis ( ATSA ) and aspect - category sentiment analysis ( ACSA ) .",Introduction,Introduction,sentiment_analysis,48,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.03125,12,0.05084745762711865,1,0.03125,1,1,research-problem
14,"ACSA is to infer the sentiment polarity with regard to the predefined categories , e.g. , the aspect food , price , ambience .",Introduction,Introduction,sentiment_analysis,48,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.0625,13,0.05508474576271186,2,0.0625,1,1,research-problem
15,"On the other hand , ATSA aims at classifying the sentiment polarity of a given aspect word or phrase in the text .",Introduction,Introduction,sentiment_analysis,48,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.09375,14,0.059322033898305086,3,0.09375,1,1,research-problem
29,"In this paper , we proposed a classifier - agnostic framework which named Aspect - term Semi-supervised Variational Autoencoder ( Kingma and Welling , 2014 ) based on Transformer ( ASVAET ) .",Introduction,Introduction,sentiment_analysis,48,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.53125,28,0.11864406779661017,17,0.53125,1,1,model
30,The variational autoencoder offers the flexibility to customize the model structure .,Introduction,Introduction,sentiment_analysis,48,"['O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",18,0.5625,29,0.1228813559322034,18,0.5625,1,1,model
33,"By regarding the aspect sentiment polarity of the unlabeled data as the discrete latent variable , the model implicitly induces the sentiment polarity via the variational inference .",Introduction,Introduction,sentiment_analysis,48,"['B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",21,0.65625,32,0.13559322033898305,21,0.65625,1,1,model
34,"Specifically , the representation of the lexical context is extracted by the encoder and the aspect - term sentiment polarity is inferred from the specific ATSA classifier .",Introduction,Introduction,sentiment_analysis,48,"['O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",22,0.6875,33,0.13983050847457626,22,0.6875,1,1,model
38,"In addition , by separating the representation of the input sentence , the classifier becomes an independent module in our framework , which endows the method with the ability to integrate different classifiers .",Introduction,Introduction,sentiment_analysis,48,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",26,0.8125,37,0.15677966101694915,26,0.8125,1,1,model
151,"The number of units in the encoder and the decoder is 100 and the latent variable is of size 50 and the number of layers of both Transformer blocks is 2 , the number of selfattention heads is 8 .",Model Configuration & Classifiers,Model Configuration & Classifiers,sentiment_analysis,48,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O']",,,2,0.06451612903225806,150,0.635593220338983,2,0.06451612903225806,1,1,hyperparameters
158,"In this work , the KL weight is set to be 1e - 4 .",Model Configuration & Classifiers,Model Configuration & Classifiers,sentiment_analysis,48,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.2903225806451613,157,0.6652542372881356,9,0.2903225806451613,1,1,hyperparameters
164,"TC - LSTM : Two LSTMs are used to model the left and right context of the target separately , then the concatenation of two representations is used to predict the label .",Model Configuration & Classifiers,Model Configuration & Classifiers,sentiment_analysis,48,"['B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O']",,,15,0.4838709677419355,163,0.690677966101695,15,0.4838709677419355,1,1,baselines
165,"MemNet : It uses the attention mechanism over the word embedding over multiple rounds to aggregate the information in the sentence , the vector of the final round is used for the prediction .",Model Configuration & Classifiers,Model Configuration & Classifiers,sentiment_analysis,48,"['B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,16,0.5161290322580645,164,0.6949152542372882,16,0.5161290322580645,1,1,baselines
166,IAN : IAN adopts two LSTMs to derive the representations of the context and the target phrase interactively and the concatenation is fed to the softmax layer .,Model Configuration & Classifiers,Model Configuration & Classifiers,sentiment_analysis,48,"['B', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",17,0.5483870967741935,165,0.6991525423728814,17,0.5483870967741935,1,1,baselines
168,BILSTM - ATT -G : It models left and right contexts using two attention - based LSTMs and makes use of a special gate layer to combine these two representations .,Model Configuration & Classifiers,Model Configuration & Classifiers,sentiment_analysis,48,"['B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",19,0.6129032258064516,167,0.7076271186440678,19,0.6129032258064516,1,1,baselines
170,"TNet - AS : Without using an attention module , TNet adopts a convolutional layer to get salient features from the transformed word representations originated from a bidirectional LSTM layer .",Model Configuration & Classifiers,Model Configuration & Classifiers,sentiment_analysis,48,"['B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.6774193548387096,169,0.7161016949152542,21,0.6774193548387096,1,1,baselines
197,"From the , the ASVAET is able to improve supervised performance consistently for all classifiers .",Main Results,Main Results,sentiment_analysis,48,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",16,0.7619047619047619,196,0.8305084745762712,16,0.7619047619047619,1,1,results
198,"For the MemNet , the test accuracy can be improved by about 2 % by the TSSVAE , and so as the Macro - averaged F1 .",Main Results,Main Results,sentiment_analysis,48,"['B', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.8095238095238095,197,0.8347457627118644,17,0.8095238095238095,1,1,results
199,The TNet - AS outperforms the other three models .,Main Results,Main Results,sentiment_analysis,48,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",18,0.8571428571428571,198,0.8389830508474576,18,0.8571428571428571,1,1,results
200,"Compared with the other two semi-supervised methods , the ASVAET also shows better results .",Main Results,Main Results,sentiment_analysis,48,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",19,0.9047619047619048,199,0.8432203389830508,19,0.9047619047619048,1,1,results
201,The ASVAET outperforms the compared semisupervised methods evidently .,Main Results,Main Results,sentiment_analysis,48,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",20,0.9523809523809523,200,0.847457627118644,20,0.9523809523809523,1,1,results
202,The adoption of indomain pre-trained word vectors is beneficial for the performance compared with the Glove vectors .,Main Results,Main Results,sentiment_analysis,48,"['O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",21,1.0,201,0.8516949152542372,21,1.0,1,1,results
2,Contextual Inter-modal Attention for Multi-modal Sentiment Analysis,title,,sentiment_analysis,49,"['O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.003952569169960474,1,0.0,1,1,research-problem
12,"Traditionally , sentiment analysis has been applied to a wide variety of texts .",Introduction,Introduction,sentiment_analysis,49,"['O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.03125,11,0.043478260869565216,1,0.03125,1,1,research-problem
26,"In this paper , we propose a novel method that employs a recurrent neural network based multimodal multi-utterance attention framework for sentiment prediction .",Introduction,Introduction,sentiment_analysis,49,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",15,0.46875,25,0.09881422924901186,15,0.46875,1,1,model
31,To better address these concerns we propose a novel fusion method by focusing on inter-modality relations computed between the target utterance and its context .,Introduction,Introduction,sentiment_analysis,49,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",20,0.625,30,0.11857707509881422,20,0.625,1,1,model
37,The attention mechanism is then used to attend to the important contextual utterances having higher relatedness or similarity ( computed using inter-modality correlations ) with the target utterance .,Introduction,Think of an utterance,sentiment_analysis,49,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",26,0.8125,36,0.1422924901185771,26,0.8125,1,1,model
38,"Unlike previous approaches that simply apply attentions over the contextual utterance for classification , we attend over the contextual utterances by computing correlations among the modalities of the target utterance and the context utterances .",Introduction,Think of an utterance,sentiment_analysis,49,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,0.84375,37,0.14624505928853754,27,0.84375,1,1,model
40,The model facilitates this modality selection by attending over the contextual utterances and thus generates better multimodal feature representation when these modalities from the context are combined with the modalities of the target utterance .,Introduction,Think of an utterance,sentiment_analysis,49,"['O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",29,0.90625,39,0.1541501976284585,29,0.90625,1,1,model
149,"We use Bi-directional GRUs having 300 neurons , each followed by a dense layer consisting of 100 neurons .",Experiments,Experiments,sentiment_analysis,49,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",4,0.044444444444444446,148,0.5849802371541502,4,0.2,1,1,hyperparameters
150,"Utilizing the dense layer , we project the input features of all the three modalities to the same dimensions .",Experiments,Experiments,sentiment_analysis,49,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.05555555555555555,149,0.5889328063241107,5,0.25,1,1,hyperparameters
151,We set dropout = 0.5 ( MOSI ) & 0.3 ( MOSEI ) as a measure of regularization .,Experiments,Experiments,sentiment_analysis,49,"['O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'O']","['O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'O']",6,0.06666666666666667,150,0.5928853754940712,6,0.3,1,1,hyperparameters
152,"In addition , we also use dropout = 0.4 ( MOSI ) & 0.3 ( MOSEI ) for the Bi - GRU layers .",Experiments,Experiments,sentiment_analysis,49,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']",,,7,0.07777777777777778,151,0.5968379446640316,7,0.35,1,1,hyperparameters
153,"We employ ReLu activation function in the dense layers , and softmax activation in the final classification layer .",Experiments,Experiments,sentiment_analysis,49,"['O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']",,,8,0.08888888888888889,152,0.6007905138339921,8,0.4,1,1,hyperparameters
154,"For training the network we set the batch size = 32 , use Adam optimizer with cross - entropy loss function and train for 50 epochs .",Experiments,Experiments,sentiment_analysis,49,"['B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",9,0.1,153,0.6047430830039525,9,0.45,1,1,hyperparameters
158,"For MOSEI dataset , we obtain better performance with text .",Experiments,Experiments,sentiment_analysis,49,"['B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",13,0.14444444444444443,157,0.6205533596837944,13,0.65,1,1,results
160,"For text - acoustic input pairs , we obtain the highest accuracies with 79. 74 % , 79.60 % and 79.32 % for MMMU - BA , MMUU - SA and MU - SA frameworks , respectively .",Experiments,Experiments,sentiment_analysis,49,"['O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",15,0.16666666666666666,159,0.6284584980237155,15,0.75,1,1,results
162,"Finally , we experiment with tri-modal inputs and observe an improved performance of 79. 80 % , 79.76 % and 79.63 % for MMMU - BA , MMUU - SA and MU - SA frameworks , respectively .",Experiments,Experiments,sentiment_analysis,49,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",17,0.18888888888888888,161,0.6363636363636364,17,0.85,1,1,results
164,The performance improvement was also found to be statistically significant ( T-test ) than the bimodality and uni-modality inputs .,Experiments,Experiments,sentiment_analysis,49,"['O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.2111111111111111,163,0.6442687747035574,19,0.95,1,1,results
165,"Further , we observe that the MMMU - BA framework reports the best accuracy of 79 . 80 % for the MOSEI dataset , thus supporting our claim that multi-modal attention framework ( i.e. MMMU - BA ) captures more information than the self - attention frameworks ( i.e. MMUU - SA & MU - SA ) .",Experiments,Experiments,sentiment_analysis,49,"['O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.2222222222222222,164,0.6482213438735178,20,1.0,1,1,results
2,A Novel Bi-hemispheric Discrepancy Model for EEG Emotion Recognition,title,title,sentiment_analysis,5,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0037735849056603774,1,0.0,1,1,research-problem
5,"Inspired by this study , in this paper , we propose a novel bi-hemispheric discrepancy model ( BiHDM ) to learn the asymmetric differences between two hemispheres for electroencephalograph ( EEG ) emotion recognition .",abstract,abstract,sentiment_analysis,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.3333333333333333,4,0.01509433962264151,2,0.01015228426395939,1,1,research-problem
13,"As the first step to make machines capture human emotions , emotion recognition has received substantial attention from human - machine - interaction ( HMI ) and pattern recognition research communities in recent years , , .",I. INTRODUCTION,I. INTRODUCTION,sentiment_analysis,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.05555555555555555,12,0.045283018867924525,10,0.050761421319796954,1,1,research-problem
43,"Thus , in this paper , we propose a novel neural network model BiHDM to learn the bi-hemispheric discrepancy for EEG emotion recognition .",I. INTRODUCTION,Li et al.,sentiment_analysis,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",33,0.6111111111111112,42,0.15849056603773584,40,0.20304568527918782,1,1,model
44,"BiHDM aims to obtain the deep discrepant features between the left and right hemispheres , which is expected to contain more discriminative information to recognize the EEG emotion signals .",I. INTRODUCTION,Li et al.,sentiment_analysis,5,"['B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",34,0.6296296296296297,43,0.16226415094339622,41,0.20812182741116753,1,1,model
47,"Hence , to avoid losing this intrinsic graph structural information of EEG data , we can simplify the graph structure learning process by using the horizontal and vertical traversing RNNs , which will construct a complete relationship graph and generate discriminative deep features for all the EEG electrodes .",I. INTRODUCTION,Li et al.,sentiment_analysis,5,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",37,0.6851851851851852,46,0.17358490566037735,44,0.2233502538071066,1,1,model
48,"After obtaining these deep features of each electrodes , we can extract the asymmetric discrepancy information between two hemispheres by performing specific pairwise operations for any paired symmetric electrodes .",I. INTRODUCTION,Li et al.,sentiment_analysis,5,"['B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",38,0.7037037037037037,47,0.17735849056603772,45,0.22842639593908629,1,1,model
158,"We use the released handcrafted features , i.e. , the differential entropy ( DE ) in SEED and SEED - IV , and the Short - Time Fourier Transform ( STFT ) in MPED , as the input to feed our model .",EXPERIMENTS,There are totally 3360 samples in one subject .,sentiment_analysis,5,"['O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O']",,,22,0.1774193548387097,157,0.5924528301886792,155,0.7868020304568528,1,1,experimental-setup
159,"Thus the sizes d N of the input sample X t are 5 62 , 5 62 and 1 62 for these three datasets , respectively .",EXPERIMENTS,There are totally 3360 samples in one subject .,sentiment_analysis,5,"['O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",23,0.18548387096774194,158,0.5962264150943396,156,0.7918781725888325,1,1,experimental-setup
160,"Moreover , in the experiment , we respectively set the dimension d l of each electrode 's deep representation to 32 ; the parameters d g and K of the global high - level feature to 32 and 6 ; and the dimension do of the output feature to 16 without elaborate traversal .",EXPERIMENTS,There are totally 3360 samples in one subject .,sentiment_analysis,5,"['O', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O']",,,24,0.1935483870967742,159,0.6,157,0.7969543147208121,1,1,experimental-setup
161,"Specifically , we implemented BiHDM using Tensor Flow on one Nvidia 1080 Ti GPU .",EXPERIMENTS,There are totally 3360 samples in one subject .,sentiment_analysis,5,"['O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",25,0.20161290322580644,160,0.6037735849056604,158,0.8020304568527918,1,1,experimental-setup
162,"The learning rate , momentum and weight decay rate are set as 0.003 , 0.9 and 0.95 respectively .",EXPERIMENTS,There are totally 3360 samples in one subject .,sentiment_analysis,5,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",26,0.20967741935483872,161,0.6075471698113207,159,0.8071065989847716,1,1,experimental-setup
163,The network is trained using SGD with batch size of 200 .,EXPERIMENTS,There are totally 3360 samples in one subject .,sentiment_analysis,5,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'B', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",27,0.21774193548387097,162,0.6113207547169811,160,0.8121827411167513,1,1,experimental-setup
164,"In addition , we adopt the subtraction as the pairwise operation of the BiHDM model in the experiment section , and discuss the other two types of operations in section III - D.",EXPERIMENTS,There are totally 3360 samples in one subject .,sentiment_analysis,5,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",28,0.22580645161290322,163,0.6150943396226415,161,0.817258883248731,1,1,experimental-setup
167,1 ) The subject - dependent experiment :,EXPERIMENTS,The EEG emotion recognition experiments,sentiment_analysis,5,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",31,0.25,166,0.6264150943396226,164,0.8324873096446701,1,1,experiments
171,"To validate the superiority of BiHDM , we also conduct the same experiments using twelve methods , including linear support vector machine ( SVM ) , random forest ( RF ) , canonical correlation analysis ( CCA ) , group sparse canonical correlation analysis ( GSCCA ) , deep believe network ( DBN ) , graph regularization sparse linear regression ( GRSLR ) , graph convolutional neural network ( GCNN ) , dynamical graph convolutional neural network ( DGCNN ) , domain adversarial neural networks ( DANN ) , bi-hemisphere domain adversarial neural network ( BiDANN ) , EmotionMeter , and attention - long short - term memory ( A - LSTM ) .",EXPERIMENTS,The EEG emotion recognition experiments,sentiment_analysis,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",35,0.28225806451612906,170,0.6415094339622641,168,0.8527918781725888,1,1,experiments
175,"From , we can see that the proposed BiHDM model outperforms all the compared methods on all the three public EEG emotional datasets , which verifies the effectiveness of BiHDM .",EXPERIMENTS,The results are summarized in .,sentiment_analysis,5,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",39,0.31451612903225806,174,0.6566037735849056,172,0.8730964467005076,1,1,experiments
176,"Especially for the result on SEED - IV , the proposed method improves over the state - of - the - art method Emotion - Meter by 4 % .",EXPERIMENTS,The results are summarized in .,sentiment_analysis,5,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",40,0.3225806451612903,175,0.660377358490566,173,0.8781725888324873,1,1,experiments
177,"Besides , we can see that the compared method BiDANN , which also considers the bi-hemispheric asymmetry , achieves a comparable performance .",EXPERIMENTS,The results are summarized in .,sentiment_analysis,5,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",41,0.33064516129032256,176,0.6641509433962264,174,0.883248730964467,1,1,experiments
183,"shows the t- test statistical analysis results , from which we can see BiHDM is significantly better than the baseline method .",EXPERIMENTS,The results are summarized in .,sentiment_analysis,5,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",47,0.3790322580645161,182,0.6867924528301886,180,0.9137055837563451,1,1,experiments
188,2 ) The subject - independent experiment :,EXPERIMENTS,The results are summarized in .,sentiment_analysis,5,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",52,0.41935483870967744,187,0.7056603773584905,185,0.9390862944162437,1,1,experiments
193,"In addition , for comparison purpose , we use twelve methods including Kullback - Leibler importance estimation procedure ( KLIEP ) , unconstrained least - squares importance fitting ( ULSIF ) , selective transfer machine ( STM ) , linear SVM , transfer component analysis ( TCA ) , transfer component analysis ( TCA ) , geodesic flow kernel ( GFK ) , DANN , DGCNN , deep adaptation network ( DAN ) , BiDANN , and A - LSTM , to conduct the same experiments .",EXPERIMENTS,The results are summarized in .,sentiment_analysis,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",57,0.4596774193548387,192,0.7245283018867924,190,0.9644670050761421,1,1,experiments
197,"The results are shown in From , it can be clearly seen that the proposed BiHDM method achieves the best performance in the three public datasets , which verifies the effectiveness of BiHDM in dealing with subject - independent EEG emotion recognition .",EXPERIMENTS,The results are summarized in .,sentiment_analysis,5,"['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",61,0.49193548387096775,196,0.7396226415094339,194,0.9847715736040609,1,1,experiments
198,"For the three datasets , the improvements on accuracy are 2.2 % , 3.5 % and 2.4 % , respectively , when compared with the existing state - of - the - art methods .",EXPERIMENTS,The results are summarized in .,sentiment_analysis,5,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",62,0.5,197,0.7433962264150943,195,0.9898477157360406,1,1,experiments
200,"shows the t- test statistical analysis results , from which we can see BiHDM is significantly better than the baseline method .",EXPERIMENTS,The results are summarized in .,sentiment_analysis,5,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,64,0.5161290322580645,199,0.7509433962264151,197,1.0,1,1,experiments
2,Exploiting Document Knowledge for Aspect - level Sentiment Classification,title,,sentiment_analysis,50,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.006172839506172839,1,0.0,1,1,research-problem
21,"Specifically , we explore two transfer methods to incorporate this sort of knowledge - pretraining and multi-task learning .",Introduction,Introduction,sentiment_analysis,50,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'O', 'B-b', 'O', 'B-ob', 'O', 'B-ob', 'I-ob', 'O']",13,0.8125,20,0.12345679012345678,13,0.8125,1,1,model
24,Our source code can be obtained from https://github.com/ruidan/Aspect-level-sentiment.,Introduction,Introduction,sentiment_analysis,50,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,1.0,23,0.1419753086419753,16,1.0,1,1,code
87,"In all experiments , 300 - dimension Glo Ve vectors are used to initialize E and E when pretraining is not conducted for weight initialization .",Datasets and Experimental Settings,Datasets and Experimental Settings,sentiment_analysis,50,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",10,0.47619047619047616,86,0.5308641975308642,10,0.47619047619047616,1,1,hyperparameters
88,These vectors are also used for initializing E in the pretraining phase .,Datasets and Experimental Settings,Datasets and Experimental Settings,sentiment_analysis,50,"['O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",11,0.5238095238095238,87,0.5370370370370371,11,0.5238095238095238,1,1,hyperparameters
90,We randomly sample 20 % of the original training data from the aspectlevel dataset as the development set and only use the remaining 80 % for training .,Datasets and Experimental Settings,Datasets and Experimental Settings,sentiment_analysis,50,"['O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.6190476190476191,89,0.5493827160493827,13,0.6190476190476191,1,1,hyperparameters
91,"For all experiments , the dimension of LSTM hidden vectors is set to 300 , ?",Datasets and Experimental Settings,Datasets and Experimental Settings,sentiment_analysis,50,"['B', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O']",14,0.6666666666666666,90,0.5555555555555556,14,0.6666666666666666,1,1,hyperparameters
92,"is set to 0.1 , and we use dropout with probability 0.5 on sentence / document representations before the output layer .",Datasets and Experimental Settings,Datasets and Experimental Settings,sentiment_analysis,50,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",15,0.7142857142857143,91,0.5617283950617284,15,0.7142857142857143,1,1,hyperparameters
93,We use RMSProp as the optimizer with the decay rate set to 0.9 and the base learning rate set to 0.001 .,Datasets and Experimental Settings,Datasets and Experimental Settings,sentiment_analysis,50,"['O', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O']",,,16,0.7619047619047619,92,0.5679012345679012,16,0.7619047619047619,1,1,hyperparameters
94,The mini - batch size is set to 32 .,Datasets and Experimental Settings,Datasets and Experimental Settings,sentiment_analysis,50,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",17,0.8095238095238095,93,0.5740740740740741,17,0.8095238095238095,1,1,hyperparameters
100,"We observe that PRET is very helpful , and consistently gives a 1 - 3 % increase in accuracy over LSTM + ATT across all datasets .",Model Comparison,Model Comparison,sentiment_analysis,50,"['O', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.07142857142857142,99,0.6111111111111112,1,0.07142857142857142,1,1,results
102,"MULT gives similar performance as LSTM + ATT on D1 and D2 , but improvements can be clearly observed for D3 and D4 .",Model Comparison,Model Comparison,sentiment_analysis,50,"['B', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.21428571428571427,101,0.6234567901234568,3,0.21428571428571427,1,1,results
103,The combination ( PRET + MULT ) over all yields better results .,Model Comparison,Model Comparison,sentiment_analysis,50,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",4,0.2857142857142857,102,0.6296296296296297,4,0.2857142857142857,1,1,results
105,( 2 ) The numbers of neutral examples in the test sets of D3 and D4 are very small .,Model Comparison,Model Comparison,sentiment_analysis,50,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'O']",6,0.42857142857142855,104,0.6419753086419753,6,0.42857142857142855,1,1,results
115,"( 2 ) Overall , transfers of the LSTM and embedding layer are more useful than the output layer .",Ablation Tests,Ablation Tests,sentiment_analysis,50,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",1,0.023255813953488372,114,0.7037037037037037,1,0.14285714285714285,1,1,ablation-analysis
117,( 3 ) Transfer of the embedding layer is more helpful on D3 and D4 .,Ablation Tests,Ablation Tests,sentiment_analysis,50,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.06976744186046512,116,0.7160493827160493,3,0.42857142857142855,1,1,ablation-analysis
119,Sentiment information is not adequately captured by Glo Ve word embeddings .,Ablation Tests,Ablation Tests,sentiment_analysis,50,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.11627906976744186,118,0.7283950617283951,5,0.7142857142857143,1,1,ablation-analysis
2,Fine - grained Sentiment Classification using BERT,title,title,sentiment_analysis,51,"['B', 'I', 'I', 'I', 'I', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",1,0.0,1,0.006666666666666667,1,0.0,1,1,research-problem
4,"Sentiment classification is an important process in understanding people 's perception towards a product , service , or topic .",abstract,abstract,sentiment_analysis,51,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.16666666666666666,3,0.02,1,0.013157894736842105,1,1,research-problem
22,"In this paper , we use the pretrained BERT model and finetune it for the fine - grained sentiment classification task on the Stanford Sentiment Treebank ( SST ) dataset .",I. INTRODUCTION,I. INTRODUCTION,sentiment_analysis,51,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.1875,21,0.14,19,0.25,1,1,model
127,1 ) Word embeddings :,A. Comparison Models,A. Comparison Models,sentiment_analysis,51,"['O', 'O', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O']",1,0.1,126,0.84,21,0.7,1,1,baselines
128,"In this method , the word vectors pretrained on large text corpus such as Wikipedia dump are averaged to get the document vector , which is then fed to the sentiment classifier to compute the sentiment score .",A. Comparison Models,A. Comparison Models,sentiment_analysis,51,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",2,0.2,127,0.8466666666666667,22,0.7333333333333333,1,1,baselines
129,2 ) Recursive networks :,A. Comparison Models,A. Comparison Models,sentiment_analysis,51,"['O', 'O', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O']",3,0.3,128,0.8533333333333334,23,0.7666666666666667,1,1,baselines
130,Various types of recursive neural networks ( RNN ) have been applied on SST .,A. Comparison Models,A. Comparison Models,sentiment_analysis,51,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",4,0.4,129,0.86,24,0.8,1,1,baselines
133,3 ) Recurrent networks :,A. Comparison Models,A. Comparison Models,sentiment_analysis,51,"['O', 'O', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O']",7,0.7,132,0.88,27,0.9,1,1,baselines
134,Sophisticated recurrent networks such as left - to - right and bidrectional LSTM networks have also been applied on SST .,A. Comparison Models,A. Comparison Models,sentiment_analysis,51,"['B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",8,0.8,133,0.8866666666666667,28,0.9333333333333333,1,1,baselines
135,4 ) Convolutional networks :,A. Comparison Models,A. Comparison Models,sentiment_analysis,51,"['O', 'O', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O']",9,0.9,134,0.8933333333333333,29,0.9666666666666667,1,1,baselines
136,"In this approach , the input sequences were passed through a 1 - dimensional convolutional neural network as feature extractors .",A. Comparison Models,A. Comparison Models,sentiment_analysis,51,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",10,1.0,135,0.9,30,1.0,1,1,baselines
145,"We can see that our model , despite being a simple architecture , performs better in terms of accuracy than many popular and sophisticated NLP models .",C. Results,C. Results,sentiment_analysis,51,"['O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.8,144,0.96,4,0.4444444444444444,1,1,results
2,Context - Dependent Sentiment Analysis in User- Generated Videos,title,,sentiment_analysis,6,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.0034602076124567475,1,0.0,1,1,research-problem
4,"Multimodal sentiment analysis is a developing area of research , which involves the identification of sentiments in videos .",abstract,abstract,sentiment_analysis,6,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.25,3,0.010380622837370242,1,0.25,1,1,research-problem
9,"Sentiment analysis is a ' suitcase ' research problem that requires tackling many NLP sub - tasks , e.g. , aspect extraction , named entity recognition , concept extraction , sarcasm detection , personality recognition , and more .",Introduction,Introduction,sentiment_analysis,6,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.02857142857142857,8,0.02768166089965398,1,0.02857142857142857,1,1,research-problem
11,"Emotion recognition further breaks down the inferred polarity into a set of emotions conveyed by the subjective data , e.g. , positive sentiment can be caused by joy or anticipation , while negative sentiment can be caused by fear or disgust .",Introduction,Introduction,sentiment_analysis,6,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.08571428571428572,10,0.03460207612456748,3,0.08571428571428572,1,1,research-problem
22,"Recently , a number of approaches to multimodal sentiment analysis , producing interesting results , have been proposed .",Introduction,Introduction,sentiment_analysis,6,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.4,21,0.0726643598615917,14,0.4,1,1,research-problem
36,"In this paper , we discard such an oversimplifying hypothesis and develop a framework based on long shortterm memory ( LSTM ) that takes a sequence of utterances as input and extracts contextual utterancelevel features .",Introduction,Introduction,sentiment_analysis,6,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",28,0.8,35,0.12110726643598616,28,0.8,1,1,model
40,"Our model preserves the sequential order of utterances and enables consecutive utterances to share information , thus providing contextual information to the utterance - level sentiment classification process .",Introduction,Introduction,sentiment_analysis,6,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",32,0.9142857142857143,39,0.13494809688581316,32,0.9142857142857143,1,1,model
237,"As expected , trained contextual unimodal features help the hierarchical fusion framework to outperform the non-hierarchical framework .",Performance of Different Models,Performance of Different Models,sentiment_analysis,6,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",3,0.09375,236,0.8166089965397924,3,0.5,1,1,results
240,"The non-hierarchical model outperforms the baseline uni - SVM , which confirms that it is the contextsensitive learning paradigm that plays the key role in improving performance over the baseline .",Performance of Different Models,Performance of Different Models,sentiment_analysis,6,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.1875,239,0.8269896193771626,6,1.0,1,1,results
242,It is to be noted that both sc - LSTM and bc - LSTM perform quite well on the multimodal emotion recognition and sentiment analysis datasets .,Performance of Different Models,Comparison of Different Network Variants,sentiment_analysis,6,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.25,241,0.8339100346020761,1,0.06666666666666667,1,1,results
243,"Since bc - LSTM has access to both the preceding and following information of the utterance sequence , it performs consistently better on all the datasets over sc - LSTM .",Performance of Different Models,Comparison of Different Network Variants,sentiment_analysis,6,"['O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.28125,242,0.8373702422145328,2,0.13333333333333333,1,1,results
245,The performance improvement is in the range of 0.3 % to 1.5 % on MOSI and MOUD datasets .,Performance of Different Models,Comparison of Different Network Variants,sentiment_analysis,6,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.34375,244,0.8442906574394463,4,0.26666666666666666,1,1,results
246,"On the IEMOCAP dataset , the performance improvement of bc - LSTM and sc - LSTM over h- LSTM is in the range of 1 % to 5 % .",Performance of Different Models,Comparison of Different Network Variants,sentiment_analysis,6,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.375,245,0.8477508650519031,5,0.3333333333333333,1,1,results
248,Every LSTM network variant has outperformed the baseline uni - SVM on all the datasets by the margin of 2 % to 5 % ( see ) .,Performance of Different Models,Comparison with the Baselines ,sentiment_analysis,6,"['B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",14,0.4375,247,0.8546712802768166,7,0.4666666666666667,1,1,results
255,Experimental results in show that the proposed method outperformes by a significant margin .,Performance of Different Models,Comparison with the Baselines ,sentiment_analysis,6,"['O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",21,0.65625,254,0.8788927335640139,14,0.9333333333333333,1,1,results
2,MULTI - MODAL EMOTION RECOGNITION ON IEMOCAP WITH NEURAL NETWORKS,title,title,sentiment_analysis,7,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.009433962264150943,1,0.0,1,1,research-problem
4,Emotion recognition has become an important field of research in human computer interactions and there is a growing need for automatic emotion recognition systems .,abstract,abstract,sentiment_analysis,7,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.25,3,0.02830188679245283,1,0.25,1,1,research-problem
15,We explore various deep learning based architectures to first get the best individual detection accuracy from each of the different modes .,INTRODUCTION,INTRODUCTION,sentiment_analysis,7,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.10294117647058823,14,0.1320754716981132,7,0.4375,1,1,approach
16,We then combine them in an ensemble based architecture to allow for training across the different modalities using the variations of the better individual models .,INTRODUCTION,INTRODUCTION,sentiment_analysis,7,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.11764705882352941,15,0.14150943396226415,8,0.5,1,1,approach
17,"Our ensemble consists of Long Short Term Memory networks , Convolution Neural Networks , fully connected Multi - Layer Perceptrons and we complement them using techniques such as Dropout , adaptive optimizers such as Adam , pretrained word - embedding models and Attention based RNN decoders .",INTRODUCTION,INTRODUCTION,sentiment_analysis,7,"['B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-p', 'I-p', 'B-ob', 'O', 'B-b', 'I-b', 'O', 'O', 'B-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.1323529411764706,16,0.1509433962264151,9,0.5625,1,1,approach
18,This allows us to individually target each modality and only perform feature fusion at the final stage .,INTRODUCTION,INTRODUCTION,sentiment_analysis,7,"['O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",10,0.14705882352941177,17,0.16037735849056603,10,0.625,1,1,approach
64,"For the text transcript of each of the utterance we use pretrained Glove embeddings of dimension 300 , along with the maximum sequence length of 500 to obtain a ( 500,300 ) vector for each utterance .",INTRODUCTION,INTRODUCTION,sentiment_analysis,7,"['O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']",,,56,0.8235294117647058,63,0.5943396226415094,19,0.6129032258064516,1,1,hyperparameters
65,"For the Mocap data , for each different mode such as face , hand , head rotation we sample all the feature values between the start and finish time values and split them into 200 partitioned arrays .",INTRODUCTION,INTRODUCTION,sentiment_analysis,7,"['B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",57,0.8382352941176471,64,0.6037735849056604,20,0.6451612903225806,1,1,hyperparameters
66,"We then average each of the 200 arrays along the columns ( 165 for faces , 18 for hands , and 6 for rotation ) , and finally concatenate all of them to obtain ( 200,189 ) dimension vector for each utterance .",INTRODUCTION,INTRODUCTION,sentiment_analysis,7,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",58,0.8529411764705882,65,0.6132075471698113,21,0.6774193548387096,1,1,hyperparameters
97,"Our performance matches the prior state of the art , however the comparison is not fair .",RESULTS,Combined Multi-Modal Emotion Detection,sentiment_analysis,7,"['B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.9166666666666666,96,0.9056603773584906,10,0.9090909090909091,1,1,results
2,Multimodal Speech Emotion Recognition and Ambiguity Resolution,title,,sentiment_analysis,8,"['B', 'I', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004273504273504274,1,0.0,1,1,research-problem
4,Identifying emotion from speech is a nontrivial task pertaining to the ambiguous definition of emotion itself .,abstract,abstract,sentiment_analysis,8,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.125,3,0.01282051282051282,1,0.017543859649122806,1,1,research-problem
16,"With the rise of deep learning algorithms , there have been multiple attempts to tackle the task of Speech Emotion Recognition ( SER ) as in [ 2 ] and .",I. INTRODUCTION,I. INTRODUCTION,sentiment_analysis,8,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.11764705882352941,15,0.0641025641025641,13,0.22807017543859648,1,1,research-problem
18,"In this work , we explore the implication of hand - crafted features for SER and compare the performance of lighter machine learning models with the heavily data - reliant deep learning models .",I. INTRODUCTION,I. INTRODUCTION,sentiment_analysis,8,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.17647058823529413,17,0.07264957264957266,15,0.2631578947368421,1,1,research-problem
19,"Furthermore , we also combine features from the textual modality to understand the correlation between different modalities and aid ambiguity resolution .",I. INTRODUCTION,I. INTRODUCTION,sentiment_analysis,8,"['O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.20588235294117646,18,0.07692307692307693,16,0.2807017543859649,1,1,model
21,"For both the approaches , we first extract handcrafted features from the time domain of the audio signal and train the respective models .",I. INTRODUCTION,I. INTRODUCTION,sentiment_analysis,8,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",9,0.2647058823529412,20,0.08547008547008547,18,0.3157894736842105,1,1,model
22,"In the first approach , we train traditional machine learning classifiers , namely , Random Forests , Gradient Boosting , Support Vector Machines , Naive - Bayes and Logistic Regression .",I. INTRODUCTION,I. INTRODUCTION,sentiment_analysis,8,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",10,0.29411764705882354,21,0.08974358974358974,19,0.3333333333333333,1,1,model
23,"In the second approach , we build a Multi - Layer Perceptron and an LSTM classifier to recognize emotion given a speech signal .",I. INTRODUCTION,I. INTRODUCTION,sentiment_analysis,8,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",11,0.3235294117647059,22,0.09401709401709402,20,0.3508771929824561,1,1,model
164,"We use librosa , a Python library , to process the audio files and extract features from them .",F. Implementation Details,F. Implementation Details,sentiment_analysis,8,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.058823529411764705,163,0.6965811965811965,2,0.027777777777777776,1,1,experimental-setup
165,"We use scikit - learn and xgboost [ 25 ] , the machine learning libraries for Python , to implement all the ML classifiers ( RF , XGB , SVM , MNB , and LR ) and the MLP .",F. Implementation Details,F. Implementation Details,sentiment_analysis,8,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.08823529411764706,164,0.7008547008547008,3,0.041666666666666664,1,1,experimental-setup
166,We use PyTorch to implement the LSTM classifiers described earlier .,F. Implementation Details,F. Implementation Details,sentiment_analysis,8,"['O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O']","['O', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O']",4,0.11764705882352941,165,0.7051282051282052,4,0.05555555555555555,1,1,experimental-setup
167,"In order to regularize the hidden space of the LSTM classifiers , we use a shut - off mechanism , called dropout , where a fraction of neurons are not used for final prediction .",F. Implementation Details,F. Implementation Details,sentiment_analysis,8,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",5,0.14705882352941177,166,0.7094017094017094,5,0.06944444444444445,1,1,experimental-setup
169,We randomly split our dataset into a train ( 80 % ) and test ( 20 % ) set .,F. Implementation Details,F. Implementation Details,sentiment_analysis,8,"['O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.20588235294117646,168,0.717948717948718,7,0.09722222222222222,1,1,experimental-setup
171,The LSTM classifiers were trained on an NVIDIA Titan X GPU for faster processing .,F. Implementation Details,F. Implementation Details,sentiment_analysis,8,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",9,0.2647058823529412,170,0.7264957264957265,9,0.125,1,1,experimental-setup
172,We stop the training when we do not see any improvement in validation performance for > 10 epochs .,F. Implementation Details,F. Implementation Details,sentiment_analysis,8,"['O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.29411764705882354,171,0.7307692307692307,10,0.1388888888888889,1,1,experimental-setup
199,"From , we can see that our simpler and lighter ML models either outperform or are comparable to the much heavier current state - of - the art on this dataset .",RESULTS,RESULTS,sentiment_analysis,8,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",2,0.05405405405405406,198,0.8461538461538461,37,0.5138888888888888,1,1,results
201,Audio - only results :,RESULTS,RESULTS,sentiment_analysis,8,"['B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O']",4,0.10810810810810811,200,0.8547008547008547,39,0.5416666666666666,1,1,results
203,Performance of LSTM and ARE reveals that deep models indeed need a lot of information to learn features as the LSTM classifier trained on eight - dimensional features achieves very low accuracy as compared to the end - to - end trained ARE .,RESULTS,RESULTS,sentiment_analysis,8,"['B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.16216216216216217,202,0.8632478632478633,41,0.5694444444444444,1,1,results
207,Text - only results :,RESULTS,RESULTS,sentiment_analysis,8,"['B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O']",10,0.2702702702702703,206,0.8803418803418803,45,0.625,1,1,results
208,We observe that the performance of all the models for this setting is similar .,RESULTS,RESULTS,sentiment_analysis,8,"['O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'B-ob', 'O']",11,0.2972972972972973,207,0.8846153846153846,46,0.6388888888888888,1,1,results
212,c) Audio + Text results :,RESULTS,RESULTS,sentiment_analysis,8,"['O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",15,0.40540540540540543,211,0.9017094017094017,50,0.6944444444444444,1,1,results
213,We see that combining audio and text features gives us a boost of ? 14 % for all the metrics .,RESULTS,RESULTS,sentiment_analysis,8,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.43243243243243246,212,0.905982905982906,51,0.7083333333333334,1,1,results
219,"Overall , we can conclude that our simple ML methods are very robust to have achieved comparable performance even though they are modeled to predict six - classes as opposed to four in previous works .",RESULTS,RESULTS,sentiment_analysis,8,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.5945945945945946,218,0.9316239316239316,57,0.7916666666666666,1,1,results
2,Graphical Abstract A Multi-task Learning Model for Chinese - oriented Aspect Polarity Classification and Aspect Term Extraction Highlights A Multi-task Learning Model for Chinese - oriented Aspect Polarity Classification and Aspect Term Extraction A Multi-task Learning Model for Chinese - oriented Aspect Polarity Classification and Aspect Term Extraction,title,title,sentiment_analysis,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.0036101083032490976,1,0.0,1,1,research-problem
8,Aspect - based sentiment analysis ( ABSA ) task is a multi - grained task of natural language processing and consists of two subtasks : aspect term extraction ( ATE ) and aspect polarity classification ( APC ) .,abstract,abstract,sentiment_analysis,9,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.45454545454545453,7,0.02527075812274368,5,0.45454545454545453,1,1,research-problem
9,Most of the existing work focuses on the subtask of aspect term polarity inferring and ignores the significance of aspect term extraction .,abstract,abstract,sentiment_analysis,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.5454545454545454,8,0.02888086642599278,6,0.5454545454545454,1,1,research-problem
13,"By integrating the domain - adapted BERT model , the LCF - ATEPC model achieved the state - of the - art performance of aspect term extraction and aspect polarity classification in four Chinese review datasets .",abstract,abstract,sentiment_analysis,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.9090909090909091,12,0.04332129963898917,10,0.9090909090909091,1,1,research-problem
16,"Aspect - based sentiment analysis ; Pontiki , Galanis , Papageorgiou , Androutsopoulos , Manandhar , AL - Smadi , Al - Ayyoub , Zhao , Qin , De Clercq , Hoste , Apidianaki , Tannier , Loukachevitch , Kotelnikov , Bel , Jimnez - Zafra and Eryigit ( 2016 ) ( ABSA ) is a fine - grained task compared with traditional sentiment analysis , which requires the model to be able to automatic extract the aspects and predict the polarities of all the aspects .",Introduction,Introduction,sentiment_analysis,9,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.02702702702702703,15,0.05415162454873646,1,0.02702702702702703,1,1,research-problem
23,The APC task is a kind of classification problem .,Introduction,Introduction,sentiment_analysis,9,"['O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.21621621621621623,22,0.07942238267148015,8,0.21621621621621623,1,1,research-problem
24,"The researches concerning APC tasks is more abundant than the ATE task , and a large number of deep learning - based models have been proposed to solve APC problems , such as the models ; ; ; based on long short - term memory ( LSTM ) and the methodologies based on transformer .",Introduction,Introduction,sentiment_analysis,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.24324324324324326,23,0.08303249097472924,9,0.24324324324324326,1,1,research-problem
32,"Aiming to automatically extract aspects from the text efficiently and analyze the sentiment polarity of aspects simultaneously , this paper proposes a multi-task learning model for aspect - based sentiment analysis .",Introduction,Introduction,sentiment_analysis,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.4594594594594595,31,0.11191335740072202,17,0.4594594594594595,1,1,model
34,The LCF - ATEPC 3 model proposed in this paper is a novel multilingual and multi-task - oriented model .,Introduction,Introduction,sentiment_analysis,9,"['O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.5135135135135135,33,0.11913357400722022,19,0.5135135135135135,1,1,model
36,"The proposed model is based on multi-head self - attention ( MHSA ) and integrates the pre-trained and the local context focus mechanism , namely LCF - ATEPC .",Introduction,Introduction,sentiment_analysis,9,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",21,0.5675675675675675,35,0.1263537906137184,21,0.5675675675675675,1,1,model
37,"By training on a small amount of annotated data of aspect and their polarity , the model can be adapted to a large - scale dataset , automatically extracting the aspects and predicting the sentiment polarities .",Introduction,Introduction,sentiment_analysis,9,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",22,0.5945945945945946,36,0.1299638989169675,22,0.5945945945945946,1,1,model
48,The codes for this paper are available at https://github.com/yangheng95/LCF-ATEPC,Introduction,Introduction,sentiment_analysis,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob']",33,0.8918918918918919,47,0.16967509025270758,33,0.8918918918918919,1,1,code
192,"ATAE - LSTM is a classical LSTM - based network for the APC task , which applies the attention mechanism to focus on the important words in the context .",Compared Methods,Compared Methods,sentiment_analysis,9,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",3,0.125,191,0.6895306859205776,3,0.125,1,1,baselines
195,ATSM -S Peng et al.,Compared Methods,Compared Methods,sentiment_analysis,9,"['B', 'I', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O']","['B-b', 'I-b', 'O', 'O', 'O']",6,0.25,194,0.7003610108303249,6,0.25,1,1,baselines
196,is a baseline model of the ATSM variations for Chinese language - oriented ABSA task .,Compared Methods,Compared Methods,sentiment_analysis,9,"['B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.2916666666666667,195,0.703971119133574,7,0.2916666666666667,1,1,baselines
198,GANN is novel neural network model for APC task aimed to solve the shortcomings of traditional RNNs and CNNs .,Compared Methods,Compared Methods,sentiment_analysis,9,"['B', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.375,197,0.7111913357400722,9,0.375,1,1,baselines
201,"AEN - is an attentional encoder network based on the pretrained BERT model , which aims to solve the aspect polarity classification .",Compared Methods,Compared Methods,sentiment_analysis,9,"['B', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.5,200,0.7220216606498195,12,0.5,1,1,baselines
202,"BERT - is a BERT - adapted model for Review Reading Comprehension ( RRC ) task , a task inspired by machine reading comprehension ( MRC ) , it could be adapted to aspect - level sentiment classification task .",Compared Methods,Compared Methods,sentiment_analysis,9,"['B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.5416666666666666,201,0.7256317689530686,13,0.5416666666666666,1,1,baselines
203,BERT - BASE is the basic pretrained BERT model .,Compared Methods,Compared Methods,sentiment_analysis,9,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.5833333333333334,202,0.7292418772563177,14,0.5833333333333334,1,1,baselines
204,"We adapt it to ABSA multi-task learning , which equips the same ability to automatically extract aspect terms and classify aspects polarity as LCF - ATEPC model .",Compared Methods,Compared Methods,sentiment_analysis,9,"['O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.625,203,0.7328519855595668,15,0.625,1,1,baselines
207,BERT - ADA,Compared Methods,Compared Methods,sentiment_analysis,9,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",18,0.75,206,0.7436823104693141,18,0.75,1,1,baselines
209,"is a domain - adapted BERT - based model proposed for the APC task , which finetuned the BERT - BASE model on task - related corpus .",Compared Methods,Compared Methods,sentiment_analysis,9,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",20,0.8333333333333334,208,0.7509025270758123,20,0.8333333333333334,1,1,baselines
211,"LCF - ATEPC 5 is the multi -task learning model for the ATE and APC tasks , which is based on the the BERT - SPC model and local context focus mechanism .",Compared Methods,Compared Methods,sentiment_analysis,9,"['B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.9166666666666666,210,0.7581227436823105,22,0.9166666666666666,1,1,baselines
212,LCF - ATE are the variations of the LCF - ATEPC model which only optimize for the ATE task .,Compared Methods,Compared Methods,sentiment_analysis,9,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",23,0.9583333333333334,211,0.7617328519855595,23,0.9583333333333334,1,1,baselines
213,LCF - APC are the variations of LCF - ATEPC and it only optimize for the APC task during training process .,Compared Methods,Compared Methods,sentiment_analysis,9,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",24,1.0,212,0.7653429602888087,24,1.0,1,1,baselines
238,"The CDM layer works better on twitter dataset because there are a lot of non-standard grammar usage and language abbreviations within it , and the local context focus techniques can promote to infer the polarity of terms .",Model,Overall Performance Analysis,sentiment_analysis,9,"['O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.3404255319148936,237,0.855595667870036,3,0.21428571428571427,1,1,results
244,"After optimizing the model parameters according to the empirical result , the joint model based on BERT - BASE achieved hopeful performance on all three datasets and even surpassed other proposed BERT based improved models on some datasets , such as BERT - PT , AEN - BERT , SDGCN - BERT , and soon .",Model,Overall Performance Analysis,sentiment_analysis,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,22,0.46808510638297873,243,0.8772563176895307,9,0.6428571428571429,1,1,results
246,"Compared with the BERT - BASE model , BERT - SPC significantly improves the accuracy and F 1 score of aspect polarity classification .",Model,Overall Performance Analysis,sentiment_analysis,9,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",24,0.5106382978723404,245,0.8844765342960289,11,0.7857142857142857,1,1,results
247,"In addition , for the first time , BERT - SPC has increased the F 1 score of ATE subtask on three datasets up to 99 % .",Model,Overall Performance Analysis,sentiment_analysis,9,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",25,0.5319148936170213,246,0.8880866425992779,12,0.8571428571428571,1,1,results
248,"ATEPC - Fusion is a supplementary scheme of LCF mechanism , and it adopts a moderate approach to generate local context features .",Model,Overall Performance Analysis,sentiment_analysis,9,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",26,0.5531914893617021,247,0.8916967509025271,13,0.9285714285714286,1,1,results
249,The experimental results show that its performance is also better than the existing BERT - based models .,Model,Overall Performance Analysis,sentiment_analysis,9,"['O', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,0.574468085106383,248,0.8953068592057761,14,1.0,1,1,results
2,Deep Learning For Smile Recognition,title,title,smile_recognition,0,"['O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.011111111111111112,1,0.0,1,1,research-problem
4,"Inspired by recent successes of deep learning in computer vision , we propose a novel application of deep convolutional neural networks to facial expression recognition , in particular smile recognition .",abstract,abstract,smile_recognition,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.25,3,0.03333333333333333,1,0.25,1,1,research-problem
56,The input images are fed into a convolution comprising a convolutional and a subsampling layer .,Model,Model,smile_recognition,0,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.3333333333333333,55,0.6111111111111112,2,0.3333333333333333,1,1,model
57,That convolution maybe followed by more convolutions to become gradually more invariant to distortions in the input .,Model,Model,smile_recognition,0,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'O']",3,0.5,56,0.6222222222222222,3,0.5,1,1,model
58,"In the second stage , a regular neural network follows the convolutions in order to discriminate the features learned by the convolutions .",Model,Model,smile_recognition,0,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'O']",,,4,0.6666666666666666,57,0.6333333333333333,4,0.6666666666666666,1,1,model
59,The output layer consists of two units for smile or no smile .,Model,Model,smile_recognition,0,"['O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.8333333333333334,58,0.6444444444444445,5,0.8333333333333334,1,1,model
60,"The novelty of this approach is that the exact number of convolutions , number of hidden layers and size of hidden layers are not fixed but subject to extensive model selection in Sec. 4.3 .",Model,Model,smile_recognition,0,"['O', 'B', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'B-n', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-b', 'O', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",6,1.0,59,0.6555555555555556,6,1.0,1,1,model
62,"Due to training time constraints , some parameters have been fixed to reasonable and empirical values , such as the size of convolutions ( 5 5 pixels , 32 feature maps ) and the size of subsamplings ( 2 2 pixels using max pooling ) .",Experiment setting,Experiment setting,smile_recognition,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.041666666666666664,61,0.6777777777777778,1,0.06666666666666667,1,1,experimental-setup
63,"All layers use ReLU units , except of softmax being used in the output layer .",Experiment setting,Experiment setting,smile_recognition,0,"['B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",2,0.08333333333333333,62,0.6888888888888889,2,0.13333333333333333,1,1,experimental-setup
64,The learning rate is fixed to ? = 0.01 and not subject to model selection as it would significantly prolong the model selection .,Experiment setting,Experiment setting,smile_recognition,0,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.125,63,0.7,3,0.2,1,1,experimental-setup
65,"The same considerations apply to the momentum , which is fixed to = 0.9 .",Experiment setting,Experiment setting,smile_recognition,0,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",4,0.16666666666666666,64,0.7111111111111111,4,0.26666666666666666,1,1,experimental-setup
66,The entire database has been randomly split into a 60% / 20 % / 20 % training / validation / test ratio .,Experiment setting,Experiment setting,smile_recognition,0,"['O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.20833333333333334,65,0.7222222222222222,5,0.3333333333333333,1,1,experimental-setup
71,The model is implemented using Lasagne 4 and the generated CUDA code is executed on a Tesla K40c 9 as training on a GPU allows to perform a comprehensive model selection in a feasible amount of time .,Experiment setting,Experiment setting,smile_recognition,0,"['O', 'O', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.4166666666666667,70,0.7777777777777778,10,0.6666666666666666,1,1,experimental-setup
72,Stochastic gradient descent with a batch size of 500 is used .,Experiment setting,Experiment setting,smile_recognition,0,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O']",11,0.4583333333333333,71,0.7888888888888889,11,0.7333333333333333,1,1,experimental-setup
73,"contains the four parameters to be optimized : the number of convolutions , the number of hidden layers , the number of units per hidden layer and the dropout factor .",Experiment setting,Experiment setting,smile_recognition,0,"['B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O']",12,0.5,72,0.8,12,0.8,1,1,experimental-setup
76,Each model was trained for 50 epochs in the model selection .,Experiment setting,Experiment setting,smile_recognition,0,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",15,0.625,75,0.8333333333333334,15,1.0,1,1,experimental-setup
4,"We present CATENA , a sieve - based system to perform temporal and causal relation extraction and classification from English texts , exploiting the interaction between the temporal and the causal model .",abstract,abstract,temporal_information_extraction,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.041666666666666664,3,0.015873015873015872,1,0.041666666666666664,1,1,research-problem
19,"The CATENA system includes two main classification modules , one for temporal and the other for causal relations between events .",abstract,abstract,temporal_information_extraction,0,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O']",16,0.6666666666666666,18,0.09523809523809523,16,0.6666666666666666,1,1,model
20,"As shown in , they both take as input a document annotated with the so - called temporal entities according to TimeML guidelines , including the document creation time ( DCT ) , events and time expressions ( timexes ) .",abstract,abstract,temporal_information_extraction,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.7083333333333334,19,0.10052910052910052,17,0.7083333333333334,1,1,model
21,"The output is the same document with temporal links ( TLINKs ) set between pairs of temporal entities , each assigned to one of the TimeML temporal relation types , such as or SIMULTANEOUS , which denotes the temporal ordering .",abstract,abstract,temporal_information_extraction,0,"['O', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",18,0.75,20,0.10582010582010581,18,0.75,1,1,model
22,The document is also annotated with causal relations ( CLINKs ) between event pairs .,abstract,abstract,temporal_information_extraction,0,"['O', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",19,0.7916666666666666,21,0.1111111111111111,19,0.7916666666666666,1,1,model
23,"The modules for temporal and causal relation classification rely both on a sieve - based architecture , in which the remaining unlabelled pairs - after running a rule - based component and / or a transitive reasoner are fed into a supervised classifier .",abstract,abstract,temporal_information_extraction,0,"['O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",20,0.8333333333333334,22,0.1164021164021164,20,0.8333333333333334,1,1,model
150,"The evaluation shows that CATENA is the best performing system in both tasks , even if in Task C best precision and best recall are yielded by and , respectively .",Evaluation Results,Evaluation Results,temporal_information_extraction,0,"['O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.13793103448275862,149,0.7883597883597884,4,0.21052631578947367,1,1,results
156,"If we consider the different entity pairs , CATENA performs best on timex - timex and event - timex relations , while CAEVO still achieves the best results on event - DCT and event - event pairs .",Evaluation Results,Evaluation Results,temporal_information_extraction,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.3448275862068966,155,0.8201058201058201,10,0.5263157894736842,1,1,results
160,"As expected , running a transitive closure module after the temporal rule - based sieve ( RB + TR ) results in improving recall , but the over all performance is still lacking ( less than .30 F1-score ) .",Evaluation Results,Evaluation Results,temporal_information_extraction,0,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.4827586206896552,159,0.8412698412698413,14,0.7368421052631579,1,1,ablation-analysis
161,Combining rule - based and machine - learned sieves ( RB + ML ) yields a slight improvement compared with enabling only the machine - learned sieve in the system ( ML ) .,Evaluation Results,Evaluation Results,temporal_information_extraction,0,"['B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.5172413793103449,160,0.8465608465608465,15,0.7894736842105263,1,1,ablation-analysis
162,Introducing the temporal reasoner module between the two sieves ( RB + TR + ML ) proves to be even more beneficial .,Evaluation Results,Evaluation Results,temporal_information_extraction,0,"['B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",16,0.5517241379310345,161,0.8518518518518519,16,0.8421052631578947,1,1,ablation-analysis
2,A Structured Learning Approach to Temporal Relation Extraction,title,,temporal_information_extraction,1,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0038910505836575876,1,0.0,1,1,research-problem
4,Identifying temporal relations between events is an essential step towards natural language understanding .,abstract,abstract,temporal_information_extraction,1,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.16666666666666666,3,0.011673151750972763,1,0.16666666666666666,1,1,research-problem
13,"The fundamental tasks in temporal processing , as identified in the TE workshops , are 1 ) time expression ( the so - called "" timex "" ) extraction and normalization and 2 ) temporal relation ( also known as TLINKs ) extraction .",Introduction,Introduction,temporal_information_extraction,1,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.06976744186046512,12,0.04669260700389105,3,0.06976744186046512,1,1,research-problem
17,"In this paper , we propose a structured learning approach to temporal relation extraction , where local models are updated based on feedback from global inferences .",Introduction,Introduction,temporal_information_extraction,1,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",7,0.16279069767441862,16,0.0622568093385214,7,0.16279069767441862,1,1,approach
18,"The structured approach also gives rise to a semisupervised method , making it possible to take advantage of the readily available unlabeled data .",Introduction,Introduction,temporal_information_extraction,1,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.18604651162790697,17,0.06614785992217899,8,0.18604651162790697,1,1,approach
199,The first is the regularized averaged perceptron ( AP ) implemented in the LBJava package and is a local method .,Baseline Methods,Baseline Methods,temporal_information_extraction,1,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.037037037037037035,198,0.7704280155642024,2,0.08,1,1,baselines
200,"On top of the first baseline , we performed global inference in Eq .",Baseline Methods,Baseline Methods,temporal_information_extraction,1,"['B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O']",3,0.05555555555555555,199,0.77431906614786,3,0.12,1,1,baselines
202,"Both of them used the same feature set ( i.e. , as designed in ) as in the proposed structured perceptron ( SP ) and CoDL for fair comparisons .",Baseline Methods,Baseline Methods,temporal_information_extraction,1,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'O', 'O', 'O', 'O']",5,0.09259259259259259,201,0.7821011673151751,5,0.2,1,1,baselines
205,TE3 Task C - Relation Only,Baseline Methods,,temporal_information_extraction,1,"['B', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",8,0.14814814814814814,204,0.7937743190661478,8,0.32,1,1,results
214,"We can see that UT - Time is about 3 % better than AP - 1 in the absolute value of F 1 , which is expected since UTTime included more advanced features derived from syntactic parse trees .",Baseline Methods,TE3 Task C - Relation Only,temporal_information_extraction,1,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.3148148148148148,213,0.8287937743190662,17,0.68,1,1,results
220,"On top of AP - 2 , a global inference step enforcing symmetry and transitivity constraints ( "" AP + ILP "" ) can further improve the F 1 score by 9.3 % , which is consistent with previous observations .",Baseline Methods,TE3 Task C - Relation Only,temporal_information_extraction,1,"['B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",23,0.42592592592592593,219,0.8521400778210116,23,0.92,1,1,results
221,"SP + ILP further improved the performance in precision , recall , and F 1 significantly ( per the McNemar 's test with p < 0.0005 ) , reaching an F 1 score of 67.2 % .",Baseline Methods,TE3 Task C - Relation Only,temporal_information_extraction,1,"['B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",24,0.4444444444444444,220,0.8560311284046692,24,0.96,1,1,results
223,TE3 Task C,Baseline Methods,,temporal_information_extraction,1,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",26,0.48148148148148145,222,0.8638132295719845,0,0.0,1,1,results
232,"The improvement of SP + ILP ( line 4 ) over AP ( line 2 ) was small and AP + ILP ( line 3 ) was even worse than AP , which necessitates the use of a better approach towards vague TLINKs .",Baseline Methods,TE3 Task C,temporal_information_extraction,1,"['O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,35,0.6481481481481481,231,0.8988326848249028,9,0.6,1,1,results
233,"By applying the postfiltering method proposed in Sec. 4 , we were able to achieve better performances using SP + ILP ( line 5 ) , which shows the effectiveness of this strategy .",Baseline Methods,TE3 Task C,temporal_information_extraction,1,"['O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",36,0.6666666666666666,232,0.9027237354085603,10,0.6666666666666666,1,1,results
239,Comparison with CAEVO,Baseline Methods,,temporal_information_extraction,1,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",42,0.7777777777777778,238,0.9260700389105059,0,0.0,1,1,results
249,"SP + ILP outperformed CAEVO and if additional unlabeled dataset TE3 - SV was used , CoDL + ILP achieved the best score with a relative improvement in F 1 score being 6.3 % .",Baseline Methods,Comparison with CAEVO,temporal_information_extraction,1,"['B', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",52,0.9629629629629629,248,0.9649805447470817,10,0.8333333333333334,1,1,results
2,Bag of Tricks for Efficient Text Classification,title,title,text-classification,2,"['O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.010752688172043012,1,0.0,1,1,research-problem
4,This paper explores a simple and efficient baseline for text classification .,abstract,abstract,text-classification,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",1,0.3333333333333333,3,0.03225806451612903,1,0.3333333333333333,1,1,research-problem
22,shows a simple linear model with rank constraint .,Model architecture,Model architecture,text-classification,2,"['B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",5,0.16666666666666666,21,0.22580645161290322,5,0.38461538461538464,1,1,model
23,The first weight matrix A is a look - up table over the words .,Model architecture,Model architecture,text-classification,2,"['O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",6,0.2,22,0.23655913978494625,6,0.46153846153846156,1,1,model
24,"The word representations are then averaged into a text representation , which is in turn fed to a linear classifier .",Model architecture,Model architecture,text-classification,2,"['O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",7,0.23333333333333334,23,0.24731182795698925,7,0.5384615384615384,1,1,model
27,We use the softmax function f to compute the probability distribution over the predefined classes .,Model architecture,Model architecture,text-classification,2,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",10,0.3333333333333333,26,0.27956989247311825,10,0.7692307692307693,1,1,model
34,"In order to improve our running time , we use a hierarchical softmax ) based on the Huffman coding tree .",Model architecture,Hierarchical softmax,text-classification,2,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.5666666666666667,33,0.3548387096774194,3,0.1875,1,1,model
45,"Instead , we use a bag of n-grams as additional features to capture some partial information about the local word order .",Model architecture,N - gram features,text-classification,2,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",28,0.9333333333333333,44,0.4731182795698925,14,0.875,1,1,model
46,This is very efficient in practice while achieving comparable results to methods that explicitly use the order .,Model architecture,N - gram features,text-classification,2,"['O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'O']",29,0.9666666666666667,45,0.4838709677419355,15,0.9375,1,1,model
47,"We maintain a fast and memory efficient mapping of the n-grams by using the hashing trick with the same hashing function as in and 10M bins if we only used bigrams , and 100M otherwise .",Model architecture,N - gram features,text-classification,2,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O']",30,1.0,46,0.4946236559139785,16,1.0,1,1,model
53,Sentiment analysis,Experiments,,text-classification,2,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",5,1.0,52,0.5591397849462365,0,0.0,1,1,tasks
60,"We use 10 hidden units and run fastText for 5 epochs with a learning rate selected on a validation set from { 0.05 , 0.1 , 0.25 , 0.5 } .",Results .,We present the results in .,text-classification,2,"['O', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-ob', 'B-p', 'I-p', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.18181818181818182,59,0.6344086021505376,7,0.4666666666666667,1,1,tasks
61,"On this task , adding bigram information improves the performance by 1 - 4 % .",Results .,We present the results in .,text-classification,2,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.2727272727272727,60,0.6451612903225806,8,0.5333333333333333,1,1,tasks
62,"Overall our accuracy is slightly better than char - CNN and char - CRNN and , a bit worse than VDCNN .",Results .,We present the results in .,text-classification,2,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'O']",4,0.36363636363636365,61,0.6559139784946236,9,0.6,1,1,tasks
63,"Note that we can increase the accuracy slightly by using more n-grams , for example with trigrams , the performance on Sogou goes up to 97.1 % .",Results .,We present the results in .,text-classification,2,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",5,0.45454545454545453,62,0.6666666666666666,10,0.6666666666666666,1,1,tasks
69,Tag prediction,Results .,,text-classification,2,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",11,1.0,68,0.7311827956989247,0,0.0,1,1,tasks
84,"At test time , Tagspace needs to compute the scores for all the classes which makes it relatively slow , while our fast inference gives a significant speed - up when the number of classes is large ( more than 300 K here ) .",Dataset and baselines .,Results and training time . and 200 .,text-classification,2,"['B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.8235294117647058,83,0.8924731182795699,15,0.8333333333333334,1,1,tasks
85,"Overall , we are more than an order of magnitude faster to obtain model with a better quality .",Dataset and baselines .,Results and training time . and 200 .,text-classification,2,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",15,0.8823529411764706,84,0.9032258064516129,16,0.8888888888888888,1,1,tasks
2,Universal Sentence Encoder,title,,text-classification,6,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.006756756756756757,1,0.0,1,1,research-problem
4,We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks .,abstract,abstract,text-classification,6,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.1111111111111111,3,0.02027027027027027,1,0.1111111111111111,1,1,research-problem
9,We find that transfer learning using sentence embeddings tends to outperform word level transfer .,abstract,abstract,text-classification,6,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.6666666666666666,8,0.05405405405405406,6,0.6666666666666666,1,1,research-problem
10,"With transfer learning via sentence embeddings , we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task .",abstract,abstract,text-classification,6,"['O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.7777777777777778,9,0.060810810810810814,7,0.7777777777777778,1,1,research-problem
32,Both models are implemented in TensorFlow and are available to download from TF Hub : 1 https://tfhub.dev/google/universal-sentence-encoder/1,Model Toolkit,Model Toolkit,text-classification,6,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob']",3,0.0967741935483871,31,0.20945945945945946,3,0.375,1,1,code
44,The transformer based sentence encoding model constructs sentence embeddings using the encoding sub - graph of the transformer architecture .,Model Toolkit,Transformer,text-classification,6,"['O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.4838709677419355,43,0.2905405405405405,1,0.058823529411764705,1,1,model
45,This sub - graph uses attention to compute context aware representations of words in a sentence that take into account both the ordering and identity of all the other words .,Model Toolkit,Transformer,text-classification,6,"['O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.5161290322580645,44,0.2972972972972973,2,0.11764705882352941,1,1,model
46,The context aware word representations are converted to a fixed length sentence encoding vector by computing the element - wise sum of the representations at each word position .,Model Toolkit,Transformer,text-classification,6,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.5483870967741935,45,0.30405405405405406,3,0.17647058823529413,1,1,model
48,The encoding model is designed to be as general purpose as possible .,Model Toolkit,Transformer,text-classification,6,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O']",19,0.6129032258064516,47,0.31756756756756754,5,0.29411764705882354,1,1,model
49,This is accomplished by using multi-task learning whereby a single encoding model is used to feed multiple downstream tasks .,Model Toolkit,Transformer,text-classification,6,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",20,0.6451612903225806,48,0.32432432432432434,6,0.35294117647058826,1,1,model
54,Deep Averaging Network ( DAN ),Model Toolkit,Transformer,text-classification,6,"['B', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",25,0.8064516129032258,53,0.3581081081081081,11,0.6470588235294118,1,1,model
55,The second encoding model makes use of a deep averaging network ( DAN ) whereby input embeddings for words and bi-grams are first averaged together and then passed through a feedforward deep neural network ( DNN ) to produce sentence embeddings .,Model Toolkit,Transformer,text-classification,6,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",26,0.8387096774193549,54,0.36486486486486486,12,0.7058823529411765,1,1,model
56,"Similar to the Transformer encoder , the DAN encoder takes as input a lowercased PTB tokenized string and outputs a 512 dimensional sentence embedding .",Model Toolkit,Transformer,text-classification,6,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']",,,27,0.8709677419354839,55,0.3716216216216216,13,0.7647058823529411,1,1,model
58,We make use of mul-titask learning whereby a single DAN encoder is used to supply sentence embeddings for multiple downstream tasks .,Model Toolkit,Transformer,text-classification,6,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",29,0.9354838709677419,57,0.38513513513513514,15,0.8823529411764706,1,1,model
59,The primary advantage of the DAN encoder is that compute time is linear in the length of the input sequence .,Model Toolkit,Transformer,text-classification,6,"['O', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'B-p', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-p', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'O']",30,0.967741935483871,58,0.3918918918918919,16,0.9411764705882353,1,1,model
69,MR : Movie review snippet sentiment on a five star scale .,Encoder Training Data,Transfer Tasks,text-classification,6,"['B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.4,68,0.4594594594594595,3,0.2,1,1,tasks
70,CR : Sentiment of sentences mined from customer reviews .,Encoder Training Data,Transfer Tasks,text-classification,6,"['B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['B-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",9,0.45,69,0.46621621621621623,4,0.26666666666666666,1,1,tasks
71,SUBJ : Subjectivity of sentences from movie reviews and plot summaries .,Encoder Training Data,Transfer Tasks,text-classification,6,"['B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.5,70,0.47297297297297297,5,0.3333333333333333,1,1,tasks
72,MPQA : Phrase level opinion polarity from news data .,Encoder Training Data,Transfer Tasks,text-classification,6,"['B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.55,71,0.4797297297297297,6,0.4,1,1,tasks
73,TREC : Fine grained question classification sourced from TREC .,Encoder Training Data,Transfer Tasks,text-classification,6,"['B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'O']",,,12,0.6,72,0.4864864864864865,7,0.4666666666666667,1,1,tasks
74,SST : Binary phrase level sentiment classification .,Encoder Training Data,Transfer Tasks,text-classification,6,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.65,73,0.49324324324324326,8,0.5333333333333333,1,1,tasks
75,STS Benchmark : Semantic textual similarity ( STS ) between sentence pairs scored by Pearson correlation with human judgments .,Encoder Training Data,Transfer Tasks,text-classification,6,"['B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",14,0.7,74,0.5,9,0.6,1,1,tasks
76,WEAT : Word pairs from the psychology literature on implicit association tests ( IAT ) that are used to characterize model bias .,Encoder Training Data,Transfer Tasks,text-classification,6,"['B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.75,75,0.5067567567567568,10,0.6666666666666666,1,1,tasks
84,"For word level transfer , we use word embeddings from a word2 vec skip - gram model trained on a corpus of news data .",Baselines,Baselines,text-classification,6,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",2,0.4,83,0.5608108108108109,2,0.4,1,1,baselines
85,The pretrained word embeddings are included as input to two model types : a convolutional neural network models ( CNN ) ; a DAN .,Baselines,Baselines,text-classification,6,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'O', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'O', 'O', 'O', 'B-ob', 'O']",3,0.6,84,0.5675675675675675,3,0.6,1,1,baselines
87,Additional baseline CNN and DAN models are trained without using any pretrained word or sentence embeddings .,Baselines,Baselines,text-classification,6,"['B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,1.0,86,0.581081081081081,5,1.0,1,1,baselines
112,We observe that transfer learning from the transformer based sentence encoder usually performs as good or better than transfer learning from the DAN encoder .,Results,Results,text-classification,6,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O']",,,2,0.06451612903225806,111,0.75,2,0.16666666666666666,1,1,results
114,Models that make use of sentence level transfer learning tend to perform better than models that only use word level transfer .,Results,Results,text-classification,6,"['B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.12903225806451613,113,0.7635135135135135,4,0.3333333333333333,1,1,results
117,"We observe that , for smaller quantities of data , sentence level transfer learning can achieve surprisingly good task performance .",Results,Results,text-classification,6,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.22580645161290322,116,0.7837837837837838,7,0.5833333333333334,1,1,results
118,"As the training set size increases , models that do not make use of transfer learning approach the performance of the other models .",Results,Results,text-classification,6,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",8,0.25806451612903225,117,0.7905405405405406,8,0.6666666666666666,1,1,results
2,Token - Level Ensemble Distillation for Grapheme - to - Phoneme Conversion,title,title,text-to-speech_synthesis,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.006172839506172839,1,0.0,1,1,research-problem
4,Grapheme - to - phoneme ( G2P ) conversion is an important task in automatic speech recognition and text - to - speech systems .,abstract,abstract,text-to-speech_synthesis,0,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.125,3,0.018518518518518517,1,0.125,1,1,research-problem
22,"Inspired by the knowledge distillation in computer vision and natural language processing , in this work , we propose the token - level ensemble distillation for G2P conversion , to address the practical problems mentioned above .",Introduction,Introduction,text-to-speech_synthesis,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.47619047619047616,21,0.12962962962962962,10,0.47619047619047616,1,1,approach
23,"First , we use knowledge distillation to leverage the large amount of unlabeled words .",Introduction,Introduction,text-to-speech_synthesis,0,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.5238095238095238,22,0.13580246913580246,11,0.5238095238095238,1,1,approach
24,"Specifically , we train a teacher model to generate the phoneme sequence as well as its probability distribution given unlabeled grapheme sequence , and regard the unlabeled grapheme sequence and the generated phoneme sequence as pseudo labeled data , and add them into the original training data .",Introduction,Introduction,text-to-speech_synthesis,0,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.5714285714285714,23,0.1419753086419753,12,0.5714285714285714,1,1,approach
25,"Second , we train a variety of models ( CNN , RNN and Transformer ) for ensemble to get higher accuracy , and transfer the knowledge of the ensemble models to a light - weight model that is suitable for online deployment , again by knowledge distillation .",Introduction,Introduction,text-to-speech_synthesis,0,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",13,0.6190476190476191,24,0.14814814814814814,13,0.6190476190476191,1,1,approach
26,"Besides , we adopt Transformer instead of RNN or CNN as the basic encoder - decoder model structure , since it demonstrates advantages in a variety of sequence to sequence tasks , such as neural machine translation , text summarization , automatic speech recognition .",Introduction,Introduction,text-to-speech_synthesis,0,"['O', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.6666666666666666,25,0.15432098765432098,14,0.6666666666666666,1,1,approach
110,Ensemble Model,,,text-to-speech_synthesis,0,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",0,0.0,109,0.6728395061728395,1,0.1111111111111111,1,1,experiments
112,"We use 4 Transformer models , 3 CNN models and 3 Bi - LSTM models with different hyperparameters for ensemble , which give the best performance on the validation set .",Ensemble Model,Ensemble Model,text-to-speech_synthesis,0,"['O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.4,111,0.6851851851851852,3,0.3333333333333333,1,1,experiments
113,The 4 Transformer models share the same hidden size ( 256 ) but vary in the number of the encoder - decoder layers .,Ensemble Model,Ensemble Model,text-to-speech_synthesis,0,"['O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.6,112,0.691358024691358,4,0.4444444444444444,1,1,experiments
114,"For the 3 CNN models , they share the same hidden size ( 256 ) but vary in the number of encoder - decoder layers ( 10 - 10 , 10 - 10 , 8 - 8 ) and convolutional kernel widths ( 3 , 2 , 2 ) respectively .",Ensemble Model,Ensemble Model,text-to-speech_synthesis,0,"['O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",4,0.8,113,0.6975308641975309,5,0.5555555555555556,1,1,experiments
115,"For the 3 Bi - LSTM models , they share the same number of encoder - decoder layers ( 1 - 1 ) , but with different hidden sizes ( 256 , 384 and 512 ) .",Ensemble Model,Ensemble Model,text-to-speech_synthesis,0,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,1.0,114,0.7037037037037037,6,0.6666666666666666,1,1,experiments
116,Student Model,,,text-to-speech_synthesis,0,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",0,0.0,115,0.7098765432098766,7,0.7777777777777778,1,1,experiments
117,We choose Transformer as the student model and use the default configurations ( 256 hidden size and 6 - 6 layers of encoder - decoder ) unless otherwise stated .,Student Model,Student Model,text-to-speech_synthesis,0,"['O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.5,116,0.7160493827160493,8,0.8888888888888888,1,1,experiments
120,We implement experiments with the fairseq - py 4 library in Py-Torch .,Training and Evaluation,Training and Evaluation,text-to-speech_synthesis,0,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.1,119,0.7345679012345679,1,0.1,1,1,experiments
121,We use Adam optimizer for all models and follow the learning rate schedule in .,Training and Evaluation,Training and Evaluation,text-to-speech_synthesis,0,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",2,0.2,120,0.7407407407407407,2,0.2,1,1,experiments
122,"The dropout is 0.3 for Bi - LSTM and CNN models , while the residual dropout , attention dropout and ReLU dropout for Transformer models is 0.2 , 0.4 , 0.4 respectively .",Training and Evaluation,Training and Evaluation,text-to-speech_synthesis,0,"['O', 'B', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O']",,,3,0.3,121,0.7469135802469136,3,0.3,1,1,experiments
124,We train each model on 8 NVIDIA M40 GPUs .,Training and Evaluation,Training and Evaluation,text-to-speech_synthesis,0,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",5,0.5,123,0.7592592592592593,5,0.5,1,1,experiments
125,Each GPU contains roughly 4000 tokens in one mini-batch .,Training and Evaluation,Training and Evaluation,text-to-speech_synthesis,0,"['O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",6,0.6,124,0.7654320987654321,6,0.6,1,1,experiments
126,We use beam search during inference and set beam size to 10 .,Training and Evaluation,Training and Evaluation,text-to-speech_synthesis,0,"['O', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.7,125,0.7716049382716049,7,0.7,1,1,experiments
127,We use WER ( word error rate ) and PER ( phoneme error rate ) to measure the accuracy of G2P conversion .,Training and Evaluation,Training and Evaluation,text-to-speech_synthesis,0,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.8,126,0.7777777777777778,8,0.8,1,1,experiments
132,"We first compare our method with previous works on CMUDict 0.7 b dataset , as shown in .",Results and Analyses,Results and Analyses,text-to-speech_synthesis,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.15384615384615385,131,0.808641975308642,2,0.15384615384615385,1,1,results
136,"It can be seen that our method on 6 - layer encoder and 6 - layer decoder Transformer achieves the new state - of - the - art result of 19.88 % WER , outperforming NSGD by 4.22 % WER .",Results and Analyses,Results and Analyses,text-to-speech_synthesis,0,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.46153846153846156,135,0.8333333333333334,6,0.46153846153846156,1,1,results
145,"We first study the effect of distilling from unlabeled source words , as shown in .",Analyses of Our Method,Analyses of Our Method,text-to-speech_synthesis,0,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O']",1,0.07142857142857142,144,0.8888888888888888,1,0.09090909090909091,1,1,ablation-analysis
146,"It can be seen that unlabeled source words can boost the accuracy by nearly 1 % WER , demonstrating the effectiveness by introducing abundant unlabeled data into knowledge distillation .",Analyses of Our Method,Analyses of Our Method,text-to-speech_synthesis,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",2,0.14285714285714285,145,0.8950617283950617,2,0.18181818181818182,1,1,ablation-analysis
152,"Furthermore , we study the effect of ensemble teacher model in knowledge distillation .",Analyses of Our Method,Analyses of Our Method,text-to-speech_synthesis,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",8,0.5714285714285714,151,0.9320987654320988,8,0.7272727272727273,1,1,ablation-analysis
153,"As shown in , the ensemble teacher model can boost the accuracy by more than 1 % WER , compared with the single teacher model ( a Transformer model with 6 - layer encoder and 6 - layer decoder ) , which demonstrates the strong ensemble teacher model is essential to guarantee the performance of student model in knowledge distillation .",Analyses of Our Method,Analyses of Our Method,text-to-speech_synthesis,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.6428571428571429,152,0.9382716049382716,9,0.8181818181818182,1,1,ablation-analysis
154,"At last , we compare Transformer with RNN and CNN based models , without using knowledge distillation and unlabeled data , as shown in .",Analyses of Our Method,Analyses of Our Method,text-to-speech_synthesis,0,"['O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",10,0.7142857142857143,153,0.9444444444444444,10,0.9090909090909091,1,1,ablation-analysis
155,"We can see that Transformer model outperforms the RNN and CNN based models used in previous works , demonstrating the advantage of Transformer model .",Analyses of Our Method,Analyses of Our Method,text-to-speech_synthesis,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,11,0.7857142857142857,154,0.9506172839506173,11,1.0,1,1,ablation-analysis
157,"We compare our method with the previous state - of - the - art CNN with NSGD ( which is reproduced by ourself ) on our internal dataset , as shown in .",Analyses of Our Method,Results on Our Internal Dataset,text-to-speech_synthesis,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O']",13,0.9285714285714286,156,0.9629629629629629,1,0.5,1,1,results
158,"Our method outperforms CNN with NSGD by 3.52 % WER , which demonstrates the effectiveness of our method for G2P conversion .",Analyses of Our Method,Results on Our Internal Dataset,text-to-speech_synthesis,0,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",14,1.0,157,0.9691358024691358,2,1.0,1,1,results
2,"FastSpeech : Fast , Robust and Controllable Text to Speech",title,title,text-to-speech_synthesis,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0045662100456621,1,0.0,1,1,research-problem
4,Neural network based end - to - end text to speech ( TTS ) has significantly improved the quality of synthesized speech .,abstract,abstract,text-to-speech_synthesis,1,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.1,3,0.0136986301369863,1,0.1,1,1,research-problem
15,Text to speech ( TTS ) has attracted a lot of attention in recent years due to the advance in deep learning .,Introduction,Introduction,text-to-speech_synthesis,1,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.038461538461538464,14,0.0639269406392694,1,0.038461538461538464,1,1,research-problem
18,Neural network based TTS has outperformed conventional concatenative and statistical parametric approaches in terms of speech quality .,Introduction,Introduction,text-to-speech_synthesis,1,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.15384615384615385,17,0.0776255707762557,4,0.15384615384615385,1,1,research-problem
28,"Considering the monotonous alignment between text and speech , to speedup mel- spectrogram generation , in this work , we propose a novel model , FastSpeech , which takes a text ( phoneme ) sequence as input and generates mel-spectrograms non-autoregressively .",Introduction,Synthesized speech is lack of controllability .,text-to-speech_synthesis,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",14,0.5384615384615384,27,0.1232876712328767,14,0.5384615384615384,1,1,model
29,It adopts a feed - forward network based on the self - attention in Transformer and 1D convolution .,Introduction,Synthesized speech is lack of controllability .,text-to-speech_synthesis,1,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.5769230769230769,28,0.1278538812785388,15,0.5769230769230769,1,1,model
30,"Since a mel-spectrogram sequence is much longer than its corresponding phoneme sequence , in order to solve the problem of length mismatch between the two sequences , FastSpeech adopts a length regulator that up - samples the phoneme sequence according to the phoneme duration ( i.e. , the number of mel- spectrograms that each phoneme corresponds to ) to match the length of the mel-spectrogram sequence .",Introduction,Synthesized speech is lack of controllability .,text-to-speech_synthesis,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.6153846153846154,29,0.1324200913242009,16,0.6153846153846154,1,1,model
31,"The regulator is built on a phoneme duration predictor , which predicts the duration of each phoneme .",Introduction,Synthesized speech is lack of controllability .,text-to-speech_synthesis,1,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.6538461538461539,30,0.136986301369863,17,0.6538461538461539,1,1,model
130,"We first train the autoregressive Transformer TTS model on 4 NVIDIA V100 GPUs , with batchsize of 16 sentences on each GPU .",Training and Inference,Training and Inference,text-to-speech_synthesis,1,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.1,129,0.589041095890411,1,0.1,1,1,experimental-setup
131,"We use the Adam optimizer with ? 1 = 0.9 , ? 2 = 0.98 , ? = 10 ?9 and follow the same learning rate schedule in .",Training and Inference,Training and Inference,text-to-speech_synthesis,1,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.2,130,0.593607305936073,2,0.2,1,1,experimental-setup
134,"In addition , we also leverage sequence - level knowledge distillation that has achieved good performance in non-autoregressive machine translation to transfer the knowledge from the teacher model to the student model .",Training and Inference,Training and Inference,text-to-speech_synthesis,1,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.5,133,0.6073059360730594,5,0.5,1,1,experimental-setup
139,"In the inference process , the output mel-spectrograms of our FastSpeech model are transformed into audio samples using the pretrained WaveGlow [ 20 ] 5 .",Training and Inference,Training and Inference,text-to-speech_synthesis,1,"['B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",10,1.0,138,0.6301369863013698,10,1.0,1,1,experimental-setup
142,Audio Quality,Results,,text-to-speech_synthesis,1,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",2,0.04878048780487805,141,0.6438356164383562,2,0.09523809523809523,1,1,results
143,We conduct the MOS ( mean opinion score ) evaluation on the test set to measure the audio quality .,Results,Audio Quality,text-to-speech_synthesis,1,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",3,0.07317073170731707,142,0.6484018264840182,3,0.14285714285714285,1,1,results
155,Robustness,Results,,text-to-speech_synthesis,1,['B'],['B-n'],['B-b'],15,0.36585365853658536,154,0.7031963470319634,15,0.7142857142857143,1,1,results
159,"It can be seen that Transformer TTS is not robust to these hard cases and gets 34 % error rate , while FastSpeech can effectively eliminate word repeating and skipping to improve intelligibility .",Results,Word error counts are listed in .,text-to-speech_synthesis,1,"['O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'O']","['O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",19,0.4634146341463415,158,0.7214611872146118,19,0.9047619047619048,1,1,results
166,Voice Speed,Results,,text-to-speech_synthesis,1,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",26,0.6341463414634146,165,0.7534246575342466,4,0.21052631578947367,1,1,results
169,"As demonstrated by the samples , FastSpeech can adjust the voice speed from 0.5x to 1.5 x smoothly , with stable and almost unchanged pitch .",Results,Voice Speed,text-to-speech_synthesis,1,"['O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",29,0.7073170731707317,168,0.7671232876712328,7,0.3684210526315789,1,1,results
189,1D Convolution in FFT Block,System CMOS,FastSpeech 0,text-to-speech_synthesis,1,"['B', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b']",4,0.36363636363636365,188,0.8584474885844748,0,0.0,1,1,ablation-analysis
190,"We propose to replace the original fully connected layer ( adopted in Transformer ) with 1D convolution in FFT block , as described in Section 3.1 .",System CMOS,FastSpeech 0,text-to-speech_synthesis,1,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.45454545454545453,189,0.863013698630137,1,0.14285714285714285,1,1,ablation-analysis
192,"As shown in , replacing 1D convolution with fully connected layer results in - 0.113 CMOS , which demonstrates the effectiveness of 1D convolution .",System CMOS,FastSpeech 0,text-to-speech_synthesis,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.6363636363636364,191,0.8721461187214612,3,0.42857142857142855,1,1,ablation-analysis
193,Sequence - Level Knowledge Distillation,System CMOS,FastSpeech 0,text-to-speech_synthesis,1,"['B', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b']",8,0.7272727272727273,192,0.8767123287671232,4,0.5714285714285714,1,1,ablation-analysis
196,"We find that removing sequence - level knowledge distillation results in - 0.325 CMOS , which demonstrates the effectiveness of sequence - level knowledge distillation .",System CMOS,FastSpeech 0,text-to-speech_synthesis,1,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,1.0,195,0.8904109589041096,7,1.0,1,1,ablation-analysis
2,Transfer Learning from Speaker Verification to Multispeaker Text - To - Speech Synthesis,title,title,text-to-speech_synthesis,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004081632653061225,1,0.0,1,1,research-problem
4,"We describe a neural network - based system for text - to - speech ( TTS ) synthesis that is able to generate speech audio in the voice of different speakers , including those unseen during training .",abstract,abstract,text-to-speech_synthesis,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.2,3,0.012244897959183673,1,0.2,1,1,research-problem
10,The goal of this work is to build a TTS system which can generate natural speech for a variety of speakers in a data efficient manner .,Introduction,Introduction,text-to-speech_synthesis,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.02702702702702703,9,0.036734693877551024,1,0.02702702702702703,1,1,research-problem
18,Our approach is to decouple speaker modeling from speech synthesis by independently training a speaker - discriminative embedding network that captures the space of speaker characteristics and training a high quality TTS model on a smaller dataset conditioned on the representation learned by the first network .,Introduction,Introduction,text-to-speech_synthesis,2,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.24324324324324326,17,0.06938775510204082,9,0.24324324324324326,1,1,approach
20,We train the speaker embedding network on a speaker verification task to determine if two different utterances were spoken by the same speaker .,Introduction,Introduction,text-to-speech_synthesis,2,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.2972972972972973,19,0.07755102040816327,11,0.2972972972972973,1,1,approach
21,"In contrast to the subsequent TTS model , this network is trained on untranscribed speech containing reverberation and background noise from a large number of speakers .",Introduction,Introduction,text-to-speech_synthesis,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.32432432432432434,20,0.08163265306122448,12,0.32432432432432434,1,1,approach
115,Speech naturalness,Experiments,,text-to-speech_synthesis,2,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",23,0.22330097087378642,114,0.46530612244897956,0,0.0,1,1,results
123,"The proposed model achieved about 4.0 MOS in all datasets , with the VCTK model obtaining a MOS about 0.2 points higher than the LibriSpeech model when evaluated on seen speakers .",Experiments,Speech naturalness,text-to-speech_synthesis,2,"['O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",31,0.30097087378640774,122,0.49795918367346936,8,0.5333333333333333,1,1,results
125,"Most importantly , the audio generated by our model for unseen speakers is deemed to be at least as natural as that generated for seen speakers .",Experiments,Speech naturalness,text-to-speech_synthesis,2,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",33,0.32038834951456313,124,0.5061224489795918,10,0.6666666666666666,1,1,results
126,"Surprisingly , the MOS on unseen speakers is higher than that of seen speakers , by as much as 0.2 points on LibriSpeech .",Experiments,Speech naturalness,text-to-speech_synthesis,2,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",34,0.3300970873786408,125,0.5102040816326531,11,0.7333333333333333,1,1,results
131,Speaker similarity,Experiments,,text-to-speech_synthesis,2,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",39,0.3786407766990291,130,0.5306122448979592,0,0.0,1,1,results
135,"The scores for the VCTK model tend to be higher than those for LibriSpeech , reflecting the cleaner nature of the dataset .",Experiments,Results are shown in .,text-to-speech_synthesis,2,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",43,0.4174757281553398,134,0.5469387755102041,4,0.2,1,1,results
137,"For seen speakers on VCTK , the proposed model performs about as well as the baseline which uses an embedding lookup table for speaker conditioning .",Experiments,Results are shown in .,text-to-speech_synthesis,2,"['B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",45,0.4368932038834951,136,0.5551020408163265,6,0.3,1,1,results
152,Speaker verification,Experiments,,text-to-speech_synthesis,2,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",60,0.5825242718446602,151,0.6163265306122448,0,0.0,1,1,results
160,"As shown in , as long as the synthesizer was trained on a sufficiently large set of speakers , i.e. on LibriSpeech , the synthesized speech is typically most similar to the ground truth voices .",Experiments,Speaker verification,text-to-speech_synthesis,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",68,0.6601941747572816,159,0.6489795918367347,8,0.6153846153846154,1,1,results
164,"On this 20 voice discrimination task we obtain an EER of 2.86 % , demonstrating that , while the synthetic speech tends to be close to the target speaker ( cosine similarity > 0.6 , and as in ) , it is nearly always even closer to other synthetic utterances for the same speaker ( similarity > 0.7 ) .",Experiments,Speaker verification,text-to-speech_synthesis,2,"['B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",72,0.6990291262135923,163,0.6653061224489796,12,0.9230769230769231,1,1,results
166,Speaker embedding space,Experiments,,text-to-speech_synthesis,2,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",74,0.7184466019417476,165,0.673469387755102,0,0.0,1,1,results
169,The PCA visualization ( left ) shows that synthesized utterances tend to lie very close to real speech from the same speaker in the embedding space .,Experiments,Speaker embedding space,text-to-speech_synthesis,2,"['O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",77,0.7475728155339806,168,0.6857142857142857,3,0.5,1,1,results
170,"However , synthetic utterances are still easily distinguishable from the real human speech as demonstrated by the t - SNE visualization ( right ) where utterances from each synthetic speaker form a distinct cluster adjacent to a cluster of real utterances from the corresponding speaker .",Experiments,Speaker embedding space,text-to-speech_synthesis,2,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,78,0.7572815533980582,169,0.689795918367347,4,0.6666666666666666,1,1,results
173,Number of speaker encoder training speakers,Experiments,,text-to-speech_synthesis,2,"['B', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",81,0.7864077669902912,172,0.7020408163265306,0,0.0,1,1,results
185,"As the number of training speakers increases , both naturalness and similarity improve significantly .",Experiments,Number of speaker encoder training speakers,text-to-speech_synthesis,2,"['B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O']","['B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O']",93,0.9029126213592233,184,0.7510204081632653,12,0.75,1,1,results
190,Fictitious speakers,Experiments,,text-to-speech_synthesis,2,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",98,0.9514563106796117,189,0.7714285714285715,0,0.0,1,1,results
191,Bypassing the speaker encoder network and conditioning the synthesizer on random points in the speaker embedding space results in speech from fictitious speakers which are not present in the train or test sets of either the synthesizer or the speaker encoder .,Experiments,Fictitious speakers,text-to-speech_synthesis,2,"['B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,99,0.9611650485436893,190,0.7755102040816326,1,0.2,1,1,results
4,"As a new way of training generative models , Generative Adversarial Net ( GAN ) that uses a discriminative model to guide the training of the generative model has enjoyed considerable success in generating real - valued data .",abstract,abstract,text_generation,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.125,3,0.009259259259259259,1,0.125,1,1,research-problem
5,"However , it has limitations when the goal is for generating sequences of discrete tokens .",abstract,abstract,text_generation,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",2,0.25,4,0.012345679012345678,2,0.25,1,1,research-problem
13,Generating sequential synthetic data that mimics the real one is an important problem in unsupervised learning .,Introduction,Introduction,text_generation,0,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.03571428571428571,12,0.037037037037037035,1,0.03571428571428571,1,1,research-problem
32,"In this paper , to address the above two issues , we follow ) and consider the sequence generation procedure as a sequential decision making process .",Introduction,Introduction,text_generation,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",20,0.7142857142857143,31,0.09567901234567901,20,0.7142857142857143,1,1,model
33,The generative model is treated as an agent of reinforcement learning ( RL ) ; the state is the generated tokens so far and the action is the next token to be generated .,Introduction,Introduction,text_generation,0,"['O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']",,,21,0.75,32,0.09876543209876543,21,0.75,1,1,model
34,"Unlike the work in ) that requires a task - specific sequence score , such as BLEU in machine translation , to give the reward , we employ a discriminator to evaluate the sequence and feedback the evaluation to guide the learning of the generative model .",Introduction,Introduction,text_generation,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",22,0.7857142857142857,33,0.10185185185185185,22,0.7857142857142857,1,1,model
35,"To solve the problem that the gradient can not pass back to the generative model when the output is discrete , we regard the generative model as a stochastic parametrized policy .",Introduction,Introduction,text_generation,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",23,0.8214285714285714,34,0.10493827160493827,23,0.8214285714285714,1,1,model
36,"In our policy gradient , we employ Monte Carlo ( MC ) search to approximate the state - action value .",Introduction,Introduction,text_generation,0,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",24,0.8571428571428571,35,0.10802469135802469,24,0.8571428571428571,1,1,model
37,"We directly train the policy ( generative model ) via policy gradient , which naturally avoids the differentiation difficulty for discrete data in a conventional GAN .",Introduction,Introduction,text_generation,0,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",25,0.8928571428571429,36,0.1111111111111111,25,0.8928571428571429,1,1,model
185,"To setup the synthetic data experiments , we first initialize the parameters of an LSTM network following the normal distribution N ( 0 , 1 ) as the oracle describing the real data distribution G oracle ( x t |x 1 , . . . , x t?1 ) .",Training Setting,Training Setting,text_generation,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.06666666666666667,184,0.5679012345679012,1,0.06666666666666667,1,1,hyperparameters
187,"In SeqGAN algorithm , the training set for the discriminator is comprised by the generated examples with the label 0 and the instances from S with the label",Training Setting,Training Setting,text_generation,0,"['B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'O', 'B']",,,3,0.2,186,0.5740740740740741,3,0.2,1,1,hyperparameters
189,"For different tasks , one should design specific structure for the convolutional layer and in our synthetic data experiments , the kernel size is from 1 to T and the number of each kernel size is between 100 to 200 3 . ",Training Setting,Training Setting,text_generation,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O']",,,5,0.3333333333333333,188,0.5802469135802469,5,0.3333333333333333,1,1,
190,Dropout ) and L2 regularization are used to avoid over-fitting .,Training Setting,Training Setting,text_generation,0,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",6,0.4,189,0.5833333333333334,6,0.4,1,1,hyperparameters
192,The first model is a random token generation .,Training Setting,Training Setting,text_generation,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.5333333333333333,191,0.5895061728395061,8,0.5333333333333333,1,1,baselines
193,The second one is the MLE trained LSTM G ? .,Training Setting,Training Setting,text_generation,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",9,0.6,192,0.5925925925925926,9,0.6,1,1,baselines
194,The third one is scheduled sampling .,Training Setting,Training Setting,text_generation,0,"['O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",10,0.6666666666666666,193,0.595679012345679,10,0.6666666666666666,1,1,baselines
195,The fourth one is the Policy Gradient with BLEU ( PG - BLEU ) .,Training Setting,Training Setting,text_generation,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.7333333333333333,194,0.5987654320987654,11,0.7333333333333333,1,1,baselines
196,"In the scheduled sampling , the training process gradually changes from a fully guided scheme feeding the true previous tokens into LSTM , towards a less guided scheme which mostly feeds the LSTM with its generated tokens .",Training Setting,Training Setting,text_generation,0,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",12,0.8,195,0.6018518518518519,12,0.8,1,1,hyperparameters
197,A curriculum rate ? is used to control the probability of replacing the true tokens with the generated ones .,Training Setting,Training Setting,text_generation,0,"['O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",13,0.8666666666666667,196,0.6049382716049383,13,0.8666666666666667,1,1,hyperparameters
202,"Since the evaluation metric is fundamentally instructive , we can see the impact of SeqGAN , which outperforms other baselines significantly .",Results,Results,text_generation,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.04,201,0.6203703703703703,2,0.2857142857142857,1,1,results
203,"A significance T - test on the NLL oracle score distribution of the generated sequences from the compared models is also performed , which demonstrates the significant improvement of SeqGAN over all compared models .",Results,Results,text_generation,0,"['O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'B', 'I', 'O']",,,3,0.06,202,0.6234567901234568,3,0.42857142857142855,1,1,results
205,"After about 150 training epochs , both the maximum likelihood estimation and the schedule sampling methods converge to a relatively high NLL oracle score , whereas SeqGAN can improve the limit of the generator with the same structure as the baselines significantly .",Results,Results,text_generation,0,"['B', 'I', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O']",5,0.1,204,0.6296296296296297,5,0.7142857142857143,1,1,results
206,This indicates the prospect of applying adversarial training strategies to discrete sequence generative models to breakthrough the limitations of MLE .,Results,Results,text_generation,0,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.12,205,0.6327160493827161,6,0.8571428571428571,1,1,results
207,"Additionally , SeqGAN outperforms PG - BLEU , which means the discriminative signal in GAN is more general and effective than a predefined score ( e.g. BLEU ) to guide the generative policy to capture the underlying distribution of the sequence data .",Results,Results,text_generation,0,"['O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.14,206,0.6358024691358025,7,1.0,1,1,results
2,Adversarial Ranking for Language Generation,title,title,text_generation,1,"['O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.0036496350364963502,1,0.0,1,1,research-problem
28,"In this paper , we propose a novel adversarial learning framework , RankGAN , for generating highquality language descriptions .",Introduction,"Therefore , the optimization of GANs is challenging .",text_generation,1,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",17,0.6538461538461539,27,0.09854014598540146,17,0.6538461538461539,1,1,model
29,RankGAN learns the model from the relative ranking information between the machine - written and the human - written sentences in an adversarial framework .,Introduction,"Therefore , the optimization of GANs is challenging .",text_generation,1,"['O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",18,0.6923076923076923,28,0.10218978102189781,18,0.6923076923076923,1,1,model
30,"In the proposed RankGAN , we relax the training of the discriminator to a learning - to - rank optimization problem .",Introduction,"Therefore , the optimization of GANs is challenging .",text_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.7307692307692307,29,0.10583941605839416,19,0.7307692307692307,1,1,model
31,"Specifically , the proposed new adversarial network consists of two neural network models , a generator and a ranker .",Introduction,"Therefore , the optimization of GANs is challenging .",text_generation,1,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",20,0.7692307692307693,30,0.10948905109489052,20,0.7692307692307693,1,1,model
32,"As opposed to performing a binary classification task , we propose to train the ranker to rank the machine - written sentences lower than human - written sentences with respect to a reference sentence which is human-written .",Introduction,"Therefore , the optimization of GANs is challenging .",text_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",21,0.8076923076923077,31,0.11313868613138686,21,0.8076923076923077,1,1,model
33,"Accordingly , we train the generator to synthesize sentences which confuse the ranker so that machine - written sentences are ranked higher than human - written sentences in regard to the reference .",Introduction,"Therefore , the optimization of GANs is challenging .",text_generation,1,"['O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.8461538461538461,32,0.11678832116788321,22,0.8461538461538461,1,1,model
34,"During learning , we adopt the policy gradient technique to overcome the non-differentiable problem .",Introduction,"Therefore , the optimization of GANs is challenging .",text_generation,1,"['B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",23,0.8846153846153846,33,0.12043795620437957,23,0.8846153846153846,1,1,model
35,"Consequently , by viewing a set of data samples collectively and evaluating their quality through relative ranking , the discriminator is able to make better assessment of the quality of the samples , which in turn helps the generator to learn better .",Introduction,"Therefore , the optimization of GANs is challenging .",text_generation,1,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'O']",24,0.9230769230769231,34,0.12408759124087591,24,0.9230769230769231,1,1,model
36,Our method is suitable for language learning in comparison to conventional GANs .,Introduction,"Therefore , the optimization of GANs is challenging .",text_generation,1,"['O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",25,0.9615384615384616,35,0.12773722627737227,25,0.9615384615384616,1,1,model
168,Simulation on synthetic data,Experimental results,,text_generation,1,"['O', 'B', 'B', 'I']","['O', 'B-p', 'B-n', 'I-n']","['O', 'B-p', 'B-b', 'I-b']",3,0.05263157894736842,167,0.6094890510948905,0,0.0,1,1,results
189,It can be seen that the proposed RankGAN performs more favourably against the compared methods .,Experimental results,These two methods are fundamentally different .,text_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",24,0.42105263157894735,188,0.6861313868613139,21,0.6176470588235294,1,1,results
191,"While MLE , PG - BLEU and SeqGAN tend to converge after 200 training epochs , the proposed RankGAN consistently improves the language generator and achieves relatively lower NLL score .",Experimental results,These two methods are fundamentally different .,text_generation,1,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-ob', 'I-ob', 'O']",26,0.45614035087719296,190,0.6934306569343066,23,0.6764705882352942,1,1,results
193,It is worth noting that the proposed RankGAN achieves better performance than that of PG - BLEU .,Experimental results,These two methods are fundamentally different .,text_generation,1,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",28,0.49122807017543857,192,0.7007299270072993,25,0.7352941176470589,1,1,results
203,Results on Chinese poems composition,Experimental results,,text_generation,1,"['O', 'O', 'B', 'I', 'I']","['O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'B-b', 'I-b', 'I-b']",38,0.6666666666666666,202,0.7372262773722628,0,0.0,1,1,results
209,"Following the evaluation protocol in , we compute the BLEU - 2 score and estimate the similarity between the human - written poem and the machine - created one .",Experimental results,Results on Chinese poems composition,text_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",44,0.7719298245614035,208,0.7591240875912408,6,0.16666666666666666,1,1,results
211,It can be seen that the proposed Rank GAN performs more favourably compared to the state - of - the - art methods in terms of BLEU - 2 score .,Experimental results,Results on Chinese poems composition,text_generation,1,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",46,0.8070175438596491,210,0.7664233576642335,8,0.2222222222222222,1,1,results
238,RankGAN outperforms the compared method in terms of the human evaluation score .,SeqGAN ( Baseline ),This bathroom has brown bench .,text_generation,1,"['B', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O']",15,0.3409090909090909,237,0.864963503649635,35,0.9722222222222222,1,1,results
240,Results on COCO image captions,SeqGAN ( Baseline ),,text_generation,1,"['O', 'O', 'B', 'I', 'I']","['O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'B-b', 'I-b', 'I-b']",17,0.38636363636363635,239,0.8722627737226277,0,0.0,1,1,results
249,RankGAN achieves better performance than the other methods in terms of different BLEU scores .,SeqGAN ( Baseline ),Results on COCO image captions,text_generation,1,"['B', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",26,0.5909090909090909,248,0.9051094890510949,9,0.3333333333333333,1,1,results
251,"These examples show that our model is able to generate fluent , novel sentences that are not existing in the training set .",SeqGAN ( Baseline ),Results on COCO image captions,text_generation,1,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",28,0.6363636363636364,250,0.9124087591240876,11,0.4074074074074074,1,1,results
257,"As can be seen , the human - written sentences get the highest score comparing to the language models .",SeqGAN ( Baseline ),Results on COCO image captions,text_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",34,0.7727272727272727,256,0.9343065693430657,17,0.6296296296296297,1,1,results
258,"Among the GANs approaches , RankGAN receives better score than SeqGAN , which is consistent to the finding in the Chinese poem composition .",SeqGAN ( Baseline ),Results on COCO image captions,text_generation,1,"['B', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",35,0.7954545454545454,257,0.9379562043795621,18,0.6666666666666666,1,1,results
260,Results on Shakespeare 's plays,SeqGAN ( Baseline ),,text_generation,1,"['O', 'O', 'B', 'I', 'I']","['O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'B-b', 'I-b', 'I-b']",37,0.8409090909090909,259,0.9452554744525548,20,0.7407407407407407,1,1,results
266,"As can be seen , the proposed method achieves consistently higher BLEU score than the other methods in terms of the different n-grams criteria .",SeqGAN ( Baseline ),Results on Shakespeare 's plays,text_generation,1,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",43,0.9772727272727273,265,0.9671532846715328,26,0.9629629629629629,1,1,results
267,"The results indicate the proposed RankGAN is able to capture the transition pattern among the words , even if the training sentences are novel , delicate and complicated .",SeqGAN ( Baseline ),Results on Shakespeare 's plays,text_generation,1,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",44,1.0,266,0.9708029197080292,27,1.0,1,1,results
2,Long Text Generation via Adversarial Training with Leaked Information,title,,text_generation,2,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.002857142857142857,1,0.0,1,1,research-problem
4,"Automatically generating coherent and semantically meaningful text has many applications in machine translation , dialogue systems , image captioning , etc .",abstract,abstract,text_generation,2,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.1111111111111111,3,0.008571428571428572,1,0.1111111111111111,1,1,research-problem
33,"In this paper , we propose a new algorithmic framework called Leak GAN to address both the non-informativeness and the sparsity issues .",Introduction,Introduction,text_generation,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",20,0.5405405405405406,32,0.09142857142857143,20,0.5405405405405406,1,1,approach
34,LeakGAN is a new way of providing richer information from the discriminator to the generator by borrowing the recent advances in hierarchical reinforcement learning .,Introduction,Introduction,text_generation,2,"['B', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",21,0.5675675675675675,33,0.09428571428571429,21,0.5675675675675675,1,1,approach
35,"As illustrated in , we specifically introduce a hierarchical generator G , which consists of a high - level MANAGER module and a low - level WORKER module .",Introduction,Introduction,text_generation,2,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",22,0.5945945945945946,34,0.09714285714285714,22,0.5945945945945946,1,1,approach
36,The MANAGER is along shortterm memory network ( LSTM ) and serves as a mediator .,Introduction,Introduction,text_generation,2,"['O', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",23,0.6216216216216216,35,0.1,23,0.6216216216216216,1,1,approach
37,"In each step , it receives generator D 's high - level feature representation , e.g. , the feature map of the CNN , and uses it to form the guiding goal for the WORKER module in that timestep .",Introduction,Introduction,text_generation,2,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O']",24,0.6486486486486487,36,0.10285714285714286,24,0.6486486486486487,1,1,approach
40,"Next , given the goal embedding produced by the MAN - AGER , the WORKER first encodes current generated words with another LSTM , then combines the output of the LSTM and the goal embedding to take a final action at current state .",Introduction,Introduction,text_generation,2,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",27,0.7297297297297297,39,0.11142857142857143,27,0.7297297297297297,1,1,approach
163,GAN Setting .,Training Settings,Synthetic Oracle .,text_generation,2,"['B', 'I', 'O']","['B-n', 'I-n', 'O']","['B-b', 'I-b', 'O']",4,0.2857142857142857,162,0.46285714285714286,4,0.2222222222222222,1,1,hyperparameters
164,"For the discriminator , we choose the CNN architecture as the feature extractor and the binary classifier .",Training Settings,Synthetic Oracle .,text_generation,2,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.35714285714285715,163,0.4657142857142857,5,0.2777777777777778,1,1,hyperparameters
166,"For the synthetic data experiment , the CNN kernel size ranges from 1 to T .",Training Settings,Synthetic Oracle .,text_generation,2,"['B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.5,165,0.4714285714285714,7,0.3888888888888889,1,1,hyperparameters
167,The number of each kernel is between 100 and 200 .,Training Settings,Synthetic Oracle .,text_generation,2,"['O', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.5714285714285714,166,0.4742857142857143,8,0.4444444444444444,1,1,hyperparameters
168,"In this case , the feature of text is a 1,720 dimensional vector .",Training Settings,Synthetic Oracle .,text_generation,2,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.6428571428571429,167,0.47714285714285715,9,0.5,1,1,hyperparameters
169,Dropout with the keep rate 0.75 and L2 regularization are performed to avoid overfitting .,Training Settings,Synthetic Oracle .,text_generation,2,"['B', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'O']","['B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'O']",10,0.7142857142857143,168,0.48,10,0.5555555555555556,1,1,hyperparameters
170,"For the generator , we adopt LSTM as the architectures of MANAGER and WORKER to capture the sequence context information .",Training Settings,Synthetic Oracle .,text_generation,2,"['O', 'O', 'B', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'O', 'O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'O', 'O', 'B-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",11,0.7857142857142857,169,0.4828571428571429,11,0.6111111111111112,1,1,hyperparameters
171,The MANAGER produces the 16 - dimensional goal embedding feature vector wt using the feature map extracted by CNN .,Training Settings,Synthetic Oracle .,text_generation,2,"['O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'O']","['O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",12,0.8571428571428571,170,0.4857142857142857,12,0.6666666666666666,1,1,hyperparameters
172,The goal duration time c is a hyperparameter set as 4 after some preliminary experiments .,Training Settings,Synthetic Oracle .,text_generation,2,"['O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",13,0.9285714285714286,171,0.48857142857142855,13,0.7222222222222222,1,1,hyperparameters
178,Synthetic Data Experiments,,,text_generation,2,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",0,0.0,177,0.5057142857142857,0,0.0,1,1,results
182,"( i ) In the pre-training stage , LeakGAN has already shown observable performance superiority compared to other models , which indicates that the proposed hierarchical architecture itself brings improvement over the previous ones .",Synthetic Data Experiments,Synthetic Data Experiments,text_generation,2,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.06451612903225806,181,0.5171428571428571,4,0.1111111111111111,1,1,results
183,"( ii ) In the adversarial training stage , Leak GAN shows a better speed of convergence , and the local minimum it explores is significantly better than previous results .",Synthetic Data Experiments,Synthetic Data Experiments,text_generation,2,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",5,0.08064516129032258,182,0.52,5,0.1388888888888889,1,1,results
185,Long Text Generation : EMNLP2017 WMT News,Synthetic Data Experiments,Synthetic Data Experiments,text_generation,2,"['B', 'I', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",7,0.11290322580645161,184,0.5257142857142857,7,0.19444444444444445,1,1,results
196,"In all measured metrics , LeakGAN shows significant performance gain compared to baseline models .",Synthetic Data Experiments,Synthetic Data Experiments,text_generation,2,"['B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",18,0.2903225806451613,195,0.5571428571428572,18,0.5,1,1,results
198,Middle Text Generation : COCO Image Captions,Synthetic Data Experiments,,text_generation,2,"['B', 'I', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",20,0.3225806451612903,197,0.5628571428571428,20,0.5555555555555556,1,1,results
208,The results of the BLEU scores on the COCO dataset indicate that Leak GAN performs significantly better than baseline models in mid-length text generation task .,Synthetic Data Experiments,Middle Text Generation : COCO Image Captions,text_generation,2,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",30,0.4838709677419355,207,0.5914285714285714,30,0.8333333333333334,1,1,results
209,Short Text Generation : Chinese Poems,Synthetic Data Experiments,,text_generation,2,"['B', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",31,0.5,208,0.5942857142857143,31,0.8611111111111112,1,1,results
214,The results on Chinese Poems indicate that LeakGAN successfully handles the short text generation tasks .,Synthetic Data Experiments,Short Text Generation : Chinese Poems,text_generation,2,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",36,0.5806451612903226,213,0.6085714285714285,36,1.0,1,1,results
223,Turing Test and Generated Samples,Synthetic Data Experiments,,text_generation,2,"['B', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b']",45,0.7258064516129032,222,0.6342857142857142,0,0.0,1,1,results
231,The performance on two datasets indicates that the generated sentences of Leak GAN are of higher global consistency and better readability than those of SeqGAN .,Synthetic Data Experiments,Turing Test and Generated Samples,text_generation,2,"['O', 'B', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'O']",,,53,0.8548387096774194,230,0.6571428571428571,8,0.47058823529411764,1,1,results
2,An Auto - Encoder Matching Model for Learning Utterance - Level Semantic Dependency in Dialogue Generation,title,title,text_generation,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.0070921985815602835,1,0.0,1,1,research-problem
12,"Automatic dialogue generation task is of great importance to many applications , ranging from open - domain chatbots to goal - oriented technical support agents .",Introduction,Introduction,text_generation,3,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.047619047619047616,11,0.07801418439716312,1,0.047619047619047616,1,1,research-problem
20,"However , conversation generation is a much more complex and flexible task as there are less "" word - to - words "" relations between inputs and responses .",Introduction,Introduction,text_generation,3,"['O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.42857142857142855,19,0.1347517730496454,9,0.42857142857142855,1,1,research-problem
24,"To address this problem , we propose a novel Auto - Encoder Matching model to learn utterance - level dependency .",Introduction,Introduction,text_generation,3,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.6190476190476191,23,0.16312056737588654,13,0.6190476190476191,1,1,model
25,"First , motivated by , we use two auto- encoders to learn the semantic representations of inputs and responses in an unsupervised style .",Introduction,Introduction,text_generation,3,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",14,0.6666666666666666,24,0.1702127659574468,14,0.6666666666666666,1,1,model
26,"Second , given the utterance - level representations , the mapping module is taught to learn the utterance - level dependency .",Introduction,Introduction,text_generation,3,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.7142857142857143,25,0.1773049645390071,15,0.7142857142857143,1,1,model
86,"For dialogue generation , we set the maximum length to 15 words for each generated sentence .",Experimental Details,Experimental Details,text_generation,3,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.125,85,0.6028368794326241,1,0.125,1,1,hyperparameters
87,"Based on the performance on the validation set , we set the hidden size to 512 , embedding size to 64 and vocabulary size to 40 K for baseline models and the proposed model .",Experimental Details,Experimental Details,text_generation,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'O', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.25,86,0.6099290780141844,2,0.25,1,1,hyperparameters
88,"The parameters are updated by the Adam algorithm ( Kingma and Ba , 2014 ) and initialized by sampling from the uniform distribution ( [? 0.1 , 0.1 ] ) .",Experimental Details,Experimental Details,text_generation,3,"['O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.375,87,0.6170212765957447,3,0.375,1,1,hyperparameters
89,The initial learning rate is 0.002 and the model is trained in minibatches with a batch size of 256 . ? 1 and ?,Experimental Details,Experimental Details,text_generation,3,"['O', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O']",4,0.5,88,0.624113475177305,4,0.5,1,1,hyperparameters
97,The proposed AEM model significantly outperforms the Seq2Seq model .,Results,Results,text_generation,3,"['O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",3,0.06976744186046512,96,0.6808510638297872,3,0.08333333333333333,1,1,results
98,It demonstrates the effectiveness of utterance - level dependency on improving the quality of generated text .,Results,Results,text_generation,3,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.09302325581395349,97,0.6879432624113475,4,0.1111111111111111,1,1,results
100,The improvement from the AEM model to the AEM + Attention model 2 is 0.68 BLEU - 4 point .,Results,Results,text_generation,3,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.13953488372093023,99,0.7021276595744681,6,0.16666666666666666,1,1,results
104,We find that the AEM model achieves significant improvement on the diversity of generated text .,Results,Results,text_generation,3,"['O', 'B', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.23255813953488372,103,0.7304964539007093,10,0.2777777777777778,1,1,results
106,"Also , it should be noticed that the attention mechanism performs almost the same compared to the AEM model ( 31.2 K vs. 34.6 K in terms of Dist - 3 ) , which indicates that the utterance - level dependency and the word - level dependency are both indispensable for dialogue generation .",Results,Results,text_generation,3,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.27906976744186046,105,0.7446808510638298,12,0.3333333333333333,1,1,results
107,"Therefore , by combining the two dependencies together , the AEM + Attention model achieves the best results .",Results,Results,text_generation,3,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",13,0.3023255813953488,106,0.75177304964539,13,0.3611111111111111,1,1,results
120,shows the results of human evaluation .,Results,Results,text_generation,3,"['O', 'O', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O']",26,0.6046511627906976,119,0.8439716312056738,26,0.7222222222222222,1,1,results
121,The inter-annotator agreement is satisfactory considering the difficulty of human evaluation .,Results,Results,text_generation,3,"['O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",27,0.627906976744186,120,0.851063829787234,27,0.75,1,1,results
122,"The Pearson 's correlation coefficient is 0.69 on coherence and 0.57 on fluency , with p < 0.0001 .",Results,Results,text_generation,3,"['O', 'B', 'I', 'I', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O']",,,28,0.6511627906976745,121,0.8581560283687943,28,0.7777777777777778,1,1,results
123,"First , it is clear that the AEM model outperforms the Seq2Seq model with a large margin , which proves the effectiveness of the AEM model on generating high quality responses .",Results,Results,text_generation,3,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",29,0.6744186046511628,122,0.8652482269503546,29,0.8055555555555556,1,1,results
124,"Second , it is interesting to note that with the attention mechanism , the coherence is decreased slightly in the Seq2Seq model but increased significantly in the AEM model .",Results,Results,text_generation,3,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",30,0.6976744186046512,123,0.8723404255319149,30,0.8333333333333334,1,1,results
126,"Therefore , it is expected that the AEM + Attention model achieves the best G-score .",Results,Results,text_generation,3,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",32,0.7441860465116279,125,0.8865248226950354,32,0.8888888888888888,1,1,results
2,Generating Text through Adversarial Training using Skip - Thought Vectors,title,title,text_generation,4,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.009174311926605505,1,0.0,1,1,research-problem
7,Attempts have been made for utilizing GANs with word embeddings for text generation .,abstract,abstract,text_generation,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",4,0.6666666666666666,6,0.05504587155963303,4,0.6666666666666666,1,1,research-problem
11,Numerous efforts have been made in the field of natural language text generation for tasks such as sentiment analysis and machine translation .,Introduction,Introduction,text_generation,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,10,0.09174311926605505,1,0.14285714285714285,1,1,research-problem
14,This work pro-Code available at : https://github.com/enigmaeth/skip-thought-gan poses an approach for text generation using Generative Adversarial Networks with Skip - Thought vectors .,Introduction,Introduction,text_generation,4,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.5714285714285714,13,0.11926605504587157,4,0.5714285714285714,1,1,code
71,The Skip - Thought encoder for the model encodes sentences with length less than 30 words using 2400 GRU units with word vector dimensionality of 620 to produce 4800 - dimensional combineskip vectors . .,Model Architecture,Model Architecture,text_generation,4,"['O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O']",,,3,0.5,70,0.6422018348623854,3,0.5,1,1,hyperparameters
72,"The combine - skip vectors , with the first 2400 dimensions being uni-skip model and the last 2400 bi-skip model , are used as they have been found to be the best performing in the experiments",Model Architecture,Model Architecture,text_generation,4,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",4,0.6666666666666666,71,0.6513761467889908,4,0.6666666666666666,1,1,hyperparameters
2,Improved Variational Autoencoders for Text Modeling using Dilated Convolutions,title,title,text_generation,5,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O']",1,0.0,1,0.003389830508474576,1,0.0,1,1,research-problem
4,"Recent work on generative text modeling has found that variational autoencoders ( VAE ) with LSTM decoders perform worse than simpler LSTM language models ( Bowman et al. , 2015 ) .",abstract,abstract,text_generation,5,"['O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.125,3,0.010169491525423728,1,0.125,1,1,research-problem
33,"We propose the use of a dilated CNN as a decoder in VAE , inspired by the recent success of using CNNs for audio , image and language modeling ( van den .",Introduction,Copyright 2017 by the author ( s ) .,text_generation,5,"['O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",21,0.65625,32,0.10847457627118644,21,0.65625,1,1,model
34,"In contrast with prior work where extremely large CNNs are used , we exploit the dilated CNN for its flexibility in varying the amount of conditioning context .",Introduction,Copyright 2017 by the author ( s ) .,text_generation,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",22,0.6875,33,0.11186440677966102,22,0.6875,1,1,model
154,We use an LSTM as an encoder for VAE and explore LSTMs and CNNs as decoders .,Experiments,Model configurations and Training details,text_generation,5,"['O', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'O']",,,9,0.23076923076923078,153,0.5186440677966102,1,0.03225806451612903,1,1,hyperparameters
155,"For CNNs , we explore several different configurations .",Experiments,,text_generation,5,"['B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.2564102564102564,154,0.5220338983050847,2,0.06451612903225806,1,1,hyperparameters
156,"We set the convolution filter size to be 3 and gradually increase the depth and dilation from [ 1 , 2 , 4 ] , ] to .",Experiments,"For CNNs , we explore several different configurations .",text_generation,5,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.28205128205128205,155,0.5254237288135594,3,0.0967741935483871,1,1,hyperparameters
165,We use Gumbel - softmax to sample y from q ( y|x ) .,Experiments,"For CNNs , we explore several different configurations .",text_generation,5,"['O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",20,0.5128205128205128,164,0.5559322033898305,12,0.3870967741935484,1,1,hyperparameters
168,We use a vocabulary size of 20 k for both data sets and set the word embedding dimension to be 512 .,Experiments,"For CNNs , we explore several different configurations .",text_generation,5,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",23,0.5897435897435898,167,0.5661016949152542,15,0.4838709677419355,1,1,hyperparameters
170,"The number of channels for convolutions in CNN decoders is 512 internally and 1024 externally , as shown in Section 2.3 .",Experiments,The LSTM dimension is 1024 .,text_generation,5,"['O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",25,0.6410256410256411,169,0.5728813559322034,17,0.5483870967741935,1,1,hyperparameters
173,"We use Adam to optimize all models and the learning rate is selected from [ 2e - 3 , 1 e - 3 , 7.5 e - 4 ] and ?",Experiments,We select the dimension of z from .,text_generation,5,"['O', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",28,0.717948717948718,172,0.5830508474576271,20,0.6451612903225806,1,1,hyperparameters
175,"Empirically , we find learning rate 1e - 3 and ?1 = 0.5 to perform the best .",Experiments,We select the dimension of z from .,text_generation,5,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",30,0.7692307692307693,174,0.5898305084745763,22,0.7096774193548387,1,1,hyperparameters
176,"We select dropout ratio of LSTMs ( both encoder and decoder ) from [ 0.3 , 0.5 ] .",Experiments,We select the dimension of z from .,text_generation,5,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",31,0.7948717948717948,175,0.5932203389830508,23,0.7419354838709677,1,1,hyperparameters
177,"Following , we also use drop word for the LSTM decoder , the drop word ratio is selected from [ 0 , 0.3 , 0.5 , 0.7 ] .",Experiments,We select the dimension of z from .,text_generation,5,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",32,0.8205128205128205,176,0.5966101694915255,24,0.7741935483870968,1,1,hyperparameters
178,"For the CNN decoder , we use a dropout ratio of 0.1 at each layer .",Experiments,We select the dimension of z from .,text_generation,5,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",33,0.8461538461538461,177,0.6,25,0.8064516129032258,1,1,hyperparameters
180,We use batch size of 32 and all model are trained for 40 epochs .,Experiments,We select the dimension of z from .,text_generation,5,"['O', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",35,0.8974358974358975,179,0.6067796610169491,27,0.8709677419354839,1,1,hyperparameters
182,"Following , we use KL cost annealing strategy .",Experiments,,text_generation,5,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",37,0.9487179487179487,181,0.6135593220338983,29,0.9354838709677419,1,1,hyperparameters
183,We set the initial weight of KL cost term to be 0.01 and increase it linearly until a given iteration T .,Experiments,"Following , we use KL cost annealing strategy .",text_generation,5,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",38,0.9743589743589743,182,0.6169491525423729,30,0.967741935483871,1,1,hyperparameters
186,The results for language modeling are shown in .,Language modeling results,,text_generation,5,"['O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O']",1,0.0196078431372549,185,0.6271186440677966,1,0.041666666666666664,1,1,results
191,"For SCNN , MCNN and LCNN , the VAE results improve over LM results from 345.3 to 337.8 , 338.3 to 336.2 , and 335.4 to 333.9 respectively .",Language modeling results,The results for language modeling are shown in .,text_generation,5,"['B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'B', 'B', 'B', 'O', 'O']",,,6,0.11764705882352941,190,0.6440677966101694,6,0.25,1,1,results
195,"When LCNN is used as the decoder , we obtain an optimal trade off between using contextual information and latent representation .",Language modeling results,The results for language modeling are shown in .,text_generation,5,"['B', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.19607843137254902,194,0.6576271186440678,10,0.4166666666666667,1,1,results
196,"LCNN - VAE achieves a NLL of 333.9 , which improves over LSTM - LM with NLL of 334.9 .",Language modeling results,The results for language modeling are shown in .,text_generation,5,"['B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'O']",,,11,0.21568627450980393,195,0.6610169491525424,11,0.4583333333333333,1,1,results
216,We can see that SCNN - VAE - Semi has the best classification accuracy of 65.5 .,Language modeling results,Accuracy is in percentage .,text_generation,5,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",31,0.6078431372549019,215,0.7288135593220338,6,0.23076923076923078,1,1,ablation-analysis
218,"On the other hand , LCNN - VAE - Semi has the best NLL result .",Language modeling results,Accuracy is in percentage .,text_generation,5,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",33,0.6470588235294118,217,0.735593220338983,8,0.3076923076923077,1,1,ablation-analysis
2,Abstractive Text Summarization by Incorporating Reader Comments,title,title,text_summarization,0,"['B', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.0033222591362126247,1,0.0,1,1,research-problem
4,"In neural abstractive summarization field , conventional sequence - to - sequence based models often suffer from summarizing the wrong aspect of the document with respect to the main aspect .",abstract,abstract,text_summarization,0,"['O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.08333333333333333,3,0.009966777408637873,1,0.08333333333333333,1,1,research-problem
5,"To tackle this problem , we propose the task of reader - aware abstractive summary generation , which utilizes the reader comments to help the model produce better summary about the main aspect .",abstract,abstract,text_summarization,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.16666666666666666,4,0.013289036544850499,2,0.16666666666666666,1,1,research-problem
6,"Unlike traditional abstractive summarization task , reader - aware summarization confronts two main challenges :",abstract,abstract,text_summarization,0,"['O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.25,5,0.016611295681063124,3,0.25,1,1,research-problem
51,"In this paper , we propose a summarization framework named reader - aware summary generator ( RASG ) that incorporates reader comments to improve the summarization performance .",Introduction,"However , its development path is not smooth .",text_summarization,0,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",35,0.7,50,0.16611295681063123,35,0.7,1,1,model
52,"Specifically , a seq2seq architecture with attention mechanism is employed as the basic summary generator .",Introduction,"However , its development path is not smooth .",text_summarization,0,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",36,0.72,51,0.16943521594684385,36,0.72,1,1,model
53,"We first calculate alignment between the reader comments words and document words , and this alignment information is regarded as reader attention representing the "" reader focused aspect "" .",Introduction,"However , its development path is not smooth .",text_summarization,0,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",37,0.74,52,0.17275747508305647,37,0.74,1,1,model
54,"Then , we treat the decoder attention weights as the focused aspect of the generated summary , a.k.a. , "" decoder focused aspect "" .",Introduction,"However , its development path is not smooth .",text_summarization,0,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",38,0.76,53,0.1760797342192691,38,0.76,1,1,model
55,"After each decoding step , a supervisor is designed to measure the distance between the reader focused aspect and the decoder focused aspect .",Introduction,"However , its development path is not smooth .",text_summarization,0,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'O', 'B-p', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'O', 'B-p', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",39,0.78,54,0.17940199335548174,39,0.78,1,1,model
57,The training of our framework RASG is conducted in an adversarial way .,Introduction,"However , its development path is not smooth .",text_summarization,0,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",41,0.82,56,0.18604651162790697,41,0.82,1,1,model
224,( 1 ) S2S : Sequence - to - sequence framework has been proposed for language generation task .,Comparison methods,Comparison methods,text_summarization,0,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.375,223,0.7408637873754153,3,0.375,1,1,baselines
225,"( 2 ) S2SR : We simply add the reader attention on attention distribution ? t , in each decoding step .",Comparison methods,Comparison methods,text_summarization,0,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",4,0.5,224,0.7441860465116279,4,0.5,1,1,baselines
226,"( 3 ) CGU : propose to use the convolutional gated unit to refine the source representation , which achieves the state - of - the - art performance on social media text summarization dataset .",Comparison methods,Comparison methods,text_summarization,0,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.625,225,0.7475083056478405,5,0.625,1,1,baselines
227,"( 4 ) LEAD1 : LEAD1 is a commonly used baseline , which selects the first sentence of document as the summary .",Comparison methods,Comparison methods,text_summarization,0,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.75,226,0.7508305647840532,6,0.75,1,1,baselines
228,"( 5 ) TextRank : propose to build a graph , then add each sentence as a vertex and use link to represent semantic similarity .",Comparison methods,Comparison methods,text_summarization,0,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",7,0.875,227,0.7541528239202658,7,0.875,1,1,baselines
231,We implement our experiments in TensorFlow ) on an NVIDIA P40 GPU .,Implementation details,Implementation details,text_summarization,0,"['O', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.2,230,0.7641196013289037,1,0.2,1,1,experimental-setup
232,The word embedding dimension is set to 256 and the number of hidden units is 512 .,Implementation details,Implementation details,text_summarization,0,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-ob', 'O']",2,0.4,231,0.7674418604651163,2,0.4,1,1,experimental-setup
234,We use Adagrad optimizer as our optimizing algorithm .,Implementation details,,text_summarization,0,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",4,0.8,233,0.7740863787375415,4,0.8,1,1,experimental-setup
235,We employ beam search with beam size 5 to generate more fluency summary sentence .,Implementation details,We use Adagrad optimizer as our optimizing algorithm .,text_summarization,0,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,1.0,234,0.7774086378737541,5,1.0,1,1,experimental-setup
240,"We see that RASG achieves a 11.0 % , 9.1 % and 6.6 % increment over the state - of - the - art method CGU in terms of ROUGE - 1 , ROUGE - 2 and ROUGE - L respectively .",Experimental Results,Overall performance,text_summarization,0,"['O', 'B', 'I', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'B-p', 'I-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-p', 'I-p', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",4,0.5714285714285714,239,0.7940199335548173,3,0.5,1,1,results
241,It is worth noticing that the baseline model S2SR achieves better performance than S2S which demonstrates the effectiveness of incorporating reader focused aspect in summary generation .,Experimental Results,Overall performance,text_summarization,0,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.7142857142857143,240,0.7973421926910299,4,0.6666666666666666,1,1,results
247,The discriminator provides the scalar training signal L g c for generator training and the feature vector F ( m t ) for goal tracker .,Ablation study,"Next , we turn to research question RQ2 .",text_summarization,0,"['O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']",,,3,0.10344827586206896,246,0.8172757475083057,3,0.375,1,1,ablation-analysis
248,"Consequently , there is an increment of 17.51 % from RASG w / o GTD to RASG w / o GT in terms of ROUGE - L , which demonstrates the effectiveness of discriminator .",Ablation study,"Next , we turn to research question RQ2 .",text_summarization,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.13793103448275862,247,0.8205980066445183,4,0.5,1,1,ablation-analysis
249,"As for the effectiveness of goal tracker , compared with RASG and RASG w / o GT , RASG w/ o GTD offers a decrease of 45. 23 % and 17.88 % in terms of ROUGE - 1 , respectively .",Ablation study,"Next , we turn to research question RQ2 .",text_summarization,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",5,0.1724137931034483,248,0.8239202657807309,5,0.625,1,1,ablation-analysis
252,"Finally , RASG w/o DM offers a decrease of 10 . 22 % compared with RASG in terms of ROUGE - L , which demonstrates the effectiveness of denoising module .",Ablation study,"Next , we turn to research question RQ2 .",text_summarization,0,"['O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.27586206896551724,251,0.8338870431893688,8,1.0,1,1,ablation-analysis
2,Mixture Content Selection for Diverse Sequence Generation,title,,text_summarization,1,"['O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.004166666666666667,1,0.0,1,1,research-problem
4,Generating diverse sequences is important in many NLP applications such as question generation or summarization that exhibit semantically one - to - many relationships between source and the target sequences .,abstract,abstract,text_summarization,1,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.14285714285714285,3,0.0125,1,0.14285714285714285,1,1,research-problem
12,Generating target sequences given a source sequence has applications in a wide range of problems in NLP with different types of relationships between the source and target sequences .,Introduction,Introduction,text_summarization,1,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.029411764705882353,11,0.04583333333333333,1,0.029411764705882353,1,1,research-problem
30,"Encoder - decoder models are widely used for sequence generation , most notably in machine translation where neural models are now often almost as good as human translators in some language pairs .",Introduction,Introduction,text_summarization,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",19,0.5588235294117647,29,0.12083333333333333,19,0.5588235294117647,1,1,research-problem
34,"In this paper , we present a method for diverse generation that separates diversification and generation stages .",Introduction,Introduction,text_summarization,1,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",23,0.6764705882352942,33,0.1375,23,0.6764705882352942,1,1,model
35,"The diversification stage leverages content selection to map the source to multiple sequences , where each mapping is modeled by focusing on different tokens in the source ( oneto - many mapping ) .",Introduction,Introduction,text_summarization,1,"['O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",24,0.7058823529411765,34,0.14166666666666666,24,0.7058823529411765,1,1,model
36,The generation stage uses a standard encoder - decoder model to generate a target sequence given each selected content from the source ( one - to - one mapping ) .,Introduction,Introduction,text_summarization,1,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",25,0.7352941176470589,35,0.14583333333333334,25,0.7352941176470589,1,1,model
37,We present a generic module called SELECTOR that is specialized for diversification .,Introduction,Introduction,text_summarization,1,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'O', 'B', 'I', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O']",26,0.7647058823529411,36,0.15,26,0.7647058823529411,1,1,model
38,This module can be used as a plug - and - play to an arbitrary encoder - decoder model for generation without architecture change .,Introduction,Introduction,text_summarization,1,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,0.7941176470588235,37,0.15416666666666667,27,0.7941176470588235,1,1,model
161,Beam Search,Baselines,,text_summarization,1,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",7,0.1891891891891892,160,0.6666666666666666,7,0.1891891891891892,1,1,baselines
162,This baseline keeps K hypotheses with highest log-probability scores at each decoding step .,Baselines,Beam Search,text_summarization,1,"['O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.21621621621621623,161,0.6708333333333333,8,0.21621621621621623,1,1,baselines
163,Truncated Sampling,Baselines,,text_summarization,1,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",9,0.24324324324324326,162,0.675,9,0.24324324324324326,1,1,baselines
164,This baseline randomly samples words from top - 10 candidates of the distribution at the decoding step .,Baselines,Truncated Sampling,text_summarization,1,"['O', 'O', 'B', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",10,0.2702702702702703,163,0.6791666666666667,10,0.2702702702702703,1,1,baselines
165,Mixture Decoder,Baselines,,text_summarization,1,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",11,0.2972972972972973,164,0.6833333333333333,11,0.2972972972972973,1,1,baselines
166,This baseline constructs a hard - MoE of K decoders with uniform mixing coefficient ( referred as hMup in ) and conducts parallel greedy decoding .,Baselines,Mixture Decoder,text_summarization,1,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.32432432432432434,165,0.6875,12,0.32432432432432434,1,1,baselines
168,Mixture Selector ( Ours ),Baselines,Mixture Decoder,text_summarization,1,"['B', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b']",14,0.3783783783783784,167,0.6958333333333333,14,0.3783783783783784,1,1,baselines
169,We construct a hard - MoE of K SELECTORs with uniform mixing coefficient that infers K different focus from source sequence .,Baselines,Mixture Decoder,text_summarization,1,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.40540540540540543,168,0.7,15,0.40540540540540543,1,1,baselines
201,"For all experiments , we tie the weights of the encoder embedding , the decoder embedding , and the decoder output layers .",Implementation details,Implementation details,text_summarization,1,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.16666666666666666,200,0.8333333333333334,1,0.16666666666666666,1,1,experimental-setup
203,We train up to 20 epochs and select the checkpoint with the best oracle metric .,Implementation details,Implementation details,text_summarization,1,"['O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",3,0.5,202,0.8416666666666667,3,0.5,1,1,experimental-setup
204,"We use Adam ( Kingma and Ba , 2015 ) optimizer with learning rate 0.001 and momentum parmeters ? 1 = 0.9 and ? 2 = 0.999 . ",Implementation details,Implementation details,text_summarization,1,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']",,,4,0.6666666666666666,203,0.8458333333333333,4,0.6666666666666666,1,1,
205,Minibatch size is 64 and 32 for question generation and abstractive summarization .,Implementation details,Implementation details,text_summarization,1,"['B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.8333333333333334,204,0.85,5,0.8333333333333334,1,1,experimental-setup
206,"All models are implemented in PyTorch and trained on single Tesla P40 GPU , based on NAVER Smart Machine Learning ( NSML ) platform .",Implementation details,Implementation details,text_summarization,1,"['O', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,1.0,205,0.8541666666666666,6,1.0,1,1,experimental-setup
208,Diversity vs. Accuracy Trade - off compare our method with different diversitypromoting techniques in question generation and abstractive summarization .,Results,Results,text_summarization,1,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.038461538461538464,207,0.8625,1,0.16666666666666666,1,1,results
209,The tables show that our mixture SELECTOR method outperforms all baselines in Top - 1 and oracle metrics and achieves the best trade - off between diversity and accuracy .,Results,Results,text_summarization,1,"['O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.07692307692307693,208,0.8666666666666667,2,0.3333333333333333,1,1,results
213,"Notably , our method scores state - of - the - art BLEU - 4 in question generation on SQuAD and ROUGE comparable to state - of - the - art methods in abstractive summarization in CNN - DM ( See also for state - of - the - art results in CNN - DM ) .",Results,Results,text_summarization,1,"['O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,6,0.23076923076923078,212,0.8833333333333333,6,1.0,1,1,results
214,Diversity vs. Number of Mixtures,Results,,text_summarization,1,"['B', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b']",7,0.2692307692307692,213,0.8875,0,0.0,1,1,results
215,Here we compare the effect of number of mixtures in our SELECTOR and Mixture Decoder .,Results,Diversity vs. Number of Mixtures,text_summarization,1,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.3076923076923077,214,0.8916666666666667,1,0.05555555555555555,1,1,results
216,show that pairwise similarity increases ( diversity ?) when the number of mixtures increases for Mixture Decoder .,Results,Diversity vs. Number of Mixtures,text_summarization,1,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'O']",9,0.34615384615384615,215,0.8958333333333334,2,0.1111111111111111,1,1,results
2,Soft Layer - Specific Multi - Task Summarization with Entailment and Question Generation,title,title,text_summarization,10,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.0038022813688212928,1,0.0,1,1,research-problem
5,"We improve these important aspects of abstractive summarization via multi-task learning with the auxiliary tasks of question generation and entailment generation , where the former teaches the summarization model how to look for salient questioning - worthy details , and the latter teaches the model how to rewrite a summary which is a directed - logical subset of the input document .",abstract,abstract,text_summarization,10,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.4,4,0.015209125475285171,2,0.4,1,1,research-problem
17,"In this work , we improve abstractive text summarization via soft , high - level ( semantic ) layerspecific multi-task learning with two relevant auxiliary tasks .",Introduction,Introduction,text_summarization,10,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.42105263157894735,16,0.060836501901140684,8,0.42105263157894735,1,1,research-problem
22,"Further , we also present novel multi-task learning architectures based on multi-layered encoder and decoder models , where we empirically show that it is substantially better to share the higherlevel semantic layers between the three aforementioned tasks , while keeping the lower - level ( lexico- syntactic ) layers unshared .",Introduction,Introduction,text_summarization,10,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.6842105263157895,21,0.07984790874524715,13,0.6842105263157895,1,1,model
144,Pointer + Coverage Baseline,,,text_summarization,10,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",0,0.0,143,0.5437262357414449,2,0.1,1,1,results
149,"4 On Gigaword dataset , our baseline model ( with pointer only , since coverage not needed for this single - sentence summarization task ) performs better than all previous works , as shown in .",Pointer + Coverage Baseline,Pointer + Coverage Baseline,text_summarization,10,"['O', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",5,0.2777777777777778,148,0.5627376425855514,7,0.35,1,1,results
150,Multi - Task with Entailment Generation,Pointer + Coverage Baseline,,text_summarization,10,"['B', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",6,0.3333333333333333,149,0.5665399239543726,8,0.4,1,1,results
152,"4 . shows that this multi-task setting is better than our strong baseline models and the improvements are statistically significant on all metrics 5 on both CNN / DailyMail ( p < 0.01 in ROUGE - 1 / ROUGE - L / METEOR and p < 0.05 in ROUGE - 2 ) and Gigaword ( p < 0.01 on all metrics ) datasets , showing that entailment generation task is inducing useful inference skills to the summarization task ( also see analysis examples in Sec. 7 ) .",Pointer + Coverage Baseline,Multi - Task with Entailment Generation,text_summarization,10,"['O', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.4444444444444444,151,0.5741444866920152,10,0.5,1,1,results
154,"For multi-task learning with question generation , the improvements are statistically significant in ROUGE - 1 ( p < 0.01 ) , ROUGE - L ( p < 0.05 ) , and METEOR ( p < 0.01 ) for CNN / DailyMail and in all metrics ( p < 0.01 ) for Gigaword , compared to the respective baseline models .",Pointer + Coverage Baseline,Multi - Task with Question Generation,text_summarization,10,"['B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,10,0.5555555555555556,153,0.5817490494296578,12,0.6,1,1,results
192,Soft - sharing vs. Hard - sharing,Ablation and Analysis Studies,Ablation and Analysis Studies,text_summarization,10,"['B', 'I', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",1,0.03571428571428571,191,0.7262357414448669,1,0.09090909090909091,1,1,ablation-analysis
193,"As described in Sec. 4.2 , we choose soft - sharing over hard - sharing because of the more expressive parameter sharing it provides to the model .",Ablation and Analysis Studies,Ablation and Analysis Studies,text_summarization,10,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.07142857142857142,192,0.7300380228136882,2,0.18181818181818182,1,1,ablation-analysis
194,Empirical results in 8 prove that soft - sharing method is statistically significantly better than hard - sharing with p < 0.001 in all metrics .,Ablation and Analysis Studies,Ablation and Analysis Studies,text_summarization,10,"['O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-ob', 'I-ob', 'O']",3,0.10714285714285714,193,0.7338403041825095,3,0.2727272727272727,1,1,ablation-analysis
203,Quantitative Improvements in Entailment,Ablation and Analysis Studies,,text_summarization,10,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",12,0.42857142857142855,202,0.7680608365019012,0,0.0,1,1,ablation-analysis
208,We found that our 2 - way MTL model with entailment generation reduces this extraneous count by 17.2 % w.r.t. the baseline .,Ablation and Analysis Studies,Quantitative Improvements in Entailment,text_summarization,10,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.6071428571428571,207,0.7870722433460076,5,0.08771929824561403,1,1,ablation-analysis
210,Quantitative Improvements in Saliency Detection,Ablation and Analysis Studies,,text_summarization,10,"['B', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b']",19,0.6785714285714286,209,0.7946768060836502,7,0.12280701754385964,1,1,ablation-analysis
213,"The results are shown in Table 10 , where the 2 - way - QG MTL model ( with question generation ) versus baseline improvement is stat. significant ( p < 0.01 ) .",Ablation and Analysis Studies,Quantitative Improvements in Saliency Detection,text_summarization,10,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",22,0.7857142857142857,212,0.8060836501901141,10,0.17543859649122806,1,1,ablation-analysis
215,"Qualitative Examples on Entailment and Saliency Improvements presents an example of output summaries generated by , our baseline , and our 3 - way multitask model .",Ablation and Analysis Studies,Quantitative Improvements in Saliency Detection,text_summarization,10,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",24,0.8571428571428571,214,0.8136882129277566,12,0.21052631578947367,1,1,ablation-analysis
218,"Hence , our 3 - way multi-task model generates summaries that are both better at logical entailment and contain more salient information .",Ablation and Analysis Studies,Quantitative Improvements in Saliency Detection,text_summarization,10,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,0.9642857142857143,217,0.8250950570342205,15,0.2631578947368421,1,1,ablation-analysis
2,Global Encoding for Abstractive Summarization,title,,text_summarization,11,"['O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.006944444444444444,1,0.0,1,1,research-problem
10,"Therefore , sequence - to - sequence learning can be applied to neural abstractive summarization , whose model consists of an encoder and a decoder .",Introduction,Introduction,text_summarization,11,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.03225806451612903,9,0.0625,2,0.09523809523809523,1,1,research-problem
23,"To tackle this problem , we propose a model of global encoding for abstractive summarization .",Introduction,Introduction,text_summarization,11,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",15,0.24193548387096775,22,0.1527777777777778,15,0.7142857142857143,1,1,model
24,We set a convolutional gated unit to perform global encoding on the source context .,Introduction,Introduction,text_summarization,11,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",16,0.25806451612903225,23,0.1597222222222222,16,0.7619047619047619,1,1,model
25,"The gate based on convolutional neural network ( CNN ) filters each encoder output based on the global context due to the parameter sharing , so that the representations at each time step are refined with consideration of the global context .",Introduction,Introduction,text_summarization,11,"['O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,17,0.27419354838709675,24,0.16666666666666666,17,0.8095238095238095,1,1,model
88,We implement our experiments in PyTorch on an NVIDIA 1080 Ti GPU .,Experiment Settings,Experiment Settings,text_summarization,11,"['O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.1111111111111111,87,0.6041666666666666,1,0.1111111111111111,1,1,experimental-setup
89,The word embedding dimension and the number of hidden units are both 512 .,Experiment Settings,Experiment Settings,text_summarization,11,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O']","['O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'B-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'B-ob', 'O']",2,0.2222222222222222,88,0.6111111111111112,2,0.2222222222222222,1,1,experimental-setup
90,"In both experiments , the batch size is set to 64 .",Experiment Settings,Experiment Settings,text_summarization,11,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",3,0.3333333333333333,89,0.6180555555555556,3,0.3333333333333333,1,1,experimental-setup
91,"We use Adam optimizer ( Kingma and Ba , 2014 ) with the default setting ? = 0.001 , ? 1 = 0.9 , ? 2 = 0.999 and = 1 10 ?8 .",Experiment Settings,Experiment Settings,text_summarization,11,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.4444444444444444,90,0.625,4,0.4444444444444444,1,1,experimental-setup
92,The learning rate is halved every epoch .,Experiment Settings,Experiment Settings,text_summarization,11,"['O', 'B', 'I', 'O', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",5,0.5555555555555556,91,0.6319444444444444,5,0.5555555555555556,1,1,experimental-setup
93,"Gradient clipping is applied with range [ - 10 , 10 ] .",Experiment Settings,Experiment Settings,text_summarization,11,"['B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.6666666666666666,92,0.6388888888888888,6,0.6666666666666666,1,1,experimental-setup
100,Baselines for LCSTS are introduced in the following .,Baseline Models,Baseline Models,text_summarization,11,"['O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-n', 'B-p', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'B-b', 'B-p', 'O', 'O', 'O', 'O', 'O']",3,0.1875,99,0.6875,3,0.23076923076923078,1,1,baselines
101,"RNN and RNN - context are the RNNbased seq2seq models , without and with attention mechanism respectively .",Baseline Models,Baseline Models,text_summarization,11,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O']",4,0.25,100,0.6944444444444444,4,0.3076923076923077,1,1,baselines
102,Copy - Net is the attention - based seq2seq model with the copy mechanism .,Baseline Models,Baseline Models,text_summarization,11,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.3125,101,0.7013888888888888,5,0.38461538461538464,1,1,baselines
103,SRB is a model that improves semantic relevance between source text and summary .,Baseline Models,Baseline Models,text_summarization,11,"['B', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",6,0.375,102,0.7083333333333334,6,0.46153846153846156,1,1,baselines
104,DRGD is the conventional seq2seq with a deep recurrent generative decoder .,Baseline Models,Baseline Models,text_summarization,11,"['B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.4375,103,0.7152777777777778,7,0.5384615384615384,1,1,baselines
105,"As to the baselines for Gigaword , ABS and ABS + are the models with local attention and handcrafted features .",Baseline Models,Baseline Models,text_summarization,11,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.5,104,0.7222222222222222,8,0.6153846153846154,1,1,baselines
106,Feats is a fully RNN seq2seq model with some specific methods to control the vocabulary size .,Baseline Models,Baseline Models,text_summarization,11,"['B', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",9,0.5625,105,0.7291666666666666,9,0.6923076923076923,1,1,baselines
107,RAS - LSTM and RAS - Elman are seq2seq models with a convolutional encoder and an LSTM decoder and an Elman RNN decoder respectively .,Baseline Models,Baseline Models,text_summarization,11,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",10,0.625,106,0.7361111111111112,10,0.7692307692307693,1,1,baselines
108,SEASS is a seq2seq model with a selective gate mechanism .,Baseline Models,Baseline Models,text_summarization,11,"['B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",11,0.6875,107,0.7430555555555556,11,0.8461538461538461,1,1,baselines
109,DRGD is also a baseline for Gigaword .,Baseline Models,Baseline Models,text_summarization,11,"['B', 'O', 'O', 'O', 'B', 'I', 'B', 'O']","['B-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'O']",12,0.75,108,0.75,12,0.9230769230769231,1,1,baselines
115,"In the experiments on the two datasets , our model achieves advantages of ROUGE score over the baselines , and the advantages of ROUGE score on the LCSTS are significant .",Results,Results,text_summarization,11,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'O']",,,1,0.05555555555555555,114,0.7916666666666666,1,0.25,1,1,results
118,"Compared with the conventional seq2seq model , our model owns an advantage of ROUGE - 2 score 3.7 and 1.5 on the LCSTS and Gigaword respectively .",Results,Results,text_summarization,11,"['B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",4,0.2222222222222222,117,0.8125,4,1.0,1,1,results
2,Selective Encoding for Abstractive Sentence Summarization,title,,text_summarization,12,"['O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0043859649122807015,1,0.0,1,1,research-problem
8,"The second level representation is tailored for sentence summarization task , which leads to better performance .",abstract,abstract,text_summarization,12,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.7142857142857143,7,0.03070175438596491,5,0.7142857142857143,1,1,research-problem
35,In this paper we propose Selective Encoding for Abstractive Sentence Summarization ( SEASS ) .,Introduction,Introduction,text_summarization,12,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",24,0.75,34,0.14912280701754385,24,0.75,1,1,model
36,"We treat the sentence summarization as a threephase task : encoding , selection , and decoding .",Introduction,Introduction,text_summarization,12,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O', 'O', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-ob', 'O', 'B-ob', 'O', 'O', 'B-ob', 'O']",25,0.78125,35,0.15350877192982457,25,0.78125,1,1,model
37,"It consists of a sentence encoder , a selective gate network , and a summary decoder .",Introduction,Introduction,text_summarization,12,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",26,0.8125,36,0.15789473684210525,26,0.8125,1,1,model
38,"First , the sentence encoder reads the input words through an RNN unit to construct the first level sentence representation .",Introduction,Introduction,text_summarization,12,"['B', 'O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",27,0.84375,37,0.16228070175438597,27,0.84375,1,1,model
39,Then the selective gate network selects the encoded information to construct the second level sentence representation .,Introduction,Introduction,text_summarization,12,"['O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",28,0.875,38,0.16666666666666666,28,0.875,1,1,model
40,"The selective mechanism controls the information flow from encoder to decoder by applying a gate network according to the sentence information , which helps improve encoding effectiveness and release the burden of the decoder .",Introduction,Introduction,text_summarization,12,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",29,0.90625,39,0.17105263157894737,29,0.90625,1,1,model
41,"Finally , the attention - equipped decoder generates the summary using the second level sentence representation .",Introduction,Introduction,text_summarization,12,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",30,0.9375,40,0.17543859649122806,30,0.9375,1,1,model
164,We initialize model parameters randomly using a Gaussian distribution with Xavier scheme .,Model Training,Model Training,text_summarization,12,"['O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",1,0.09090909090909091,163,0.7149122807017544,1,0.09090909090909091,1,1,hyperparameters
165,We use Adam as our optimizing algorithm .,Model Training,Model Training,text_summarization,12,"['O', 'B', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",2,0.18181818181818182,164,0.7192982456140351,2,0.18181818181818182,1,1,hyperparameters
166,"For the hyperparameters of Adam optimizer , we set the learning rate ? = 0.001 , two momentum parameters ? 1 = 0.9 and ? 2 = 0.999 respectively , and = 10 ?8 .",Model Training,Model Training,text_summarization,12,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.2727272727272727,165,0.7236842105263158,3,0.2727272727272727,1,1,hyperparameters
167,"During training , we test the model performance ( ROUGE - 2 F1 ) on development set for every 2,000 batches .",Model Training,Model Training,text_summarization,12,"['B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.36363636363636365,166,0.7280701754385965,4,0.36363636363636365,1,1,hyperparameters
169,"We also apply gradient clipping with range [ ? 5 , 5 ] during training .",Model Training,Model Training,text_summarization,12,"['O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",6,0.5454545454545454,168,0.7368421052631579,6,0.5454545454545454,1,1,hyperparameters
170,"To both speedup the training and converge quickly , we use mini-batch size 64 by grid search .",Model Training,Model Training,text_summarization,12,"['B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'O']",7,0.6363636363636364,169,0.7412280701754386,7,0.6363636363636364,1,1,hyperparameters
178,"ABS + Based on ABS model , further with two - layer LSTMs for the encoder - decoder with 500 hidden units in each layer implemented in .",Baseline,Baseline,text_summarization,12,"['B', 'I', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O']",3,0.6,177,0.7763157894736842,3,0.6,1,1,baselines
179,s 2 s+ att,Baseline,Baseline,text_summarization,12,"['B', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b']",4,0.8,178,0.7807017543859649,4,0.8,1,1,baselines
180,"We also implement a sequence - to sequence model with attention as our baseline and denote it as "" s2 s + att "" .",Baseline,Baseline,text_summarization,12,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,1.0,179,0.7850877192982456,5,1.0,1,1,baselines
189,Our SEASS model with beam search outperforms all baseline models by a large margin .,Results,English Gigaword,text_summarization,12,"['O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",8,0.19047619047619047,188,0.8245614035087719,8,0.5714285714285714,1,1,results
190,"Even for greedy search , our model still performs better than other methods which used beam search .",Results,English Gigaword,text_summarization,12,"['B', 'I', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",9,0.21428571428571427,189,0.8289473684210527,9,0.6428571428571429,1,1,results
191,"For the popular ROUGE - 2 metric , our SEASS model achieves 17.54 F1 score and performs better than the previous works .",Results,English Gigaword,text_summarization,12,"['B', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",10,0.23809523809523808,190,0.8333333333333334,10,0.7142857142857143,1,1,results
192,"Compared to the ABS model , our model has a 6.22 ROUGE - 2 F1 relative gain .",Results,English Gigaword,text_summarization,12,"['B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.2619047619047619,191,0.8377192982456141,11,0.7857142857142857,1,1,results
193,"Compared to the highest CAs 2s baseline , our model achieves 1.57 ROUGE - 2 F1 improvement and passes the significant test according to the official ROUGE script .",Results,English Gigaword,text_summarization,12,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",12,0.2857142857142857,192,0.8421052631578947,12,0.8571428571428571,1,1,results
196,DUC 2004,Results,English Gigaword,text_summarization,12,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",15,0.35714285714285715,195,0.8552631578947368,0,0.0,1,1,results
199,"As summarized in , our SEASS outperforms all the baseline methods and achieves 29.21 , 9.56 and 25.51 for ROUGE 1 , 2 and L recall .",Results,English Gigaword,text_summarization,12,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.42857142857142855,198,0.868421052631579,3,0.42857142857142855,1,1,results
200,"Compared to the ABS + model which is tuned using DUC 2003 data , our model performs significantly better by 1.07 ROUGE - 2 recall score and is trained only with English Gigaword sentence - summary data without being tuned using DUC data .",Results,English Gigaword,text_summarization,12,"['B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,19,0.4523809523809524,199,0.8728070175438597,4,0.5714285714285714,1,1,results
2,Coarse-to-Fine Attention Models for Document Summarization,title,,text_summarization,13,"['O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.003745318352059925,1,0.0,1,1,research-problem
16,"Therefore , in order to scale attention models for this problem , we aim to prune down the length of the source sequence in an intelligent way .",Introduction,Introduction,text_summarization,13,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",8,0.5,15,0.056179775280898875,8,0.5,1,1,approach
17,"Instead of naively attending to all the words of the source at once , our solution is to use a two - layer hierarchical attention .",Introduction,Introduction,text_summarization,13,"['B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",9,0.5625,16,0.0599250936329588,9,0.5625,1,1,approach
18,"For document summarization , this means dividing the document into chunks of text , sparsely attending to one or a few chunks at a time using hard attention , then applying the usual full attention over those chunks - we call this method coarse - to - fine attention .",Introduction,Introduction,text_summarization,13,"['B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.625,17,0.06367041198501873,10,0.625,1,1,approach
185,"We train with minibatch stochastic gradient descent ( SGD ) with batch size 20 for 20 epochs , renormalizing gradients below norm 5 .",Training,Training,text_summarization,13,"['O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",1,0.09090909090909091,184,0.6891385767790262,1,0.09090909090909091,1,1,experimental-setup
186,"We initialize the learning rate to 0.1 for the top - level encoder and 1 for the rest of the model , and begin decaying it by a factor of 0.5 each epoch after the validation perplexity stops decreasing .",Training,Training,text_summarization,13,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O']",,,2,0.18181818181818182,185,0.6928838951310862,2,0.18181818181818182,1,1,experimental-setup
187,"We use 2 layer LSTMs with 500 hidden units , and we initialize word embeddings with 300 dimensional word2vec embeddings .",Training,Training,text_summarization,13,"['O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']",,,3,0.2727272727272727,186,0.6966292134831461,3,0.2727272727272727,1,1,experimental-setup
188,"We initialize all other parameters as uniform in the interval [ ? 0.1 , 0.1 ] .",Training,Training,text_summarization,13,"['O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.36363636363636365,187,0.700374531835206,4,0.36363636363636365,1,1,experimental-setup
189,"For convolutional layers , we use a kernel width of 6 and 600 filters .",Training,Training,text_summarization,13,"['B', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",5,0.45454545454545453,188,0.704119850187266,5,0.45454545454545453,1,1,experimental-setup
190,Positional embeddings have dimension 25 .,Training,Training,text_summarization,13,"['B', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",6,0.5454545454545454,189,0.7078651685393258,6,0.5454545454545454,1,1,experimental-setup
191,We use dropout between stacked LSTM hidden states and before the final word generator layer to regularize ( with dropout probability 0.3 ) .,Training,Training,text_summarization,13,"['O', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O']","['O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",7,0.6363636363636364,190,0.7116104868913857,7,0.6363636363636364,1,1,experimental-setup
192,"At test time , we run beam search to produce the summary with a beam size of 5 .",Training,Training,text_summarization,13,"['B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",8,0.7272727272727273,191,0.7153558052434457,8,0.7272727272727273,1,1,experimental-setup
193,Our models are implemented using Torch based on a past version of the Open NMT system,Training,Training,text_summarization,13,"['O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I']","['O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob']",9,0.8181818181818182,192,0.7191011235955056,9,0.8181818181818182,1,1,experimental-setup
194,4 . We ran our experiments on a 12GB Geforce GTX Titan X GPU .,Training,Training,text_summarization,13,"['O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.9090909090909091,193,0.7228464419475655,10,0.9090909090909091,1,1,experimental-setup
204,The ILP model ROUGE scores are surprisingly low .,Results,Results,text_summarization,13,"['O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",1,0.017857142857142856,203,0.7602996254681648,1,0.034482758620689655,1,1,results
213,C2 F results are significantly worse than soft attention results .,Results,Results,text_summarization,13,"['B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.17857142857142858,212,0.7940074906367042,10,0.3448275862068966,1,1,results
234,Sharpness of Attention,Results,,text_summarization,13,"['B', 'I', 'I']","['B-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b']",31,0.5535714285714286,233,0.8726591760299626,1,0.038461538461538464,1,1,ablation-analysis
237,We compute the entropy numbers by averaging over all generated words in the validation set .,Results,Sharpness of Attention,text_summarization,13,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",34,0.6071428571428571,236,0.8838951310861424,4,0.15384615384615385,1,1,ablation-analysis
239,We note that the entropy of C2F is very low ( before taking the argmax at test time ) .,Results,Sharpness of Attention,text_summarization,13,"['O', 'B', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",36,0.6428571428571429,238,0.8913857677902621,6,0.23076923076923078,1,1,ablation-analysis
240,This is exactly what we had hoped for - we will see that the model in fact learns to focus on only a few top - level chunks of the document over the course of generation .,Results,Sharpness of Attention,text_summarization,13,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",37,0.6607142857142857,239,0.8951310861423221,7,0.2692307692307692,1,1,ablation-analysis
245,Attention Heatmaps,Results,,text_summarization,13,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",42,0.75,244,0.9138576779026217,12,0.46153846153846156,1,1,ablation-analysis
250,"In HIER , we observe that the attention becomes washed out ( in accord with its high entropy ) and is essentially averaging all of the encoder hidden states .",Results,Attention Heatmaps,text_summarization,13,"['B', 'B', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",47,0.8392857142857143,249,0.9325842696629213,17,0.6538461538461539,1,1,ablation-analysis
255,"In C2 F , we see that we get very sharp attention on some rows as we had hoped .",Results,Attention Heatmaps,text_summarization,13,"['O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",52,0.9285714285714286,254,0.951310861423221,22,0.8461538461538461,1,1,ablation-analysis
2,Ensure the Correctness of the Summary : Incorporate Entailment Knowledge into Abstractive Sentence Summarization,title,title,text_summarization,14,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.0043859649122807015,1,0.0,1,1,research-problem
4,"In this paper , we investigate the sentence summarization task that produces a summary from a source sentence .",abstract,abstract,text_summarization,14,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.125,3,0.013157894736842105,1,0.125,1,1,research-problem
27,"To incorporate entailment knowledge into abstractive summarization models , we propose in this work an entailment - aware encoder and an entailment - aware decoder .",Introduction,Introduction,text_summarization,14,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.6521739130434783,26,0.11403508771929824,15,0.42857142857142855,1,1,model
28,"We share the encoder of the summarization generation system with the entailment recognition system , so that the encoder can grasp both the gist of the source sentence and be aware of entailment relationships .",Introduction,Introduction,text_summarization,14,"['O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",16,0.6956521739130435,27,0.11842105263157894,16,0.45714285714285713,1,1,model
29,"Furthermore , we propose an entailment Reward Augmented Maximum Likelihood ( RAML ) training that encourages the decoder of the summarization system to produce summary entailed by the source .",Introduction,Introduction,text_summarization,14,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",17,0.7391304347826086,28,0.12280701754385964,17,0.4857142857142857,1,1,model
151,ABS . first apply the seq2seq model to abstractive sentence summarization .,Comparative Methods,We compare a set of sentence summarization baselines .,text_summarization,14,"['B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",2,0.10526315789473684,150,0.6578947368421053,2,0.10526315789473684,1,1,baselines
153,ABS +. propose a neural machine translation model with two - layer LSTMs for the encoder - decoder .,Comparative Methods,We compare a set of sentence summarization baselines .,text_summarization,14,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",4,0.21052631578947367,152,0.6666666666666666,4,0.21052631578947367,1,1,baselines
154,Seq2seq .,Comparative Methods,,text_summarization,14,"['B', 'O']","['B-n', 'O']","['B-b', 'O']",5,0.2631578947368421,153,0.6710526315789473,5,0.2631578947368421,1,1,baselines
155,This is a standard seq2seq model with attention mechanism .,Comparative Methods,Seq2seq .,text_summarization,14,"['O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",6,0.3157894736842105,154,0.6754385964912281,6,0.3157894736842105,1,1,baselines
156,Seq2seq + MTL .,Comparative Methods,,text_summarization,14,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",7,0.3684210526315789,155,0.6798245614035088,7,0.3684210526315789,1,1,baselines
157,"This is our proposed model with entailment - aware encoder , which applies a multi-task learning ( MTL ) framework to seq2seq model .",Comparative Methods,Seq2seq + MTL .,text_summarization,14,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",8,0.42105263157894735,156,0.6842105263157895,8,0.42105263157894735,1,1,baselines
158,Seq2seq + MTL ( Share decoder ) .,Comparative Methods,,text_summarization,14,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",9,0.47368421052631576,157,0.6885964912280702,9,0.47368421052631576,1,1,baselines
159,propose a multi - task learning ( MTL ) framework in which the decoder is shared for summarization generation and entailment generation task .,Comparative Methods,Seq2seq + MTL ( Share decoder ) .,text_summarization,14,"['B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.5263157894736842,158,0.6929824561403509,10,0.5263157894736842,1,1,baselines
160,Seq2seq + ERAML .,Comparative Methods,,text_summarization,14,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",11,0.5789473684210527,159,0.6973684210526315,11,0.5789473684210527,1,1,baselines
161,"This is our proposed model with entailment - aware decoder , which conducts an Entailment Reward Augmented Maximum Likelihood ( ERAML ) training framework .",Comparative Methods,Seq2seq + ERAML .,text_summarization,14,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.631578947368421,160,0.7017543859649122,12,0.631578947368421,1,1,baselines
162,Seq2seq + ROUGE -2 RAML .,Comparative Methods,Seq2seq + ERAML .,text_summarization,14,"['B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",13,0.6842105263157895,161,0.706140350877193,13,0.6842105263157895,1,1,baselines
163,We apply ROUGE - 2 RAML training for seq2seq model .,Comparative Methods,Seq2seq + ERAML .,text_summarization,14,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",14,0.7368421052631579,162,0.7105263157894737,14,0.7368421052631579,1,1,baselines
164,Seq2seq + RL .,Comparative Methods,,text_summarization,14,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",15,0.7894736842105263,163,0.7149122807017544,15,0.7894736842105263,1,1,baselines
165,We implement Reinforcement Learning ( RL ) models ( policy gradient ) with reward metrics of Entailment and ROUGE - 2 .,Comparative Methods,Seq2seq + RL .,text_summarization,14,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.8421052631578947,164,0.7192982456140351,16,0.8421052631578947,1,1,baselines
166,Seq2seq + selective .,Comparative Methods,,text_summarization,14,"['B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O']",17,0.8947368421052632,165,0.7236842105263158,17,0.8947368421052632,1,1,baselines
167,employ a selective encoding model to control the information flow from encoder to decoder .,Comparative Methods,Seq2seq + selective .,text_summarization,14,"['B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",18,0.9473684210526315,166,0.7280701754385965,18,0.9473684210526315,1,1,baselines
172,Experimental Results : Gigaword Corpus,Model,Model,text_summarization,14,"['O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'B-b', 'I-b']",3,0.25,171,0.75,3,0.25,1,1,results
176,Our model performs better than the previous works .,Model,,text_summarization,14,"['B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",7,0.5833333333333334,175,0.7675438596491229,7,0.5833333333333334,1,1,results
177,Experimental Results : DUC 2004,Model,,text_summarization,14,"['O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'B-b', 'I-b']",8,0.6666666666666666,176,0.7719298245614035,8,0.6666666666666666,1,1,results
181,"In , experimental results also show our Seq2seq + selective + MTL + ERAML model achieves significant improvements over baseline models , surpassing Feats2s by 0.98 % ROUGE - 1 , 0.78 % ROUGE - 2 and 0.65 % ROUGE - L without fine - tuning on DUC data .",Model,Test Corpus,text_summarization,14,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'O', 'O', 'O']",12,1.0,180,0.7894736842105263,12,1.0,1,1,results
189,Does our summarization model learn entailment knowledge ?,Manual Evaluation,Further Analysis,text_summarization,14,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",7,0.1794871794871795,188,0.8245614035087719,2,0.09090909090909091,1,1,ablation-analysis
192,"For the test set of , the average entailment score for the reference is 0.72 , while for the basic seq2seq model , the entailment score is only 0.46 .",Manual Evaluation,Further Analysis,text_summarization,14,"['B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'O']",10,0.2564102564102564,191,0.8377192982456141,5,0.22727272727272727,1,1,ablation-analysis
193,"When we adopt entailmentbased strategies , the entailment score rises to 0.63 for seq2seq model .",Manual Evaluation,Further Analysis,text_summarization,14,"['O', 'O', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",11,0.28205128205128205,192,0.8421052631578947,6,0.2727272727272727,1,1,ablation-analysis
194,"Note that the entailment score is 0.57 for seq2seq model with selective encoding , and we believe that the selective mechanism can filter out secondary information in the input , which will reduce the possibility to generate irrelevant information .",Manual Evaluation,Further Analysis,text_summarization,14,"['B', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.3076923076923077,193,0.8464912280701754,7,0.3181818181818182,1,1,ablation-analysis
195,Entailment - aware selective model achieves a high entailment reward of 0.71 .,Manual Evaluation,Further Analysis,text_summarization,14,"['B', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",13,0.3333333333333333,194,0.8508771929824561,8,0.36363636363636365,1,1,ablation-analysis
196,"In part at least , we can conclude that our model has successfully learned entailment knowledge .",Manual Evaluation,Further Analysis,text_summarization,14,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",14,0.358974358974359,195,0.8552631578947368,9,0.4090909090909091,1,1,ablation-analysis
198,Is it less abstractive for our model ?,Manual Evaluation,Further Analysis,text_summarization,14,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",16,0.41025641025641024,197,0.8640350877192983,11,0.5,1,1,ablation-analysis
202,"shows that the seq2seq model produces more novel words ( i.e. , words that do not appear in the article ) than our model , indicating a lower degree of abstraction for our model .",Manual Evaluation,Further Analysis,text_summarization,14,"['B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",20,0.5128205128205128,201,0.881578947368421,15,0.6818181818181818,1,1,ablation-analysis
203,"However , when we exclude all the words not in the reference ( these words may lead to wrong information ) , our model generates more novel words , suggesting that our model provides a compromise solution for informativeness and correctness .",Manual Evaluation,Further Analysis,text_summarization,14,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",21,0.5384615384615384,202,0.8859649122807017,16,0.7272727272727273,1,1,ablation-analysis
205,6.6.3 Could the entailment recognition also be improved ?,Manual Evaluation,Further Analysis,text_summarization,14,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b']",23,0.5897435897435898,204,0.8947368421052632,18,0.8181818181818182,1,1,ablation-analysis
208,shows that our summarization model with MTL outperforms basic seq2seq model .,Manual Evaluation,Further Analysis,text_summarization,14,"['B', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'I', 'I', 'O']","['B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",26,0.6666666666666666,207,0.9078947368421053,21,0.9545454545454546,1,1,ablation-analysis
209,"As ? increases , the accuracy of entailment recognition improves and finally exceeds that of the model without MTL , which reveals the advantage of MTL framework .",Manual Evaluation,Further Analysis,text_summarization,14,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",27,0.6923076923076923,208,0.9122807017543859,22,1.0,1,1,ablation-analysis
2,Structure - Infused Copy Mechanisms for Abstractive Summarization,title,title,text_summarization,2,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.0035971223021582736,1,0.0,1,1,research-problem
4,Seq2seq learning has produced promising results on summarization .,abstract,,text_summarization,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'O']",1,0.16666666666666666,3,0.01079136690647482,1,0.16666666666666666,1,1,research-problem
25,In this paper we seek to address this problem by incorporating source syntactic structure in neural sentence summarization to help the system identify summary - worthy content and compose summaries that preserve the important meaning of the source texts .,Introduction,Introduction,text_summarization,2,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.6,24,0.08633093525179857,15,0.6,1,1,model
26,We present structure - infused copy mechanisms to facilitate copying source words and relations to the summary based on their semantic and structural importance in the source sentences .,Introduction,Introduction,text_summarization,2,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",16,0.64,25,0.08992805755395683,16,0.64,1,1,model
215,We first report results on the Gigaword valid - 2000 dataset in .,Results,ROUGE results on valid set .,text_summarization,2,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O']",2,0.0625,214,0.7697841726618705,2,0.0625,1,1,results
216,"We present R - 1 , R - 2 , and R - L scores ) that respectively measures the overlapped unigrams , bigrams , and longest common subsequences between the system and reference summaries 3 .",Results,ROUGE results on valid set .,text_summarization,2,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",3,0.09375,215,0.7733812949640287,3,0.09375,1,1,results
221,"Overall , we observe that models equipped with the structure - infused copy mechanisms are superior to the baseline , suggesting that combining source syntactic structure with the copy mechanism is effective .",Results,ROUGE results on valid set .,text_summarization,2,"['O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",8,0.25,220,0.7913669064748201,8,0.25,1,1,results
222,"We found that the "" Struct + Hidden "" architecture , which directly concatenates structural embeddings with the encoder hidden states , outperforms "" Struct + Input "" despite that the latter requires more parameters .",Results,ROUGE results on valid set .,text_summarization,2,"['O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",9,0.28125,221,0.7949640287769785,9,0.28125,1,1,results
223,""" Struct + 2 Way + Word "" also demonstrates strong performance , achieving 43.21 % , 21. 84 % , and 40.86 % F 1 scores , for R - 1 , R - 2 , and R - L respectively .",Results,ROUGE results on valid set .,text_summarization,2,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O']",10,0.3125,222,0.7985611510791367,10,0.3125,1,1,results
2,Concept Pointer Network for Abstractive Summarization,title,,text_summarization,3,"['O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.004132231404958678,1,0.0,1,1,research-problem
14,Abstractive summarization ( ABS ) has gained overwhelming success owing to a tremendous development of sequence - to - sequence ( seq2seq ) model and its variants .,Introduction,Introduction,text_summarization,3,"['B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.043478260869565216,13,0.05371900826446281,1,0.043478260869565216,1,1,research-problem
26,"Hence , in this paper , we propose a novel model based on a concept pointer generator that encourages the generation of conceptual and abstract words .",Introduction,Introduction,text_summarization,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",13,0.5652173913043478,25,0.10330578512396695,13,0.5652173913043478,1,1,model
27,"As a hidden benefit , the model also alleviates the OOV problems .",Introduction,Introduction,text_summarization,3,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",14,0.6086956521739131,26,0.10743801652892562,14,0.6086956521739131,1,1,model
28,"Our model uses pointer network to capture the salient information from a source text , and then employs another pointer to generalize the detailed words according to their upper level of expressions .",Introduction,Introduction,text_summarization,3,"['O', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.6521739130434783,27,0.1115702479338843,15,0.6521739130434783,1,1,model
34,The optimization function is adaptive so as to cater for different datasets with distantly - supervised training .,Introduction,Introduction,text_summarization,3,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",21,0.9130434782608695,33,0.13636363636363635,21,0.9130434782608695,1,1,model
35,"The network is then optimized end - to - end using reinforcement learning , with the distant - supervision strategy as a complement to further improve the summary .",Introduction,Introduction,text_summarization,3,"['O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",22,0.9565217391304348,34,0.14049586776859505,22,0.9565217391304348,1,1,model
159,We initialize word embeddings with 128 - d vectors and fine - tune them during training .,Related Work,Basic MLE,text_summarization,3,"['O', 'B', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",122,0.8187919463087249,158,0.6528925619834711,45,0.625,0,1,experimental-setup
161,The vocabulary size was set to 150 k for both the source and target text .,Related Work,Basic MLE,text_summarization,3,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",124,0.8322147651006712,160,0.6611570247933884,47,0.6527777777777778,0,1,experimental-setup
162,The hidden state size was set to 256 .,Related Work,Basic MLE,text_summarization,3,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O']",125,0.8389261744966443,161,0.6652892561983471,48,0.6666666666666666,0,1,experimental-setup
165,"Our code is available on https :// github.com/wprojectsn/codes , and the vocabularies and candidate concepts are also included .",Related Work,Basic MLE,text_summarization,3,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",128,0.8590604026845637,164,0.6776859504132231,51,0.7083333333333334,0,1,code
166,We trained our models on a single GTX TI - TAN GPU machine .,Related Work,Basic MLE,text_summarization,3,"['O', 'O', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",129,0.8657718120805369,165,0.6818181818181818,52,0.7222222222222222,0,1,experimental-setup
167,We used the Adagrad optimizer with a batch size of 64 to minimize the loss .,Related Work,Basic MLE,text_summarization,3,"['O', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",130,0.87248322147651,166,0.6859504132231405,53,0.7361111111111112,0,1,experimental-setup
168,"The initial learning rate and the accumulator value were set to 0.15 and 0.1 , respectively .",Related Work,Basic MLE,text_summarization,3,"['O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'O', 'O', 'O']","['O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-b', 'O', 'O', 'O']",131,0.8791946308724832,167,0.6900826446280992,54,0.75,0,1,experimental-setup
169,We used gradient clipping with a maximum gradient norm of 2 .,Related Work,Basic MLE,text_summarization,3,"['O', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",132,0.8859060402684564,168,0.6942148760330579,55,0.7638888888888888,0,1,experimental-setup
173,"We trained our concept pointer generator for 450 k iterations yielded the best performance , then took the optimization using RL rewards for RG - L at 95 K iterations on DUC - 2004 and at 50 K iterations on Gigaword .",Related Work,Basic MLE,text_summarization,3,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O']",,,136,0.912751677852349,172,0.7107438016528925,59,0.8194444444444444,0,1,experimental-setup
174,We took the distancesupervised training at 5 K iterations on DUC - 2004 and at 6.5 K iterations on Gigaword .,Related Work,Basic MLE,text_summarization,3,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O']",,,137,0.9194630872483222,173,0.7148760330578512,60,0.8333333333333334,0,1,experimental-setup
177,ABS + is a tuned ABS model with additional features .,Related Work,Basic MLE,text_summarization,3,"['B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",140,0.9395973154362416,176,0.7272727272727273,63,0.875,0,1,baselines
179,RAS - Elman ) is a convolution encoder and an Elman RNN decoder with attention .,Related Work,Basic MLE,text_summarization,3,"['B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O']",142,0.9530201342281879,178,0.7355371900826446,65,0.9027777777777778,0,1,baselines
180,Seq2seq + att is two - layer BiLSTM encoder and one - layer LSTM decoder equipped with attention .,Related Work,Basic MLE,text_summarization,3,"['B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O']",143,0.959731543624161,179,0.7396694214876033,66,0.9166666666666666,0,1,baselines
181,lvt5 k - lsent uses temporal attention to keep track of the past attentive weights of the decoder and restrains the repetition in later sequences .,Related Work,Basic MLE,text_summarization,3,"['B', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",144,0.9664429530201343,180,0.743801652892562,67,0.9305555555555556,0,1,baselines
182,SEASS includes an additional selective gate to control information flow from the encoder to the decoder .,Related Work,Basic MLE,text_summarization,3,"['B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'B', 'O', 'B', 'O']","['B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'O']",145,0.9731543624161074,181,0.7479338842975206,68,0.9444444444444444,0,1,baselines
183,Pointer - generator is an integrated pointer network and seq2seq model .,Related Work,Basic MLE,text_summarization,3,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O']",146,0.9798657718120806,182,0.7520661157024794,69,0.9583333333333334,0,1,baselines
186,CGU ) sets a convolutional gated unit and self - attention for global encoding .,Related Work,Basic MLE,text_summarization,3,"['B', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'O']",149,1.0,185,0.7644628099173554,72,1.0,0,1,baselines
191,We observe that our model outperformed all the strong state of - the - art models on both datasets in all metrics except for RG - 2 on Gigaword .,Results and Analysis,Quantitative Analysis,text_summarization,3,"['O', 'B', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.4,190,0.7851239669421488,2,0.25,1,1,results
192,"In terms of the pointer generator performance , the improvements made by our concept pointer are statistically significant ( p < 0.01 ) across all metrics .",Results and Analysis,Quantitative Analysis,text_summarization,3,"['B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",5,0.5,191,0.7892561983471075,3,0.375,1,1,results
2,Entity Commonsense Representation for Neural Abstractive Summarization,title,,text_summarization,4,"['O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.003875968992248062,1,0.0,1,1,research-problem
13,Text summarization is a task to generate a shorter and concise version of a text while preserving the meaning of the original text .,Introduction,Introduction,text_summarization,4,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.017241379310344827,12,0.046511627906976744,1,0.037037037037037035,1,1,research-problem
31,"To this end , we present a method to effectively apply linked entities in sequence - tosequence models , called Entity2Topic ( E2T ) .",Introduction,Introduction,text_summarization,4,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.3275862068965517,30,0.11627906976744186,19,0.7037037037037037,1,1,model
32,E2T is a module that can be easily attached to any sequence - to - sequence based summarization model .,Introduction,Introduction,text_summarization,4,"['B', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",20,0.3448275862068966,31,0.12015503875968993,20,0.7407407407407407,1,1,model
33,"The module encodes the entities extracted from the original text by an entity linking system ( ELS ) , constructs a vector representing the topic of the summary to be generated , and informs the decoder about the constructed topic vector .",Introduction,Introduction,text_summarization,4,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",21,0.3620689655172414,32,0.12403100775193798,21,0.7777777777777778,1,1,model
35,We solve this issue by using entity encoders with selective disambiguation and by constructing topic vectors using firm attention .,Introduction,Introduction,text_summarization,4,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'B', 'B', 'I', 'O']",,,23,0.39655172413793105,34,0.13178294573643412,23,0.8518518518518519,1,1,model
177,"For both datasets , we further reduce the size of the input , output , and entity vocabularies to at most 50 K as suggested in and replace less frequent words to "" < unk > "" .",Implementation,Implementation,text_summarization,4,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O']",,,1,0.09090909090909091,176,0.6821705426356589,14,0.45161290322580644,1,1,experimental-setup
178,We use 300D Glove 6 and 1000D wiki2vec 7 pre-trained vectors to initialize our word and entity vectors .,Implementation,Implementation,text_summarization,4,"['O', 'B', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'O', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O']",2,0.18181818181818182,177,0.686046511627907,15,0.4838709677419355,1,1,experimental-setup
179,"For GRUs , we set the state size to 500 .",Implementation,Implementation,text_summarization,4,"['B', 'B', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",3,0.2727272727272727,178,0.689922480620155,16,0.5161290322580645,1,1,experimental-setup
180,"For CNN , we set h = 3 , 4 , 5 with 400 , 300 , 300 feature maps , respectively .",Implementation,Implementation,text_summarization,4,"['O', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'B-b', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",4,0.36363636363636365,179,0.6937984496124031,17,0.5483870967741935,1,1,experimental-setup
181,"For firm attention , k is tuned by calculating the perplexity of the model starting with smaller values ( i.e. k = 1 , 2 , 5 , 10 , 20 , ... ) and stopping when the perplexity of the model becomes worse than the previous model .",Implementation,Implementation,text_summarization,4,"['O', 'B', 'I', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-p', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-b', 'O', 'B-p', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",5,0.45454545454545453,180,0.6976744186046512,18,0.5806451612903226,1,1,experimental-setup
183,We use dropout on all non-linear connections with a dropout rate of 0.5 .,Implementation,Implementation,text_summarization,4,"['O', 'B', 'B', 'B', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",7,0.6363636363636364,182,0.7054263565891473,20,0.6451612903225806,1,1,experimental-setup
184,"We set the batch sizes of Gigaword and CNN datasets to 80 and 10 , respectively .",Implementation,Implementation,text_summarization,4,"['O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",8,0.7272727272727273,183,0.7093023255813954,21,0.6774193548387096,1,1,experimental-setup
185,"Training is done via stochastic gradient descent over shuffled mini-batches with the Adadelta update rule , with l 2 constraint ( Hinton et al. , 2012 ) of 3 .",Implementation,Implementation,text_summarization,4,"['B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",9,0.8181818181818182,184,0.7131782945736435,22,0.7096774193548387,1,1,experimental-setup
186,We perform early stopping using a subset of the given development dataset .,Implementation,Implementation,text_summarization,4,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",10,0.9090909090909091,185,0.7170542635658915,23,0.7419354838709677,1,1,experimental-setup
187,We use beam search of size 10 to generate the summary .,Implementation,Implementation,text_summarization,4,"['O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'O', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'O', 'B-ob', 'O']",11,1.0,186,0.7209302325581395,24,0.7741935483870968,1,1,experimental-setup
189,"For the Gigaword dataset , we compare our models with the following abstractive baselines :",Baselines,Baselines,text_summarization,4,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'O', 'O', 'O']",1,0.16666666666666666,188,0.7286821705426356,26,0.8387096774193549,1,1,baselines
190,"ABS + is a fine tuned version of ABS which uses an attentive CNN encoder and an NNLM decoder , Feat2s ( Nallapati et al. , 2016 ) is an RNN sequence - to - sequence model with lexical and statistical features in the encoder , Luong - NMT is a two - layer LSTM encoder - decoder model , RAS - Elman uses an attentive CNN encoder and an Elman RNN decoder , and SEASS uses BiGRU encoders and GRU decoders with selective encoding .",Baselines,Baselines,text_summarization,4,"['B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'I', 'O']",,,2,0.3333333333333333,189,0.7325581395348837,27,0.8709677419354839,1,1,baselines
191,"For the CNN dataset , we compare our models with the following extractive and abstractive baselines :",Baselines,Baselines,text_summarization,4,"['O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.5,190,0.7364341085271318,28,0.9032258064516129,1,1,baselines
192,"Lead - 3 is a strong baseline that extracts the first three sentences of the document as summary , LexRank extracts texts using LexRank , Bi - GRU is a non-hierarchical one - layer sequence - to - sequence abstractive baseline , Distraction - M3 uses a sequence - to - sequence abstractive model with distraction - based networks , and GBA is a graph - based attentional neural abstractive model .",Baselines,Baselines,text_summarization,4,"['B', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O']",,,4,0.6666666666666666,191,0.7403100775193798,29,0.9354838709677419,1,1,baselines
198,"In Gigaword dataset where the texts are short , our best model achieves a comparable performance with the current state - of - the - art .",Results,Results,text_summarization,4,"['B', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.05263157894736842,197,0.7635658914728682,3,0.06,1,1,results
199,"In CNN dataset where the texts are longer , our best model outperforms all the previous models .",Results,Results,text_summarization,4,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",4,0.07017543859649122,198,0.7674418604651163,4,0.08,1,1,results
201,"Overall , E2T achieves a significant improvement over the baseline model BASE , with at least 2 ROUGE - 1 points increase in the Gigaword dataset and 6 ROUGE - 1 points increase in the CNN dataset .",Results,Results,text_summarization,4,"['O', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,6,0.10526315789473684,200,0.7751937984496124,6,0.12,1,1,results
203,"Among the model variants , the CNN - based encoder with selective disambiguation and firm attention performs the best .",Results,Results,text_summarization,4,"['B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'O']","['B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'B-p', 'O', 'B-ob', 'O']",8,0.14035087719298245,202,0.7829457364341085,8,0.16,1,1,results
2,"Retrieve , Rerank and Rewrite : Soft Template Based Neural Summarization",title,title,text_summarization,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.003968253968253968,1,0.0,1,1,research-problem
12,"In this paper , we focus on an increasingly intriguing task , i.e. , abstractive sentence summarization , which generates a shorter version of a given sentence while attempting to preserve its original meaning .",Introduction,Introduction,text_summarization,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",2,0.05714285714285714,11,0.04365079365079365,2,0.05714285714285714,1,1,research-problem
30,"Due to the strong rewriting ability of the seq2seq framework , in this paper , we propose to combine the seq2seq and template based summarization approaches .",Introduction,Introduction,text_summarization,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",20,0.5714285714285714,29,0.11507936507936507,20,0.5714285714285714,1,1,approach
31,"We call our summarization system Re 3 Sum , which consists of three modules : Retrieve , Rerank and Rewrite .",Introduction,Introduction,text_summarization,5,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-ob', 'O']",21,0.6,30,0.11904761904761904,21,0.6,1,1,approach
32,We utilize a widely - used Information Retrieval ( IR ) platform to find out candidate soft templates from the training corpus .,Introduction,Introduction,text_summarization,5,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",22,0.6285714285714286,31,0.12301587301587301,22,0.6285714285714286,1,1,approach
33,"Then , we extend the seq2seq model to jointly learn template saliency measurement ( Rerank ) and final summary generation ( Rewrite ) .",Introduction,Introduction,text_summarization,5,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",23,0.6571428571428571,32,0.12698412698412698,23,0.6571428571428571,1,1,approach
34,"Specifically , a Recurrent Neural Network ( RNN ) encoder is applied to convert the input sentence and each candidate template into hidden states .",Introduction,Introduction,text_summarization,5,"['O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'B-p', 'B-b', 'I-b', 'O']",24,0.6857142857142857,33,0.13095238095238096,24,0.6857142857142857,1,1,approach
35,"In Rerank , we measure the informativeness of a candidate template according to its hidden state relevance to the input sentence .",Introduction,Introduction,text_summarization,5,"['B', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'O']","['B-p', 'B-n', 'O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",25,0.7142857142857143,34,0.1349206349206349,25,0.7142857142857143,1,1,approach
36,The candidate template with the highest predicted informativeness is regarded as the actual soft template .,Introduction,Introduction,text_summarization,5,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",26,0.7428571428571429,35,0.1388888888888889,26,0.7428571428571429,1,1,approach
37,"In Rewrite , the summary is generated according to the hidden states of both the sentence and template .",Introduction,Introduction,text_summarization,5,"['O', 'B', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-n', 'O', 'O', 'B-n', 'O', 'B-p', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'O', 'O', 'B-b', 'O', 'B-p', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",27,0.7714285714285715,36,0.14285714285714285,27,0.7714285714285715,1,1,approach
43,Code and results can be found at http://www4.comp.polyu.edu.hk/cszqcao/,Introduction,Introduction,text_summarization,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob']",33,0.9428571428571428,42,0.16666666666666666,33,0.9428571428571428,1,1,code
139,We use the popular seq2seq framework Open - NMT 5 as the starting point .,Implementation Details,Implementation Details,text_summarization,5,"['O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.1111111111111111,138,0.5476190476190477,1,0.1111111111111111,1,1,experimental-setup
140,"To make our model more general , we retain the default settings of Open NMT to build the network architecture .",Implementation Details,Implementation Details,text_summarization,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",2,0.2222222222222222,139,0.5515873015873016,2,0.2222222222222222,1,1,experimental-setup
141,"Specifically , the dimensions of word embeddings and RNN are both 500 , and the encoder and decoder structures are two - layer bidirectional Long Short Term Memory Networks ( LSTMs ) .",Implementation Details,Implementation Details,text_summarization,5,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",3,0.3333333333333333,140,0.5555555555555556,3,0.3333333333333333,1,1,experimental-setup
144,"On our computer ( GPU : GTX 1080 , Memory : 16G , CPU : i7-7700 K ) , the training spends about 2 days .",Implementation Details,Implementation Details,text_summarization,5,"['B', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['B-p', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-ob', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",6,0.6666666666666666,143,0.5674603174603174,6,0.6666666666666666,1,1,experimental-setup
145,"During test , we use beam search of size 5 to generate summaries .",Implementation Details,Implementation Details,text_summarization,5,"['B', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'O']","['B-p', 'I-p', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'O']","['B-p', 'I-p', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'O']",7,0.7777777777777778,144,0.5714285714285714,7,0.7777777777777778,1,1,experimental-setup
146,"We add the argument "" replace unk "" to replace the generated unknown words with the source word that holds the highest attention weight .",Implementation Details,Implementation Details,text_summarization,5,"['O', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.8888888888888888,145,0.5753968253968254,8,0.8888888888888888,1,1,experimental-setup
147,"Since the generated summaries are often shorter than the actual ones , we introduce an additional length penalty argument "" alpha 1 "" to encourage longer generation , like .",Implementation Details,Implementation Details,text_summarization,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O', 'O', 'O']",9,1.0,146,0.5793650793650794,9,1.0,1,1,experimental-setup
151,OpenNMT,Baselines,,text_summarization,5,['B'],['B-n'],['B-b'],3,0.23076923076923078,150,0.5952380952380952,3,0.23076923076923078,1,1,baselines
152,We also implement the standard attentional seq2seq model with OpenNMT .,Baselines,OpenNMT,text_summarization,5,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O']",4,0.3076923076923077,151,0.5992063492063492,4,0.3076923076923077,1,1,baselines
156,FTSum encoded the facts extracted from the source sentence to improve both the faithfulness and informativeness of generated summaries .,Baselines,OpenNMT,text_summarization,5,"['B', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'O']","['B-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-p', 'O', 'B-n', 'O', 'B-n', 'O', 'B-n', 'I-n', 'O']","['B-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-p', 'O', 'B-ob', 'O', 'B-ob', 'O', 'B-b', 'I-b', 'O']",8,0.6153846153846154,155,0.6150793650793651,8,0.6153846153846154,1,1,baselines
157,"In addition , to evaluate the effectiveness of our joint learning framework , we develop a baseline named "" PIPELINE "" .",Baselines,OpenNMT,text_summarization,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'O', 'O']",9,0.6923076923076923,156,0.6190476190476191,9,0.6923076923076923,1,1,baselines
159,"However , it trains the Rerank module and Rewrite module in pipeline .",Baselines,OpenNMT,text_summarization,5,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'O', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O']",11,0.8461538461538461,158,0.626984126984127,11,0.8461538461538461,1,1,baselines
163,We also examine the performance of directly regarding soft templates as output summaries .,Informativeness Evaluation,Informativeness Evaluation,text_summarization,5,"['O', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",1,0.05263157894736842,162,0.6428571428571429,1,0.1,1,1,results
164,We introduce five types of different soft templates :,Informativeness Evaluation,Informativeness Evaluation,text_summarization,5,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O']",2,0.10526315789473684,163,0.6468253968253969,2,0.2,1,1,results
176,"As shown in , the performance of Random is terrible , indicating it is impossible to use one summary template to fit various actual summaries .",Informativeness Evaluation,Rerank,text_summarization,5,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",14,0.7368421052631579,175,0.6944444444444444,3,0.375,1,1,results
177,"Rerank largely outperforms First , which verifies the effectiveness of the Rerank module .",Informativeness Evaluation,Rerank,text_summarization,5,"['B', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-b', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",15,0.7894736842105263,176,0.6984126984126984,4,0.5,1,1,results
179,"Likewise , comparing Max and First , we observe that the improving capacity of the Retrieve module is high .",Informativeness Evaluation,Rerank,text_summarization,5,"['O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",17,0.8947368421052632,178,0.7063492063492064,6,0.75,1,1,results
180,Notice that Optimal greatly exceeds all the state - of - the - art approaches .,Informativeness Evaluation,Rerank,text_summarization,5,"['O', 'O', 'B', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.9473684210526315,179,0.7103174603174603,7,0.875,1,1,results
183,"We also measure the linguistic quality of generated summaries from various aspects , and the results are present in .",Linguistic Quality Evaluation,Linguistic Quality Evaluation,text_summarization,5,"['O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.023809523809523808,182,0.7222222222222222,1,0.05,1,1,results
184,"As can be seen from the rows "" LEN DIF "" and "" LESS 3 "" , the performance of Re 3 Sum is almost the same as that of soft templates .",Linguistic Quality Evaluation,Linguistic Quality Evaluation,text_summarization,5,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'B-ob', 'I-ob', 'O']",2,0.047619047619047616,183,0.7261904761904762,2,0.1,1,1,results
204,"In this section , we investigate how soft templates affect our model .",Linguistic Quality Evaluation,Effect of Templates,text_summarization,5,"['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",22,0.5238095238095238,203,0.8055555555555556,1,0.047619047619047616,1,1,results
206,"As illustrated in , the more high - quality templates are provided , the higher ROUGE scores are achieved .",Linguistic Quality Evaluation,Effect of Templates,text_summarization,5,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-p', 'O']",24,0.5714285714285714,205,0.8134920634920635,3,0.14285714285714285,1,1,results
210,"Next , we manually inspect the summaries generated by different methods .",Linguistic Quality Evaluation,Effect of Templates,text_summarization,5,"['O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",28,0.6666666666666666,209,0.8293650793650794,7,0.3333333333333333,1,1,results
211,We find the outputs of Re 3 Sum are usually longer and more flu - ent than the outputs of OpenNMT .,Linguistic Quality Evaluation,Effect of Templates,text_summarization,5,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",29,0.6904761904761905,210,0.8333333333333334,8,0.38095238095238093,1,1,results
222,"As can be seen , with different templates given , our model is likely to generate dissimilar summaries .",Linguistic Quality Evaluation,Effect of Templates,text_summarization,5,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'O']",40,0.9523809523809523,221,0.876984126984127,19,0.9047619047619048,1,1,results
2,Deep Recurrent Generative Decoder for Abstractive Text Summarization,title,,text_summarization,6,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.5,1,0.003816793893129771,1,0.5,1,1,research-problem
11,Automatic summarization is the process of automatically generating a summary that retains the most important content of the original text document .,Introduction,Introduction,text_summarization,6,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.037037037037037035,10,0.03816793893129771,1,0.037037037037037035,1,1,research-problem
26,"To tackle the above mentioned problems , we design a new framework based on sequence to - sequence oriented encoder - decoder model equipped with a latent structure modeling component .",Introduction,Introduction,text_summarization,6,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.5925925925925926,25,0.09541984732824428,16,0.5925925925925926,1,1,model
27,We employ Variational Auto - Encoders ( VAEs ) as the base model for our generative framework which can handle the inference problem associated with complex generative modeling .,Introduction,Introduction,text_summarization,6,"['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.6296296296296297,26,0.09923664122137404,17,0.6296296296296297,1,1,model
29,"Inspired by , we add historical dependencies on the latent variables of VAEs and propose a deep recurrent generative decoder ( DRGD ) for latent structure modeling .",Introduction,Introduction,text_summarization,6,"['O', 'O', 'O', 'O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",19,0.7037037037037037,28,0.10687022900763359,19,0.7037037037037037,1,1,model
30,Then the standard discriminative deterministic decoder and the recurrent generative decoder are integrated into a unified decoding framework .,Introduction,Introduction,text_summarization,6,"['O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",20,0.7407407407407407,29,0.11068702290076336,20,0.7407407407407407,1,1,model
31,The target summaries will be decoded based on both the discriminative deterministic variables and the generative latent structural information .,Introduction,Introduction,text_summarization,6,"['O', 'B', 'I', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'B-p', 'I-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",21,0.7777777777777778,30,0.11450381679389313,21,0.7777777777777778,1,1,model
39,Automatic summarization is the process of automatically generating a summary that retains the most important content of the original text document .,Related Works,Related Works,text_summarization,6,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,1,0.014084507042253521,38,0.1450381679389313,1,0.05,0,1,research-problem
192,TOPIARY is the best on DUC2004 Task - 1 for compressive text summarization .,Comparative Methods,Comparative Methods,text_summarization,6,"['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O']","['B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O']",4,0.21052631578947367,191,0.7290076335877863,4,0.21052631578947367,1,1,baselines
193,It combines a system using linguistic based transformations and an unsupervised topic detection algorithm for compressive text summarization .,Comparative Methods,Comparative Methods,text_summarization,6,"['O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",5,0.2631578947368421,192,0.732824427480916,5,0.2631578947368421,1,1,baselines
194,MOSES + uses a phrasebased statistical machine translation system trained on Gigaword to produce summaries .,Comparative Methods,Comparative Methods,text_summarization,6,"['B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'B', 'I', 'B', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'B-p', 'I-p', 'B-n', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'O']",6,0.3157894736842105,193,0.7366412213740458,6,0.3157894736842105,1,1,baselines
196,ABS and ABS + are both the neural network based models with local attention modeling for abstractive sentence summarization .,Comparative Methods,Comparative Methods,text_summarization,6,"['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",8,0.42105263157894735,195,0.7442748091603053,8,0.42105263157894735,1,1,baselines
197,"ABS + is trained on the Gigaword corpus , but combined with an additional log - linear extractive summarization model with handcrafted features .",Comparative Methods,Comparative Methods,text_summarization,6,"['B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'O']","['B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",9,0.47368421052631576,196,0.7480916030534351,9,0.47368421052631576,1,1,baselines
198,RNN and RNN - context are two seq2seq architectures .,Comparative Methods,Comparative Methods,text_summarization,6,"['B', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.5263157894736842,197,0.7519083969465649,10,0.5263157894736842,1,1,baselines
200,Copy Net integrates a copying mechanism into the sequence - to sequence framework .,Comparative Methods,Comparative Methods,text_summarization,6,"['B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",12,0.631578947368421,199,0.7595419847328244,12,0.631578947368421,1,1,baselines
201,RNN - distract uses a new attention mechanism by distracting the historical attention in the decoding steps .,Comparative Methods,Comparative Methods,text_summarization,6,"['B', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",13,0.6842105263157895,200,0.7633587786259542,13,0.6842105263157895,1,1,baselines
202,RAS - LSTM and RAS - Elman both consider words and word positions as input and use convolutional encoders to handle the source information .,Comparative Methods,Comparative Methods,text_summarization,6,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'I', 'B', 'B', 'O', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'O', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'O', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",14,0.7368421052631579,201,0.767175572519084,14,0.7368421052631579,1,1,baselines
204,LenEmb uses a mechanism to control the summary length by considering the length embedding vector as the input .,Comparative Methods,Comparative Methods,text_summarization,6,"['B', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'O', 'B', 'O']","['B-n', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'O']","['B-b', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'O', 'B-ob', 'O']",16,0.8421052631578947,203,0.7748091603053435,16,0.8421052631578947,1,1,baselines
205,ASC+ FSC 1 ) uses a generative model with attention mechanism to conduct the sentence compression problem .,Comparative Methods,Comparative Methods,text_summarization,6,"['B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'O']","['B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O']",17,0.8947368421052632,204,0.7786259541984732,17,0.8947368421052632,1,1,baselines
207,lvt2k - 1sent and lvt5k - 1sent utilize a trick to control the vocabulary size to improve the training efficiency .,Comparative Methods,Comparative Methods,text_summarization,6,"['B', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",19,1.0,206,0.7862595419847328,19,1.0,1,1,baselines
209,"For the experiments on the English dataset Gigawords , we set the dimension of word embeddings to 300 , and the dimension of hidden states and latent variables to 500 .",Experimental Settings,Experimental Settings,text_summarization,6,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O']",,,1,0.05263157894736842,208,0.7938931297709924,1,0.05263157894736842,1,1,experimental-setup
210,The maximum length of documents and summaries is 100 and 50 respectively .,Experimental Settings,Experimental Settings,text_summarization,6,"['O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O']",2,0.10526315789473684,209,0.7977099236641222,2,0.10526315789473684,1,1,experimental-setup
211,The batch size of mini-batch training is 256 .,Experimental Settings,Experimental Settings,text_summarization,6,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'B', 'O']","['O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",3,0.15789473684210525,210,0.8015267175572519,3,0.15789473684210525,1,1,experimental-setup
212,"For DUC - 2004 , the maximum length of summaries is 75 bytes .",Experimental Settings,Experimental Settings,text_summarization,6,"['B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'B-p', 'B-n', 'I-n', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'B-p', 'B-ob', 'I-ob', 'O']",4,0.21052631578947367,211,0.8053435114503816,4,0.21052631578947367,1,1,experimental-setup
213,"For the dataset of LCSTS , the dimension of word embeddings is 350 .",Experimental Settings,Experimental Settings,text_summarization,6,"['O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'B', 'B', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O']",5,0.2631578947368421,212,0.8091603053435115,5,0.2631578947368421,1,1,experimental-setup
214,We also set the dimension of hidden states and latent variables to 500 .,Experimental Settings,Experimental Settings,text_summarization,6,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'B', 'O']",,,6,0.3157894736842105,213,0.8129770992366412,6,0.3157894736842105,1,1,experimental-setup
215,"The maximum length of documents and summaries is 120 and 25 respectively , and the batch size is also 256 .",Experimental Settings,Experimental Settings,text_summarization,6,"['O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.3684210526315789,214,0.816793893129771,7,0.3684210526315789,1,1,experimental-setup
216,The beam size of the decoder was set to be 10 .,Experimental Settings,Experimental Settings,text_summarization,6,"['O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",8,0.42105263157894735,215,0.8206106870229007,8,0.42105263157894735,1,1,experimental-setup
217,Adadelta with hyperparameter ? = 0.95 and = 1 e ? 6 is used for gradient based optimization .,Experimental Settings,Experimental Settings,text_summarization,6,"['B', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']","['B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['B-b', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",9,0.47368421052631576,216,0.8244274809160306,9,0.47368421052631576,1,1,experimental-setup
218,"Our neural network based framework is implemented using Theano ( Theano Development Team , 2016 ) .",Experimental Settings,Experimental Settings,text_summarization,6,"['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.5263157894736842,217,0.8282442748091603,10,0.5263157894736842,1,1,experimental-setup
229,ROUGE Evaluation,,,text_summarization,6,"['B', 'I']","['B-n', 'I-n']","['B-b', 'I-b']",0,0.0,228,0.8702290076335878,0,0.0,1,1,results
230,The results on the Chinese dataset LCSTS are shown in .,ROUGE Evaluation,ROUGE Evaluation,text_summarization,6,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O']",1,0.08333333333333333,229,0.8740458015267175,1,0.25,1,1,results
231,Our model DRGD also achieves the best performance .,ROUGE Evaluation,ROUGE Evaluation,text_summarization,6,"['B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'O']","['B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O']","['B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",2,0.16666666666666666,230,0.8778625954198473,2,0.5,1,1,results
2,Cutting - off Redundant Repeating Generations for Neural Abstractive Summarization,title,title,text_summarization,7,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob']",1,0.0,1,0.006622516556291391,1,0.0,1,1,research-problem
8,"The RNN - based encoder - decoder ( EncDec ) approach has recently been providing significant progress in various natural language generation ( NLG ) tasks , i.e. , machine translation ( MT ) and abstractive summarization ( ABS ) .",Introduction,Introduction,text_summarization,7,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",1,0.010416666666666666,7,0.046357615894039736,1,0.02564102564102564,1,1,research-problem
17,The basic idea of our method is to jointly estimate the upper-bound frequency of each target vocabulary that can occur in a summary during the encoding process and exploit the estimation to control the output words in each decoding step .,Introduction,Introduction,text_summarization,7,"['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O']",10,0.10416666666666667,16,0.10596026490066225,10,0.2564102564102564,1,1,model
18,We refer to our additional component as a wordfrequency estimation ( WFE ) sub-model .,Introduction,Introduction,text_summarization,7,"['O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.11458333333333333,17,0.11258278145695365,11,0.28205128205128205,1,1,model
19,The WFE sub-model explicitly manages how many times each word has been generated so far and might be generated in the future during the decoding process .,Introduction,Introduction,text_summarization,7,"['O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",12,0.125,18,0.11920529801324503,12,0.3076923076923077,1,1,model
2,Bottom - Up Abstractive Summarization,title,,text_summarization,8,"['O', 'O', 'O', 'B', 'I']","['O', 'O', 'O', 'B-n', 'I-n']","['O', 'O', 'O', 'B-ob', 'I-ob']",1,0.0,1,0.0034965034965034965,1,0.0,1,1,research-problem
11,Text summarization systems aim to generate natural language summaries that compress the information in a longer text .,Introduction,Introduction,text_summarization,8,"['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.1111111111111111,10,0.03496503496503497,1,0.1111111111111111,1,1,research-problem
13,Current state - of - the - art neural abstractive summarization models combine extractive and abstractive techniques by using pointergenerator style models which can copy words from the source document .,Introduction,Introduction,text_summarization,8,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",3,0.3333333333333333,12,0.04195804195804196,3,0.3333333333333333,1,1,research-problem
29,"Motivated by this approach , we consider bottom - up attention for neural abstractive summarization .",Baseline Approach,Bottom - Up Summarization,text_summarization,8,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",9,0.391304347826087,28,0.0979020979020979,9,0.391304347826087,1,1,approach
30,Our approach first selects a selection mask for the source document and then constrains a standard neural model by this mask .,Baseline Approach,Bottom - Up Summarization,text_summarization,8,"['O', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'O']","['O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'B-p', 'I-p', 'I-p', 'O']",10,0.43478260869565216,29,0.10139860139860139,10,0.43478260869565216,1,1,approach
33,Our full model incorporates a separate content selection system to decide on relevant aspects of the source document .,Baseline Approach,Bottom - Up Summarization,text_summarization,8,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",13,0.5652173913043478,32,0.11188811188811189,13,0.5652173913043478,1,1,approach
34,"We frame this selection task as a sequence - tagging problem , with the objective of identifying tokens from a document that are part of its summary .",Baseline Approach,Bottom - Up Summarization,text_summarization,8,"['O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'B', 'O']","['O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'O']","['O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'O']",14,0.6086956521739131,33,0.11538461538461539,14,0.6086956521739131,1,1,approach
36,"To incorporate bottom - up attention into abstractive summarization models , we employ masking to constrain copying words to the selected parts of the text , which produces grammatical outputs .",Baseline Approach,Bottom - Up Summarization,text_summarization,8,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'O']",16,0.6956521739130435,35,0.12237762237762238,16,0.6956521739130435,1,1,approach
186,All inference parameters are tuned on a 200 example subset of the validation set .,Data and Experiments,Data and Experiments,text_summarization,8,"['O', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",24,0.75,185,0.6468531468531469,24,0.75,1,1,experimental-setup
187,"Length penalty parameter ? and copy mask differ across models , with ? ranging from 0.6 to 1.4 , and ranging from 0.1 to 0.2 .",Data and Experiments,Data and Experiments,text_summarization,8,"['B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'O']",,,25,0.78125,186,0.6503496503496503,25,0.78125,1,1,experimental-setup
188,The minimum length of the generated summary is set to 35 for CNN - DM and 6 for NYT .,Data and Experiments,Data and Experiments,text_summarization,8,"['O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'B', 'O']",,,26,0.8125,187,0.6538461538461539,26,0.8125,1,1,experimental-setup
190,"The coverage penalty parameter ? is set to 10 , and the copy attention normalization parameter ? to 2 for both approaches .",Data and Experiments,Data and Experiments,text_summarization,8,"['O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'B-n', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'B-ob', 'O', 'O', 'O', 'O']",28,0.875,189,0.6608391608391608,28,0.875,1,1,experimental-setup
191,"We use AllenNLP for the content selector , and Open NMT - py for the abstractive models .",Data and Experiments,Data and Experiments,text_summarization,8,"['O', 'B', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'O']",,,29,0.90625,190,0.6643356643356644,29,0.90625,1,1,experimental-setup
192,"3 . shows our main results on the CNN - DM corpus , with abstractive models shown in the top , and bottom - up attention methods at the bottom .",Data and Experiments,Data and Experiments,text_summarization,8,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",30,0.9375,191,0.6678321678321678,30,0.9375,1,1,results
193,"We first observe that using a coverage inference penalty scores the same as a full coverage mechanism , without requiring any additional model parameters or model fine - tuning .",Data and Experiments,Data and Experiments,text_summarization,8,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",31,0.96875,192,0.6713286713286714,31,0.96875,1,1,results
194,"The results with the CopyTransformer and coverage penalty indicate a slight improvement across all three scores , but we observe no significant difference between Pointer - Generator and CopyTransformer with bottom - up attention .",Data and Experiments,Data and Experiments,text_summarization,8,"['O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",32,1.0,193,0.6748251748251748,32,1.0,1,1,results
2,Abstractive Sentence Summarization with Attentive Recurrent Neural Networks,title,,text_summarization,9,"['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O']",1,0.0,1,0.006535947712418301,1,0.0,1,1,research-problem
10,Generating a condensed version of a passage while preserving its meaning is known as text summarization .,Introduction,Introduction,text_summarization,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O']",1,0.03571428571428571,9,0.058823529411764705,1,0.05263157894736842,1,1,research-problem
16,"Inspired by the recently proposed architectures for machine translation , our model consists of a conditional recurrent neural network , which acts as a decoder to generate the summary of an input sentence , much like a standard recurrent language model .",Introduction,Introduction,text_summarization,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.25,15,0.09803921568627451,7,0.3684210526315789,1,1,model
17,"In addition , at every time step the decoder also takes a conditioning input which is the output of an encoder module .",Introduction,Introduction,text_summarization,9,"['O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'O', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O']",8,0.2857142857142857,16,0.10457516339869281,8,0.42105263157894735,1,1,model
18,"Depending on the current state of the RNN , the encoder computes scores over the words in the input sentence .",Introduction,Introduction,text_summarization,9,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'B', 'O', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",9,0.32142857142857145,17,0.1111111111111111,9,0.47368421052631576,1,1,model
20,Both the decoder and encoder are jointly trained on a data set consisting of sentence - summary pairs .,Introduction,Introduction,text_summarization,9,"['O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",11,0.39285714285714285,19,0.12418300653594772,11,0.5789473684210527,1,1,model
24,"Lastly , our encoder uses a convolutional network to encode input words .",Introduction,Introduction,text_summarization,9,"['O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",15,0.5357142857142857,23,0.1503267973856209,15,0.7894736842105263,1,1,model
96,We implemented our models in the Torch library ( http://torch.ch/),Datasets and Evaluation,Architectural Choices,text_summarization,9,"['O', 'B', 'B', 'I', 'B', 'O', 'B', 'I', 'O', 'O']","['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'O']","['O', 'B-p', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'O']",8,0.47058823529411764,95,0.6209150326797386,1,0.1,1,1,experimental-setup
97,2 . To optimize our loss ( Equation 5 ) we used stochastic gradient descent with mini-batches of size 32 .,Datasets and Evaluation,Architectural Choices,text_summarization,9,"['O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'B', 'O']","['O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'I-p', 'B-n', 'O']","['O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-b', 'B-p', 'I-p', 'B-ob', 'O']",9,0.5294117647058824,96,0.6274509803921569,2,0.2,1,1,experimental-setup
98,"During training we measure the perplexity of the summaries in the validation set and adjust our hyper - parameters , such as the learning rate , based on this number .",Datasets and Evaluation,Architectural Choices,text_summarization,9,"['B', 'B', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",10,0.5882352941176471,97,0.6339869281045751,3,0.3,1,1,experimental-setup
99,For the decoder we experimented with both the Elman RNN and the Long - Short Term Memory ( LSTM ) architecture ( as discussed in 3.1 ) .,Datasets and Evaluation,Architectural Choices,text_summarization,9,"['B', 'O', 'B', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-n', 'O', 'B-p', 'I-p', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'B-b', 'O', 'B-p', 'I-p', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",11,0.6470588235294118,98,0.6405228758169934,4,0.4,1,1,experimental-setup
100,We chose hyper - parameters based on a grid search and picked the one which gave the best perplexity on the validation set .,Datasets and Evaluation,Architectural Choices,text_summarization,9,"['O', 'B', 'B', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'O', 'B', 'I', 'O']","['O', 'B-p', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'O']","['O', 'B-p', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'B-p', 'O', 'B-ob', 'I-ob', 'O']",12,0.7058823529411765,99,0.6470588235294118,5,0.5,1,1,experimental-setup
104,"Our final Elman architecture ( RAS - Elman ) uses a single layer with H = 512 , ? = 0.5 , ? = 2 , and ? = 10 . ",Datasets and Evaluation,Architectural Choices,text_summarization,9,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']",,,16,0.9411764705882353,103,0.673202614379085,9,0.9,1,1,
105,"The LSTM model ( RAS - LSTM ) also has a single layer with H = 512 , ? = 0.1 , ? = 2 , and ? = 10 .",Datasets and Evaluation,Architectural Choices,text_summarization,9,"['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'O', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,1.0,104,0.6797385620915033,10,1.0,1,1,experimental-setup
112,shows that both our RAS - Elman and RAS - LSTM models achieve lower perplexity than ABS as well as other models reported in .,Results,Results,text_summarization,9,"['B', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'B-p', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",6,0.14285714285714285,111,0.7254901960784313,6,0.14285714285714285,1,1,results
113,"The RAS - LSTM performs slightly worse than RAS - Elman , most likely due to over-fitting .",Results,Results,text_summarization,9,"['O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",7,0.16666666666666666,112,0.7320261437908496,7,0.16666666666666666,1,1,results
115,The ROUGE results show that our models comfortably outperform both ABS and ABS + by a wide margin on all metrics .,Results,Results,text_summarization,9,"['O', 'B', 'I', 'B', 'O', 'B', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'O']","['O', 'B-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'O']",9,0.21428571428571427,114,0.7450980392156863,9,0.21428571428571427,1,1,results
118,On DUC - 2004 we report recall ROUGE as is customary on this dataset .,Results,Results,text_summarization,9,"['B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",12,0.2857142857142857,117,0.7647058823529411,12,0.2857142857142857,1,1,results
119,The results ( Table 3 ) show that our models are better than ABS + .,Results,Results,text_summarization,9,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'O']",13,0.30952380952380953,118,0.7712418300653595,13,0.30952380952380953,1,1,results
2,Learning document embeddings along with their uncertainties,title,,topic_models,0,"['B', 'I', 'I', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O']",1,0.0,1,0.0024271844660194173,1,0.0,1,1,research-problem
8,We also present a generative Gaussian linear classifier for topic identification that exploits the uncertainty in document embeddings .,abstract,abstract,topic_models,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",5,0.2631578947368421,7,0.01699029126213592,5,0.2631578947368421,1,1,research-problem
18,We also present a generative Gaussian linear classifier for topic identification that exploits the uncertainty in document embeddings .,abstract,abstract,topic_models,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",,,15,0.7894736842105263,17,0.0412621359223301,15,0.7894736842105263,1,1,research-problem
24,"L EARNING word and document embeddings have proven to be useful in wide range of information retrieval , speech and natural language processing applications -.",I. INTRODUCTION,I. INTRODUCTION,topic_models,0,"['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",1,0.011904761904761904,23,0.055825242718446605,1,0.011904761904761904,1,1,research-problem
38,"In this paper , we present Bayesian subspace multinomial model ( Bayesian SMM ) as a generative model for bag - ofwords representation of documents .",I. INTRODUCTION,I. INTRODUCTION,topic_models,0,"['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'I-p', 'B-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'I-p', 'B-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",15,0.17857142857142858,37,0.08980582524271845,15,0.17857142857142858,1,1,model
39,"We show that our model can learn to represent each document in the form of a Gaussian distribution , thereby encoding the uncertainty in its covariance .",I. INTRODUCTION,I. INTRODUCTION,topic_models,0,"['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-n', 'I-n', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'I-p', 'I-p', 'B-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'O', 'B-b', 'I-b', 'O', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",16,0.19047619047619047,38,0.09223300970873786,16,0.19047619047619047,1,1,model
40,"Further , we propose a generative Gaussian classifier that exploits this uncertainty for topic identification ( ID ) .",I. INTRODUCTION,I. INTRODUCTION,topic_models,0,"['O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'O', 'B-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",17,0.20238095238095238,39,0.09466019417475728,17,0.20238095238095238,1,1,model
41,"The proposed VB framework can be extended in a straightforward way for subspace n-gram model , that can model n-gram distribution of words in sentences .",I. INTRODUCTION,I. INTRODUCTION,topic_models,0,"['O', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'O', 'O', 'O', 'O', 'B-p', 'B-b', 'I-b', 'I-b', 'O', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.21428571428571427,40,0.0970873786407767,18,0.21428571428571427,1,1,model
274,"The embedding dimension was chosen from K = { 100 , . . . , 800 } , and regularization weight from ? = { 0.0001 , . . . , 10.0 }.",Neural network based models,The average document length is 290 words .,topic_models,0,"['O', 'B', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'B-n', 'I-n', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'B-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'B-b', 'I-b', 'B-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",32,0.2782608695652174,273,0.662621359223301,24,1.0,1,1,hyperparameters
285,"1 ) NVDM : Since NVDM and our proposed Bayesian SMM share similarities , we chose to extract the embeddings from NVDM and use them for training linear classifiers .",Neural network based models,D. Baseline topic ID systems,topic_models,0,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'O']",43,0.3739130434782609,284,0.6893203883495146,10,0.23809523809523808,1,1,baselines
293,"2 ) SMM : Our second baseline system is non-Bayesian SMM with 1 regularization over the rows in T matrix , i.e. , 1 SMM .",Neural network based models,D. Baseline topic ID systems,topic_models,0,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O']",51,0.4434782608695652,292,0.7087378640776699,18,0.42857142857142855,1,1,baselines
299,3 ) ULMFiT : The third baseline system is the universal language model fine - tuned for classification ( ULMFiT ) .,Neural network based models,D. Baseline topic ID systems,topic_models,0,"['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'O']","['O', 'O', 'B-n', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'I-p', 'I-p', 'I-p', 'B-n', 'O', 'O', 'O', 'O']","['O', 'O', 'B-b', 'O', 'O', 'O', 'O', 'O', 'B-p', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'I-p', 'I-p', 'I-p', 'B-ob', 'O', 'O', 'O', 'O']",57,0.4956521739130435,298,0.7233009708737864,24,0.5714285714285714,1,1,baselines
306,4 ) TF - IDF :,Neural network based models,D. Baseline topic ID systems,topic_models,0,"['O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'B-b', 'I-b', 'I-b', 'O']",64,0.5565217391304348,305,0.7402912621359223,31,0.7380952380952381,1,1,baselines
307,"The fourth baseline system is a standard term frequency - inverse document frequency ( TF - IDF ) based document representation , followed by multi-class logistic regression ( LR ) .",Neural network based models,D. Baseline topic ID systems,topic_models,0,"['O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",65,0.5652173913043478,306,0.7427184466019418,32,0.7619047619047619,1,1,baselines
362,"presents the classification results on Fisher speech corpora with manual and automatic transcriptions , where the first two rows are the results from earlier published works .",D. Topic ID results,D. Topic ID results,topic_models,0,"['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",4,0.0784313725490196,361,0.8762135922330098,4,0.2,1,1,results
367,"We can see that our proposed systems achieve consistently better accuracies ; notably , GLCU which exploits the uncertainty in document embeddings has much lower cross - entropy than its counterpart , GLC .",D. Topic ID results,D. Topic ID results,topic_models,0,"['O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'O', 'O', 'O', 'B', 'O']","['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O', 'B-n', 'O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'B-p', 'O', 'O', 'O', 'B-n', 'O']","['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'B-p', 'B-ob', 'I-ob', 'I-ob', 'O', 'O', 'O', 'B-b', 'O', 'B-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'B-p', 'O', 'O', 'O', 'B-ob', 'O']",9,0.17647058823529413,366,0.8883495145631068,9,0.45,1,1,results
370,presents classification results on 20 Newsgroups dataset .,D. Topic ID results,D. Topic ID results,topic_models,0,"['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O']",12,0.23529411764705882,369,0.8956310679611651,12,0.6,1,1,results
376,"We see that the topic ID systems based on Bayesian SMM and logistic regression is better than all the other models , except for the purely discriminative CNN model .",D. Topic ID results,D. Topic ID results,topic_models,0,"['O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O']","['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'O', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",18,0.35294117647058826,375,0.9101941747572816,18,0.9,1,1,results
377,"We can also see that all the topic ID systems based on Bayesian SMM are consistently better than variational auto encoder inspired NVDM , and ( non-Bayesian ) SMM .",D. Topic ID results,D. Topic ID results,topic_models,0,"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O', 'B-p', 'I-p', 'I-p', 'B-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'I-n', 'O']","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'I-b', 'O', 'B-p', 'I-p', 'I-p', 'B-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'I-ob', 'O']",19,0.37254901960784315,376,0.912621359223301,19,0.95,1,1,results
